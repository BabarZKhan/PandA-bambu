; ModuleID = 'fused_nn_contrib_conv2d_NCHWc_add_1'
source_filename = "fused_nn_contrib_conv2d_NCHWc_add_1"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

%0 = type { i32*, i32 }
%1 = type { i8*, %2, i32, %3, i64*, i64*, i64 }
%2 = type { i32, i32 }
%3 = type { i8, i8, i16 }
%4 = type { i8*, i8*, i8*, i8*, i32 }
%5 = type { i8*, i8* }
%6 = type { i8*, i8* }
%7 = type { i8*, i8* }
%8 = type { i8*, i8*, i8*, i8*, i32 }
%9 = type { i8*, i8* }
%10 = type { i8*, i8*, i8*, i8* }
%11 = type { i8*, i8* }
%12 = type { i8*, i8* }
%13 = type { i8*, i8* }
%14 = type { i8*, i8* }
%15 = type { i8*, i8*, i8*, i8*, i8* }
%16 = type { i8*, i8* }
%17 = type { i8*, i8* }
%18 = type { i8*, i8* }
%19 = type { i8*, i8* }
%20 = type { i8*, i8*, i8*, i8* }
%21 = type { i8*, i8* }
%22 = type { i8*, i8*, i8*, i8*, i32 }
%23 = type { i8*, i8* }
%24 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%25 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%26 = type { i8*, i8*, i8* }
%27 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%28 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8* }
%29 = type { i8*, i8* }
%30 = type { i8*, i8* }
%31 = type { i8*, i8*, i8*, i8* }
%32 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%33 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%34 = type { i8*, i8* }
%35 = type { i8*, i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%36 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%37 = type { i8*, i8* }
%38 = type { i8*, i8*, i8*, i8*, i32 }
%39 = type { i8*, i8*, i8*, i8*, i32 }
%40 = type { i8*, i8* }
%41 = type { i8*, i8*, i8*, i8*, i8*, i32 }
%42 = type { i8*, i8* }
%43 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%44 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%45 = type { i8*, i8* }
%46 = type { i8*, i8* }
%47 = type { i8*, i8* }
%48 = type { i8*, i8*, i8*, i8*, i8*, i8*, i32 }
%49 = type { i8*, i8*, i8*, i8*, i8* }
%50 = type { i8*, i8* }
%51 = type { i8*, i8*, i8*, i8*, i32 }
%52 = type { i8*, i8* }
%53 = type { i8*, i8* }

@__TVMBackendParallelLaunch = linkonce dllexport local_unnamed_addr global i32 (i32 (i32, %0*, i8*)*, i8*, i32)* null, align 8
@__TVMBackendAllocWorkspace = linkonce dllexport local_unnamed_addr global i8* (i32, i32, i64, i32, i32)* null, align 8
@__TVMBackendFreeWorkspace = linkonce dllexport local_unnamed_addr global i32 (i32, i32, i8*)* null, align 8
@__tvm_main__ = weak local_unnamed_addr constant [36 x i8] c"fused_nn_contrib_conv2d_NCHWc_add_1\00", align 1

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_1(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !5 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !12, metadata !DIExpression()), !dbg !15
  call void @llvm.dbg.value(metadata i8* %1, metadata !13, metadata !DIExpression()), !dbg !15
  call void @llvm.dbg.value(metadata i32 %2, metadata !14, metadata !DIExpression()), !dbg !15
  %3 = bitcast i8* %0 to %1**, !dbg !15
  %4 = load %1*, %1** %3, align 8, !dbg !15
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !15
  %6 = bitcast i8* %5 to %1**, !dbg !15
  %7 = load %1*, %1** %6, align 8, !dbg !15
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !15
  %9 = bitcast i8* %8 to %1**, !dbg !15
  %10 = load %1*, %1** %9, align 8, !dbg !15
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !15
  %12 = bitcast i8* %11 to %1**, !dbg !15
  %13 = load %1*, %1** %12, align 8, !dbg !15
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !15
  %15 = load i8*, i8** %14, align 8, !dbg !15
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !15
  %17 = load i32, i32* %16, align 4, !dbg !15
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !15
  %19 = load i8*, i8** %18, align 8, !dbg !15
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !15
  %21 = load i8*, i8** %20, align 8, !dbg !15
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !15
  %23 = load i8*, i8** %22, align 8, !dbg !15
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_1_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !15
  ret i32 %24, !dbg !15
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = alloca %4, align 8
  %6 = getelementptr inbounds %4, %4* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %4, %4* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %4, %4* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %4, %4* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %4, %4* %5, i64 0, i32 4
  store i32 %4, i32* %10, align 8
  %11 = bitcast %4* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda, i8* nonnull %11, i32 0)
  ret i32 %13
}

define private i32 @__tvm_parallel_lambda(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 223
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 224
  %24 = select i1 %23, i32 %22, i32 224
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 224
  %27 = select i1 %26, i32 %25, i32 224
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.6
  %indvars.iv33 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next34, %for_end6.6 ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %34 = tail call i8* %33(i32 1, i32 %16, i64 7168, i32 2, i32 32)
  %35 = trunc i64 %indvars.iv33 to i32
  %36 = srem i32 %35, 28
  %37 = mul nsw i32 %36, 28672
  %38 = sdiv i32 %35, 28
  %39 = shl i32 %38, 14
  %40 = sext i32 %39 to i64
  %41 = sext i32 %37 to i64
  %42 = bitcast i8* %34 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %42, align 64, !tbaa !20
  %43 = getelementptr inbounds i8, i8* %34, i64 256
  %44 = bitcast i8* %43 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %44, align 64, !tbaa !20
  %45 = getelementptr inbounds i8, i8* %34, i64 512
  %46 = bitcast i8* %45 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %46, align 64, !tbaa !20
  %47 = getelementptr inbounds i8, i8* %34, i64 768
  %48 = bitcast i8* %47 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %48, align 64, !tbaa !20
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %49 = phi <64 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %50 = phi <64 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %51 = phi <64 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %52 = phi <64 x float> [ zeroinitializer, %for_body ], [ %63, %for_body5 ]
  %53 = add nsw i64 %indvars.iv, %41
  %54 = getelementptr inbounds float, float* %4, i64 %53
  %55 = load float, float* %54, align 4, !tbaa !23
  %56 = insertelement <64 x float> undef, float %55, i32 0
  %57 = shufflevector <64 x float> %56, <64 x float> undef, <64 x i32> zeroinitializer
  %58 = shl i64 %indvars.iv, 6
  %59 = add nuw nsw i64 %58, %40
  %60 = getelementptr inbounds float, float* %7, i64 %59
  %61 = bitcast float* %60 to <64 x float>*
  %62 = load <64 x float>, <64 x float>* %61, align 64, !tbaa !26
  %63 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %57, <64 x float> %62, <64 x float> %52)
  %64 = add nsw i64 %53, 512
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !23
  %67 = insertelement <64 x float> undef, float %66, i32 0
  %68 = shufflevector <64 x float> %67, <64 x float> undef, <64 x i32> zeroinitializer
  %69 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %68, <64 x float> %62, <64 x float> %51)
  %70 = add nsw i64 %53, 1024
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !23
  %73 = insertelement <64 x float> undef, float %72, i32 0
  %74 = shufflevector <64 x float> %73, <64 x float> undef, <64 x i32> zeroinitializer
  %75 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %74, <64 x float> %62, <64 x float> %50)
  %76 = add nsw i64 %53, 1536
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !23
  %79 = insertelement <64 x float> undef, float %78, i32 0
  %80 = shufflevector <64 x float> %79, <64 x float> undef, <64 x i32> zeroinitializer
  %81 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %80, <64 x float> %62, <64 x float> %49)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <64 x float> %63, <64 x float>* %42, align 64, !tbaa !20
  store <64 x float> %69, <64 x float>* %44, align 64, !tbaa !20
  store <64 x float> %75, <64 x float>* %46, align 64, !tbaa !20
  store <64 x float> %81, <64 x float>* %48, align 64, !tbaa !20
  %82 = getelementptr inbounds i8, i8* %34, i64 1024
  %83 = bitcast i8* %82 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %83, align 64, !tbaa !20
  %84 = getelementptr inbounds i8, i8* %34, i64 1280
  %85 = bitcast i8* %84 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %85, align 64, !tbaa !20
  %86 = getelementptr inbounds i8, i8* %34, i64 1536
  %87 = bitcast i8* %86 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %87, align 64, !tbaa !20
  %88 = getelementptr inbounds i8, i8* %34, i64 1792
  %89 = bitcast i8* %88 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %89, align 64, !tbaa !20
  %90 = or i64 %41, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %91 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %123, %for_body5.1 ]
  %92 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %117, %for_body5.1 ]
  %93 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %111, %for_body5.1 ]
  %94 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %105, %for_body5.1 ]
  %95 = add nsw i64 %90, %indvars.iv.1
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !23
  %98 = insertelement <64 x float> undef, float %97, i32 0
  %99 = shufflevector <64 x float> %98, <64 x float> undef, <64 x i32> zeroinitializer
  %100 = shl i64 %indvars.iv.1, 6
  %101 = add nuw nsw i64 %100, %40
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = bitcast float* %102 to <64 x float>*
  %104 = load <64 x float>, <64 x float>* %103, align 64, !tbaa !26
  %105 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %99, <64 x float> %104, <64 x float> %94)
  %106 = add nsw i64 %95, 512
  %107 = getelementptr inbounds float, float* %4, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !23
  %109 = insertelement <64 x float> undef, float %108, i32 0
  %110 = shufflevector <64 x float> %109, <64 x float> undef, <64 x i32> zeroinitializer
  %111 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %110, <64 x float> %104, <64 x float> %93)
  %112 = add nsw i64 %95, 1024
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = load float, float* %113, align 4, !tbaa !23
  %115 = insertelement <64 x float> undef, float %114, i32 0
  %116 = shufflevector <64 x float> %115, <64 x float> undef, <64 x i32> zeroinitializer
  %117 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %116, <64 x float> %104, <64 x float> %92)
  %118 = add nsw i64 %95, 1536
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = load float, float* %119, align 4, !tbaa !23
  %121 = insertelement <64 x float> undef, float %120, i32 0
  %122 = shufflevector <64 x float> %121, <64 x float> undef, <64 x i32> zeroinitializer
  %123 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %122, <64 x float> %104, <64 x float> %91)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %105, <64 x float>* %83, align 64, !tbaa !20
  store <64 x float> %111, <64 x float>* %85, align 64, !tbaa !20
  store <64 x float> %117, <64 x float>* %87, align 64, !tbaa !20
  store <64 x float> %123, <64 x float>* %89, align 64, !tbaa !20
  %124 = getelementptr inbounds i8, i8* %34, i64 2048
  %125 = bitcast i8* %124 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %125, align 64, !tbaa !20
  %126 = getelementptr inbounds i8, i8* %34, i64 2304
  %127 = bitcast i8* %126 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %127, align 64, !tbaa !20
  %128 = getelementptr inbounds i8, i8* %34, i64 2560
  %129 = bitcast i8* %128 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %129, align 64, !tbaa !20
  %130 = getelementptr inbounds i8, i8* %34, i64 2816
  %131 = bitcast i8* %130 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %131, align 64, !tbaa !20
  %132 = add nsw i64 %41, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %133 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %165, %for_body5.2 ]
  %134 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %159, %for_body5.2 ]
  %135 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %153, %for_body5.2 ]
  %136 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %147, %for_body5.2 ]
  %137 = add nsw i64 %132, %indvars.iv.2
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !23
  %140 = insertelement <64 x float> undef, float %139, i32 0
  %141 = shufflevector <64 x float> %140, <64 x float> undef, <64 x i32> zeroinitializer
  %142 = shl i64 %indvars.iv.2, 6
  %143 = add nuw nsw i64 %142, %40
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <64 x float>*
  %146 = load <64 x float>, <64 x float>* %145, align 64, !tbaa !26
  %147 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %141, <64 x float> %146, <64 x float> %136)
  %148 = add nsw i64 %137, 512
  %149 = getelementptr inbounds float, float* %4, i64 %148
  %150 = load float, float* %149, align 4, !tbaa !23
  %151 = insertelement <64 x float> undef, float %150, i32 0
  %152 = shufflevector <64 x float> %151, <64 x float> undef, <64 x i32> zeroinitializer
  %153 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %152, <64 x float> %146, <64 x float> %135)
  %154 = add nsw i64 %137, 1024
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !23
  %157 = insertelement <64 x float> undef, float %156, i32 0
  %158 = shufflevector <64 x float> %157, <64 x float> undef, <64 x i32> zeroinitializer
  %159 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %158, <64 x float> %146, <64 x float> %134)
  %160 = add nsw i64 %137, 1536
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !23
  %163 = insertelement <64 x float> undef, float %162, i32 0
  %164 = shufflevector <64 x float> %163, <64 x float> undef, <64 x i32> zeroinitializer
  %165 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %164, <64 x float> %146, <64 x float> %133)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %147, <64 x float>* %125, align 64, !tbaa !20
  store <64 x float> %153, <64 x float>* %127, align 64, !tbaa !20
  store <64 x float> %159, <64 x float>* %129, align 64, !tbaa !20
  store <64 x float> %165, <64 x float>* %131, align 64, !tbaa !20
  %166 = getelementptr inbounds i8, i8* %34, i64 3072
  %167 = bitcast i8* %166 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %167, align 64, !tbaa !20
  %168 = getelementptr inbounds i8, i8* %34, i64 3328
  %169 = bitcast i8* %168 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %169, align 64, !tbaa !20
  %170 = getelementptr inbounds i8, i8* %34, i64 3584
  %171 = bitcast i8* %170 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %171, align 64, !tbaa !20
  %172 = getelementptr inbounds i8, i8* %34, i64 3840
  %173 = bitcast i8* %172 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %173, align 64, !tbaa !20
  %174 = add nsw i64 %41, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %175 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %207, %for_body5.3 ]
  %176 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %201, %for_body5.3 ]
  %177 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %195, %for_body5.3 ]
  %178 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %189, %for_body5.3 ]
  %179 = add nsw i64 %174, %indvars.iv.3
  %180 = getelementptr inbounds float, float* %4, i64 %179
  %181 = load float, float* %180, align 4, !tbaa !23
  %182 = insertelement <64 x float> undef, float %181, i32 0
  %183 = shufflevector <64 x float> %182, <64 x float> undef, <64 x i32> zeroinitializer
  %184 = shl i64 %indvars.iv.3, 6
  %185 = add nuw nsw i64 %184, %40
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = bitcast float* %186 to <64 x float>*
  %188 = load <64 x float>, <64 x float>* %187, align 64, !tbaa !26
  %189 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %183, <64 x float> %188, <64 x float> %178)
  %190 = add nsw i64 %179, 512
  %191 = getelementptr inbounds float, float* %4, i64 %190
  %192 = load float, float* %191, align 4, !tbaa !23
  %193 = insertelement <64 x float> undef, float %192, i32 0
  %194 = shufflevector <64 x float> %193, <64 x float> undef, <64 x i32> zeroinitializer
  %195 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %194, <64 x float> %188, <64 x float> %177)
  %196 = add nsw i64 %179, 1024
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !23
  %199 = insertelement <64 x float> undef, float %198, i32 0
  %200 = shufflevector <64 x float> %199, <64 x float> undef, <64 x i32> zeroinitializer
  %201 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %200, <64 x float> %188, <64 x float> %176)
  %202 = add nsw i64 %179, 1536
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !23
  %205 = insertelement <64 x float> undef, float %204, i32 0
  %206 = shufflevector <64 x float> %205, <64 x float> undef, <64 x i32> zeroinitializer
  %207 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %206, <64 x float> %188, <64 x float> %175)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %189, <64 x float>* %167, align 64, !tbaa !20
  store <64 x float> %195, <64 x float>* %169, align 64, !tbaa !20
  store <64 x float> %201, <64 x float>* %171, align 64, !tbaa !20
  store <64 x float> %207, <64 x float>* %173, align 64, !tbaa !20
  %208 = getelementptr inbounds i8, i8* %34, i64 4096
  %209 = bitcast i8* %208 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %209, align 64, !tbaa !20
  %210 = getelementptr inbounds i8, i8* %34, i64 4352
  %211 = bitcast i8* %210 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %211, align 64, !tbaa !20
  %212 = getelementptr inbounds i8, i8* %34, i64 4608
  %213 = bitcast i8* %212 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %213, align 64, !tbaa !20
  %214 = getelementptr inbounds i8, i8* %34, i64 4864
  %215 = bitcast i8* %214 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %215, align 64, !tbaa !20
  %216 = add nsw i64 %41, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %217 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %249, %for_body5.4 ]
  %218 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %243, %for_body5.4 ]
  %219 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %237, %for_body5.4 ]
  %220 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %231, %for_body5.4 ]
  %221 = add nsw i64 %216, %indvars.iv.4
  %222 = getelementptr inbounds float, float* %4, i64 %221
  %223 = load float, float* %222, align 4, !tbaa !23
  %224 = insertelement <64 x float> undef, float %223, i32 0
  %225 = shufflevector <64 x float> %224, <64 x float> undef, <64 x i32> zeroinitializer
  %226 = shl i64 %indvars.iv.4, 6
  %227 = add nuw nsw i64 %226, %40
  %228 = getelementptr inbounds float, float* %7, i64 %227
  %229 = bitcast float* %228 to <64 x float>*
  %230 = load <64 x float>, <64 x float>* %229, align 64, !tbaa !26
  %231 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %225, <64 x float> %230, <64 x float> %220)
  %232 = add nsw i64 %221, 512
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !23
  %235 = insertelement <64 x float> undef, float %234, i32 0
  %236 = shufflevector <64 x float> %235, <64 x float> undef, <64 x i32> zeroinitializer
  %237 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %236, <64 x float> %230, <64 x float> %219)
  %238 = add nsw i64 %221, 1024
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !23
  %241 = insertelement <64 x float> undef, float %240, i32 0
  %242 = shufflevector <64 x float> %241, <64 x float> undef, <64 x i32> zeroinitializer
  %243 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %242, <64 x float> %230, <64 x float> %218)
  %244 = add nsw i64 %221, 1536
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !23
  %247 = insertelement <64 x float> undef, float %246, i32 0
  %248 = shufflevector <64 x float> %247, <64 x float> undef, <64 x i32> zeroinitializer
  %249 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %248, <64 x float> %230, <64 x float> %217)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 256
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %231, <64 x float>* %209, align 64, !tbaa !20
  store <64 x float> %237, <64 x float>* %211, align 64, !tbaa !20
  store <64 x float> %243, <64 x float>* %213, align 64, !tbaa !20
  store <64 x float> %249, <64 x float>* %215, align 64, !tbaa !20
  %250 = getelementptr inbounds i8, i8* %34, i64 5120
  %251 = bitcast i8* %250 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %251, align 64, !tbaa !20
  %252 = getelementptr inbounds i8, i8* %34, i64 5376
  %253 = bitcast i8* %252 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %253, align 64, !tbaa !20
  %254 = getelementptr inbounds i8, i8* %34, i64 5632
  %255 = bitcast i8* %254 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %255, align 64, !tbaa !20
  %256 = getelementptr inbounds i8, i8* %34, i64 5888
  %257 = bitcast i8* %256 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %257, align 64, !tbaa !20
  %258 = add nsw i64 %41, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %259 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %291, %for_body5.5 ]
  %260 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %285, %for_body5.5 ]
  %261 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %279, %for_body5.5 ]
  %262 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %273, %for_body5.5 ]
  %263 = add nsw i64 %258, %indvars.iv.5
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !23
  %266 = insertelement <64 x float> undef, float %265, i32 0
  %267 = shufflevector <64 x float> %266, <64 x float> undef, <64 x i32> zeroinitializer
  %268 = shl i64 %indvars.iv.5, 6
  %269 = add nuw nsw i64 %268, %40
  %270 = getelementptr inbounds float, float* %7, i64 %269
  %271 = bitcast float* %270 to <64 x float>*
  %272 = load <64 x float>, <64 x float>* %271, align 64, !tbaa !26
  %273 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %267, <64 x float> %272, <64 x float> %262)
  %274 = add nsw i64 %263, 512
  %275 = getelementptr inbounds float, float* %4, i64 %274
  %276 = load float, float* %275, align 4, !tbaa !23
  %277 = insertelement <64 x float> undef, float %276, i32 0
  %278 = shufflevector <64 x float> %277, <64 x float> undef, <64 x i32> zeroinitializer
  %279 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %278, <64 x float> %272, <64 x float> %261)
  %280 = add nsw i64 %263, 1024
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !23
  %283 = insertelement <64 x float> undef, float %282, i32 0
  %284 = shufflevector <64 x float> %283, <64 x float> undef, <64 x i32> zeroinitializer
  %285 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %284, <64 x float> %272, <64 x float> %260)
  %286 = add nsw i64 %263, 1536
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !23
  %289 = insertelement <64 x float> undef, float %288, i32 0
  %290 = shufflevector <64 x float> %289, <64 x float> undef, <64 x i32> zeroinitializer
  %291 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %290, <64 x float> %272, <64 x float> %259)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 256
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %273, <64 x float>* %251, align 64, !tbaa !20
  store <64 x float> %279, <64 x float>* %253, align 64, !tbaa !20
  store <64 x float> %285, <64 x float>* %255, align 64, !tbaa !20
  store <64 x float> %291, <64 x float>* %257, align 64, !tbaa !20
  %292 = getelementptr inbounds i8, i8* %34, i64 6144
  %293 = bitcast i8* %292 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %293, align 64, !tbaa !20
  %294 = getelementptr inbounds i8, i8* %34, i64 6400
  %295 = bitcast i8* %294 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %295, align 64, !tbaa !20
  %296 = getelementptr inbounds i8, i8* %34, i64 6656
  %297 = bitcast i8* %296 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %297, align 64, !tbaa !20
  %298 = getelementptr inbounds i8, i8* %34, i64 6912
  %299 = bitcast i8* %298 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %299, align 64, !tbaa !20
  %300 = add nsw i64 %41, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %301 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %333, %for_body5.6 ]
  %302 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %327, %for_body5.6 ]
  %303 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %321, %for_body5.6 ]
  %304 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %315, %for_body5.6 ]
  %305 = add nsw i64 %300, %indvars.iv.6
  %306 = getelementptr inbounds float, float* %4, i64 %305
  %307 = load float, float* %306, align 4, !tbaa !23
  %308 = insertelement <64 x float> undef, float %307, i32 0
  %309 = shufflevector <64 x float> %308, <64 x float> undef, <64 x i32> zeroinitializer
  %310 = shl i64 %indvars.iv.6, 6
  %311 = add nuw nsw i64 %310, %40
  %312 = getelementptr inbounds float, float* %7, i64 %311
  %313 = bitcast float* %312 to <64 x float>*
  %314 = load <64 x float>, <64 x float>* %313, align 64, !tbaa !26
  %315 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %309, <64 x float> %314, <64 x float> %304)
  %316 = add nsw i64 %305, 512
  %317 = getelementptr inbounds float, float* %4, i64 %316
  %318 = load float, float* %317, align 4, !tbaa !23
  %319 = insertelement <64 x float> undef, float %318, i32 0
  %320 = shufflevector <64 x float> %319, <64 x float> undef, <64 x i32> zeroinitializer
  %321 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %320, <64 x float> %314, <64 x float> %303)
  %322 = add nsw i64 %305, 1024
  %323 = getelementptr inbounds float, float* %4, i64 %322
  %324 = load float, float* %323, align 4, !tbaa !23
  %325 = insertelement <64 x float> undef, float %324, i32 0
  %326 = shufflevector <64 x float> %325, <64 x float> undef, <64 x i32> zeroinitializer
  %327 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %326, <64 x float> %314, <64 x float> %302)
  %328 = add nsw i64 %305, 1536
  %329 = getelementptr inbounds float, float* %4, i64 %328
  %330 = load float, float* %329, align 4, !tbaa !23
  %331 = insertelement <64 x float> undef, float %330, i32 0
  %332 = shufflevector <64 x float> %331, <64 x float> undef, <64 x i32> zeroinitializer
  %333 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %332, <64 x float> %314, <64 x float> %301)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 256
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %315, <64 x float>* %293, align 64, !tbaa !20
  store <64 x float> %321, <64 x float>* %295, align 64, !tbaa !20
  store <64 x float> %327, <64 x float>* %297, align 64, !tbaa !20
  store <64 x float> %333, <64 x float>* %299, align 64, !tbaa !20
  %334 = mul nsw i64 %indvars.iv33, 1792
  %335 = shl nsw i32 %38, 6
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds float, float* %13, i64 %336
  %338 = bitcast float* %337 to <64 x float>*
  %339 = load <64 x float>, <64 x float>* %338, align 64, !tbaa !30
  %340 = bitcast i8* %34 to <64 x float>*
  %341 = load <64 x float>, <64 x float>* %340, align 64, !tbaa !20
  %342 = fadd <64 x float> %339, %341
  %343 = getelementptr inbounds float, float* %10, i64 %334
  %344 = bitcast float* %343 to <64 x float>*
  store <64 x float> %342, <64 x float>* %344, align 64, !tbaa !33
  %345 = getelementptr inbounds i8, i8* %34, i64 256
  %346 = bitcast i8* %345 to <64 x float>*
  %347 = load <64 x float>, <64 x float>* %346, align 64, !tbaa !20
  %348 = fadd <64 x float> %339, %347
  %349 = mul i64 %indvars.iv33, 7696581394432
  %sext = ashr exact i64 %349, 32
  %350 = or i64 %sext, 64
  %351 = getelementptr inbounds float, float* %10, i64 %350
  %352 = bitcast float* %351 to <64 x float>*
  store <64 x float> %348, <64 x float>* %352, align 64, !tbaa !33
  %353 = getelementptr inbounds i8, i8* %34, i64 512
  %354 = bitcast i8* %353 to <64 x float>*
  %355 = load <64 x float>, <64 x float>* %354, align 64, !tbaa !20
  %356 = fadd <64 x float> %339, %355
  %357 = mul i64 %indvars.iv33, 7696581394432
  %sext35 = ashr exact i64 %357, 32
  %358 = or i64 %sext35, 128
  %359 = getelementptr inbounds float, float* %10, i64 %358
  %360 = bitcast float* %359 to <64 x float>*
  store <64 x float> %356, <64 x float>* %360, align 64, !tbaa !33
  %361 = getelementptr inbounds i8, i8* %34, i64 768
  %362 = bitcast i8* %361 to <64 x float>*
  %363 = load <64 x float>, <64 x float>* %362, align 64, !tbaa !20
  %364 = fadd <64 x float> %339, %363
  %365 = mul i64 %indvars.iv33, 7696581394432
  %sext36 = ashr exact i64 %365, 32
  %366 = or i64 %sext36, 192
  %367 = getelementptr inbounds float, float* %10, i64 %366
  %368 = bitcast float* %367 to <64 x float>*
  store <64 x float> %364, <64 x float>* %368, align 64, !tbaa !33
  %369 = getelementptr inbounds i8, i8* %34, i64 1024
  %370 = bitcast i8* %369 to <64 x float>*
  %371 = load <64 x float>, <64 x float>* %370, align 64, !tbaa !20
  %372 = fadd <64 x float> %339, %371
  %373 = mul i64 %indvars.iv33, 7696581394432
  %sext37 = add i64 %373, 1099511627776
  %374 = ashr exact i64 %sext37, 32
  %375 = getelementptr inbounds float, float* %10, i64 %374
  %376 = bitcast float* %375 to <64 x float>*
  store <64 x float> %372, <64 x float>* %376, align 64, !tbaa !33
  %377 = getelementptr inbounds i8, i8* %34, i64 1280
  %378 = bitcast i8* %377 to <64 x float>*
  %379 = load <64 x float>, <64 x float>* %378, align 64, !tbaa !20
  %380 = fadd <64 x float> %339, %379
  %381 = mul i64 %indvars.iv33, 7696581394432
  %sext38 = add i64 %381, 1374389534720
  %382 = ashr exact i64 %sext38, 32
  %383 = getelementptr inbounds float, float* %10, i64 %382
  %384 = bitcast float* %383 to <64 x float>*
  store <64 x float> %380, <64 x float>* %384, align 64, !tbaa !33
  %385 = getelementptr inbounds i8, i8* %34, i64 1536
  %386 = bitcast i8* %385 to <64 x float>*
  %387 = load <64 x float>, <64 x float>* %386, align 64, !tbaa !20
  %388 = fadd <64 x float> %339, %387
  %389 = mul i64 %indvars.iv33, 7696581394432
  %sext39 = add i64 %389, 1649267441664
  %390 = ashr exact i64 %sext39, 32
  %391 = getelementptr inbounds float, float* %10, i64 %390
  %392 = bitcast float* %391 to <64 x float>*
  store <64 x float> %388, <64 x float>* %392, align 64, !tbaa !33
  %393 = getelementptr inbounds i8, i8* %34, i64 1792
  %394 = bitcast i8* %393 to <64 x float>*
  %395 = load <64 x float>, <64 x float>* %394, align 64, !tbaa !20
  %396 = fadd <64 x float> %339, %395
  %397 = mul i64 %indvars.iv33, 7696581394432
  %sext40 = add i64 %397, 1924145348608
  %398 = ashr exact i64 %sext40, 32
  %399 = getelementptr inbounds float, float* %10, i64 %398
  %400 = bitcast float* %399 to <64 x float>*
  store <64 x float> %396, <64 x float>* %400, align 64, !tbaa !33
  %401 = getelementptr inbounds i8, i8* %34, i64 2048
  %402 = bitcast i8* %401 to <64 x float>*
  %403 = load <64 x float>, <64 x float>* %402, align 64, !tbaa !20
  %404 = fadd <64 x float> %339, %403
  %405 = mul i64 %indvars.iv33, 7696581394432
  %sext41 = add i64 %405, 2199023255552
  %406 = ashr exact i64 %sext41, 32
  %407 = getelementptr inbounds float, float* %10, i64 %406
  %408 = bitcast float* %407 to <64 x float>*
  store <64 x float> %404, <64 x float>* %408, align 64, !tbaa !33
  %409 = getelementptr inbounds i8, i8* %34, i64 2304
  %410 = bitcast i8* %409 to <64 x float>*
  %411 = load <64 x float>, <64 x float>* %410, align 64, !tbaa !20
  %412 = fadd <64 x float> %339, %411
  %413 = mul i64 %indvars.iv33, 7696581394432
  %sext42 = add i64 %413, 2473901162496
  %414 = ashr exact i64 %sext42, 32
  %415 = getelementptr inbounds float, float* %10, i64 %414
  %416 = bitcast float* %415 to <64 x float>*
  store <64 x float> %412, <64 x float>* %416, align 64, !tbaa !33
  %417 = getelementptr inbounds i8, i8* %34, i64 2560
  %418 = bitcast i8* %417 to <64 x float>*
  %419 = load <64 x float>, <64 x float>* %418, align 64, !tbaa !20
  %420 = fadd <64 x float> %339, %419
  %421 = mul i64 %indvars.iv33, 7696581394432
  %sext43 = add i64 %421, 2748779069440
  %422 = ashr exact i64 %sext43, 32
  %423 = getelementptr inbounds float, float* %10, i64 %422
  %424 = bitcast float* %423 to <64 x float>*
  store <64 x float> %420, <64 x float>* %424, align 64, !tbaa !33
  %425 = getelementptr inbounds i8, i8* %34, i64 2816
  %426 = bitcast i8* %425 to <64 x float>*
  %427 = load <64 x float>, <64 x float>* %426, align 64, !tbaa !20
  %428 = fadd <64 x float> %339, %427
  %429 = mul i64 %indvars.iv33, 7696581394432
  %sext44 = add i64 %429, 3023656976384
  %430 = ashr exact i64 %sext44, 32
  %431 = getelementptr inbounds float, float* %10, i64 %430
  %432 = bitcast float* %431 to <64 x float>*
  store <64 x float> %428, <64 x float>* %432, align 64, !tbaa !33
  %433 = getelementptr inbounds i8, i8* %34, i64 3072
  %434 = bitcast i8* %433 to <64 x float>*
  %435 = load <64 x float>, <64 x float>* %434, align 64, !tbaa !20
  %436 = fadd <64 x float> %339, %435
  %437 = mul i64 %indvars.iv33, 7696581394432
  %sext45 = add i64 %437, 3298534883328
  %438 = ashr exact i64 %sext45, 32
  %439 = getelementptr inbounds float, float* %10, i64 %438
  %440 = bitcast float* %439 to <64 x float>*
  store <64 x float> %436, <64 x float>* %440, align 64, !tbaa !33
  %441 = getelementptr inbounds i8, i8* %34, i64 3328
  %442 = bitcast i8* %441 to <64 x float>*
  %443 = load <64 x float>, <64 x float>* %442, align 64, !tbaa !20
  %444 = fadd <64 x float> %339, %443
  %445 = mul i64 %indvars.iv33, 7696581394432
  %sext46 = add i64 %445, 3573412790272
  %446 = ashr exact i64 %sext46, 32
  %447 = getelementptr inbounds float, float* %10, i64 %446
  %448 = bitcast float* %447 to <64 x float>*
  store <64 x float> %444, <64 x float>* %448, align 64, !tbaa !33
  %449 = getelementptr inbounds i8, i8* %34, i64 3584
  %450 = bitcast i8* %449 to <64 x float>*
  %451 = load <64 x float>, <64 x float>* %450, align 64, !tbaa !20
  %452 = fadd <64 x float> %339, %451
  %453 = mul i64 %indvars.iv33, 7696581394432
  %sext47 = add i64 %453, 3848290697216
  %454 = ashr exact i64 %sext47, 32
  %455 = getelementptr inbounds float, float* %10, i64 %454
  %456 = bitcast float* %455 to <64 x float>*
  store <64 x float> %452, <64 x float>* %456, align 64, !tbaa !33
  %457 = getelementptr inbounds i8, i8* %34, i64 3840
  %458 = bitcast i8* %457 to <64 x float>*
  %459 = load <64 x float>, <64 x float>* %458, align 64, !tbaa !20
  %460 = fadd <64 x float> %339, %459
  %461 = mul i64 %indvars.iv33, 7696581394432
  %sext48 = add i64 %461, 4123168604160
  %462 = ashr exact i64 %sext48, 32
  %463 = getelementptr inbounds float, float* %10, i64 %462
  %464 = bitcast float* %463 to <64 x float>*
  store <64 x float> %460, <64 x float>* %464, align 64, !tbaa !33
  %465 = getelementptr inbounds i8, i8* %34, i64 4096
  %466 = bitcast i8* %465 to <64 x float>*
  %467 = load <64 x float>, <64 x float>* %466, align 64, !tbaa !20
  %468 = fadd <64 x float> %339, %467
  %469 = mul i64 %indvars.iv33, 7696581394432
  %sext49 = add i64 %469, 4398046511104
  %470 = ashr exact i64 %sext49, 32
  %471 = getelementptr inbounds float, float* %10, i64 %470
  %472 = bitcast float* %471 to <64 x float>*
  store <64 x float> %468, <64 x float>* %472, align 64, !tbaa !33
  %473 = getelementptr inbounds i8, i8* %34, i64 4352
  %474 = bitcast i8* %473 to <64 x float>*
  %475 = load <64 x float>, <64 x float>* %474, align 64, !tbaa !20
  %476 = fadd <64 x float> %339, %475
  %477 = mul i64 %indvars.iv33, 7696581394432
  %sext50 = add i64 %477, 4672924418048
  %478 = ashr exact i64 %sext50, 32
  %479 = getelementptr inbounds float, float* %10, i64 %478
  %480 = bitcast float* %479 to <64 x float>*
  store <64 x float> %476, <64 x float>* %480, align 64, !tbaa !33
  %481 = getelementptr inbounds i8, i8* %34, i64 4608
  %482 = bitcast i8* %481 to <64 x float>*
  %483 = load <64 x float>, <64 x float>* %482, align 64, !tbaa !20
  %484 = fadd <64 x float> %339, %483
  %485 = mul i64 %indvars.iv33, 7696581394432
  %sext51 = add i64 %485, 4947802324992
  %486 = ashr exact i64 %sext51, 32
  %487 = getelementptr inbounds float, float* %10, i64 %486
  %488 = bitcast float* %487 to <64 x float>*
  store <64 x float> %484, <64 x float>* %488, align 64, !tbaa !33
  %489 = getelementptr inbounds i8, i8* %34, i64 4864
  %490 = bitcast i8* %489 to <64 x float>*
  %491 = load <64 x float>, <64 x float>* %490, align 64, !tbaa !20
  %492 = fadd <64 x float> %339, %491
  %493 = mul i64 %indvars.iv33, 7696581394432
  %sext52 = add i64 %493, 5222680231936
  %494 = ashr exact i64 %sext52, 32
  %495 = getelementptr inbounds float, float* %10, i64 %494
  %496 = bitcast float* %495 to <64 x float>*
  store <64 x float> %492, <64 x float>* %496, align 64, !tbaa !33
  %497 = getelementptr inbounds i8, i8* %34, i64 5120
  %498 = bitcast i8* %497 to <64 x float>*
  %499 = load <64 x float>, <64 x float>* %498, align 64, !tbaa !20
  %500 = fadd <64 x float> %339, %499
  %501 = mul i64 %indvars.iv33, 7696581394432
  %sext53 = add i64 %501, 5497558138880
  %502 = ashr exact i64 %sext53, 32
  %503 = getelementptr inbounds float, float* %10, i64 %502
  %504 = bitcast float* %503 to <64 x float>*
  store <64 x float> %500, <64 x float>* %504, align 64, !tbaa !33
  %505 = getelementptr inbounds i8, i8* %34, i64 5376
  %506 = bitcast i8* %505 to <64 x float>*
  %507 = load <64 x float>, <64 x float>* %506, align 64, !tbaa !20
  %508 = fadd <64 x float> %339, %507
  %509 = mul i64 %indvars.iv33, 7696581394432
  %sext54 = add i64 %509, 5772436045824
  %510 = ashr exact i64 %sext54, 32
  %511 = getelementptr inbounds float, float* %10, i64 %510
  %512 = bitcast float* %511 to <64 x float>*
  store <64 x float> %508, <64 x float>* %512, align 64, !tbaa !33
  %513 = getelementptr inbounds i8, i8* %34, i64 5632
  %514 = bitcast i8* %513 to <64 x float>*
  %515 = load <64 x float>, <64 x float>* %514, align 64, !tbaa !20
  %516 = fadd <64 x float> %339, %515
  %517 = mul i64 %indvars.iv33, 7696581394432
  %sext55 = add i64 %517, 6047313952768
  %518 = ashr exact i64 %sext55, 32
  %519 = getelementptr inbounds float, float* %10, i64 %518
  %520 = bitcast float* %519 to <64 x float>*
  store <64 x float> %516, <64 x float>* %520, align 64, !tbaa !33
  %521 = getelementptr inbounds i8, i8* %34, i64 5888
  %522 = bitcast i8* %521 to <64 x float>*
  %523 = load <64 x float>, <64 x float>* %522, align 64, !tbaa !20
  %524 = fadd <64 x float> %339, %523
  %525 = mul i64 %indvars.iv33, 7696581394432
  %sext56 = add i64 %525, 6322191859712
  %526 = ashr exact i64 %sext56, 32
  %527 = getelementptr inbounds float, float* %10, i64 %526
  %528 = bitcast float* %527 to <64 x float>*
  store <64 x float> %524, <64 x float>* %528, align 64, !tbaa !33
  %529 = getelementptr inbounds i8, i8* %34, i64 6144
  %530 = bitcast i8* %529 to <64 x float>*
  %531 = load <64 x float>, <64 x float>* %530, align 64, !tbaa !20
  %532 = fadd <64 x float> %339, %531
  %533 = mul i64 %indvars.iv33, 7696581394432
  %sext57 = add i64 %533, 6597069766656
  %534 = ashr exact i64 %sext57, 32
  %535 = getelementptr inbounds float, float* %10, i64 %534
  %536 = bitcast float* %535 to <64 x float>*
  store <64 x float> %532, <64 x float>* %536, align 64, !tbaa !33
  %537 = getelementptr inbounds i8, i8* %34, i64 6400
  %538 = bitcast i8* %537 to <64 x float>*
  %539 = load <64 x float>, <64 x float>* %538, align 64, !tbaa !20
  %540 = fadd <64 x float> %339, %539
  %541 = mul i64 %indvars.iv33, 7696581394432
  %sext58 = add i64 %541, 6871947673600
  %542 = ashr exact i64 %sext58, 32
  %543 = getelementptr inbounds float, float* %10, i64 %542
  %544 = bitcast float* %543 to <64 x float>*
  store <64 x float> %540, <64 x float>* %544, align 64, !tbaa !33
  %545 = getelementptr inbounds i8, i8* %34, i64 6656
  %546 = bitcast i8* %545 to <64 x float>*
  %547 = load <64 x float>, <64 x float>* %546, align 64, !tbaa !20
  %548 = fadd <64 x float> %339, %547
  %549 = mul i64 %indvars.iv33, 7696581394432
  %sext59 = add i64 %549, 7146825580544
  %550 = ashr exact i64 %sext59, 32
  %551 = getelementptr inbounds float, float* %10, i64 %550
  %552 = bitcast float* %551 to <64 x float>*
  store <64 x float> %548, <64 x float>* %552, align 64, !tbaa !33
  %553 = getelementptr inbounds i8, i8* %34, i64 6912
  %554 = bitcast i8* %553 to <64 x float>*
  %555 = load <64 x float>, <64 x float>* %554, align 64, !tbaa !20
  %556 = fadd <64 x float> %339, %555
  %557 = mul i64 %indvars.iv33, 7696581394432
  %sext60 = add i64 %557, 7421703487488
  %558 = ashr exact i64 %sext60, 32
  %559 = getelementptr inbounds float, float* %10, i64 %558
  %560 = bitcast float* %559 to <64 x float>*
  store <64 x float> %556, <64 x float>* %560, align 64, !tbaa !33
  %561 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %562 = tail call i32 %561(i32 1, i32 %16, i8* nonnull %34)
  %indvars.iv.next34 = add nsw i64 %indvars.iv33, 1
  %563 = icmp slt i64 %indvars.iv.next34, %32
  br i1 %563, label %for_body, label %for_end, !prof !19
}

; Function Attrs: nounwind readnone speculatable
declare <64 x float> @llvm.fmuladd.v64f32(<64 x float>, <64 x float>, <64 x float>) #1

define dllexport i32 @fused_layout_transform_48(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !36 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !38, metadata !DIExpression()), !dbg !41
  call void @llvm.dbg.value(metadata i8* %1, metadata !39, metadata !DIExpression()), !dbg !41
  call void @llvm.dbg.value(metadata i32 %2, metadata !40, metadata !DIExpression()), !dbg !41
  %3 = bitcast i8* %0 to %1**, !dbg !41
  %4 = load %1*, %1** %3, align 8, !dbg !41
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !41
  %6 = bitcast i8* %5 to %1**, !dbg !41
  %7 = load %1*, %1** %6, align 8, !dbg !41
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !41
  %9 = load i8*, i8** %8, align 8, !dbg !41
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !41
  %11 = load i8*, i8** %10, align 8, !dbg !41
  %12 = tail call fastcc i32 @fused_layout_transform_48_compute_(i8* %11, i8* %9), !dbg !41
  ret i32 %12, !dbg !41
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_48_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %5, align 8
  %3 = getelementptr inbounds %5, %5* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %5, %5* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %5* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.1, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.1(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 447
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 448
  %15 = select i1 %14, i32 %13, i32 448
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 448
  %18 = select i1 %17, i32 %16, i32 448
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 896
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = sdiv i32 %25, 28
  %27 = shl nsw i32 %26, 5
  %28 = srem i32 %25, 28
  %29 = mul nsw i32 %28, 1792
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %30 = shl i64 %indvars.iv7, 5
  %31 = add nsw i64 %30, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %32 = shl i32 %indvars.iv7.tr, 6
  %33 = add i32 %29, %32
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %34 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %34, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %35 = add nsw i64 %31, %indvars.iv
  %36 = trunc i64 %indvars.iv to i32
  %37 = add i32 %27, %36
  %38 = srem i32 %37, 64
  %39 = sdiv i32 %37, 64
  %40 = mul nsw i32 %39, 50176
  %41 = add i32 %33, %38
  %42 = add i32 %41, %40
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds float, float* %7, i64 %43
  %45 = bitcast float* %44 to i32*
  %46 = load i32, i32* %45, align 4, !tbaa !42
  %47 = getelementptr inbounds float, float* %4, i64 %35
  %48 = bitcast float* %47 to i32*
  store i32 %46, i32* %48, align 4, !tbaa !45
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_layout_transform_47(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !48 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !50, metadata !DIExpression()), !dbg !53
  call void @llvm.dbg.value(metadata i8* %1, metadata !51, metadata !DIExpression()), !dbg !53
  call void @llvm.dbg.value(metadata i32 %2, metadata !52, metadata !DIExpression()), !dbg !53
  %3 = bitcast i8* %0 to %1**, !dbg !53
  %4 = load %1*, %1** %3, align 8, !dbg !53
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !53
  %6 = bitcast i8* %5 to %1**, !dbg !53
  %7 = load %1*, %1** %6, align 8, !dbg !53
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !53
  %9 = load i8*, i8** %8, align 8, !dbg !53
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !53
  %11 = load i8*, i8** %10, align 8, !dbg !53
  %12 = tail call fastcc i32 @fused_layout_transform_47_compute_(i8* %11, i8* %9), !dbg !53
  ret i32 %12, !dbg !53
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_47_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %6, align 8
  %3 = getelementptr inbounds %6, %6* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %6, %6* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %6* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.2, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.2(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 223
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 224
  %15 = select i1 %14, i32 %13, i32 224
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 224
  %18 = select i1 %17, i32 %16, i32 224
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  %24 = xor i32 %16, -1
  %25 = icmp sgt i32 %24, -225
  %smax = select i1 %25, i32 %24, i32 -225
  %26 = mul i32 %smax, 224
  %27 = sub i32 -224, %26
  %28 = sub i32 49952, %26
  %29 = sub i32 100128, %26
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvar = phi i32 [ 0, %for_body.lr.ph ], [ %indvar.next, %for_end3 ]
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_end3 ]
  %30 = mul i32 %indvar, 224
  %31 = mul nsw i64 %indvars.iv7, 672
  %32 = trunc i64 %indvars.iv7 to i32
  %33 = mul i32 %32, 224
  %34 = add i32 %29, %30
  %35 = add i32 %28, %30
  %36 = add i32 %27, %30
  %37 = icmp sgt i32 %36, 2147483424
  %38 = icmp sgt i32 %35, 2147483424
  %39 = or i1 %37, %38
  %40 = icmp sgt i32 %34, 2147483424
  %41 = or i1 %39, %40
  br i1 %41, label %for_body2.preheader, label %vector.body.preheader

vector.body.preheader:                            ; preds = %for_body
  br label %vector.body

for_body2.preheader:                              ; preds = %for_body
  br label %for_body2

vector.body:                                      ; preds = %vector.body.preheader, %vector.body
  %index = phi i64 [ %index.next, %vector.body ], [ 0, %vector.body.preheader ]
  %42 = mul nuw nsw i64 %index, 3
  %43 = add nsw i64 %42, %31
  %44 = trunc i64 %index to i32
  %45 = add i32 %33, %44
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds float, float* %7, i64 %46
  %48 = bitcast float* %47 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %48, align 4, !tbaa !54
  %49 = add i32 %45, 50176
  %50 = sext i32 %49 to i64
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = bitcast float* %51 to <4 x i32>*
  %wide.load18 = load <4 x i32>, <4 x i32>* %52, align 4, !tbaa !54
  %53 = or i64 %43, 2
  %54 = add i32 %45, 100352
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds float, float* %7, i64 %55
  %57 = bitcast float* %56 to <4 x i32>*
  %wide.load19 = load <4 x i32>, <4 x i32>* %57, align 4, !tbaa !54
  %58 = getelementptr inbounds float, float* %4, i64 %53
  %59 = getelementptr float, float* %58, i64 -2
  %60 = bitcast float* %59 to <12 x i32>*
  %61 = shufflevector <4 x i32> %wide.load, <4 x i32> %wide.load18, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
  %62 = shufflevector <4 x i32> %wide.load19, <4 x i32> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %interleaved.vec = shufflevector <8 x i32> %61, <8 x i32> %62, <12 x i32> <i32 0, i32 4, i32 8, i32 1, i32 5, i32 9, i32 2, i32 6, i32 10, i32 3, i32 7, i32 11>
  store <12 x i32> %interleaved.vec, <12 x i32>* %60, align 4, !tbaa !57
  %index.next = add i64 %index, 4
  %63 = icmp eq i64 %index.next, 224
  br i1 %63, label %for_end3, label %vector.body, !llvm.loop !60

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2.preheader, %for_body2
  %indvars.iv = phi i64 [ %indvars.iv.next, %for_body2 ], [ 0, %for_body2.preheader ]
  %64 = mul nuw nsw i64 %indvars.iv, 3
  %65 = add nsw i64 %64, %31
  %66 = trunc i64 %indvars.iv to i32
  %67 = add i32 %33, %66
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to i32*
  %71 = load i32, i32* %70, align 4, !tbaa !54
  %72 = getelementptr inbounds float, float* %4, i64 %65
  %73 = bitcast float* %72 to i32*
  store i32 %71, i32* %73, align 4, !tbaa !57
  %74 = add nsw i64 %65, 1
  %75 = add i32 %67, 50176
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds float, float* %7, i64 %76
  %78 = bitcast float* %77 to i32*
  %79 = load i32, i32* %78, align 4, !tbaa !54
  %80 = getelementptr inbounds float, float* %4, i64 %74
  %81 = bitcast float* %80 to i32*
  store i32 %79, i32* %81, align 4, !tbaa !57
  %82 = add nsw i64 %65, 2
  %83 = add i32 %67, 100352
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds float, float* %7, i64 %84
  %86 = bitcast float* %85 to i32*
  %87 = load i32, i32* %86, align 4, !tbaa !54
  %88 = getelementptr inbounds float, float* %4, i64 %82
  %89 = bitcast float* %88 to i32*
  store i32 %87, i32* %89, align 4, !tbaa !57
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 224
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29, !llvm.loop !62

for_end3:                                         ; preds = %vector.body, %for_body2
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %90 = icmp slt i64 %indvars.iv.next8, %23
  %indvar.next = add i32 %indvar, 1
  br i1 %90, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !63 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !65, metadata !DIExpression()), !dbg !68
  call void @llvm.dbg.value(metadata i8* %1, metadata !66, metadata !DIExpression()), !dbg !68
  call void @llvm.dbg.value(metadata i32 %2, metadata !67, metadata !DIExpression()), !dbg !68
  %3 = bitcast i8* %0 to %1**, !dbg !68
  %4 = load %1*, %1** %3, align 8, !dbg !68
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !68
  %6 = bitcast i8* %5 to %1**, !dbg !68
  %7 = load %1*, %1** %6, align 8, !dbg !68
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !68
  %9 = bitcast i8* %8 to %1**, !dbg !68
  %10 = load %1*, %1** %9, align 8, !dbg !68
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !68
  %12 = bitcast i8* %11 to %1**, !dbg !68
  %13 = load %1*, %1** %12, align 8, !dbg !68
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !68
  %15 = load i8*, i8** %14, align 8, !dbg !68
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !68
  %17 = load i32, i32* %16, align 4, !dbg !68
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !68
  %19 = load i8*, i8** %18, align 8, !dbg !68
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !68
  %21 = load i8*, i8** %20, align 8, !dbg !68
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !68
  %23 = load i8*, i8** %22, align 8, !dbg !68
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !68
  ret i32 %24, !dbg !68
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %6 = tail call i8* %5(i32 1, i32 %4, i64 629292, i32 2, i32 32)
  %7 = alloca %7, align 8
  %8 = getelementptr inbounds %7, %7* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %7, %7* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %7* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.3, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !19

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %8, align 8
  %15 = getelementptr inbounds %8, %8* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %8, %8* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %8, %8* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %8, %8* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %8, %8* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %8* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.4, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !19

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.3(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 228
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 229
  %15 = select i1 %14, i32 %13, i32 229
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 229
  %18 = select i1 %17, i32 %16, i32 229
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end3
  %20 = phi i32 [ %93, %for_end3 ], [ %18, %for_body.preheader ]
  %21 = mul nsw i32 %20, 687
  %.off = add i32 %20, -3
  %22 = icmp ult i32 %.off, 224
  %23 = mul nsw i32 %20, 672
  br i1 %22, label %for_body2.us.preheader, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_body
  br label %for_body2

for_body2.us.preheader:                           ; preds = %for_body
  br label %for_body2.us

for_body2.us:                                     ; preds = %for_body2.us.preheader, %for_end6.us
  %indvars.iv21 = phi i64 [ %indvars.iv.next22, %for_end6.us ], [ 0, %for_body2.us.preheader ]
  %24 = mul nuw nsw i64 %indvars.iv21, 3
  %25 = trunc i64 %indvars.iv21 to i32
  %26 = add i32 %25, -3
  %27 = icmp ult i32 %26, 224
  %28 = trunc i64 %24 to i32
  %29 = add i32 %21, %28
  br i1 %27, label %for_body2.split.us.us, label %for_body2.for_body2.split_crit_edge.us

for_end6.us:                                      ; preds = %for_body2.for_body2.split_crit_edge.us, %for_body2.split.us.us
  %indvars.iv.next22 = add nuw nsw i64 %indvars.iv21, 1
  %exitcond24 = icmp eq i64 %indvars.iv.next22, 229
  br i1 %exitcond24, label %for_end3, label %for_body2.us, !prof !29

for_body2.split.us.us:                            ; preds = %for_body2.us
  %30 = trunc i64 %24 to i32
  %31 = add i32 %30, -2025
  %32 = add i32 %31, %23
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds float, float* %7, i64 %33
  %35 = bitcast float* %34 to i32*
  %36 = load i32, i32* %35, align 4, !tbaa !69
  %37 = sext i32 %29 to i64
  %38 = getelementptr inbounds float, float* %4, i64 %37
  %39 = bitcast float* %38 to i32*
  store i32 %36, i32* %39, align 4, !tbaa !72
  %40 = trunc i64 %24 to i32
  %41 = add i32 %40, 1
  %42 = add i32 %21, %41
  %43 = trunc i64 %24 to i32
  %44 = add i32 %43, -2024
  %45 = add i32 %44, %23
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds float, float* %7, i64 %46
  %48 = bitcast float* %47 to i32*
  %49 = load i32, i32* %48, align 4, !tbaa !69
  %50 = sext i32 %42 to i64
  %51 = getelementptr inbounds float, float* %4, i64 %50
  %52 = bitcast float* %51 to i32*
  store i32 %49, i32* %52, align 4, !tbaa !72
  %53 = trunc i64 %24 to i32
  %54 = add i32 %53, 2
  %55 = add i32 %21, %54
  %56 = trunc i64 %24 to i32
  %57 = add i32 %56, -2023
  %58 = add i32 %57, %23
  %59 = sext i32 %58 to i64
  %60 = getelementptr inbounds float, float* %7, i64 %59
  %61 = bitcast float* %60 to i32*
  %62 = load i32, i32* %61, align 4, !tbaa !69
  %63 = sext i32 %55 to i64
  %64 = getelementptr inbounds float, float* %4, i64 %63
  %65 = bitcast float* %64 to i32*
  store i32 %62, i32* %65, align 4, !tbaa !72
  br label %for_end6.us

for_body2.for_body2.split_crit_edge.us:           ; preds = %for_body2.us
  %66 = sext i32 %29 to i64
  %67 = getelementptr inbounds float, float* %4, i64 %66
  store float 0.000000e+00, float* %67, align 4, !tbaa !72
  %68 = trunc i64 %24 to i32
  %69 = add i32 %68, 1
  %70 = add i32 %69, %21
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds float, float* %4, i64 %71
  store float 0.000000e+00, float* %72, align 4, !tbaa !72
  %73 = trunc i64 %24 to i32
  %74 = add i32 %73, 2
  %75 = add i32 %74, %21
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds float, float* %4, i64 %76
  store float 0.000000e+00, float* %77, align 4, !tbaa !72
  br label %for_end6.us

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2.preheader, %for_body2
  %indvars.iv = phi i64 [ %indvars.iv.next, %for_body2 ], [ 0, %for_body2.preheader ]
  %78 = mul nuw nsw i64 %indvars.iv, 3
  %79 = trunc i64 %78 to i32
  %80 = add i32 %21, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %4, i64 %81
  store float 0.000000e+00, float* %82, align 4, !tbaa !72
  %83 = trunc i64 %78 to i32
  %84 = add i32 %83, 1
  %85 = add i32 %84, %21
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds float, float* %4, i64 %86
  store float 0.000000e+00, float* %87, align 4, !tbaa !72
  %88 = trunc i64 %78 to i32
  %89 = add i32 %88, 2
  %90 = add i32 %89, %21
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds float, float* %4, i64 %91
  store float 0.000000e+00, float* %92, align 4, !tbaa !72
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 229
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2, %for_end6.us
  %93 = add nsw i32 %20, 1
  %94 = icmp slt i32 %93, %15
  br i1 %94, label %for_body, label %for_end, !prof !19
}

define private i32 @__tvm_parallel_lambda.4(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 223
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 224
  %24 = select i1 %23, i32 %22, i32 224
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 224
  %27 = select i1 %26, i32 %25, i32 224
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end20
  %29 = phi i32 [ %350, %for_end20 ], [ %27, %for_body.preheader ]
  %30 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %31 = tail call i8* %30(i32 1, i32 %16, i64 14336, i32 2, i32 32)
  %32 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %33 = tail call i8* %32(i32 1, i32 %16, i64 1024, i32 2, i32 32)
  %34 = bitcast i8* %33 to <32 x float>*
  %35 = getelementptr inbounds i8, i8* %33, i64 128
  %36 = bitcast i8* %35 to <32 x float>*
  %37 = getelementptr inbounds i8, i8* %33, i64 256
  %38 = bitcast i8* %37 to <32 x float>*
  %39 = getelementptr inbounds i8, i8* %33, i64 384
  %40 = bitcast i8* %39 to <32 x float>*
  %41 = getelementptr inbounds i8, i8* %33, i64 512
  %42 = bitcast i8* %41 to <32 x float>*
  %43 = getelementptr inbounds i8, i8* %33, i64 640
  %44 = bitcast i8* %43 to <32 x float>*
  %45 = getelementptr inbounds i8, i8* %33, i64 768
  %46 = bitcast i8* %45 to <32 x float>*
  %47 = getelementptr inbounds i8, i8* %33, i64 896
  %48 = bitcast i8* %47 to <32 x float>*
  %49 = srem i32 %29, 112
  %50 = mul nsw i32 %49, 1374
  %51 = sdiv i32 %29, 112
  %52 = mul nsw i32 %51, 4704
  %53 = bitcast i8* %31 to float*
  %54 = sext i32 %52 to i64
  %55 = sext i32 %50 to i64
  br label %for_body4

for_end:                                          ; preds = %for_end20, %entry
  ret i32 0

for_body4:                                        ; preds = %for_end8, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end8 ]
  %56 = mul nuw nsw i64 %indvar, 48
  %57 = add nsw i64 %56, %55
  call void @llvm.memset.p0i8.i64(i8* %33, i8 0, i64 1024, i32 64, i1 false)
  br label %for_body7

for_end5:                                         ; preds = %for_end8
  %58 = mul nsw i32 %29, 3584
  %59 = shl nsw i32 %51, 5
  %60 = sext i32 %59 to i64
  %61 = getelementptr inbounds float, float* %13, i64 %60
  %62 = bitcast float* %61 to <32 x float>*
  %63 = load <32 x float>, <32 x float>* %62, align 64, !tbaa !75
  br label %for_body19

for_body7:                                        ; preds = %for_end11, %for_body4
  %indvars.iv79 = phi i64 [ 0, %for_body4 ], [ %indvars.iv.next80, %for_end11 ]
  %.lcssa41.lcssa71 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %249, %for_end11 ]
  %.lcssa39.lcssa69 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %243, %for_end11 ]
  %.lcssa37.lcssa67 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %237, %for_end11 ]
  %.lcssa35.lcssa65 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %231, %for_end11 ]
  %.lcssa33.lcssa63 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %225, %for_end11 ]
  %.lcssa31.lcssa61 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %219, %for_end11 ]
  %.lcssa29.lcssa60 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %213, %for_end11 ]
  %.lcssa.lcssa58 = phi <32 x float> [ zeroinitializer, %for_body4 ], [ %207, %for_end11 ]
  %64 = mul nuw nsw i64 %indvars.iv79, 687
  %65 = add nsw i64 %57, %64
  %66 = mul nuw nsw i64 %indvars.iv79, 672
  %67 = add nsw i64 %66, %54
  br label %for_body10

for_end8:                                         ; preds = %for_end11
  store <32 x float> %207, <32 x float>* %34, align 64, !tbaa !78
  store <32 x float> %213, <32 x float>* %36, align 64, !tbaa !78
  store <32 x float> %219, <32 x float>* %38, align 64, !tbaa !78
  store <32 x float> %225, <32 x float>* %40, align 64, !tbaa !78
  store <32 x float> %231, <32 x float>* %42, align 64, !tbaa !78
  store <32 x float> %237, <32 x float>* %44, align 64, !tbaa !78
  store <32 x float> %243, <32 x float>* %46, align 64, !tbaa !78
  store <32 x float> %249, <32 x float>* %48, align 64, !tbaa !78
  %68 = shl i64 %indvar, 8
  %69 = getelementptr inbounds float, float* %53, i64 %68
  %70 = bitcast float* %69 to <32 x float>*
  store <32 x float> %207, <32 x float>* %70, align 64, !tbaa !87
  %71 = or i64 %68, 32
  %72 = getelementptr inbounds float, float* %53, i64 %71
  %73 = bitcast float* %72 to <32 x float>*
  store <32 x float> %213, <32 x float>* %73, align 64, !tbaa !87
  %74 = or i64 %68, 64
  %75 = getelementptr inbounds float, float* %53, i64 %74
  %76 = bitcast float* %75 to <32 x float>*
  store <32 x float> %219, <32 x float>* %76, align 64, !tbaa !87
  %77 = or i64 %68, 96
  %78 = getelementptr inbounds float, float* %53, i64 %77
  %79 = bitcast float* %78 to <32 x float>*
  store <32 x float> %225, <32 x float>* %79, align 64, !tbaa !87
  %80 = or i64 %68, 128
  %81 = getelementptr inbounds float, float* %53, i64 %80
  %82 = bitcast float* %81 to <32 x float>*
  store <32 x float> %231, <32 x float>* %82, align 64, !tbaa !87
  %83 = or i64 %68, 160
  %84 = getelementptr inbounds float, float* %53, i64 %83
  %85 = bitcast float* %84 to <32 x float>*
  store <32 x float> %237, <32 x float>* %85, align 64, !tbaa !87
  %86 = or i64 %68, 192
  %87 = getelementptr inbounds float, float* %53, i64 %86
  %88 = bitcast float* %87 to <32 x float>*
  store <32 x float> %243, <32 x float>* %88, align 64, !tbaa !87
  %89 = or i64 %68, 224
  %90 = getelementptr inbounds float, float* %53, i64 %89
  %91 = bitcast float* %90 to <32 x float>*
  store <32 x float> %249, <32 x float>* %91, align 64, !tbaa !87
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond85 = icmp eq i64 %indvar.next, 14
  br i1 %exitcond85, label %for_end5, label %for_body4, !prof !29

for_body10:                                       ; preds = %for_body10, %for_body7
  %indvars.iv = phi i64 [ 0, %for_body7 ], [ %indvars.iv.next, %for_body10 ]
  %.lcssa4156 = phi <32 x float> [ %.lcssa41.lcssa71, %for_body7 ], [ %249, %for_body10 ]
  %.lcssa3954 = phi <32 x float> [ %.lcssa39.lcssa69, %for_body7 ], [ %243, %for_body10 ]
  %.lcssa3752 = phi <32 x float> [ %.lcssa37.lcssa67, %for_body7 ], [ %237, %for_body10 ]
  %.lcssa3550 = phi <32 x float> [ %.lcssa35.lcssa65, %for_body7 ], [ %231, %for_body10 ]
  %.lcssa3348 = phi <32 x float> [ %.lcssa33.lcssa63, %for_body7 ], [ %225, %for_body10 ]
  %.lcssa3146 = phi <32 x float> [ %.lcssa31.lcssa61, %for_body7 ], [ %219, %for_body10 ]
  %.lcssa2944 = phi <32 x float> [ %.lcssa29.lcssa60, %for_body7 ], [ %213, %for_body10 ]
  %.lcssa43 = phi <32 x float> [ %.lcssa.lcssa58, %for_body7 ], [ %207, %for_body10 ]
  %92 = mul nuw nsw i64 %indvars.iv, 3
  %93 = add nsw i64 %65, %92
  %94 = mul nuw nsw i64 %indvars.iv, 96
  %95 = add nsw i64 %67, %94
  %96 = getelementptr inbounds float, float* %4, i64 %93
  %97 = load float, float* %96, align 4, !tbaa !72
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = getelementptr inbounds float, float* %7, i64 %95
  %101 = bitcast float* %100 to <32 x float>*
  %102 = load <32 x float>, <32 x float>* %101, align 64, !tbaa !90
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %102, <32 x float> %.lcssa43)
  %104 = add nsw i64 %93, 6
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !72
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %102, <32 x float> %.lcssa2944)
  %110 = add nsw i64 %93, 12
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !72
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %102, <32 x float> %.lcssa3146)
  %116 = add nsw i64 %93, 18
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !72
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %102, <32 x float> %.lcssa3348)
  %122 = add nsw i64 %93, 24
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !72
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %102, <32 x float> %.lcssa3550)
  %128 = add nsw i64 %93, 30
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !72
  %131 = insertelement <32 x float> undef, float %130, i32 0
  %132 = shufflevector <32 x float> %131, <32 x float> undef, <32 x i32> zeroinitializer
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %132, <32 x float> %102, <32 x float> %.lcssa3752)
  %134 = add nsw i64 %93, 36
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !72
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %102, <32 x float> %.lcssa3954)
  %140 = add nsw i64 %93, 42
  %141 = getelementptr inbounds float, float* %4, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !72
  %143 = insertelement <32 x float> undef, float %142, i32 0
  %144 = shufflevector <32 x float> %143, <32 x float> undef, <32 x i32> zeroinitializer
  %145 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %144, <32 x float> %102, <32 x float> %.lcssa4156)
  %146 = add nsw i64 %93, 1
  %147 = getelementptr inbounds float, float* %4, i64 %146
  %148 = load float, float* %147, align 4, !tbaa !72
  %149 = insertelement <32 x float> undef, float %148, i32 0
  %150 = shufflevector <32 x float> %149, <32 x float> undef, <32 x i32> zeroinitializer
  %151 = add nsw i64 %95, 32
  %152 = getelementptr inbounds float, float* %7, i64 %151
  %153 = bitcast float* %152 to <32 x float>*
  %154 = load <32 x float>, <32 x float>* %153, align 64, !tbaa !90
  %155 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %150, <32 x float> %154, <32 x float> %103)
  %156 = add nsw i64 %93, 7
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !72
  %159 = insertelement <32 x float> undef, float %158, i32 0
  %160 = shufflevector <32 x float> %159, <32 x float> undef, <32 x i32> zeroinitializer
  %161 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %160, <32 x float> %154, <32 x float> %109)
  %162 = add nsw i64 %93, 13
  %163 = getelementptr inbounds float, float* %4, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !72
  %165 = insertelement <32 x float> undef, float %164, i32 0
  %166 = shufflevector <32 x float> %165, <32 x float> undef, <32 x i32> zeroinitializer
  %167 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %166, <32 x float> %154, <32 x float> %115)
  %168 = add nsw i64 %93, 19
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !72
  %171 = insertelement <32 x float> undef, float %170, i32 0
  %172 = shufflevector <32 x float> %171, <32 x float> undef, <32 x i32> zeroinitializer
  %173 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %172, <32 x float> %154, <32 x float> %121)
  %174 = add nsw i64 %93, 25
  %175 = getelementptr inbounds float, float* %4, i64 %174
  %176 = load float, float* %175, align 4, !tbaa !72
  %177 = insertelement <32 x float> undef, float %176, i32 0
  %178 = shufflevector <32 x float> %177, <32 x float> undef, <32 x i32> zeroinitializer
  %179 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %178, <32 x float> %154, <32 x float> %127)
  %180 = add nsw i64 %93, 31
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !72
  %183 = insertelement <32 x float> undef, float %182, i32 0
  %184 = shufflevector <32 x float> %183, <32 x float> undef, <32 x i32> zeroinitializer
  %185 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %184, <32 x float> %154, <32 x float> %133)
  %186 = add nsw i64 %93, 37
  %187 = getelementptr inbounds float, float* %4, i64 %186
  %188 = load float, float* %187, align 4, !tbaa !72
  %189 = insertelement <32 x float> undef, float %188, i32 0
  %190 = shufflevector <32 x float> %189, <32 x float> undef, <32 x i32> zeroinitializer
  %191 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %190, <32 x float> %154, <32 x float> %139)
  %192 = add nsw i64 %93, 43
  %193 = getelementptr inbounds float, float* %4, i64 %192
  %194 = load float, float* %193, align 4, !tbaa !72
  %195 = insertelement <32 x float> undef, float %194, i32 0
  %196 = shufflevector <32 x float> %195, <32 x float> undef, <32 x i32> zeroinitializer
  %197 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %196, <32 x float> %154, <32 x float> %145)
  %198 = add nsw i64 %93, 2
  %199 = getelementptr inbounds float, float* %4, i64 %198
  %200 = load float, float* %199, align 4, !tbaa !72
  %201 = insertelement <32 x float> undef, float %200, i32 0
  %202 = shufflevector <32 x float> %201, <32 x float> undef, <32 x i32> zeroinitializer
  %203 = add nsw i64 %95, 64
  %204 = getelementptr inbounds float, float* %7, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  %206 = load <32 x float>, <32 x float>* %205, align 64, !tbaa !90
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %202, <32 x float> %206, <32 x float> %155)
  %208 = add nsw i64 %93, 8
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !72
  %211 = insertelement <32 x float> undef, float %210, i32 0
  %212 = shufflevector <32 x float> %211, <32 x float> undef, <32 x i32> zeroinitializer
  %213 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %212, <32 x float> %206, <32 x float> %161)
  %214 = add nsw i64 %93, 14
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !72
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %206, <32 x float> %167)
  %220 = add nsw i64 %93, 20
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !72
  %223 = insertelement <32 x float> undef, float %222, i32 0
  %224 = shufflevector <32 x float> %223, <32 x float> undef, <32 x i32> zeroinitializer
  %225 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %224, <32 x float> %206, <32 x float> %173)
  %226 = add nsw i64 %93, 26
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !72
  %229 = insertelement <32 x float> undef, float %228, i32 0
  %230 = shufflevector <32 x float> %229, <32 x float> undef, <32 x i32> zeroinitializer
  %231 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %230, <32 x float> %206, <32 x float> %179)
  %232 = add nsw i64 %93, 32
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !72
  %235 = insertelement <32 x float> undef, float %234, i32 0
  %236 = shufflevector <32 x float> %235, <32 x float> undef, <32 x i32> zeroinitializer
  %237 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %236, <32 x float> %206, <32 x float> %185)
  %238 = add nsw i64 %93, 38
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !72
  %241 = insertelement <32 x float> undef, float %240, i32 0
  %242 = shufflevector <32 x float> %241, <32 x float> undef, <32 x i32> zeroinitializer
  %243 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %242, <32 x float> %206, <32 x float> %191)
  %244 = add nsw i64 %93, 44
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !72
  %247 = insertelement <32 x float> undef, float %246, i32 0
  %248 = shufflevector <32 x float> %247, <32 x float> undef, <32 x i32> zeroinitializer
  %249 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %248, <32 x float> %206, <32 x float> %197)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 7
  br i1 %exitcond, label %for_end11, label %for_body10, !prof !29

for_end11:                                        ; preds = %for_body10
  %indvars.iv.next80 = add nuw nsw i64 %indvars.iv79, 1
  %exitcond81 = icmp eq i64 %indvars.iv.next80, 7
  br i1 %exitcond81, label %for_end8, label %for_body7, !prof !29

for_body19:                                       ; preds = %for_body19, %for_end5
  %indvars.iv89 = phi i64 [ 0, %for_end5 ], [ %indvars.iv.next90, %for_body19 ]
  %250 = shl nsw i64 %indvars.iv89, 8
  %251 = trunc i64 %250 to i32
  %252 = add i32 %58, %251
  %253 = getelementptr inbounds float, float* %53, i64 %250
  %254 = bitcast float* %253 to <32 x float>*
  %255 = load <32 x float>, <32 x float>* %254, align 64, !tbaa !87
  %256 = fadd <32 x float> %63, %255
  %257 = fcmp ogt <32 x float> %256, zeroinitializer
  %258 = select <32 x i1> %257, <32 x float> %256, <32 x float> zeroinitializer
  %259 = sext i32 %252 to i64
  %260 = getelementptr inbounds float, float* %10, i64 %259
  %261 = bitcast float* %260 to <32 x float>*
  store <32 x float> %258, <32 x float>* %261, align 64, !tbaa !93
  %262 = or i64 %250, 32
  %263 = trunc i64 %262 to i32
  %264 = add i32 %58, %263
  %265 = getelementptr inbounds float, float* %53, i64 %262
  %266 = bitcast float* %265 to <32 x float>*
  %267 = load <32 x float>, <32 x float>* %266, align 64, !tbaa !87
  %268 = fadd <32 x float> %63, %267
  %269 = fcmp ogt <32 x float> %268, zeroinitializer
  %270 = select <32 x i1> %269, <32 x float> %268, <32 x float> zeroinitializer
  %271 = sext i32 %264 to i64
  %272 = getelementptr inbounds float, float* %10, i64 %271
  %273 = bitcast float* %272 to <32 x float>*
  store <32 x float> %270, <32 x float>* %273, align 64, !tbaa !93
  %274 = or i64 %250, 64
  %275 = trunc i64 %274 to i32
  %276 = add i32 %58, %275
  %277 = getelementptr inbounds float, float* %53, i64 %274
  %278 = bitcast float* %277 to <32 x float>*
  %279 = load <32 x float>, <32 x float>* %278, align 64, !tbaa !87
  %280 = fadd <32 x float> %63, %279
  %281 = fcmp ogt <32 x float> %280, zeroinitializer
  %282 = select <32 x i1> %281, <32 x float> %280, <32 x float> zeroinitializer
  %283 = sext i32 %276 to i64
  %284 = getelementptr inbounds float, float* %10, i64 %283
  %285 = bitcast float* %284 to <32 x float>*
  store <32 x float> %282, <32 x float>* %285, align 64, !tbaa !93
  %286 = or i64 %250, 96
  %287 = trunc i64 %286 to i32
  %288 = add i32 %58, %287
  %289 = getelementptr inbounds float, float* %53, i64 %286
  %290 = bitcast float* %289 to <32 x float>*
  %291 = load <32 x float>, <32 x float>* %290, align 64, !tbaa !87
  %292 = fadd <32 x float> %63, %291
  %293 = fcmp ogt <32 x float> %292, zeroinitializer
  %294 = select <32 x i1> %293, <32 x float> %292, <32 x float> zeroinitializer
  %295 = sext i32 %288 to i64
  %296 = getelementptr inbounds float, float* %10, i64 %295
  %297 = bitcast float* %296 to <32 x float>*
  store <32 x float> %294, <32 x float>* %297, align 64, !tbaa !93
  %298 = or i64 %250, 128
  %299 = trunc i64 %298 to i32
  %300 = add i32 %58, %299
  %301 = getelementptr inbounds float, float* %53, i64 %298
  %302 = bitcast float* %301 to <32 x float>*
  %303 = load <32 x float>, <32 x float>* %302, align 64, !tbaa !87
  %304 = fadd <32 x float> %63, %303
  %305 = fcmp ogt <32 x float> %304, zeroinitializer
  %306 = select <32 x i1> %305, <32 x float> %304, <32 x float> zeroinitializer
  %307 = sext i32 %300 to i64
  %308 = getelementptr inbounds float, float* %10, i64 %307
  %309 = bitcast float* %308 to <32 x float>*
  store <32 x float> %306, <32 x float>* %309, align 64, !tbaa !93
  %310 = or i64 %250, 160
  %311 = trunc i64 %310 to i32
  %312 = add i32 %58, %311
  %313 = getelementptr inbounds float, float* %53, i64 %310
  %314 = bitcast float* %313 to <32 x float>*
  %315 = load <32 x float>, <32 x float>* %314, align 64, !tbaa !87
  %316 = fadd <32 x float> %63, %315
  %317 = fcmp ogt <32 x float> %316, zeroinitializer
  %318 = select <32 x i1> %317, <32 x float> %316, <32 x float> zeroinitializer
  %319 = sext i32 %312 to i64
  %320 = getelementptr inbounds float, float* %10, i64 %319
  %321 = bitcast float* %320 to <32 x float>*
  store <32 x float> %318, <32 x float>* %321, align 64, !tbaa !93
  %322 = or i64 %250, 192
  %323 = trunc i64 %322 to i32
  %324 = add i32 %58, %323
  %325 = getelementptr inbounds float, float* %53, i64 %322
  %326 = bitcast float* %325 to <32 x float>*
  %327 = load <32 x float>, <32 x float>* %326, align 64, !tbaa !87
  %328 = fadd <32 x float> %63, %327
  %329 = fcmp ogt <32 x float> %328, zeroinitializer
  %330 = select <32 x i1> %329, <32 x float> %328, <32 x float> zeroinitializer
  %331 = sext i32 %324 to i64
  %332 = getelementptr inbounds float, float* %10, i64 %331
  %333 = bitcast float* %332 to <32 x float>*
  store <32 x float> %330, <32 x float>* %333, align 64, !tbaa !93
  %334 = or i64 %250, 224
  %335 = trunc i64 %334 to i32
  %336 = add i32 %58, %335
  %337 = getelementptr inbounds float, float* %53, i64 %334
  %338 = bitcast float* %337 to <32 x float>*
  %339 = load <32 x float>, <32 x float>* %338, align 64, !tbaa !87
  %340 = fadd <32 x float> %63, %339
  %341 = fcmp ogt <32 x float> %340, zeroinitializer
  %342 = select <32 x i1> %341, <32 x float> %340, <32 x float> zeroinitializer
  %343 = sext i32 %336 to i64
  %344 = getelementptr inbounds float, float* %10, i64 %343
  %345 = bitcast float* %344 to <32 x float>*
  store <32 x float> %342, <32 x float>* %345, align 64, !tbaa !93
  %indvars.iv.next90 = add nuw nsw i64 %indvars.iv89, 1
  %exitcond91 = icmp eq i64 %indvars.iv.next90, 14
  br i1 %exitcond91, label %for_end20, label %for_body19, !prof !29

for_end20:                                        ; preds = %for_body19
  %346 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %347 = tail call i32 %346(i32 1, i32 %16, i8* %33)
  %348 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %349 = tail call i32 %348(i32 1, i32 %16, i8* nonnull %31)
  %350 = add nsw i32 %29, 1
  %351 = icmp slt i32 %350, %24
  br i1 %351, label %for_body, label %for_end, !prof !19
}

; Function Attrs: nounwind readnone speculatable
declare <32 x float> @llvm.fmuladd.v32f32(<32 x float>, <32 x float>, <32 x float>) #1

define dllexport i32 @fused_layout_transform_46(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !96 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !98, metadata !DIExpression()), !dbg !101
  call void @llvm.dbg.value(metadata i8* %1, metadata !99, metadata !DIExpression()), !dbg !101
  call void @llvm.dbg.value(metadata i32 %2, metadata !100, metadata !DIExpression()), !dbg !101
  %3 = bitcast i8* %0 to %1**, !dbg !101
  %4 = load %1*, %1** %3, align 8, !dbg !101
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !101
  %6 = bitcast i8* %5 to %1**, !dbg !101
  %7 = load %1*, %1** %6, align 8, !dbg !101
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !101
  %9 = load i8*, i8** %8, align 8, !dbg !101
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !101
  %11 = load i8*, i8** %10, align 8, !dbg !101
  %12 = tail call fastcc i32 @fused_layout_transform_46_compute_(i8* %11, i8* %9), !dbg !101
  ret i32 %12, !dbg !101
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_46_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %9, align 8
  %3 = getelementptr inbounds %9, %9* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %9, %9* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %9* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.5, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.5(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 223
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 224
  %15 = select i1 %14, i32 %13, i32 224
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 224
  %18 = select i1 %17, i32 %16, i32 224
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 896
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 56
  %27 = shl nsw i32 %26, 4
  %28 = srem i32 %25, 56
  %29 = mul nsw i32 %28, 1792
  %30 = srem i32 %27, 32
  %31 = sdiv i32 %25, 112
  %32 = mul nsw i32 %31, 100352
  %33 = insertelement <8 x i32> undef, i32 %27, i32 0
  %34 = shufflevector <8 x i32> %33, <8 x i32> undef, <8 x i32> zeroinitializer
  %35 = or <8 x i32> %34, <i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8>
  %36 = sdiv <8 x i32> %35, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %37 = mul <8 x i32> %36, <i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32, i32 32>
  %38 = sub <8 x i32> %35, %37
  %39 = mul nsw <8 x i32> %36, <i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352, i32 100352>
  %40 = insertelement <4 x i32> undef, i32 %27, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = or <4 x i32> %41, <i32 9, i32 10, i32 11, i32 12>
  %43 = sdiv <4 x i32> %42, <i32 32, i32 32, i32 32, i32 32>
  %44 = mul <4 x i32> %43, <i32 32, i32 32, i32 32, i32 32>
  %45 = sub <4 x i32> %42, %44
  %46 = mul nsw <4 x i32> %43, <i32 100352, i32 100352, i32 100352, i32 100352>
  %47 = or i32 %27, 13
  %48 = srem i32 %47, 32
  %49 = sdiv i32 %47, 32
  %50 = mul nsw i32 %49, 100352
  %51 = or i32 %27, 14
  %52 = srem i32 %51, 32
  %53 = sdiv i32 %51, 32
  %54 = mul nsw i32 %53, 100352
  %55 = or i32 %27, 15
  %56 = srem i32 %55, 32
  %57 = sdiv i32 %55, 32
  %58 = mul nsw i32 %57, 100352
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %59 = phi i32 [ 0, %for_body ], [ %205, %for_body2 ]
  %60 = shl i64 %indvars.iv, 4
  %61 = add nsw i64 %60, %24
  %62 = shl i32 %59, 5
  %63 = add nsw i32 %62, %29
  %64 = add i32 %63, %30
  %65 = add i32 %64, %32
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float* %7, i64 %66
  %68 = bitcast float* %67 to i32*
  %69 = load i32, i32* %68, align 4, !tbaa !102
  %70 = getelementptr inbounds float, float* %4, i64 %61
  %71 = bitcast float* %70 to i32*
  store i32 %69, i32* %71, align 4, !tbaa !105
  %72 = or i64 %61, 1
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %73 = shl i32 %indvars.iv.tr, 5
  %74 = add i32 %29, %73
  %75 = insertelement <8 x i32> undef, i32 %74, i32 0
  %76 = shufflevector <8 x i32> %75, <8 x i32> undef, <8 x i32> zeroinitializer
  %77 = add <8 x i32> %76, %38
  %78 = add <8 x i32> %77, %39
  %79 = extractelement <8 x i32> %78, i32 0
  %80 = sext i32 %79 to i64
  %81 = getelementptr inbounds float, float* %7, i64 %80
  %82 = bitcast float* %81 to i32*
  %83 = load i32, i32* %82, align 4, !tbaa !102
  %84 = getelementptr inbounds float, float* %4, i64 %72
  %85 = bitcast float* %84 to i32*
  store i32 %83, i32* %85, align 4, !tbaa !105
  %86 = or i64 %61, 2
  %87 = extractelement <8 x i32> %78, i32 1
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = bitcast float* %89 to i32*
  %91 = load i32, i32* %90, align 4, !tbaa !102
  %92 = getelementptr inbounds float, float* %4, i64 %86
  %93 = bitcast float* %92 to i32*
  store i32 %91, i32* %93, align 4, !tbaa !105
  %94 = or i64 %61, 3
  %95 = extractelement <8 x i32> %78, i32 2
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds float, float* %7, i64 %96
  %98 = bitcast float* %97 to i32*
  %99 = load i32, i32* %98, align 4, !tbaa !102
  %100 = getelementptr inbounds float, float* %4, i64 %94
  %101 = bitcast float* %100 to i32*
  store i32 %99, i32* %101, align 4, !tbaa !105
  %102 = or i64 %61, 4
  %103 = extractelement <8 x i32> %78, i32 3
  %104 = sext i32 %103 to i64
  %105 = getelementptr inbounds float, float* %7, i64 %104
  %106 = bitcast float* %105 to i32*
  %107 = load i32, i32* %106, align 4, !tbaa !102
  %108 = getelementptr inbounds float, float* %4, i64 %102
  %109 = bitcast float* %108 to i32*
  store i32 %107, i32* %109, align 4, !tbaa !105
  %110 = or i64 %61, 5
  %111 = extractelement <8 x i32> %78, i32 4
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds float, float* %7, i64 %112
  %114 = bitcast float* %113 to i32*
  %115 = load i32, i32* %114, align 4, !tbaa !102
  %116 = getelementptr inbounds float, float* %4, i64 %110
  %117 = bitcast float* %116 to i32*
  store i32 %115, i32* %117, align 4, !tbaa !105
  %118 = or i64 %61, 6
  %119 = extractelement <8 x i32> %78, i32 5
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds float, float* %7, i64 %120
  %122 = bitcast float* %121 to i32*
  %123 = load i32, i32* %122, align 4, !tbaa !102
  %124 = getelementptr inbounds float, float* %4, i64 %118
  %125 = bitcast float* %124 to i32*
  store i32 %123, i32* %125, align 4, !tbaa !105
  %126 = or i64 %61, 7
  %127 = extractelement <8 x i32> %78, i32 6
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds float, float* %7, i64 %128
  %130 = bitcast float* %129 to i32*
  %131 = load i32, i32* %130, align 4, !tbaa !102
  %132 = getelementptr inbounds float, float* %4, i64 %126
  %133 = bitcast float* %132 to i32*
  store i32 %131, i32* %133, align 4, !tbaa !105
  %134 = or i64 %61, 8
  %135 = extractelement <8 x i32> %78, i32 7
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = bitcast float* %137 to i32*
  %139 = load i32, i32* %138, align 4, !tbaa !102
  %140 = getelementptr inbounds float, float* %4, i64 %134
  %141 = bitcast float* %140 to i32*
  store i32 %139, i32* %141, align 4, !tbaa !105
  %142 = or i64 %61, 9
  %143 = insertelement <4 x i32> undef, i32 %74, i32 0
  %144 = shufflevector <4 x i32> %143, <4 x i32> undef, <4 x i32> zeroinitializer
  %145 = add <4 x i32> %144, %45
  %146 = add <4 x i32> %145, %46
  %147 = extractelement <4 x i32> %146, i32 0
  %148 = sext i32 %147 to i64
  %149 = getelementptr inbounds float, float* %7, i64 %148
  %150 = bitcast float* %149 to i32*
  %151 = load i32, i32* %150, align 4, !tbaa !102
  %152 = getelementptr inbounds float, float* %4, i64 %142
  %153 = bitcast float* %152 to i32*
  store i32 %151, i32* %153, align 4, !tbaa !105
  %154 = or i64 %61, 10
  %155 = extractelement <4 x i32> %146, i32 1
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = bitcast float* %157 to i32*
  %159 = load i32, i32* %158, align 4, !tbaa !102
  %160 = getelementptr inbounds float, float* %4, i64 %154
  %161 = bitcast float* %160 to i32*
  store i32 %159, i32* %161, align 4, !tbaa !105
  %162 = or i64 %61, 11
  %163 = extractelement <4 x i32> %146, i32 2
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds float, float* %7, i64 %164
  %166 = bitcast float* %165 to i32*
  %167 = load i32, i32* %166, align 4, !tbaa !102
  %168 = getelementptr inbounds float, float* %4, i64 %162
  %169 = bitcast float* %168 to i32*
  store i32 %167, i32* %169, align 4, !tbaa !105
  %170 = or i64 %61, 12
  %171 = extractelement <4 x i32> %146, i32 3
  %172 = sext i32 %171 to i64
  %173 = getelementptr inbounds float, float* %7, i64 %172
  %174 = bitcast float* %173 to i32*
  %175 = load i32, i32* %174, align 4, !tbaa !102
  %176 = getelementptr inbounds float, float* %4, i64 %170
  %177 = bitcast float* %176 to i32*
  store i32 %175, i32* %177, align 4, !tbaa !105
  %178 = or i64 %61, 13
  %179 = add i32 %74, %48
  %180 = add i32 %179, %50
  %181 = sext i32 %180 to i64
  %182 = getelementptr inbounds float, float* %7, i64 %181
  %183 = bitcast float* %182 to i32*
  %184 = load i32, i32* %183, align 4, !tbaa !102
  %185 = getelementptr inbounds float, float* %4, i64 %178
  %186 = bitcast float* %185 to i32*
  store i32 %184, i32* %186, align 4, !tbaa !105
  %187 = or i64 %61, 14
  %188 = add i32 %74, %52
  %189 = add i32 %188, %54
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds float, float* %7, i64 %190
  %192 = bitcast float* %191 to i32*
  %193 = load i32, i32* %192, align 4, !tbaa !102
  %194 = getelementptr inbounds float, float* %4, i64 %187
  %195 = bitcast float* %194 to i32*
  store i32 %193, i32* %195, align 4, !tbaa !105
  %196 = or i64 %61, 15
  %197 = add i32 %74, %56
  %198 = add i32 %197, %58
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to i32*
  %202 = load i32, i32* %201, align 4, !tbaa !102
  %203 = getelementptr inbounds float, float* %4, i64 %196
  %204 = bitcast float* %203 to i32*
  store i32 %202, i32* %204, align 4, !tbaa !105
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %205 = add nuw nsw i32 %59, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %206 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %206, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_3(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !108 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !110, metadata !DIExpression()), !dbg !113
  call void @llvm.dbg.value(metadata i8* %1, metadata !111, metadata !DIExpression()), !dbg !113
  call void @llvm.dbg.value(metadata i32 %2, metadata !112, metadata !DIExpression()), !dbg !113
  %3 = bitcast i8* %0 to %1**, !dbg !113
  %4 = load %1*, %1** %3, align 8, !dbg !113
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !113
  %6 = bitcast i8* %5 to %1**, !dbg !113
  %7 = load %1*, %1** %6, align 8, !dbg !113
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !113
  %9 = bitcast i8* %8 to %1**, !dbg !113
  %10 = load %1*, %1** %9, align 8, !dbg !113
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !113
  %12 = bitcast i8* %11 to %1**, !dbg !113
  %13 = load %1*, %1** %12, align 8, !dbg !113
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !113
  %15 = load i8*, i8** %14, align 8, !dbg !113
  %16 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !113
  %17 = load i8*, i8** %16, align 8, !dbg !113
  %18 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !113
  %19 = load i8*, i8** %18, align 8, !dbg !113
  %20 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !113
  %21 = load i8*, i8** %20, align 8, !dbg !113
  %22 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_3_compute_(i8* %15, i8* %17, i8* %21, i8* %19), !dbg !113
  ret i32 %22, !dbg !113
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %4 = alloca %10, align 8
  %5 = getelementptr inbounds %10, %10* %4, i64 0, i32 0
  store i8* %0, i8** %5, align 8
  %6 = getelementptr inbounds %10, %10* %4, i64 0, i32 1
  store i8* %1, i8** %6, align 8
  %7 = getelementptr inbounds %10, %10* %4, i64 0, i32 2
  store i8* %2, i8** %7, align 8
  %8 = getelementptr inbounds %10, %10* %4, i64 0, i32 3
  store i8* %3, i8** %8, align 8
  %9 = bitcast %10* %4 to i8*
  %10 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %11 = call i32 %10(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.6, i8* nonnull %9, i32 0)
  ret i32 %11
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.6(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 447
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 448
  %21 = select i1 %20, i32 %19, i32 448
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 448
  %24 = select i1 %23, i32 %22, i32 448
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv27 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next28, %for_end3 ]
  %30 = trunc i64 %indvars.iv27 to i32
  %31 = srem i32 %30, 7
  %32 = mul nsw i32 %31, 28672
  %33 = sdiv i32 %30, 7
  %34 = shl i32 %33, 15
  %35 = sext i32 %32 to i64
  %36 = sext i32 %34 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %37 = phi <32 x float> [ zeroinitializer, %for_body ], [ %90, %for_body2 ]
  %38 = phi <32 x float> [ zeroinitializer, %for_body ], [ %84, %for_body2 ]
  %39 = phi <32 x float> [ zeroinitializer, %for_body ], [ %78, %for_body2 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %72, %for_body2 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %66, %for_body2 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %60, %for_body2 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %54, %for_body2 ]
  %44 = add nuw nsw i64 %indvars.iv, %35
  %45 = getelementptr inbounds float, float* %4, i64 %44
  %46 = load float, float* %45, align 4, !tbaa !114
  %47 = insertelement <32 x float> undef, float %46, i32 0
  %48 = shufflevector <32 x float> %47, <32 x float> undef, <32 x i32> zeroinitializer
  %49 = shl i64 %indvars.iv, 5
  %50 = add nuw nsw i64 %49, %36
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = bitcast float* %51 to <32 x float>*
  %53 = load <32 x float>, <32 x float>* %52, align 64, !tbaa !117
  %54 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %48, <32 x float> %53, <32 x float> %43)
  %55 = add nsw i64 %44, 2048
  %56 = getelementptr inbounds float, float* %4, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !114
  %58 = insertelement <32 x float> undef, float %57, i32 0
  %59 = shufflevector <32 x float> %58, <32 x float> undef, <32 x i32> zeroinitializer
  %60 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %59, <32 x float> %53, <32 x float> %42)
  %61 = add nsw i64 %44, 4096
  %62 = getelementptr inbounds float, float* %4, i64 %61
  %63 = load float, float* %62, align 4, !tbaa !114
  %64 = insertelement <32 x float> undef, float %63, i32 0
  %65 = shufflevector <32 x float> %64, <32 x float> undef, <32 x i32> zeroinitializer
  %66 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %53, <32 x float> %41)
  %67 = add nsw i64 %44, 6144
  %68 = getelementptr inbounds float, float* %4, i64 %67
  %69 = load float, float* %68, align 4, !tbaa !114
  %70 = insertelement <32 x float> undef, float %69, i32 0
  %71 = shufflevector <32 x float> %70, <32 x float> undef, <32 x i32> zeroinitializer
  %72 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %53, <32 x float> %40)
  %73 = add nsw i64 %44, 8192
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !114
  %76 = insertelement <32 x float> undef, float %75, i32 0
  %77 = shufflevector <32 x float> %76, <32 x float> undef, <32 x i32> zeroinitializer
  %78 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %53, <32 x float> %39)
  %79 = add nsw i64 %44, 10240
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !114
  %82 = insertelement <32 x float> undef, float %81, i32 0
  %83 = shufflevector <32 x float> %82, <32 x float> undef, <32 x i32> zeroinitializer
  %84 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %53, <32 x float> %38)
  %85 = add nsw i64 %44, 12288
  %86 = getelementptr inbounds float, float* %4, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !114
  %88 = insertelement <32 x float> undef, float %87, i32 0
  %89 = shufflevector <32 x float> %88, <32 x float> undef, <32 x i32> zeroinitializer
  %90 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %53, <32 x float> %37)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %91 = mul nsw i64 %indvars.iv27, 224
  %92 = shl nsw i32 %33, 5
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %13, i64 %93
  %95 = bitcast float* %94 to <32 x float>*
  %96 = load <32 x float>, <32 x float>* %95, align 64, !tbaa !120
  %97 = fadd <32 x float> %96, %54
  %98 = getelementptr inbounds float, float* %10, i64 %91
  %99 = bitcast float* %98 to <32 x float>*
  store <32 x float> %97, <32 x float>* %99, align 64, !tbaa !123
  %100 = add nsw i64 %91, 32
  %101 = fadd <32 x float> %96, %60
  %102 = getelementptr inbounds float, float* %10, i64 %100
  %103 = bitcast float* %102 to <32 x float>*
  store <32 x float> %101, <32 x float>* %103, align 64, !tbaa !123
  %104 = add nsw i64 %91, 64
  %105 = fadd <32 x float> %96, %66
  %106 = getelementptr inbounds float, float* %10, i64 %104
  %107 = bitcast float* %106 to <32 x float>*
  store <32 x float> %105, <32 x float>* %107, align 64, !tbaa !123
  %108 = add nsw i64 %91, 96
  %109 = fadd <32 x float> %96, %72
  %110 = getelementptr inbounds float, float* %10, i64 %108
  %111 = bitcast float* %110 to <32 x float>*
  store <32 x float> %109, <32 x float>* %111, align 64, !tbaa !123
  %112 = add nsw i64 %91, 128
  %113 = fadd <32 x float> %96, %78
  %114 = getelementptr inbounds float, float* %10, i64 %112
  %115 = bitcast float* %114 to <32 x float>*
  store <32 x float> %113, <32 x float>* %115, align 64, !tbaa !123
  %116 = add nsw i64 %91, 160
  %117 = fadd <32 x float> %96, %84
  %118 = getelementptr inbounds float, float* %10, i64 %116
  %119 = bitcast float* %118 to <32 x float>*
  store <32 x float> %117, <32 x float>* %119, align 64, !tbaa !123
  %120 = add nsw i64 %91, 192
  %121 = fadd <32 x float> %96, %90
  %122 = getelementptr inbounds float, float* %10, i64 %120
  %123 = bitcast float* %122 to <32 x float>*
  store <32 x float> %121, <32 x float>* %123, align 64, !tbaa !123
  %indvars.iv.next28 = add nsw i64 %indvars.iv27, 1
  %124 = icmp slt i64 %indvars.iv.next28, %29
  br i1 %124, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_36(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !126 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !128, metadata !DIExpression()), !dbg !131
  call void @llvm.dbg.value(metadata i8* %1, metadata !129, metadata !DIExpression()), !dbg !131
  call void @llvm.dbg.value(metadata i32 %2, metadata !130, metadata !DIExpression()), !dbg !131
  %3 = bitcast i8* %0 to %1**, !dbg !131
  %4 = load %1*, %1** %3, align 8, !dbg !131
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !131
  %6 = bitcast i8* %5 to %1**, !dbg !131
  %7 = load %1*, %1** %6, align 8, !dbg !131
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !131
  %9 = load i8*, i8** %8, align 8, !dbg !131
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !131
  %11 = load i8*, i8** %10, align 8, !dbg !131
  %12 = tail call fastcc i32 @fused_layout_transform_36_compute_(i8* %11, i8* %9), !dbg !131
  ret i32 %12, !dbg !131
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_36_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %11, align 8
  %3 = getelementptr inbounds %11, %11* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %11, %11* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %11* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.7, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.7(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 14
  %27 = mul nsw i32 %26, 896
  %28 = sdiv i32 %25, 14
  %29 = mul nsw i32 %28, 25088
  %30 = add i32 %27, %29
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %31 = add nsw i64 %24, %indvars.iv
  %32 = trunc i64 %indvars.iv to i32
  %33 = and i32 %32, 63
  %34 = lshr i32 %32, 6
  %35 = mul nsw i32 %34, 12544
  %36 = add i32 %30, %35
  %37 = or i32 %36, %33
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds float, float* %7, i64 %38
  %40 = bitcast float* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !132
  %42 = getelementptr inbounds float, float* %4, i64 %31
  %43 = bitcast float* %42 to i32*
  store i32 %41, i32* %43, align 4, !tbaa !135
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %44 = or i64 %24, 128
  %45 = or i32 %30, 64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %46 = add nsw i64 %44, %indvars.iv.1
  %47 = trunc i64 %indvars.iv.1 to i32
  %48 = and i32 %47, 63
  %49 = lshr i32 %47, 6
  %50 = mul nsw i32 %49, 12544
  %51 = add i32 %45, %50
  %52 = or i32 %51, %48
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to i32*
  %56 = load i32, i32* %55, align 4, !tbaa !132
  %57 = getelementptr inbounds float, float* %4, i64 %46
  %58 = bitcast float* %57 to i32*
  store i32 %56, i32* %58, align 4, !tbaa !135
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %59 = add nsw i64 %24, 256
  %60 = add i32 %30, 128
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %61 = add nsw i64 %59, %indvars.iv.2
  %62 = trunc i64 %indvars.iv.2 to i32
  %63 = and i32 %62, 63
  %64 = lshr i32 %62, 6
  %65 = mul nsw i32 %64, 12544
  %66 = add i32 %60, %65
  %67 = or i32 %66, %63
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to i32*
  %71 = load i32, i32* %70, align 4, !tbaa !132
  %72 = getelementptr inbounds float, float* %4, i64 %61
  %73 = bitcast float* %72 to i32*
  store i32 %71, i32* %73, align 4, !tbaa !135
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 128
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  %74 = add nsw i64 %24, 384
  %75 = add i32 %30, 192
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %76 = add nsw i64 %74, %indvars.iv.3
  %77 = trunc i64 %indvars.iv.3 to i32
  %78 = and i32 %77, 63
  %79 = lshr i32 %77, 6
  %80 = mul nsw i32 %79, 12544
  %81 = add i32 %75, %80
  %82 = or i32 %81, %78
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = bitcast float* %84 to i32*
  %86 = load i32, i32* %85, align 4, !tbaa !132
  %87 = getelementptr inbounds float, float* %4, i64 %76
  %88 = bitcast float* %87 to i32*
  store i32 %86, i32* %88, align 4, !tbaa !135
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 128
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  %89 = add nsw i64 %24, 512
  %90 = add i32 %30, 256
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %91 = add nsw i64 %89, %indvars.iv.4
  %92 = trunc i64 %indvars.iv.4 to i32
  %93 = and i32 %92, 63
  %94 = lshr i32 %92, 6
  %95 = mul nsw i32 %94, 12544
  %96 = add i32 %90, %95
  %97 = or i32 %96, %93
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = bitcast float* %99 to i32*
  %101 = load i32, i32* %100, align 4, !tbaa !132
  %102 = getelementptr inbounds float, float* %4, i64 %91
  %103 = bitcast float* %102 to i32*
  store i32 %101, i32* %103, align 4, !tbaa !135
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 128
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  %104 = add nsw i64 %24, 640
  %105 = add i32 %30, 320
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %106 = add nsw i64 %104, %indvars.iv.5
  %107 = trunc i64 %indvars.iv.5 to i32
  %108 = and i32 %107, 63
  %109 = lshr i32 %107, 6
  %110 = mul nsw i32 %109, 12544
  %111 = add i32 %105, %110
  %112 = or i32 %111, %108
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to i32*
  %116 = load i32, i32* %115, align 4, !tbaa !132
  %117 = getelementptr inbounds float, float* %4, i64 %106
  %118 = bitcast float* %117 to i32*
  store i32 %116, i32* %118, align 4, !tbaa !135
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 128
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  %119 = add nsw i64 %24, 768
  %120 = add i32 %30, 384
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %121 = add nsw i64 %119, %indvars.iv.6
  %122 = trunc i64 %indvars.iv.6 to i32
  %123 = and i32 %122, 63
  %124 = lshr i32 %122, 6
  %125 = mul nsw i32 %124, 12544
  %126 = add i32 %120, %125
  %127 = or i32 %126, %123
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds float, float* %7, i64 %128
  %130 = bitcast float* %129 to i32*
  %131 = load i32, i32* %130, align 4, !tbaa !132
  %132 = getelementptr inbounds float, float* %4, i64 %121
  %133 = bitcast float* %132 to i32*
  store i32 %131, i32* %133, align 4, !tbaa !135
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 128
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  %134 = add nsw i64 %24, 896
  %135 = add i32 %30, 448
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %136 = add nsw i64 %134, %indvars.iv.7
  %137 = trunc i64 %indvars.iv.7 to i32
  %138 = and i32 %137, 63
  %139 = lshr i32 %137, 6
  %140 = mul nsw i32 %139, 12544
  %141 = add i32 %135, %140
  %142 = or i32 %141, %138
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to i32*
  %146 = load i32, i32* %145, align 4, !tbaa !132
  %147 = getelementptr inbounds float, float* %4, i64 %136
  %148 = bitcast float* %147 to i32*
  store i32 %146, i32* %148, align 4, !tbaa !135
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 128
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !29

for_end6.7:                                       ; preds = %for_body5.7
  %149 = add nsw i64 %24, 1024
  %150 = add i32 %30, 512
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %151 = add nsw i64 %149, %indvars.iv.8
  %152 = trunc i64 %indvars.iv.8 to i32
  %153 = and i32 %152, 63
  %154 = lshr i32 %152, 6
  %155 = mul nsw i32 %154, 12544
  %156 = add i32 %150, %155
  %157 = or i32 %156, %153
  %158 = sext i32 %157 to i64
  %159 = getelementptr inbounds float, float* %7, i64 %158
  %160 = bitcast float* %159 to i32*
  %161 = load i32, i32* %160, align 4, !tbaa !132
  %162 = getelementptr inbounds float, float* %4, i64 %151
  %163 = bitcast float* %162 to i32*
  store i32 %161, i32* %163, align 4, !tbaa !135
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 128
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !29

for_end6.8:                                       ; preds = %for_body5.8
  %164 = add nsw i64 %24, 1152
  %165 = add i32 %30, 576
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %166 = add nsw i64 %164, %indvars.iv.9
  %167 = trunc i64 %indvars.iv.9 to i32
  %168 = and i32 %167, 63
  %169 = lshr i32 %167, 6
  %170 = mul nsw i32 %169, 12544
  %171 = add i32 %165, %170
  %172 = or i32 %171, %168
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to i32*
  %176 = load i32, i32* %175, align 4, !tbaa !132
  %177 = getelementptr inbounds float, float* %4, i64 %166
  %178 = bitcast float* %177 to i32*
  store i32 %176, i32* %178, align 4, !tbaa !135
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 128
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !29

for_end6.9:                                       ; preds = %for_body5.9
  %179 = add nsw i64 %24, 1280
  %180 = add i32 %30, 640
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %181 = add nsw i64 %179, %indvars.iv.10
  %182 = trunc i64 %indvars.iv.10 to i32
  %183 = and i32 %182, 63
  %184 = lshr i32 %182, 6
  %185 = mul nsw i32 %184, 12544
  %186 = add i32 %180, %185
  %187 = or i32 %186, %183
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4, !tbaa !132
  %192 = getelementptr inbounds float, float* %4, i64 %181
  %193 = bitcast float* %192 to i32*
  store i32 %191, i32* %193, align 4, !tbaa !135
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 128
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !29

for_end6.10:                                      ; preds = %for_body5.10
  %194 = add nsw i64 %24, 1408
  %195 = add i32 %30, 704
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %196 = add nsw i64 %194, %indvars.iv.11
  %197 = trunc i64 %indvars.iv.11 to i32
  %198 = and i32 %197, 63
  %199 = lshr i32 %197, 6
  %200 = mul nsw i32 %199, 12544
  %201 = add i32 %195, %200
  %202 = or i32 %201, %198
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds float, float* %7, i64 %203
  %205 = bitcast float* %204 to i32*
  %206 = load i32, i32* %205, align 4, !tbaa !132
  %207 = getelementptr inbounds float, float* %4, i64 %196
  %208 = bitcast float* %207 to i32*
  store i32 %206, i32* %208, align 4, !tbaa !135
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 128
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !29

for_end6.11:                                      ; preds = %for_body5.11
  %209 = add nsw i64 %24, 1536
  %210 = add i32 %30, 768
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %211 = add nsw i64 %209, %indvars.iv.12
  %212 = trunc i64 %indvars.iv.12 to i32
  %213 = and i32 %212, 63
  %214 = lshr i32 %212, 6
  %215 = mul nsw i32 %214, 12544
  %216 = add i32 %210, %215
  %217 = or i32 %216, %213
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds float, float* %7, i64 %218
  %220 = bitcast float* %219 to i32*
  %221 = load i32, i32* %220, align 4, !tbaa !132
  %222 = getelementptr inbounds float, float* %4, i64 %211
  %223 = bitcast float* %222 to i32*
  store i32 %221, i32* %223, align 4, !tbaa !135
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 128
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !29

for_end6.12:                                      ; preds = %for_body5.12
  %224 = add nsw i64 %24, 1664
  %225 = add i32 %30, 832
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %226 = add nsw i64 %224, %indvars.iv.13
  %227 = trunc i64 %indvars.iv.13 to i32
  %228 = and i32 %227, 63
  %229 = lshr i32 %227, 6
  %230 = mul nsw i32 %229, 12544
  %231 = add i32 %225, %230
  %232 = or i32 %231, %228
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to i32*
  %236 = load i32, i32* %235, align 4, !tbaa !132
  %237 = getelementptr inbounds float, float* %4, i64 %226
  %238 = bitcast float* %237 to i32*
  store i32 %236, i32* %238, align 4, !tbaa !135
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 128
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !29

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %239 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %239, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_35(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !138 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !140, metadata !DIExpression()), !dbg !143
  call void @llvm.dbg.value(metadata i8* %1, metadata !141, metadata !DIExpression()), !dbg !143
  call void @llvm.dbg.value(metadata i32 %2, metadata !142, metadata !DIExpression()), !dbg !143
  %3 = bitcast i8* %0 to %1**, !dbg !143
  %4 = load %1*, %1** %3, align 8, !dbg !143
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !143
  %6 = bitcast i8* %5 to %1**, !dbg !143
  %7 = load %1*, %1** %6, align 8, !dbg !143
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !143
  %9 = load i8*, i8** %8, align 8, !dbg !143
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !143
  %11 = load i8*, i8** %10, align 8, !dbg !143
  %12 = tail call fastcc i32 @fused_layout_transform_35_compute_(i8* %11, i8* %9), !dbg !143
  ret i32 %12, !dbg !143
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_35_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %12, align 8
  %3 = getelementptr inbounds %12, %12* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %12, %12* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %12* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.8, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.8(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 13
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 14
  %15 = select i1 %14, i32 %13, i32 14
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 14
  %18 = select i1 %17, i32 %16, i32 14
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 224
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %27 = add nsw i64 %24, %indvars.iv
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 15
  %30 = lshr i32 %28, 4
  %31 = mul nsw i32 %30, 3136
  %32 = add i32 %26, %31
  %33 = or i32 %32, %29
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to i32*
  %37 = load i32, i32* %36, align 4, !tbaa !144
  %38 = getelementptr inbounds float, float* %4, i64 %27
  %39 = bitcast float* %38 to i32*
  store i32 %37, i32* %39, align 4, !tbaa !147
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %40 = or i64 %24, 256
  %41 = or i32 %26, 16
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %42 = add nsw i64 %40, %indvars.iv.1
  %43 = trunc i64 %indvars.iv.1 to i32
  %44 = and i32 %43, 15
  %45 = lshr i32 %43, 4
  %46 = mul nsw i32 %45, 3136
  %47 = add i32 %41, %46
  %48 = or i32 %47, %44
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to i32*
  %52 = load i32, i32* %51, align 4, !tbaa !144
  %53 = getelementptr inbounds float, float* %4, i64 %42
  %54 = bitcast float* %53 to i32*
  store i32 %52, i32* %54, align 4, !tbaa !147
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %55 = add nsw i64 %24, 512
  %56 = add i32 %26, 32
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %57 = add nsw i64 %55, %indvars.iv.2
  %58 = trunc i64 %indvars.iv.2 to i32
  %59 = and i32 %58, 15
  %60 = lshr i32 %58, 4
  %61 = mul nsw i32 %60, 3136
  %62 = add i32 %56, %61
  %63 = or i32 %62, %59
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !144
  %68 = getelementptr inbounds float, float* %4, i64 %57
  %69 = bitcast float* %68 to i32*
  store i32 %67, i32* %69, align 4, !tbaa !147
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  %70 = add nsw i64 %24, 768
  %71 = add i32 %26, 48
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %72 = add nsw i64 %70, %indvars.iv.3
  %73 = trunc i64 %indvars.iv.3 to i32
  %74 = and i32 %73, 15
  %75 = lshr i32 %73, 4
  %76 = mul nsw i32 %75, 3136
  %77 = add i32 %71, %76
  %78 = or i32 %77, %74
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to i32*
  %82 = load i32, i32* %81, align 4, !tbaa !144
  %83 = getelementptr inbounds float, float* %4, i64 %72
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4, !tbaa !147
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  %85 = add nsw i64 %24, 1024
  %86 = add i32 %26, 64
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %87 = add nsw i64 %85, %indvars.iv.4
  %88 = trunc i64 %indvars.iv.4 to i32
  %89 = and i32 %88, 15
  %90 = lshr i32 %88, 4
  %91 = mul nsw i32 %90, 3136
  %92 = add i32 %86, %91
  %93 = or i32 %92, %89
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !144
  %98 = getelementptr inbounds float, float* %4, i64 %87
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !147
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 256
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  %100 = add nsw i64 %24, 1280
  %101 = add i32 %26, 80
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %102 = add nsw i64 %100, %indvars.iv.5
  %103 = trunc i64 %indvars.iv.5 to i32
  %104 = and i32 %103, 15
  %105 = lshr i32 %103, 4
  %106 = mul nsw i32 %105, 3136
  %107 = add i32 %101, %106
  %108 = or i32 %107, %104
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !144
  %113 = getelementptr inbounds float, float* %4, i64 %102
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !147
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 256
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  %115 = add nsw i64 %24, 1536
  %116 = add i32 %26, 96
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %117 = add nsw i64 %115, %indvars.iv.6
  %118 = trunc i64 %indvars.iv.6 to i32
  %119 = and i32 %118, 15
  %120 = lshr i32 %118, 4
  %121 = mul nsw i32 %120, 3136
  %122 = add i32 %116, %121
  %123 = or i32 %122, %119
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to i32*
  %127 = load i32, i32* %126, align 4, !tbaa !144
  %128 = getelementptr inbounds float, float* %4, i64 %117
  %129 = bitcast float* %128 to i32*
  store i32 %127, i32* %129, align 4, !tbaa !147
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 256
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  %130 = add nsw i64 %24, 1792
  %131 = add i32 %26, 112
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %132 = add nsw i64 %130, %indvars.iv.7
  %133 = trunc i64 %indvars.iv.7 to i32
  %134 = and i32 %133, 15
  %135 = lshr i32 %133, 4
  %136 = mul nsw i32 %135, 3136
  %137 = add i32 %131, %136
  %138 = or i32 %137, %134
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to i32*
  %142 = load i32, i32* %141, align 4, !tbaa !144
  %143 = getelementptr inbounds float, float* %4, i64 %132
  %144 = bitcast float* %143 to i32*
  store i32 %142, i32* %144, align 4, !tbaa !147
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 256
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !29

for_end6.7:                                       ; preds = %for_body5.7
  %145 = add nsw i64 %24, 2048
  %146 = add i32 %26, 128
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %147 = add nsw i64 %145, %indvars.iv.8
  %148 = trunc i64 %indvars.iv.8 to i32
  %149 = and i32 %148, 15
  %150 = lshr i32 %148, 4
  %151 = mul nsw i32 %150, 3136
  %152 = add i32 %146, %151
  %153 = or i32 %152, %149
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to i32*
  %157 = load i32, i32* %156, align 4, !tbaa !144
  %158 = getelementptr inbounds float, float* %4, i64 %147
  %159 = bitcast float* %158 to i32*
  store i32 %157, i32* %159, align 4, !tbaa !147
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 256
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !29

for_end6.8:                                       ; preds = %for_body5.8
  %160 = add nsw i64 %24, 2304
  %161 = add i32 %26, 144
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %162 = add nsw i64 %160, %indvars.iv.9
  %163 = trunc i64 %indvars.iv.9 to i32
  %164 = and i32 %163, 15
  %165 = lshr i32 %163, 4
  %166 = mul nsw i32 %165, 3136
  %167 = add i32 %161, %166
  %168 = or i32 %167, %164
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to i32*
  %172 = load i32, i32* %171, align 4, !tbaa !144
  %173 = getelementptr inbounds float, float* %4, i64 %162
  %174 = bitcast float* %173 to i32*
  store i32 %172, i32* %174, align 4, !tbaa !147
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 256
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !29

for_end6.9:                                       ; preds = %for_body5.9
  %175 = add nsw i64 %24, 2560
  %176 = add i32 %26, 160
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %177 = add nsw i64 %175, %indvars.iv.10
  %178 = trunc i64 %indvars.iv.10 to i32
  %179 = and i32 %178, 15
  %180 = lshr i32 %178, 4
  %181 = mul nsw i32 %180, 3136
  %182 = add i32 %176, %181
  %183 = or i32 %182, %179
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to i32*
  %187 = load i32, i32* %186, align 4, !tbaa !144
  %188 = getelementptr inbounds float, float* %4, i64 %177
  %189 = bitcast float* %188 to i32*
  store i32 %187, i32* %189, align 4, !tbaa !147
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 256
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !29

for_end6.10:                                      ; preds = %for_body5.10
  %190 = add nsw i64 %24, 2816
  %191 = add i32 %26, 176
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %192 = add nsw i64 %190, %indvars.iv.11
  %193 = trunc i64 %indvars.iv.11 to i32
  %194 = and i32 %193, 15
  %195 = lshr i32 %193, 4
  %196 = mul nsw i32 %195, 3136
  %197 = add i32 %191, %196
  %198 = or i32 %197, %194
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to i32*
  %202 = load i32, i32* %201, align 4, !tbaa !144
  %203 = getelementptr inbounds float, float* %4, i64 %192
  %204 = bitcast float* %203 to i32*
  store i32 %202, i32* %204, align 4, !tbaa !147
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 256
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !29

for_end6.11:                                      ; preds = %for_body5.11
  %205 = add nsw i64 %24, 3072
  %206 = add i32 %26, 192
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %207 = add nsw i64 %205, %indvars.iv.12
  %208 = trunc i64 %indvars.iv.12 to i32
  %209 = and i32 %208, 15
  %210 = lshr i32 %208, 4
  %211 = mul nsw i32 %210, 3136
  %212 = add i32 %206, %211
  %213 = or i32 %212, %209
  %214 = sext i32 %213 to i64
  %215 = getelementptr inbounds float, float* %7, i64 %214
  %216 = bitcast float* %215 to i32*
  %217 = load i32, i32* %216, align 4, !tbaa !144
  %218 = getelementptr inbounds float, float* %4, i64 %207
  %219 = bitcast float* %218 to i32*
  store i32 %217, i32* %219, align 4, !tbaa !147
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 256
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !29

for_end6.12:                                      ; preds = %for_body5.12
  %220 = add nsw i64 %24, 3328
  %221 = add i32 %26, 208
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %222 = add nsw i64 %220, %indvars.iv.13
  %223 = trunc i64 %indvars.iv.13 to i32
  %224 = and i32 %223, 15
  %225 = lshr i32 %223, 4
  %226 = mul nsw i32 %225, 3136
  %227 = add i32 %221, %226
  %228 = or i32 %227, %224
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to i32*
  %232 = load i32, i32* %231, align 4, !tbaa !144
  %233 = getelementptr inbounds float, float* %4, i64 %222
  %234 = bitcast float* %233 to i32*
  store i32 %232, i32* %234, align 4, !tbaa !147
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 256
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !29

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %235 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %235, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_33(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !150 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !152, metadata !DIExpression()), !dbg !155
  call void @llvm.dbg.value(metadata i8* %1, metadata !153, metadata !DIExpression()), !dbg !155
  call void @llvm.dbg.value(metadata i32 %2, metadata !154, metadata !DIExpression()), !dbg !155
  %3 = bitcast i8* %0 to %1**, !dbg !155
  %4 = load %1*, %1** %3, align 8, !dbg !155
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !155
  %6 = bitcast i8* %5 to %1**, !dbg !155
  %7 = load %1*, %1** %6, align 8, !dbg !155
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !155
  %9 = load i8*, i8** %8, align 8, !dbg !155
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !155
  %11 = load i8*, i8** %10, align 8, !dbg !155
  %12 = tail call fastcc i32 @fused_layout_transform_33_compute_(i8* %11, i8* %9), !dbg !155
  ret i32 %12, !dbg !155
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_33_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %13, align 8
  %3 = getelementptr inbounds %13, %13* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %13, %13* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %13* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.9, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.9(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 3583
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 3584
  %15 = select i1 %14, i32 %13, i32 3584
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 3584
  %18 = select i1 %17, i32 %16, i32 3584
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_body
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_body ]
  %24 = mul nsw i64 %indvars.iv7, 28
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 7
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 7
  %29 = mul nsw i32 %28, 224
  %30 = srem i32 %27, 32
  %31 = sdiv i32 %25, 56
  %32 = mul nsw i32 %31, 1568
  %33 = or i32 %27, 1
  %34 = srem i32 %33, 32
  %35 = sdiv i32 %33, 32
  %36 = mul nsw i32 %35, 1568
  %37 = or i32 %27, 2
  %38 = srem i32 %37, 32
  %39 = sdiv i32 %37, 32
  %40 = mul nsw i32 %39, 1568
  %41 = or i32 %27, 3
  %42 = srem i32 %41, 32
  %43 = sdiv i32 %41, 32
  %44 = mul nsw i32 %43, 1568
  %45 = add nsw i32 %29, %30
  %46 = add i32 %45, %32
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds float, float* %7, i64 %47
  %49 = bitcast float* %48 to i32*
  %50 = load i32, i32* %49, align 4, !tbaa !156
  %51 = getelementptr inbounds float, float* %4, i64 %24
  %52 = bitcast float* %51 to i32*
  store i32 %50, i32* %52, align 4, !tbaa !159
  %53 = or i64 %24, 1
  %54 = add nsw i32 %29, %34
  %55 = add i32 %54, %36
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds float, float* %7, i64 %56
  %58 = bitcast float* %57 to i32*
  %59 = load i32, i32* %58, align 4, !tbaa !156
  %60 = getelementptr inbounds float, float* %4, i64 %53
  %61 = bitcast float* %60 to i32*
  store i32 %59, i32* %61, align 4, !tbaa !159
  %62 = or i64 %24, 2
  %63 = add nsw i32 %29, %38
  %64 = add i32 %63, %40
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to i32*
  %68 = load i32, i32* %67, align 4, !tbaa !156
  %69 = getelementptr inbounds float, float* %4, i64 %62
  %70 = bitcast float* %69 to i32*
  store i32 %68, i32* %70, align 4, !tbaa !159
  %71 = or i64 %24, 3
  %72 = add nsw i32 %29, %42
  %73 = add i32 %72, %44
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds float, float* %7, i64 %74
  %76 = bitcast float* %75 to i32*
  %77 = load i32, i32* %76, align 4, !tbaa !156
  %78 = getelementptr inbounds float, float* %4, i64 %71
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 4, !tbaa !159
  %80 = add nsw i64 %24, 4
  %81 = add nsw i32 %29, 32
  %82 = add nsw i32 %81, %30
  %83 = add i32 %82, %32
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds float, float* %7, i64 %84
  %86 = bitcast float* %85 to i32*
  %87 = load i32, i32* %86, align 4, !tbaa !156
  %88 = getelementptr inbounds float, float* %4, i64 %80
  %89 = bitcast float* %88 to i32*
  store i32 %87, i32* %89, align 4, !tbaa !159
  %90 = or i64 %80, 1
  %91 = add nsw i32 %29, 32
  %92 = add nsw i32 %91, %34
  %93 = add i32 %92, %36
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !156
  %98 = getelementptr inbounds float, float* %4, i64 %90
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !159
  %100 = or i64 %80, 2
  %101 = add nsw i32 %91, %38
  %102 = add i32 %101, %40
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = bitcast float* %104 to i32*
  %106 = load i32, i32* %105, align 4, !tbaa !156
  %107 = getelementptr inbounds float, float* %4, i64 %100
  %108 = bitcast float* %107 to i32*
  store i32 %106, i32* %108, align 4, !tbaa !159
  %109 = or i64 %80, 3
  %110 = add nsw i32 %91, %42
  %111 = add i32 %110, %44
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds float, float* %7, i64 %112
  %114 = bitcast float* %113 to i32*
  %115 = load i32, i32* %114, align 4, !tbaa !156
  %116 = getelementptr inbounds float, float* %4, i64 %109
  %117 = bitcast float* %116 to i32*
  store i32 %115, i32* %117, align 4, !tbaa !159
  %118 = add nsw i64 %24, 8
  %119 = add nsw i32 %29, 64
  %120 = add nsw i32 %119, %30
  %121 = add i32 %120, %32
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds float, float* %7, i64 %122
  %124 = bitcast float* %123 to i32*
  %125 = load i32, i32* %124, align 4, !tbaa !156
  %126 = getelementptr inbounds float, float* %4, i64 %118
  %127 = bitcast float* %126 to i32*
  store i32 %125, i32* %127, align 4, !tbaa !159
  %128 = or i64 %118, 1
  %129 = add nsw i32 %29, 64
  %130 = add nsw i32 %129, %34
  %131 = add i32 %130, %36
  %132 = sext i32 %131 to i64
  %133 = getelementptr inbounds float, float* %7, i64 %132
  %134 = bitcast float* %133 to i32*
  %135 = load i32, i32* %134, align 4, !tbaa !156
  %136 = getelementptr inbounds float, float* %4, i64 %128
  %137 = bitcast float* %136 to i32*
  store i32 %135, i32* %137, align 4, !tbaa !159
  %138 = or i64 %118, 2
  %139 = add nsw i32 %129, %38
  %140 = add i32 %139, %40
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to i32*
  %144 = load i32, i32* %143, align 4, !tbaa !156
  %145 = getelementptr inbounds float, float* %4, i64 %138
  %146 = bitcast float* %145 to i32*
  store i32 %144, i32* %146, align 4, !tbaa !159
  %147 = or i64 %118, 3
  %148 = add nsw i32 %129, %42
  %149 = add i32 %148, %44
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds float, float* %7, i64 %150
  %152 = bitcast float* %151 to i32*
  %153 = load i32, i32* %152, align 4, !tbaa !156
  %154 = getelementptr inbounds float, float* %4, i64 %147
  %155 = bitcast float* %154 to i32*
  store i32 %153, i32* %155, align 4, !tbaa !159
  %156 = add nsw i64 %24, 12
  %157 = add nsw i32 %29, 96
  %158 = add nsw i32 %157, %30
  %159 = add i32 %158, %32
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds float, float* %7, i64 %160
  %162 = bitcast float* %161 to i32*
  %163 = load i32, i32* %162, align 4, !tbaa !156
  %164 = getelementptr inbounds float, float* %4, i64 %156
  %165 = bitcast float* %164 to i32*
  store i32 %163, i32* %165, align 4, !tbaa !159
  %166 = or i64 %156, 1
  %167 = add nsw i32 %29, 96
  %168 = add nsw i32 %167, %34
  %169 = add i32 %168, %36
  %170 = sext i32 %169 to i64
  %171 = getelementptr inbounds float, float* %7, i64 %170
  %172 = bitcast float* %171 to i32*
  %173 = load i32, i32* %172, align 4, !tbaa !156
  %174 = getelementptr inbounds float, float* %4, i64 %166
  %175 = bitcast float* %174 to i32*
  store i32 %173, i32* %175, align 4, !tbaa !159
  %176 = or i64 %156, 2
  %177 = add nsw i32 %167, %38
  %178 = add i32 %177, %40
  %179 = sext i32 %178 to i64
  %180 = getelementptr inbounds float, float* %7, i64 %179
  %181 = bitcast float* %180 to i32*
  %182 = load i32, i32* %181, align 4, !tbaa !156
  %183 = getelementptr inbounds float, float* %4, i64 %176
  %184 = bitcast float* %183 to i32*
  store i32 %182, i32* %184, align 4, !tbaa !159
  %185 = or i64 %156, 3
  %186 = add nsw i32 %167, %42
  %187 = add i32 %186, %44
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4, !tbaa !156
  %192 = getelementptr inbounds float, float* %4, i64 %185
  %193 = bitcast float* %192 to i32*
  store i32 %191, i32* %193, align 4, !tbaa !159
  %194 = add nsw i64 %24, 16
  %195 = add nsw i32 %29, 128
  %196 = add nsw i32 %195, %30
  %197 = add i32 %196, %32
  %198 = sext i32 %197 to i64
  %199 = getelementptr inbounds float, float* %7, i64 %198
  %200 = bitcast float* %199 to i32*
  %201 = load i32, i32* %200, align 4, !tbaa !156
  %202 = getelementptr inbounds float, float* %4, i64 %194
  %203 = bitcast float* %202 to i32*
  store i32 %201, i32* %203, align 4, !tbaa !159
  %204 = or i64 %194, 1
  %205 = add nsw i32 %29, 128
  %206 = add nsw i32 %205, %34
  %207 = add i32 %206, %36
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds float, float* %7, i64 %208
  %210 = bitcast float* %209 to i32*
  %211 = load i32, i32* %210, align 4, !tbaa !156
  %212 = getelementptr inbounds float, float* %4, i64 %204
  %213 = bitcast float* %212 to i32*
  store i32 %211, i32* %213, align 4, !tbaa !159
  %214 = or i64 %194, 2
  %215 = add nsw i32 %205, %38
  %216 = add i32 %215, %40
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds float, float* %7, i64 %217
  %219 = bitcast float* %218 to i32*
  %220 = load i32, i32* %219, align 4, !tbaa !156
  %221 = getelementptr inbounds float, float* %4, i64 %214
  %222 = bitcast float* %221 to i32*
  store i32 %220, i32* %222, align 4, !tbaa !159
  %223 = or i64 %194, 3
  %224 = add nsw i32 %205, %42
  %225 = add i32 %224, %44
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds float, float* %7, i64 %226
  %228 = bitcast float* %227 to i32*
  %229 = load i32, i32* %228, align 4, !tbaa !156
  %230 = getelementptr inbounds float, float* %4, i64 %223
  %231 = bitcast float* %230 to i32*
  store i32 %229, i32* %231, align 4, !tbaa !159
  %232 = add nsw i64 %24, 20
  %233 = add nsw i32 %29, 160
  %234 = add nsw i32 %233, %30
  %235 = add i32 %234, %32
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds float, float* %7, i64 %236
  %238 = bitcast float* %237 to i32*
  %239 = load i32, i32* %238, align 4, !tbaa !156
  %240 = getelementptr inbounds float, float* %4, i64 %232
  %241 = bitcast float* %240 to i32*
  store i32 %239, i32* %241, align 4, !tbaa !159
  %242 = or i64 %232, 1
  %243 = add nsw i32 %29, 160
  %244 = add nsw i32 %243, %34
  %245 = add i32 %244, %36
  %246 = sext i32 %245 to i64
  %247 = getelementptr inbounds float, float* %7, i64 %246
  %248 = bitcast float* %247 to i32*
  %249 = load i32, i32* %248, align 4, !tbaa !156
  %250 = getelementptr inbounds float, float* %4, i64 %242
  %251 = bitcast float* %250 to i32*
  store i32 %249, i32* %251, align 4, !tbaa !159
  %252 = or i64 %232, 2
  %253 = add nsw i32 %243, %38
  %254 = add i32 %253, %40
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds float, float* %7, i64 %255
  %257 = bitcast float* %256 to i32*
  %258 = load i32, i32* %257, align 4, !tbaa !156
  %259 = getelementptr inbounds float, float* %4, i64 %252
  %260 = bitcast float* %259 to i32*
  store i32 %258, i32* %260, align 4, !tbaa !159
  %261 = or i64 %232, 3
  %262 = add nsw i32 %243, %42
  %263 = add i32 %262, %44
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds float, float* %7, i64 %264
  %266 = bitcast float* %265 to i32*
  %267 = load i32, i32* %266, align 4, !tbaa !156
  %268 = getelementptr inbounds float, float* %4, i64 %261
  %269 = bitcast float* %268 to i32*
  store i32 %267, i32* %269, align 4, !tbaa !159
  %270 = add nsw i64 %24, 24
  %271 = add nsw i32 %29, 192
  %272 = add nsw i32 %271, %30
  %273 = add i32 %272, %32
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds float, float* %7, i64 %274
  %276 = bitcast float* %275 to i32*
  %277 = load i32, i32* %276, align 4, !tbaa !156
  %278 = getelementptr inbounds float, float* %4, i64 %270
  %279 = bitcast float* %278 to i32*
  store i32 %277, i32* %279, align 4, !tbaa !159
  %280 = or i64 %270, 1
  %281 = add nsw i32 %29, 192
  %282 = add nsw i32 %281, %34
  %283 = add i32 %282, %36
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds float, float* %7, i64 %284
  %286 = bitcast float* %285 to i32*
  %287 = load i32, i32* %286, align 4, !tbaa !156
  %288 = getelementptr inbounds float, float* %4, i64 %280
  %289 = bitcast float* %288 to i32*
  store i32 %287, i32* %289, align 4, !tbaa !159
  %290 = or i64 %270, 2
  %291 = add nsw i32 %281, %38
  %292 = add i32 %291, %40
  %293 = sext i32 %292 to i64
  %294 = getelementptr inbounds float, float* %7, i64 %293
  %295 = bitcast float* %294 to i32*
  %296 = load i32, i32* %295, align 4, !tbaa !156
  %297 = getelementptr inbounds float, float* %4, i64 %290
  %298 = bitcast float* %297 to i32*
  store i32 %296, i32* %298, align 4, !tbaa !159
  %299 = or i64 %270, 3
  %300 = add nsw i32 %281, %42
  %301 = add i32 %300, %44
  %302 = sext i32 %301 to i64
  %303 = getelementptr inbounds float, float* %7, i64 %302
  %304 = bitcast float* %303 to i32*
  %305 = load i32, i32* %304, align 4, !tbaa !156
  %306 = getelementptr inbounds float, float* %4, i64 %299
  %307 = bitcast float* %306 to i32*
  store i32 %305, i32* %307, align 4, !tbaa !159
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %308 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %308, label %for_body, label %for_end, !prof !19

for_end:                                          ; preds = %for_body, %entry
  ret i32 0
}

define dllexport i32 @fused_layout_transform_44(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !162 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !164, metadata !DIExpression()), !dbg !167
  call void @llvm.dbg.value(metadata i8* %1, metadata !165, metadata !DIExpression()), !dbg !167
  call void @llvm.dbg.value(metadata i32 %2, metadata !166, metadata !DIExpression()), !dbg !167
  %3 = bitcast i8* %0 to %1**, !dbg !167
  %4 = load %1*, %1** %3, align 8, !dbg !167
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !167
  %6 = bitcast i8* %5 to %1**, !dbg !167
  %7 = load %1*, %1** %6, align 8, !dbg !167
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !167
  %9 = load i8*, i8** %8, align 8, !dbg !167
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !167
  %11 = load i8*, i8** %10, align 8, !dbg !167
  %12 = tail call fastcc i32 @fused_layout_transform_44_compute_(i8* %11, i8* %9), !dbg !167
  ret i32 %12, !dbg !167
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_44_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %14, align 8
  %3 = getelementptr inbounds %14, %14* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %14, %14* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %14* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.10, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.10(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 6
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 100352
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !168
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !171
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !174 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !176, metadata !DIExpression()), !dbg !179
  call void @llvm.dbg.value(metadata i8* %1, metadata !177, metadata !DIExpression()), !dbg !179
  call void @llvm.dbg.value(metadata i32 %2, metadata !178, metadata !DIExpression()), !dbg !179
  %3 = bitcast i8* %0 to %1**, !dbg !179
  %4 = load %1*, %1** %3, align 8, !dbg !179
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !179
  %6 = bitcast i8* %5 to %1**, !dbg !179
  %7 = load %1*, %1** %6, align 8, !dbg !179
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !179
  %9 = bitcast i8* %8 to %1**, !dbg !179
  %10 = load %1*, %1** %9, align 8, !dbg !179
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !179
  %12 = bitcast i8* %11 to %1**, !dbg !179
  %13 = load %1*, %1** %12, align 8, !dbg !179
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !179
  %15 = bitcast i8* %14 to %1**, !dbg !179
  %16 = load %1*, %1** %15, align 8, !dbg !179
  %17 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !179
  %18 = load i8*, i8** %17, align 8, !dbg !179
  %19 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !179
  %20 = load i8*, i8** %19, align 8, !dbg !179
  %21 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !179
  %22 = load i8*, i8** %21, align 8, !dbg !179
  %23 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !179
  %24 = load i8*, i8** %23, align 8, !dbg !179
  %25 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !179
  %26 = load i8*, i8** %25, align 8, !dbg !179
  %27 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_compute_(i8* %18, i8* %20, i8* %26, i8* %22, i8* %24), !dbg !179
  ret i32 %27, !dbg !179
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %5 = alloca %15, align 8
  %6 = getelementptr inbounds %15, %15* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %15, %15* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %15, %15* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %15, %15* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %15, %15* %5, i64 0, i32 4
  store i8* %4, i8** %10, align 8
  %11 = bitcast %15* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.11, i8* nonnull %11, i32 0)
  ret i32 %13
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.11(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv43 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next44, %for_end3 ]
  %33 = trunc i64 %indvars.iv43 to i32
  %34 = srem i32 %33, 7
  %35 = mul nsw i32 %34, 28
  %36 = sdiv i32 %33, 7
  %37 = shl i32 %36, 16
  %38 = sext i32 %35 to i64
  %39 = sext i32 %37 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %.lcssa2033 = phi <32 x float> [ zeroinitializer, %for_body ], [ %225, %for_body2 ]
  %.lcssa1831 = phi <32 x float> [ zeroinitializer, %for_body ], [ %219, %for_body2 ]
  %.lcssa1629 = phi <32 x float> [ zeroinitializer, %for_body ], [ %213, %for_body2 ]
  %.lcssa1427 = phi <32 x float> [ zeroinitializer, %for_body ], [ %207, %for_body2 ]
  %.lcssa1225 = phi <32 x float> [ zeroinitializer, %for_body ], [ %201, %for_body2 ]
  %.lcssa1024 = phi <32 x float> [ zeroinitializer, %for_body ], [ %195, %for_body2 ]
  %.lcssa22 = phi <32 x float> [ zeroinitializer, %for_body ], [ %189, %for_body2 ]
  %40 = mul nuw nsw i64 %indvars.iv, 196
  %41 = add nsw i64 %40, %38
  %42 = shl i64 %indvars.iv, 7
  %43 = add nuw nsw i64 %42, %39
  %44 = getelementptr inbounds float, float* %4, i64 %41
  %45 = load float, float* %44, align 4, !tbaa !180
  %46 = insertelement <32 x float> undef, float %45, i32 0
  %47 = shufflevector <32 x float> %46, <32 x float> undef, <32 x i32> zeroinitializer
  %48 = getelementptr inbounds float, float* %7, i64 %43
  %49 = bitcast float* %48 to <32 x float>*
  %50 = load <32 x float>, <32 x float>* %49, align 64, !tbaa !183
  %51 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %47, <32 x float> %50, <32 x float> %.lcssa22)
  %52 = add nsw i64 %41, 4
  %53 = getelementptr inbounds float, float* %4, i64 %52
  %54 = load float, float* %53, align 4, !tbaa !180
  %55 = insertelement <32 x float> undef, float %54, i32 0
  %56 = shufflevector <32 x float> %55, <32 x float> undef, <32 x i32> zeroinitializer
  %57 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %56, <32 x float> %50, <32 x float> %.lcssa1024)
  %58 = add nsw i64 %41, 8
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = load float, float* %59, align 4, !tbaa !180
  %61 = insertelement <32 x float> undef, float %60, i32 0
  %62 = shufflevector <32 x float> %61, <32 x float> undef, <32 x i32> zeroinitializer
  %63 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %50, <32 x float> %.lcssa1225)
  %64 = add nsw i64 %41, 12
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !180
  %67 = insertelement <32 x float> undef, float %66, i32 0
  %68 = shufflevector <32 x float> %67, <32 x float> undef, <32 x i32> zeroinitializer
  %69 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %50, <32 x float> %.lcssa1427)
  %70 = add nsw i64 %41, 16
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !180
  %73 = insertelement <32 x float> undef, float %72, i32 0
  %74 = shufflevector <32 x float> %73, <32 x float> undef, <32 x i32> zeroinitializer
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %50, <32 x float> %.lcssa1629)
  %76 = add nsw i64 %41, 20
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !180
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %50, <32 x float> %.lcssa1831)
  %82 = add nsw i64 %41, 24
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !180
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %50, <32 x float> %.lcssa2033)
  %88 = or i64 %41, 1
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !180
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = or i64 %43, 32
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <32 x float>*
  %96 = load <32 x float>, <32 x float>* %95, align 64, !tbaa !183
  %97 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %96, <32 x float> %51)
  %98 = add nsw i64 %88, 4
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !180
  %101 = insertelement <32 x float> undef, float %100, i32 0
  %102 = shufflevector <32 x float> %101, <32 x float> undef, <32 x i32> zeroinitializer
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %102, <32 x float> %96, <32 x float> %57)
  %104 = add nsw i64 %88, 8
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !180
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %96, <32 x float> %63)
  %110 = add nsw i64 %88, 12
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !180
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %96, <32 x float> %69)
  %116 = add nsw i64 %88, 16
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !180
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %96, <32 x float> %75)
  %122 = add nsw i64 %88, 20
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !180
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %96, <32 x float> %81)
  %128 = add nsw i64 %88, 24
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !180
  %131 = insertelement <32 x float> undef, float %130, i32 0
  %132 = shufflevector <32 x float> %131, <32 x float> undef, <32 x i32> zeroinitializer
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %132, <32 x float> %96, <32 x float> %87)
  %134 = or i64 %41, 2
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !180
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = or i64 %43, 64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to <32 x float>*
  %142 = load <32 x float>, <32 x float>* %141, align 64, !tbaa !183
  %143 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %142, <32 x float> %97)
  %144 = add nsw i64 %134, 4
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = load float, float* %145, align 4, !tbaa !180
  %147 = insertelement <32 x float> undef, float %146, i32 0
  %148 = shufflevector <32 x float> %147, <32 x float> undef, <32 x i32> zeroinitializer
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %148, <32 x float> %142, <32 x float> %103)
  %150 = add nsw i64 %134, 8
  %151 = getelementptr inbounds float, float* %4, i64 %150
  %152 = load float, float* %151, align 4, !tbaa !180
  %153 = insertelement <32 x float> undef, float %152, i32 0
  %154 = shufflevector <32 x float> %153, <32 x float> undef, <32 x i32> zeroinitializer
  %155 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %154, <32 x float> %142, <32 x float> %109)
  %156 = add nsw i64 %134, 12
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !180
  %159 = insertelement <32 x float> undef, float %158, i32 0
  %160 = shufflevector <32 x float> %159, <32 x float> undef, <32 x i32> zeroinitializer
  %161 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %160, <32 x float> %142, <32 x float> %115)
  %162 = add nsw i64 %134, 16
  %163 = getelementptr inbounds float, float* %4, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !180
  %165 = insertelement <32 x float> undef, float %164, i32 0
  %166 = shufflevector <32 x float> %165, <32 x float> undef, <32 x i32> zeroinitializer
  %167 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %166, <32 x float> %142, <32 x float> %121)
  %168 = add nsw i64 %134, 20
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !180
  %171 = insertelement <32 x float> undef, float %170, i32 0
  %172 = shufflevector <32 x float> %171, <32 x float> undef, <32 x i32> zeroinitializer
  %173 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %172, <32 x float> %142, <32 x float> %127)
  %174 = add nsw i64 %134, 24
  %175 = getelementptr inbounds float, float* %4, i64 %174
  %176 = load float, float* %175, align 4, !tbaa !180
  %177 = insertelement <32 x float> undef, float %176, i32 0
  %178 = shufflevector <32 x float> %177, <32 x float> undef, <32 x i32> zeroinitializer
  %179 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %178, <32 x float> %142, <32 x float> %133)
  %180 = or i64 %41, 3
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !180
  %183 = insertelement <32 x float> undef, float %182, i32 0
  %184 = shufflevector <32 x float> %183, <32 x float> undef, <32 x i32> zeroinitializer
  %185 = or i64 %43, 96
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = bitcast float* %186 to <32 x float>*
  %188 = load <32 x float>, <32 x float>* %187, align 64, !tbaa !183
  %189 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %184, <32 x float> %188, <32 x float> %143)
  %190 = add nsw i64 %180, 4
  %191 = getelementptr inbounds float, float* %4, i64 %190
  %192 = load float, float* %191, align 4, !tbaa !180
  %193 = insertelement <32 x float> undef, float %192, i32 0
  %194 = shufflevector <32 x float> %193, <32 x float> undef, <32 x i32> zeroinitializer
  %195 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %194, <32 x float> %188, <32 x float> %149)
  %196 = add nsw i64 %180, 8
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !180
  %199 = insertelement <32 x float> undef, float %198, i32 0
  %200 = shufflevector <32 x float> %199, <32 x float> undef, <32 x i32> zeroinitializer
  %201 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %200, <32 x float> %188, <32 x float> %155)
  %202 = add nsw i64 %180, 12
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !180
  %205 = insertelement <32 x float> undef, float %204, i32 0
  %206 = shufflevector <32 x float> %205, <32 x float> undef, <32 x i32> zeroinitializer
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %206, <32 x float> %188, <32 x float> %161)
  %208 = add nsw i64 %180, 16
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !180
  %211 = insertelement <32 x float> undef, float %210, i32 0
  %212 = shufflevector <32 x float> %211, <32 x float> undef, <32 x i32> zeroinitializer
  %213 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %212, <32 x float> %188, <32 x float> %167)
  %214 = add nsw i64 %180, 20
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !180
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %188, <32 x float> %173)
  %220 = add nsw i64 %180, 24
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !180
  %223 = insertelement <32 x float> undef, float %222, i32 0
  %224 = shufflevector <32 x float> %223, <32 x float> undef, <32 x i32> zeroinitializer
  %225 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %224, <32 x float> %188, <32 x float> %179)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %226 = mul nsw i64 %indvars.iv43, 224
  %227 = shl nsw i32 %36, 5
  %228 = sext i32 %227 to i64
  %229 = getelementptr inbounds float, float* %16, i64 %228
  %230 = bitcast float* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !186
  %232 = getelementptr inbounds float, float* %13, i64 %228
  %233 = bitcast float* %232 to <32 x float>*
  %234 = load <32 x float>, <32 x float>* %233, align 64, !tbaa !189
  %235 = fadd <32 x float> %234, %189
  %236 = fadd <32 x float> %231, %235
  %237 = fcmp ogt <32 x float> %236, zeroinitializer
  %238 = select <32 x i1> %237, <32 x float> %236, <32 x float> zeroinitializer
  %239 = getelementptr inbounds float, float* %10, i64 %226
  %240 = bitcast float* %239 to <32 x float>*
  store <32 x float> %238, <32 x float>* %240, align 64, !tbaa !192
  %241 = add nsw i64 %226, 32
  %242 = fadd <32 x float> %234, %195
  %243 = fadd <32 x float> %231, %242
  %244 = fcmp ogt <32 x float> %243, zeroinitializer
  %245 = select <32 x i1> %244, <32 x float> %243, <32 x float> zeroinitializer
  %246 = getelementptr inbounds float, float* %10, i64 %241
  %247 = bitcast float* %246 to <32 x float>*
  store <32 x float> %245, <32 x float>* %247, align 64, !tbaa !192
  %248 = add nsw i64 %226, 64
  %249 = fadd <32 x float> %234, %201
  %250 = fadd <32 x float> %231, %249
  %251 = fcmp ogt <32 x float> %250, zeroinitializer
  %252 = select <32 x i1> %251, <32 x float> %250, <32 x float> zeroinitializer
  %253 = getelementptr inbounds float, float* %10, i64 %248
  %254 = bitcast float* %253 to <32 x float>*
  store <32 x float> %252, <32 x float>* %254, align 64, !tbaa !192
  %255 = add nsw i64 %226, 96
  %256 = fadd <32 x float> %234, %207
  %257 = fadd <32 x float> %231, %256
  %258 = fcmp ogt <32 x float> %257, zeroinitializer
  %259 = select <32 x i1> %258, <32 x float> %257, <32 x float> zeroinitializer
  %260 = getelementptr inbounds float, float* %10, i64 %255
  %261 = bitcast float* %260 to <32 x float>*
  store <32 x float> %259, <32 x float>* %261, align 64, !tbaa !192
  %262 = add nsw i64 %226, 128
  %263 = fadd <32 x float> %234, %213
  %264 = fadd <32 x float> %231, %263
  %265 = fcmp ogt <32 x float> %264, zeroinitializer
  %266 = select <32 x i1> %265, <32 x float> %264, <32 x float> zeroinitializer
  %267 = getelementptr inbounds float, float* %10, i64 %262
  %268 = bitcast float* %267 to <32 x float>*
  store <32 x float> %266, <32 x float>* %268, align 64, !tbaa !192
  %269 = add nsw i64 %226, 160
  %270 = fadd <32 x float> %234, %219
  %271 = fadd <32 x float> %231, %270
  %272 = fcmp ogt <32 x float> %271, zeroinitializer
  %273 = select <32 x i1> %272, <32 x float> %271, <32 x float> zeroinitializer
  %274 = getelementptr inbounds float, float* %10, i64 %269
  %275 = bitcast float* %274 to <32 x float>*
  store <32 x float> %273, <32 x float>* %275, align 64, !tbaa !192
  %276 = add nsw i64 %226, 192
  %277 = fadd <32 x float> %234, %225
  %278 = fadd <32 x float> %231, %277
  %279 = fcmp ogt <32 x float> %278, zeroinitializer
  %280 = select <32 x i1> %279, <32 x float> %278, <32 x float> zeroinitializer
  %281 = getelementptr inbounds float, float* %10, i64 %276
  %282 = bitcast float* %281 to <32 x float>*
  store <32 x float> %280, <32 x float>* %282, align 64, !tbaa !192
  %indvars.iv.next44 = add nsw i64 %indvars.iv43, 1
  %283 = icmp slt i64 %indvars.iv.next44, %32
  br i1 %283, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_32(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !195 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !197, metadata !DIExpression()), !dbg !200
  call void @llvm.dbg.value(metadata i8* %1, metadata !198, metadata !DIExpression()), !dbg !200
  call void @llvm.dbg.value(metadata i32 %2, metadata !199, metadata !DIExpression()), !dbg !200
  %3 = bitcast i8* %0 to %1**, !dbg !200
  %4 = load %1*, %1** %3, align 8, !dbg !200
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !200
  %6 = bitcast i8* %5 to %1**, !dbg !200
  %7 = load %1*, %1** %6, align 8, !dbg !200
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !200
  %9 = load i8*, i8** %8, align 8, !dbg !200
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !200
  %11 = load i8*, i8** %10, align 8, !dbg !200
  %12 = tail call fastcc i32 @fused_layout_transform_32_compute_(i8* %11, i8* %9), !dbg !200
  ret i32 %12, !dbg !200
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_32_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %16, align 8
  %3 = getelementptr inbounds %16, %16* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %16, %16* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %16* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.12, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.12(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 6
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 7
  %15 = select i1 %14, i32 %13, i32 7
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 7
  %18 = select i1 %17, i32 %16, i32 7
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.6
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end6.6 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 224
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %27 = add nsw i64 %24, %indvars.iv
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 31
  %30 = lshr i32 %28, 5
  %31 = mul nsw i32 %30, 1568
  %32 = add i32 %26, %31
  %33 = or i32 %32, %29
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to i32*
  %37 = load i32, i32* %36, align 4, !tbaa !201
  %38 = getelementptr inbounds float, float* %4, i64 %27
  %39 = bitcast float* %38 to i32*
  store i32 %37, i32* %39, align 4, !tbaa !204
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %40 = add nsw i64 %24, 512
  %41 = add i32 %26, 32
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %42 = add nsw i64 %40, %indvars.iv.1
  %43 = trunc i64 %indvars.iv.1 to i32
  %44 = and i32 %43, 31
  %45 = lshr i32 %43, 5
  %46 = mul nsw i32 %45, 1568
  %47 = add i32 %41, %46
  %48 = or i32 %47, %44
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to i32*
  %52 = load i32, i32* %51, align 4, !tbaa !201
  %53 = getelementptr inbounds float, float* %4, i64 %42
  %54 = bitcast float* %53 to i32*
  store i32 %52, i32* %54, align 4, !tbaa !204
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %55 = add nsw i64 %24, 1024
  %56 = add i32 %26, 64
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %57 = add nsw i64 %55, %indvars.iv.2
  %58 = trunc i64 %indvars.iv.2 to i32
  %59 = and i32 %58, 31
  %60 = lshr i32 %58, 5
  %61 = mul nsw i32 %60, 1568
  %62 = add i32 %56, %61
  %63 = or i32 %62, %59
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !201
  %68 = getelementptr inbounds float, float* %4, i64 %57
  %69 = bitcast float* %68 to i32*
  store i32 %67, i32* %69, align 4, !tbaa !204
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  %70 = add nsw i64 %24, 1536
  %71 = add i32 %26, 96
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %72 = add nsw i64 %70, %indvars.iv.3
  %73 = trunc i64 %indvars.iv.3 to i32
  %74 = and i32 %73, 31
  %75 = lshr i32 %73, 5
  %76 = mul nsw i32 %75, 1568
  %77 = add i32 %71, %76
  %78 = or i32 %77, %74
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to i32*
  %82 = load i32, i32* %81, align 4, !tbaa !201
  %83 = getelementptr inbounds float, float* %4, i64 %72
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4, !tbaa !204
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  %85 = add nsw i64 %24, 2048
  %86 = add i32 %26, 128
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %87 = add nsw i64 %85, %indvars.iv.4
  %88 = trunc i64 %indvars.iv.4 to i32
  %89 = and i32 %88, 31
  %90 = lshr i32 %88, 5
  %91 = mul nsw i32 %90, 1568
  %92 = add i32 %86, %91
  %93 = or i32 %92, %89
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !201
  %98 = getelementptr inbounds float, float* %4, i64 %87
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !204
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  %100 = add nsw i64 %24, 2560
  %101 = add i32 %26, 160
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %102 = add nsw i64 %100, %indvars.iv.5
  %103 = trunc i64 %indvars.iv.5 to i32
  %104 = and i32 %103, 31
  %105 = lshr i32 %103, 5
  %106 = mul nsw i32 %105, 1568
  %107 = add i32 %101, %106
  %108 = or i32 %107, %104
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !201
  %113 = getelementptr inbounds float, float* %4, i64 %102
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !204
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  %115 = add nsw i64 %24, 3072
  %116 = add i32 %26, 192
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %117 = add nsw i64 %115, %indvars.iv.6
  %118 = trunc i64 %indvars.iv.6 to i32
  %119 = and i32 %118, 31
  %120 = lshr i32 %118, 5
  %121 = mul nsw i32 %120, 1568
  %122 = add i32 %116, %121
  %123 = or i32 %122, %119
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to i32*
  %127 = load i32, i32* %126, align 4, !tbaa !201
  %128 = getelementptr inbounds float, float* %4, i64 %117
  %129 = bitcast float* %128 to i32*
  store i32 %127, i32* %129, align 4, !tbaa !204
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %130 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %130, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_40(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !207 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !209, metadata !DIExpression()), !dbg !212
  call void @llvm.dbg.value(metadata i8* %1, metadata !210, metadata !DIExpression()), !dbg !212
  call void @llvm.dbg.value(metadata i32 %2, metadata !211, metadata !DIExpression()), !dbg !212
  %3 = bitcast i8* %0 to %1**, !dbg !212
  %4 = load %1*, %1** %3, align 8, !dbg !212
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !212
  %6 = bitcast i8* %5 to %1**, !dbg !212
  %7 = load %1*, %1** %6, align 8, !dbg !212
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !212
  %9 = load i8*, i8** %8, align 8, !dbg !212
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !212
  %11 = load i8*, i8** %10, align 8, !dbg !212
  %12 = tail call fastcc i32 @fused_layout_transform_40_compute_(i8* %11, i8* %9), !dbg !212
  ret i32 %12, !dbg !212
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_40_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %17, align 8
  %3 = getelementptr inbounds %17, %17* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %17, %17* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %17* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.13, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.13(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 14336
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 9
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 25088
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !213
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !216
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_layout_transform_42(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !219 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !221, metadata !DIExpression()), !dbg !224
  call void @llvm.dbg.value(metadata i8* %1, metadata !222, metadata !DIExpression()), !dbg !224
  call void @llvm.dbg.value(metadata i32 %2, metadata !223, metadata !DIExpression()), !dbg !224
  %3 = bitcast i8* %0 to %1**, !dbg !224
  %4 = load %1*, %1** %3, align 8, !dbg !224
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !224
  %6 = bitcast i8* %5 to %1**, !dbg !224
  %7 = load %1*, %1** %6, align 8, !dbg !224
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !224
  %9 = load i8*, i8** %8, align 8, !dbg !224
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !224
  %11 = load i8*, i8** %10, align 8, !dbg !224
  %12 = tail call fastcc i32 @fused_layout_transform_42_compute_(i8* %11, i8* %9), !dbg !224
  ret i32 %12, !dbg !224
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_42_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %18, align 8
  %3 = getelementptr inbounds %18, %18* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %18, %18* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %18* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.14, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.14(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 14336
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 8
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 100352
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !225
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !228
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !231 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !233, metadata !DIExpression()), !dbg !236
  call void @llvm.dbg.value(metadata i8* %1, metadata !234, metadata !DIExpression()), !dbg !236
  call void @llvm.dbg.value(metadata i32 %2, metadata !235, metadata !DIExpression()), !dbg !236
  %3 = bitcast i8* %0 to %1**, !dbg !236
  %4 = load %1*, %1** %3, align 8, !dbg !236
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !236
  %6 = bitcast i8* %5 to %1**, !dbg !236
  %7 = load %1*, %1** %6, align 8, !dbg !236
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !236
  %9 = bitcast i8* %8 to %1**, !dbg !236
  %10 = load %1*, %1** %9, align 8, !dbg !236
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !236
  %12 = bitcast i8* %11 to %1**, !dbg !236
  %13 = load %1*, %1** %12, align 8, !dbg !236
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !236
  %15 = load i8*, i8** %14, align 8, !dbg !236
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !236
  %17 = load i32, i32* %16, align 4, !dbg !236
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !236
  %19 = load i8*, i8** %18, align 8, !dbg !236
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !236
  %21 = load i8*, i8** %20, align 8, !dbg !236
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !236
  %23 = load i8*, i8** %22, align 8, !dbg !236
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !236
  ret i32 %24, !dbg !236
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %6 = tail call i8* %5(i32 1, i32 %4, i64 262144, i32 2, i32 32)
  %7 = alloca %19, align 8
  %8 = getelementptr inbounds %19, %19* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %19, %19* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %19* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.15, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !19

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %21, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %20, align 8
  %15 = getelementptr inbounds %20, %20* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %20, %20* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %20, %20* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %20, %20* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = bitcast %20* %14 to i8*
  %20 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %21 = call i32 %20(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.16, i8* nonnull %19, i32 0)
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %call_end2, label %call_fail, !prof !19

call_end2:                                        ; preds = %call_end
  %23 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %24 = call i32 %23(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.15(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 31
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 32
  %15 = select i1 %14, i32 %13, i32 32
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 32
  %18 = select i1 %17, i32 %16, i32 32
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end3
  %20 = phi i32 [ %1962, %for_end3 ], [ %18, %for_body.preheader ]
  %21 = shl i32 %20, 11
  %22 = srem i32 %20, 16
  %.off = add nsw i32 %22, -1
  %23 = icmp ult i32 %.off, 14
  %24 = sdiv i32 %20, 16
  %25 = mul nsw i32 %24, 25088
  br i1 %23, label %for_body.split.us, label %vector.body385

for_body.split.us:                                ; preds = %for_body
  %26 = mul nsw i32 %22, 1792
  br label %for_body2.us

for_body2.us:                                     ; preds = %for_end6.us, %for_body.split.us
  %indvars.iv24 = phi i64 [ %indvars.iv.next25, %for_end6.us ], [ 0, %for_body.split.us ]
  %27 = shl nsw i64 %indvars.iv24, 7
  %28 = trunc i64 %indvars.iv24 to i32
  %29 = add i32 %28, -1
  %30 = icmp ult i32 %29, 14
  %31 = trunc i64 %27 to i32
  %32 = add i32 %21, %31
  br i1 %30, label %vector.body, label %vector.body37

for_end6.us:                                      ; preds = %vector.body37, %vector.body
  %indvars.iv.next25 = add nuw nsw i64 %indvars.iv24, 1
  %exitcond27 = icmp eq i64 %indvars.iv.next25, 16
  br i1 %exitcond27, label %for_end3, label %for_body2.us, !prof !29

vector.body:                                      ; preds = %for_body2.us
  %33 = trunc i64 %27 to i32
  %34 = add i32 %33, -1920
  %35 = add i32 %26, %34
  %36 = add i32 %35, %25
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds float, float* %7, i64 %37
  %39 = bitcast float* %38 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %39, align 4, !tbaa !237
  %40 = getelementptr float, float* %38, i64 4
  %41 = bitcast float* %40 to <4 x i32>*
  %wide.load36 = load <4 x i32>, <4 x i32>* %41, align 4, !tbaa !237
  %42 = sext i32 %32 to i64
  %43 = getelementptr inbounds float, float* %4, i64 %42
  %44 = bitcast float* %43 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %44, align 4, !tbaa !240
  %45 = getelementptr float, float* %43, i64 4
  %46 = bitcast float* %45 to <4 x i32>*
  store <4 x i32> %wide.load36, <4 x i32>* %46, align 4, !tbaa !240
  %47 = or i64 %27, 8
  %48 = trunc i64 %47 to i32
  %49 = add i32 %21, %48
  %50 = trunc i64 %47 to i32
  %51 = add i32 %50, -1920
  %52 = add i32 %26, %51
  %53 = add i32 %52, %25
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds float, float* %7, i64 %54
  %56 = bitcast float* %55 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %56, align 4, !tbaa !237
  %57 = getelementptr float, float* %55, i64 4
  %58 = bitcast float* %57 to <4 x i32>*
  %wide.load36.1 = load <4 x i32>, <4 x i32>* %58, align 4, !tbaa !237
  %59 = sext i32 %49 to i64
  %60 = getelementptr inbounds float, float* %4, i64 %59
  %61 = bitcast float* %60 to <4 x i32>*
  store <4 x i32> %wide.load.1, <4 x i32>* %61, align 4, !tbaa !240
  %62 = getelementptr float, float* %60, i64 4
  %63 = bitcast float* %62 to <4 x i32>*
  store <4 x i32> %wide.load36.1, <4 x i32>* %63, align 4, !tbaa !240
  %64 = or i64 %27, 16
  %65 = trunc i64 %64 to i32
  %66 = add i32 %21, %65
  %67 = trunc i64 %64 to i32
  %68 = add i32 %67, -1920
  %69 = add i32 %26, %68
  %70 = add i32 %69, %25
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds float, float* %7, i64 %71
  %73 = bitcast float* %72 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %73, align 4, !tbaa !237
  %74 = getelementptr float, float* %72, i64 4
  %75 = bitcast float* %74 to <4 x i32>*
  %wide.load36.2 = load <4 x i32>, <4 x i32>* %75, align 4, !tbaa !237
  %76 = sext i32 %66 to i64
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = bitcast float* %77 to <4 x i32>*
  store <4 x i32> %wide.load.2, <4 x i32>* %78, align 4, !tbaa !240
  %79 = getelementptr float, float* %77, i64 4
  %80 = bitcast float* %79 to <4 x i32>*
  store <4 x i32> %wide.load36.2, <4 x i32>* %80, align 4, !tbaa !240
  %81 = or i64 %27, 24
  %82 = trunc i64 %81 to i32
  %83 = add i32 %21, %82
  %84 = trunc i64 %81 to i32
  %85 = add i32 %84, -1920
  %86 = add i32 %26, %85
  %87 = add i32 %86, %25
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = bitcast float* %89 to <4 x i32>*
  %wide.load.3 = load <4 x i32>, <4 x i32>* %90, align 4, !tbaa !237
  %91 = getelementptr float, float* %89, i64 4
  %92 = bitcast float* %91 to <4 x i32>*
  %wide.load36.3 = load <4 x i32>, <4 x i32>* %92, align 4, !tbaa !237
  %93 = sext i32 %83 to i64
  %94 = getelementptr inbounds float, float* %4, i64 %93
  %95 = bitcast float* %94 to <4 x i32>*
  store <4 x i32> %wide.load.3, <4 x i32>* %95, align 4, !tbaa !240
  %96 = getelementptr float, float* %94, i64 4
  %97 = bitcast float* %96 to <4 x i32>*
  store <4 x i32> %wide.load36.3, <4 x i32>* %97, align 4, !tbaa !240
  %98 = or i64 %27, 32
  %99 = trunc i64 %98 to i32
  %100 = add i32 %21, %99
  %101 = trunc i64 %98 to i32
  %102 = add i32 %101, -1920
  %103 = add i32 %26, %102
  %104 = add i32 %103, %25
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds float, float* %7, i64 %105
  %107 = bitcast float* %106 to <4 x i32>*
  %wide.load.4 = load <4 x i32>, <4 x i32>* %107, align 4, !tbaa !237
  %108 = getelementptr float, float* %106, i64 4
  %109 = bitcast float* %108 to <4 x i32>*
  %wide.load36.4 = load <4 x i32>, <4 x i32>* %109, align 4, !tbaa !237
  %110 = sext i32 %100 to i64
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = bitcast float* %111 to <4 x i32>*
  store <4 x i32> %wide.load.4, <4 x i32>* %112, align 4, !tbaa !240
  %113 = getelementptr float, float* %111, i64 4
  %114 = bitcast float* %113 to <4 x i32>*
  store <4 x i32> %wide.load36.4, <4 x i32>* %114, align 4, !tbaa !240
  %115 = or i64 %27, 40
  %116 = trunc i64 %115 to i32
  %117 = add i32 %21, %116
  %118 = trunc i64 %115 to i32
  %119 = add i32 %118, -1920
  %120 = add i32 %26, %119
  %121 = add i32 %120, %25
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds float, float* %7, i64 %122
  %124 = bitcast float* %123 to <4 x i32>*
  %wide.load.5 = load <4 x i32>, <4 x i32>* %124, align 4, !tbaa !237
  %125 = getelementptr float, float* %123, i64 4
  %126 = bitcast float* %125 to <4 x i32>*
  %wide.load36.5 = load <4 x i32>, <4 x i32>* %126, align 4, !tbaa !237
  %127 = sext i32 %117 to i64
  %128 = getelementptr inbounds float, float* %4, i64 %127
  %129 = bitcast float* %128 to <4 x i32>*
  store <4 x i32> %wide.load.5, <4 x i32>* %129, align 4, !tbaa !240
  %130 = getelementptr float, float* %128, i64 4
  %131 = bitcast float* %130 to <4 x i32>*
  store <4 x i32> %wide.load36.5, <4 x i32>* %131, align 4, !tbaa !240
  %132 = or i64 %27, 48
  %133 = trunc i64 %132 to i32
  %134 = add i32 %21, %133
  %135 = trunc i64 %132 to i32
  %136 = add i32 %135, -1920
  %137 = add i32 %26, %136
  %138 = add i32 %137, %25
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to <4 x i32>*
  %wide.load.6 = load <4 x i32>, <4 x i32>* %141, align 4, !tbaa !237
  %142 = getelementptr float, float* %140, i64 4
  %143 = bitcast float* %142 to <4 x i32>*
  %wide.load36.6 = load <4 x i32>, <4 x i32>* %143, align 4, !tbaa !237
  %144 = sext i32 %134 to i64
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = bitcast float* %145 to <4 x i32>*
  store <4 x i32> %wide.load.6, <4 x i32>* %146, align 4, !tbaa !240
  %147 = getelementptr float, float* %145, i64 4
  %148 = bitcast float* %147 to <4 x i32>*
  store <4 x i32> %wide.load36.6, <4 x i32>* %148, align 4, !tbaa !240
  %149 = or i64 %27, 56
  %150 = trunc i64 %149 to i32
  %151 = add i32 %21, %150
  %152 = trunc i64 %149 to i32
  %153 = add i32 %152, -1920
  %154 = add i32 %26, %153
  %155 = add i32 %154, %25
  %156 = sext i32 %155 to i64
  %157 = getelementptr inbounds float, float* %7, i64 %156
  %158 = bitcast float* %157 to <4 x i32>*
  %wide.load.7 = load <4 x i32>, <4 x i32>* %158, align 4, !tbaa !237
  %159 = getelementptr float, float* %157, i64 4
  %160 = bitcast float* %159 to <4 x i32>*
  %wide.load36.7 = load <4 x i32>, <4 x i32>* %160, align 4, !tbaa !237
  %161 = sext i32 %151 to i64
  %162 = getelementptr inbounds float, float* %4, i64 %161
  %163 = bitcast float* %162 to <4 x i32>*
  store <4 x i32> %wide.load.7, <4 x i32>* %163, align 4, !tbaa !240
  %164 = getelementptr float, float* %162, i64 4
  %165 = bitcast float* %164 to <4 x i32>*
  store <4 x i32> %wide.load36.7, <4 x i32>* %165, align 4, !tbaa !240
  %166 = or i64 %27, 64
  %167 = trunc i64 %166 to i32
  %168 = add i32 %21, %167
  %169 = trunc i64 %166 to i32
  %170 = add i32 %169, -1920
  %171 = add i32 %26, %170
  %172 = add i32 %171, %25
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to <4 x i32>*
  %wide.load.8 = load <4 x i32>, <4 x i32>* %175, align 4, !tbaa !237
  %176 = getelementptr float, float* %174, i64 4
  %177 = bitcast float* %176 to <4 x i32>*
  %wide.load36.8 = load <4 x i32>, <4 x i32>* %177, align 4, !tbaa !237
  %178 = sext i32 %168 to i64
  %179 = getelementptr inbounds float, float* %4, i64 %178
  %180 = bitcast float* %179 to <4 x i32>*
  store <4 x i32> %wide.load.8, <4 x i32>* %180, align 4, !tbaa !240
  %181 = getelementptr float, float* %179, i64 4
  %182 = bitcast float* %181 to <4 x i32>*
  store <4 x i32> %wide.load36.8, <4 x i32>* %182, align 4, !tbaa !240
  %183 = or i64 %27, 72
  %184 = trunc i64 %183 to i32
  %185 = add i32 %21, %184
  %186 = trunc i64 %183 to i32
  %187 = add i32 %186, -1920
  %188 = add i32 %26, %187
  %189 = add i32 %188, %25
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds float, float* %7, i64 %190
  %192 = bitcast float* %191 to <4 x i32>*
  %wide.load.9 = load <4 x i32>, <4 x i32>* %192, align 4, !tbaa !237
  %193 = getelementptr float, float* %191, i64 4
  %194 = bitcast float* %193 to <4 x i32>*
  %wide.load36.9 = load <4 x i32>, <4 x i32>* %194, align 4, !tbaa !237
  %195 = sext i32 %185 to i64
  %196 = getelementptr inbounds float, float* %4, i64 %195
  %197 = bitcast float* %196 to <4 x i32>*
  store <4 x i32> %wide.load.9, <4 x i32>* %197, align 4, !tbaa !240
  %198 = getelementptr float, float* %196, i64 4
  %199 = bitcast float* %198 to <4 x i32>*
  store <4 x i32> %wide.load36.9, <4 x i32>* %199, align 4, !tbaa !240
  %200 = or i64 %27, 80
  %201 = trunc i64 %200 to i32
  %202 = add i32 %21, %201
  %203 = trunc i64 %200 to i32
  %204 = add i32 %203, -1920
  %205 = add i32 %26, %204
  %206 = add i32 %205, %25
  %207 = sext i32 %206 to i64
  %208 = getelementptr inbounds float, float* %7, i64 %207
  %209 = bitcast float* %208 to <4 x i32>*
  %wide.load.10 = load <4 x i32>, <4 x i32>* %209, align 4, !tbaa !237
  %210 = getelementptr float, float* %208, i64 4
  %211 = bitcast float* %210 to <4 x i32>*
  %wide.load36.10 = load <4 x i32>, <4 x i32>* %211, align 4, !tbaa !237
  %212 = sext i32 %202 to i64
  %213 = getelementptr inbounds float, float* %4, i64 %212
  %214 = bitcast float* %213 to <4 x i32>*
  store <4 x i32> %wide.load.10, <4 x i32>* %214, align 4, !tbaa !240
  %215 = getelementptr float, float* %213, i64 4
  %216 = bitcast float* %215 to <4 x i32>*
  store <4 x i32> %wide.load36.10, <4 x i32>* %216, align 4, !tbaa !240
  %217 = or i64 %27, 88
  %218 = trunc i64 %217 to i32
  %219 = add i32 %21, %218
  %220 = trunc i64 %217 to i32
  %221 = add i32 %220, -1920
  %222 = add i32 %26, %221
  %223 = add i32 %222, %25
  %224 = sext i32 %223 to i64
  %225 = getelementptr inbounds float, float* %7, i64 %224
  %226 = bitcast float* %225 to <4 x i32>*
  %wide.load.11 = load <4 x i32>, <4 x i32>* %226, align 4, !tbaa !237
  %227 = getelementptr float, float* %225, i64 4
  %228 = bitcast float* %227 to <4 x i32>*
  %wide.load36.11 = load <4 x i32>, <4 x i32>* %228, align 4, !tbaa !237
  %229 = sext i32 %219 to i64
  %230 = getelementptr inbounds float, float* %4, i64 %229
  %231 = bitcast float* %230 to <4 x i32>*
  store <4 x i32> %wide.load.11, <4 x i32>* %231, align 4, !tbaa !240
  %232 = getelementptr float, float* %230, i64 4
  %233 = bitcast float* %232 to <4 x i32>*
  store <4 x i32> %wide.load36.11, <4 x i32>* %233, align 4, !tbaa !240
  %234 = or i64 %27, 96
  %235 = trunc i64 %234 to i32
  %236 = add i32 %21, %235
  %237 = trunc i64 %234 to i32
  %238 = add i32 %237, -1920
  %239 = add i32 %26, %238
  %240 = add i32 %239, %25
  %241 = sext i32 %240 to i64
  %242 = getelementptr inbounds float, float* %7, i64 %241
  %243 = bitcast float* %242 to <4 x i32>*
  %wide.load.12 = load <4 x i32>, <4 x i32>* %243, align 4, !tbaa !237
  %244 = getelementptr float, float* %242, i64 4
  %245 = bitcast float* %244 to <4 x i32>*
  %wide.load36.12 = load <4 x i32>, <4 x i32>* %245, align 4, !tbaa !237
  %246 = sext i32 %236 to i64
  %247 = getelementptr inbounds float, float* %4, i64 %246
  %248 = bitcast float* %247 to <4 x i32>*
  store <4 x i32> %wide.load.12, <4 x i32>* %248, align 4, !tbaa !240
  %249 = getelementptr float, float* %247, i64 4
  %250 = bitcast float* %249 to <4 x i32>*
  store <4 x i32> %wide.load36.12, <4 x i32>* %250, align 4, !tbaa !240
  %251 = or i64 %27, 104
  %252 = trunc i64 %251 to i32
  %253 = add i32 %21, %252
  %254 = trunc i64 %251 to i32
  %255 = add i32 %254, -1920
  %256 = add i32 %26, %255
  %257 = add i32 %256, %25
  %258 = sext i32 %257 to i64
  %259 = getelementptr inbounds float, float* %7, i64 %258
  %260 = bitcast float* %259 to <4 x i32>*
  %wide.load.13 = load <4 x i32>, <4 x i32>* %260, align 4, !tbaa !237
  %261 = getelementptr float, float* %259, i64 4
  %262 = bitcast float* %261 to <4 x i32>*
  %wide.load36.13 = load <4 x i32>, <4 x i32>* %262, align 4, !tbaa !237
  %263 = sext i32 %253 to i64
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = bitcast float* %264 to <4 x i32>*
  store <4 x i32> %wide.load.13, <4 x i32>* %265, align 4, !tbaa !240
  %266 = getelementptr float, float* %264, i64 4
  %267 = bitcast float* %266 to <4 x i32>*
  store <4 x i32> %wide.load36.13, <4 x i32>* %267, align 4, !tbaa !240
  %268 = or i64 %27, 112
  %269 = trunc i64 %268 to i32
  %270 = add i32 %21, %269
  %271 = trunc i64 %268 to i32
  %272 = add i32 %271, -1920
  %273 = add i32 %26, %272
  %274 = add i32 %273, %25
  %275 = sext i32 %274 to i64
  %276 = getelementptr inbounds float, float* %7, i64 %275
  %277 = bitcast float* %276 to <4 x i32>*
  %wide.load.14 = load <4 x i32>, <4 x i32>* %277, align 4, !tbaa !237
  %278 = getelementptr float, float* %276, i64 4
  %279 = bitcast float* %278 to <4 x i32>*
  %wide.load36.14 = load <4 x i32>, <4 x i32>* %279, align 4, !tbaa !237
  %280 = sext i32 %270 to i64
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = bitcast float* %281 to <4 x i32>*
  store <4 x i32> %wide.load.14, <4 x i32>* %282, align 4, !tbaa !240
  %283 = getelementptr float, float* %281, i64 4
  %284 = bitcast float* %283 to <4 x i32>*
  store <4 x i32> %wide.load36.14, <4 x i32>* %284, align 4, !tbaa !240
  %285 = or i64 %27, 120
  %286 = trunc i64 %285 to i32
  %287 = add i32 %21, %286
  %288 = trunc i64 %285 to i32
  %289 = add i32 %288, -1920
  %290 = add i32 %26, %289
  %291 = add i32 %290, %25
  %292 = sext i32 %291 to i64
  %293 = getelementptr inbounds float, float* %7, i64 %292
  %294 = bitcast float* %293 to <4 x i32>*
  %wide.load.15 = load <4 x i32>, <4 x i32>* %294, align 4, !tbaa !237
  %295 = getelementptr float, float* %293, i64 4
  %296 = bitcast float* %295 to <4 x i32>*
  %wide.load36.15 = load <4 x i32>, <4 x i32>* %296, align 4, !tbaa !237
  %297 = sext i32 %287 to i64
  %298 = getelementptr inbounds float, float* %4, i64 %297
  %299 = bitcast float* %298 to <4 x i32>*
  store <4 x i32> %wide.load.15, <4 x i32>* %299, align 4, !tbaa !240
  %300 = getelementptr float, float* %298, i64 4
  %301 = bitcast float* %300 to <4 x i32>*
  store <4 x i32> %wide.load36.15, <4 x i32>* %301, align 4, !tbaa !240
  br label %for_end6.us

vector.body37:                                    ; preds = %for_body2.us
  %302 = sext i32 %32 to i64
  %303 = getelementptr inbounds float, float* %4, i64 %302
  %304 = bitcast float* %303 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %304, align 4, !tbaa !240
  %305 = getelementptr float, float* %303, i64 4
  %306 = bitcast float* %305 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %306, align 4, !tbaa !240
  %307 = trunc i64 %27 to i32
  %308 = or i32 %307, 8
  %309 = add i32 %21, %308
  %310 = sext i32 %309 to i64
  %311 = getelementptr inbounds float, float* %4, i64 %310
  %312 = bitcast float* %311 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %312, align 4, !tbaa !240
  %313 = getelementptr float, float* %311, i64 4
  %314 = bitcast float* %313 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %314, align 4, !tbaa !240
  %315 = trunc i64 %27 to i32
  %316 = or i32 %315, 16
  %317 = add i32 %21, %316
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds float, float* %4, i64 %318
  %320 = bitcast float* %319 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %320, align 4, !tbaa !240
  %321 = getelementptr float, float* %319, i64 4
  %322 = bitcast float* %321 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %322, align 4, !tbaa !240
  %323 = trunc i64 %27 to i32
  %324 = or i32 %323, 24
  %325 = add i32 %21, %324
  %326 = sext i32 %325 to i64
  %327 = getelementptr inbounds float, float* %4, i64 %326
  %328 = bitcast float* %327 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %328, align 4, !tbaa !240
  %329 = getelementptr float, float* %327, i64 4
  %330 = bitcast float* %329 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %330, align 4, !tbaa !240
  %331 = trunc i64 %27 to i32
  %332 = or i32 %331, 32
  %333 = add i32 %21, %332
  %334 = sext i32 %333 to i64
  %335 = getelementptr inbounds float, float* %4, i64 %334
  %336 = bitcast float* %335 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %336, align 4, !tbaa !240
  %337 = getelementptr float, float* %335, i64 4
  %338 = bitcast float* %337 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %338, align 4, !tbaa !240
  %339 = trunc i64 %27 to i32
  %340 = or i32 %339, 40
  %341 = add i32 %21, %340
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds float, float* %4, i64 %342
  %344 = bitcast float* %343 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %344, align 4, !tbaa !240
  %345 = getelementptr float, float* %343, i64 4
  %346 = bitcast float* %345 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %346, align 4, !tbaa !240
  %347 = trunc i64 %27 to i32
  %348 = or i32 %347, 48
  %349 = add i32 %21, %348
  %350 = sext i32 %349 to i64
  %351 = getelementptr inbounds float, float* %4, i64 %350
  %352 = bitcast float* %351 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %352, align 4, !tbaa !240
  %353 = getelementptr float, float* %351, i64 4
  %354 = bitcast float* %353 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %354, align 4, !tbaa !240
  %355 = trunc i64 %27 to i32
  %356 = or i32 %355, 56
  %357 = add i32 %21, %356
  %358 = sext i32 %357 to i64
  %359 = getelementptr inbounds float, float* %4, i64 %358
  %360 = bitcast float* %359 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %360, align 4, !tbaa !240
  %361 = getelementptr float, float* %359, i64 4
  %362 = bitcast float* %361 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %362, align 4, !tbaa !240
  %363 = trunc i64 %27 to i32
  %364 = or i32 %363, 64
  %365 = add i32 %21, %364
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds float, float* %4, i64 %366
  %368 = bitcast float* %367 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %368, align 4, !tbaa !240
  %369 = getelementptr float, float* %367, i64 4
  %370 = bitcast float* %369 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %370, align 4, !tbaa !240
  %371 = trunc i64 %27 to i32
  %372 = or i32 %371, 72
  %373 = add i32 %21, %372
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds float, float* %4, i64 %374
  %376 = bitcast float* %375 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %376, align 4, !tbaa !240
  %377 = getelementptr float, float* %375, i64 4
  %378 = bitcast float* %377 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %378, align 4, !tbaa !240
  %379 = trunc i64 %27 to i32
  %380 = or i32 %379, 80
  %381 = add i32 %21, %380
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds float, float* %4, i64 %382
  %384 = bitcast float* %383 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %384, align 4, !tbaa !240
  %385 = getelementptr float, float* %383, i64 4
  %386 = bitcast float* %385 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %386, align 4, !tbaa !240
  %387 = trunc i64 %27 to i32
  %388 = or i32 %387, 88
  %389 = add i32 %21, %388
  %390 = sext i32 %389 to i64
  %391 = getelementptr inbounds float, float* %4, i64 %390
  %392 = bitcast float* %391 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %392, align 4, !tbaa !240
  %393 = getelementptr float, float* %391, i64 4
  %394 = bitcast float* %393 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %394, align 4, !tbaa !240
  %395 = trunc i64 %27 to i32
  %396 = or i32 %395, 96
  %397 = add i32 %21, %396
  %398 = sext i32 %397 to i64
  %399 = getelementptr inbounds float, float* %4, i64 %398
  %400 = bitcast float* %399 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %400, align 4, !tbaa !240
  %401 = getelementptr float, float* %399, i64 4
  %402 = bitcast float* %401 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %402, align 4, !tbaa !240
  %403 = trunc i64 %27 to i32
  %404 = or i32 %403, 104
  %405 = add i32 %21, %404
  %406 = sext i32 %405 to i64
  %407 = getelementptr inbounds float, float* %4, i64 %406
  %408 = bitcast float* %407 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %408, align 4, !tbaa !240
  %409 = getelementptr float, float* %407, i64 4
  %410 = bitcast float* %409 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %410, align 4, !tbaa !240
  %411 = trunc i64 %27 to i32
  %412 = or i32 %411, 112
  %413 = add i32 %21, %412
  %414 = sext i32 %413 to i64
  %415 = getelementptr inbounds float, float* %4, i64 %414
  %416 = bitcast float* %415 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %416, align 4, !tbaa !240
  %417 = getelementptr float, float* %415, i64 4
  %418 = bitcast float* %417 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %418, align 4, !tbaa !240
  %419 = trunc i64 %27 to i32
  %420 = or i32 %419, 120
  %421 = add i32 %21, %420
  %422 = sext i32 %421 to i64
  %423 = getelementptr inbounds float, float* %4, i64 %422
  %424 = bitcast float* %423 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %424, align 4, !tbaa !240
  %425 = getelementptr float, float* %423, i64 4
  %426 = bitcast float* %425 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %426, align 4, !tbaa !240
  br label %for_end6.us

vector.body385:                                   ; preds = %for_body
  %427 = sext i32 %21 to i64
  %428 = getelementptr inbounds float, float* %4, i64 %427
  %429 = bitcast float* %428 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %429, align 4, !tbaa !240
  %430 = getelementptr float, float* %428, i64 4
  %431 = bitcast float* %430 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %431, align 4, !tbaa !240
  %432 = or i32 %21, 8
  %433 = sext i32 %432 to i64
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = bitcast float* %434 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %435, align 4, !tbaa !240
  %436 = getelementptr float, float* %434, i64 4
  %437 = bitcast float* %436 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %437, align 4, !tbaa !240
  %438 = or i32 %21, 16
  %439 = sext i32 %438 to i64
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = bitcast float* %440 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %441, align 4, !tbaa !240
  %442 = getelementptr float, float* %440, i64 4
  %443 = bitcast float* %442 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %443, align 4, !tbaa !240
  %444 = or i32 %21, 24
  %445 = sext i32 %444 to i64
  %446 = getelementptr inbounds float, float* %4, i64 %445
  %447 = bitcast float* %446 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %447, align 4, !tbaa !240
  %448 = getelementptr float, float* %446, i64 4
  %449 = bitcast float* %448 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %449, align 4, !tbaa !240
  %450 = or i32 %21, 32
  %451 = sext i32 %450 to i64
  %452 = getelementptr inbounds float, float* %4, i64 %451
  %453 = bitcast float* %452 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %453, align 4, !tbaa !240
  %454 = getelementptr float, float* %452, i64 4
  %455 = bitcast float* %454 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %455, align 4, !tbaa !240
  %456 = or i32 %21, 40
  %457 = sext i32 %456 to i64
  %458 = getelementptr inbounds float, float* %4, i64 %457
  %459 = bitcast float* %458 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %459, align 4, !tbaa !240
  %460 = getelementptr float, float* %458, i64 4
  %461 = bitcast float* %460 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %461, align 4, !tbaa !240
  %462 = or i32 %21, 48
  %463 = sext i32 %462 to i64
  %464 = getelementptr inbounds float, float* %4, i64 %463
  %465 = bitcast float* %464 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %465, align 4, !tbaa !240
  %466 = getelementptr float, float* %464, i64 4
  %467 = bitcast float* %466 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %467, align 4, !tbaa !240
  %468 = or i32 %21, 56
  %469 = sext i32 %468 to i64
  %470 = getelementptr inbounds float, float* %4, i64 %469
  %471 = bitcast float* %470 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %471, align 4, !tbaa !240
  %472 = getelementptr float, float* %470, i64 4
  %473 = bitcast float* %472 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %473, align 4, !tbaa !240
  %474 = or i32 %21, 64
  %475 = sext i32 %474 to i64
  %476 = getelementptr inbounds float, float* %4, i64 %475
  %477 = bitcast float* %476 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %477, align 4, !tbaa !240
  %478 = getelementptr float, float* %476, i64 4
  %479 = bitcast float* %478 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %479, align 4, !tbaa !240
  %480 = or i32 %21, 72
  %481 = sext i32 %480 to i64
  %482 = getelementptr inbounds float, float* %4, i64 %481
  %483 = bitcast float* %482 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %483, align 4, !tbaa !240
  %484 = getelementptr float, float* %482, i64 4
  %485 = bitcast float* %484 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %485, align 4, !tbaa !240
  %486 = or i32 %21, 80
  %487 = sext i32 %486 to i64
  %488 = getelementptr inbounds float, float* %4, i64 %487
  %489 = bitcast float* %488 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %489, align 4, !tbaa !240
  %490 = getelementptr float, float* %488, i64 4
  %491 = bitcast float* %490 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %491, align 4, !tbaa !240
  %492 = or i32 %21, 88
  %493 = sext i32 %492 to i64
  %494 = getelementptr inbounds float, float* %4, i64 %493
  %495 = bitcast float* %494 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %495, align 4, !tbaa !240
  %496 = getelementptr float, float* %494, i64 4
  %497 = bitcast float* %496 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %497, align 4, !tbaa !240
  %498 = or i32 %21, 96
  %499 = sext i32 %498 to i64
  %500 = getelementptr inbounds float, float* %4, i64 %499
  %501 = bitcast float* %500 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %501, align 4, !tbaa !240
  %502 = getelementptr float, float* %500, i64 4
  %503 = bitcast float* %502 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %503, align 4, !tbaa !240
  %504 = or i32 %21, 104
  %505 = sext i32 %504 to i64
  %506 = getelementptr inbounds float, float* %4, i64 %505
  %507 = bitcast float* %506 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %507, align 4, !tbaa !240
  %508 = getelementptr float, float* %506, i64 4
  %509 = bitcast float* %508 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %509, align 4, !tbaa !240
  %510 = or i32 %21, 112
  %511 = sext i32 %510 to i64
  %512 = getelementptr inbounds float, float* %4, i64 %511
  %513 = bitcast float* %512 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %513, align 4, !tbaa !240
  %514 = getelementptr float, float* %512, i64 4
  %515 = bitcast float* %514 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %515, align 4, !tbaa !240
  %516 = or i32 %21, 120
  %517 = sext i32 %516 to i64
  %518 = getelementptr inbounds float, float* %4, i64 %517
  %519 = bitcast float* %518 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %519, align 4, !tbaa !240
  %520 = getelementptr float, float* %518, i64 4
  %521 = bitcast float* %520 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %521, align 4, !tbaa !240
  %522 = or i32 %21, 128
  %523 = sext i32 %522 to i64
  %524 = getelementptr inbounds float, float* %4, i64 %523
  %525 = bitcast float* %524 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %525, align 4, !tbaa !240
  %526 = getelementptr float, float* %524, i64 4
  %527 = bitcast float* %526 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %527, align 4, !tbaa !240
  %528 = or i32 %21, 136
  %529 = sext i32 %528 to i64
  %530 = getelementptr inbounds float, float* %4, i64 %529
  %531 = bitcast float* %530 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %531, align 4, !tbaa !240
  %532 = getelementptr float, float* %530, i64 4
  %533 = bitcast float* %532 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %533, align 4, !tbaa !240
  %534 = or i32 %21, 144
  %535 = sext i32 %534 to i64
  %536 = getelementptr inbounds float, float* %4, i64 %535
  %537 = bitcast float* %536 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %537, align 4, !tbaa !240
  %538 = getelementptr float, float* %536, i64 4
  %539 = bitcast float* %538 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %539, align 4, !tbaa !240
  %540 = or i32 %21, 152
  %541 = sext i32 %540 to i64
  %542 = getelementptr inbounds float, float* %4, i64 %541
  %543 = bitcast float* %542 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %543, align 4, !tbaa !240
  %544 = getelementptr float, float* %542, i64 4
  %545 = bitcast float* %544 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %545, align 4, !tbaa !240
  %546 = or i32 %21, 160
  %547 = sext i32 %546 to i64
  %548 = getelementptr inbounds float, float* %4, i64 %547
  %549 = bitcast float* %548 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %549, align 4, !tbaa !240
  %550 = getelementptr float, float* %548, i64 4
  %551 = bitcast float* %550 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %551, align 4, !tbaa !240
  %552 = or i32 %21, 168
  %553 = sext i32 %552 to i64
  %554 = getelementptr inbounds float, float* %4, i64 %553
  %555 = bitcast float* %554 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %555, align 4, !tbaa !240
  %556 = getelementptr float, float* %554, i64 4
  %557 = bitcast float* %556 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %557, align 4, !tbaa !240
  %558 = or i32 %21, 176
  %559 = sext i32 %558 to i64
  %560 = getelementptr inbounds float, float* %4, i64 %559
  %561 = bitcast float* %560 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %561, align 4, !tbaa !240
  %562 = getelementptr float, float* %560, i64 4
  %563 = bitcast float* %562 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %563, align 4, !tbaa !240
  %564 = or i32 %21, 184
  %565 = sext i32 %564 to i64
  %566 = getelementptr inbounds float, float* %4, i64 %565
  %567 = bitcast float* %566 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %567, align 4, !tbaa !240
  %568 = getelementptr float, float* %566, i64 4
  %569 = bitcast float* %568 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %569, align 4, !tbaa !240
  %570 = or i32 %21, 192
  %571 = sext i32 %570 to i64
  %572 = getelementptr inbounds float, float* %4, i64 %571
  %573 = bitcast float* %572 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %573, align 4, !tbaa !240
  %574 = getelementptr float, float* %572, i64 4
  %575 = bitcast float* %574 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %575, align 4, !tbaa !240
  %576 = or i32 %21, 200
  %577 = sext i32 %576 to i64
  %578 = getelementptr inbounds float, float* %4, i64 %577
  %579 = bitcast float* %578 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %579, align 4, !tbaa !240
  %580 = getelementptr float, float* %578, i64 4
  %581 = bitcast float* %580 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %581, align 4, !tbaa !240
  %582 = or i32 %21, 208
  %583 = sext i32 %582 to i64
  %584 = getelementptr inbounds float, float* %4, i64 %583
  %585 = bitcast float* %584 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %585, align 4, !tbaa !240
  %586 = getelementptr float, float* %584, i64 4
  %587 = bitcast float* %586 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %587, align 4, !tbaa !240
  %588 = or i32 %21, 216
  %589 = sext i32 %588 to i64
  %590 = getelementptr inbounds float, float* %4, i64 %589
  %591 = bitcast float* %590 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %591, align 4, !tbaa !240
  %592 = getelementptr float, float* %590, i64 4
  %593 = bitcast float* %592 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %593, align 4, !tbaa !240
  %594 = or i32 %21, 224
  %595 = sext i32 %594 to i64
  %596 = getelementptr inbounds float, float* %4, i64 %595
  %597 = bitcast float* %596 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %597, align 4, !tbaa !240
  %598 = getelementptr float, float* %596, i64 4
  %599 = bitcast float* %598 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %599, align 4, !tbaa !240
  %600 = or i32 %21, 232
  %601 = sext i32 %600 to i64
  %602 = getelementptr inbounds float, float* %4, i64 %601
  %603 = bitcast float* %602 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %603, align 4, !tbaa !240
  %604 = getelementptr float, float* %602, i64 4
  %605 = bitcast float* %604 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %605, align 4, !tbaa !240
  %606 = or i32 %21, 240
  %607 = sext i32 %606 to i64
  %608 = getelementptr inbounds float, float* %4, i64 %607
  %609 = bitcast float* %608 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %609, align 4, !tbaa !240
  %610 = getelementptr float, float* %608, i64 4
  %611 = bitcast float* %610 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %611, align 4, !tbaa !240
  %612 = or i32 %21, 248
  %613 = sext i32 %612 to i64
  %614 = getelementptr inbounds float, float* %4, i64 %613
  %615 = bitcast float* %614 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %615, align 4, !tbaa !240
  %616 = getelementptr float, float* %614, i64 4
  %617 = bitcast float* %616 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %617, align 4, !tbaa !240
  %618 = or i32 %21, 256
  %619 = sext i32 %618 to i64
  %620 = getelementptr inbounds float, float* %4, i64 %619
  %621 = bitcast float* %620 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %621, align 4, !tbaa !240
  %622 = getelementptr float, float* %620, i64 4
  %623 = bitcast float* %622 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %623, align 4, !tbaa !240
  %624 = or i32 %21, 264
  %625 = sext i32 %624 to i64
  %626 = getelementptr inbounds float, float* %4, i64 %625
  %627 = bitcast float* %626 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %627, align 4, !tbaa !240
  %628 = getelementptr float, float* %626, i64 4
  %629 = bitcast float* %628 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %629, align 4, !tbaa !240
  %630 = or i32 %21, 272
  %631 = sext i32 %630 to i64
  %632 = getelementptr inbounds float, float* %4, i64 %631
  %633 = bitcast float* %632 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %633, align 4, !tbaa !240
  %634 = getelementptr float, float* %632, i64 4
  %635 = bitcast float* %634 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %635, align 4, !tbaa !240
  %636 = or i32 %21, 280
  %637 = sext i32 %636 to i64
  %638 = getelementptr inbounds float, float* %4, i64 %637
  %639 = bitcast float* %638 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %639, align 4, !tbaa !240
  %640 = getelementptr float, float* %638, i64 4
  %641 = bitcast float* %640 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %641, align 4, !tbaa !240
  %642 = or i32 %21, 288
  %643 = sext i32 %642 to i64
  %644 = getelementptr inbounds float, float* %4, i64 %643
  %645 = bitcast float* %644 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %645, align 4, !tbaa !240
  %646 = getelementptr float, float* %644, i64 4
  %647 = bitcast float* %646 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %647, align 4, !tbaa !240
  %648 = or i32 %21, 296
  %649 = sext i32 %648 to i64
  %650 = getelementptr inbounds float, float* %4, i64 %649
  %651 = bitcast float* %650 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %651, align 4, !tbaa !240
  %652 = getelementptr float, float* %650, i64 4
  %653 = bitcast float* %652 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %653, align 4, !tbaa !240
  %654 = or i32 %21, 304
  %655 = sext i32 %654 to i64
  %656 = getelementptr inbounds float, float* %4, i64 %655
  %657 = bitcast float* %656 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %657, align 4, !tbaa !240
  %658 = getelementptr float, float* %656, i64 4
  %659 = bitcast float* %658 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %659, align 4, !tbaa !240
  %660 = or i32 %21, 312
  %661 = sext i32 %660 to i64
  %662 = getelementptr inbounds float, float* %4, i64 %661
  %663 = bitcast float* %662 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %663, align 4, !tbaa !240
  %664 = getelementptr float, float* %662, i64 4
  %665 = bitcast float* %664 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %665, align 4, !tbaa !240
  %666 = or i32 %21, 320
  %667 = sext i32 %666 to i64
  %668 = getelementptr inbounds float, float* %4, i64 %667
  %669 = bitcast float* %668 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %669, align 4, !tbaa !240
  %670 = getelementptr float, float* %668, i64 4
  %671 = bitcast float* %670 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %671, align 4, !tbaa !240
  %672 = or i32 %21, 328
  %673 = sext i32 %672 to i64
  %674 = getelementptr inbounds float, float* %4, i64 %673
  %675 = bitcast float* %674 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %675, align 4, !tbaa !240
  %676 = getelementptr float, float* %674, i64 4
  %677 = bitcast float* %676 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %677, align 4, !tbaa !240
  %678 = or i32 %21, 336
  %679 = sext i32 %678 to i64
  %680 = getelementptr inbounds float, float* %4, i64 %679
  %681 = bitcast float* %680 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %681, align 4, !tbaa !240
  %682 = getelementptr float, float* %680, i64 4
  %683 = bitcast float* %682 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %683, align 4, !tbaa !240
  %684 = or i32 %21, 344
  %685 = sext i32 %684 to i64
  %686 = getelementptr inbounds float, float* %4, i64 %685
  %687 = bitcast float* %686 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %687, align 4, !tbaa !240
  %688 = getelementptr float, float* %686, i64 4
  %689 = bitcast float* %688 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %689, align 4, !tbaa !240
  %690 = or i32 %21, 352
  %691 = sext i32 %690 to i64
  %692 = getelementptr inbounds float, float* %4, i64 %691
  %693 = bitcast float* %692 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %693, align 4, !tbaa !240
  %694 = getelementptr float, float* %692, i64 4
  %695 = bitcast float* %694 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %695, align 4, !tbaa !240
  %696 = or i32 %21, 360
  %697 = sext i32 %696 to i64
  %698 = getelementptr inbounds float, float* %4, i64 %697
  %699 = bitcast float* %698 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %699, align 4, !tbaa !240
  %700 = getelementptr float, float* %698, i64 4
  %701 = bitcast float* %700 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %701, align 4, !tbaa !240
  %702 = or i32 %21, 368
  %703 = sext i32 %702 to i64
  %704 = getelementptr inbounds float, float* %4, i64 %703
  %705 = bitcast float* %704 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %705, align 4, !tbaa !240
  %706 = getelementptr float, float* %704, i64 4
  %707 = bitcast float* %706 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %707, align 4, !tbaa !240
  %708 = or i32 %21, 376
  %709 = sext i32 %708 to i64
  %710 = getelementptr inbounds float, float* %4, i64 %709
  %711 = bitcast float* %710 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %711, align 4, !tbaa !240
  %712 = getelementptr float, float* %710, i64 4
  %713 = bitcast float* %712 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %713, align 4, !tbaa !240
  %714 = or i32 %21, 384
  %715 = sext i32 %714 to i64
  %716 = getelementptr inbounds float, float* %4, i64 %715
  %717 = bitcast float* %716 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %717, align 4, !tbaa !240
  %718 = getelementptr float, float* %716, i64 4
  %719 = bitcast float* %718 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %719, align 4, !tbaa !240
  %720 = or i32 %21, 392
  %721 = sext i32 %720 to i64
  %722 = getelementptr inbounds float, float* %4, i64 %721
  %723 = bitcast float* %722 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %723, align 4, !tbaa !240
  %724 = getelementptr float, float* %722, i64 4
  %725 = bitcast float* %724 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %725, align 4, !tbaa !240
  %726 = or i32 %21, 400
  %727 = sext i32 %726 to i64
  %728 = getelementptr inbounds float, float* %4, i64 %727
  %729 = bitcast float* %728 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %729, align 4, !tbaa !240
  %730 = getelementptr float, float* %728, i64 4
  %731 = bitcast float* %730 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %731, align 4, !tbaa !240
  %732 = or i32 %21, 408
  %733 = sext i32 %732 to i64
  %734 = getelementptr inbounds float, float* %4, i64 %733
  %735 = bitcast float* %734 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %735, align 4, !tbaa !240
  %736 = getelementptr float, float* %734, i64 4
  %737 = bitcast float* %736 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %737, align 4, !tbaa !240
  %738 = or i32 %21, 416
  %739 = sext i32 %738 to i64
  %740 = getelementptr inbounds float, float* %4, i64 %739
  %741 = bitcast float* %740 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %741, align 4, !tbaa !240
  %742 = getelementptr float, float* %740, i64 4
  %743 = bitcast float* %742 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %743, align 4, !tbaa !240
  %744 = or i32 %21, 424
  %745 = sext i32 %744 to i64
  %746 = getelementptr inbounds float, float* %4, i64 %745
  %747 = bitcast float* %746 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %747, align 4, !tbaa !240
  %748 = getelementptr float, float* %746, i64 4
  %749 = bitcast float* %748 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %749, align 4, !tbaa !240
  %750 = or i32 %21, 432
  %751 = sext i32 %750 to i64
  %752 = getelementptr inbounds float, float* %4, i64 %751
  %753 = bitcast float* %752 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %753, align 4, !tbaa !240
  %754 = getelementptr float, float* %752, i64 4
  %755 = bitcast float* %754 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %755, align 4, !tbaa !240
  %756 = or i32 %21, 440
  %757 = sext i32 %756 to i64
  %758 = getelementptr inbounds float, float* %4, i64 %757
  %759 = bitcast float* %758 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %759, align 4, !tbaa !240
  %760 = getelementptr float, float* %758, i64 4
  %761 = bitcast float* %760 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %761, align 4, !tbaa !240
  %762 = or i32 %21, 448
  %763 = sext i32 %762 to i64
  %764 = getelementptr inbounds float, float* %4, i64 %763
  %765 = bitcast float* %764 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %765, align 4, !tbaa !240
  %766 = getelementptr float, float* %764, i64 4
  %767 = bitcast float* %766 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %767, align 4, !tbaa !240
  %768 = or i32 %21, 456
  %769 = sext i32 %768 to i64
  %770 = getelementptr inbounds float, float* %4, i64 %769
  %771 = bitcast float* %770 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %771, align 4, !tbaa !240
  %772 = getelementptr float, float* %770, i64 4
  %773 = bitcast float* %772 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %773, align 4, !tbaa !240
  %774 = or i32 %21, 464
  %775 = sext i32 %774 to i64
  %776 = getelementptr inbounds float, float* %4, i64 %775
  %777 = bitcast float* %776 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %777, align 4, !tbaa !240
  %778 = getelementptr float, float* %776, i64 4
  %779 = bitcast float* %778 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %779, align 4, !tbaa !240
  %780 = or i32 %21, 472
  %781 = sext i32 %780 to i64
  %782 = getelementptr inbounds float, float* %4, i64 %781
  %783 = bitcast float* %782 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %783, align 4, !tbaa !240
  %784 = getelementptr float, float* %782, i64 4
  %785 = bitcast float* %784 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %785, align 4, !tbaa !240
  %786 = or i32 %21, 480
  %787 = sext i32 %786 to i64
  %788 = getelementptr inbounds float, float* %4, i64 %787
  %789 = bitcast float* %788 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %789, align 4, !tbaa !240
  %790 = getelementptr float, float* %788, i64 4
  %791 = bitcast float* %790 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %791, align 4, !tbaa !240
  %792 = or i32 %21, 488
  %793 = sext i32 %792 to i64
  %794 = getelementptr inbounds float, float* %4, i64 %793
  %795 = bitcast float* %794 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %795, align 4, !tbaa !240
  %796 = getelementptr float, float* %794, i64 4
  %797 = bitcast float* %796 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %797, align 4, !tbaa !240
  %798 = or i32 %21, 496
  %799 = sext i32 %798 to i64
  %800 = getelementptr inbounds float, float* %4, i64 %799
  %801 = bitcast float* %800 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %801, align 4, !tbaa !240
  %802 = getelementptr float, float* %800, i64 4
  %803 = bitcast float* %802 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %803, align 4, !tbaa !240
  %804 = or i32 %21, 504
  %805 = sext i32 %804 to i64
  %806 = getelementptr inbounds float, float* %4, i64 %805
  %807 = bitcast float* %806 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %807, align 4, !tbaa !240
  %808 = getelementptr float, float* %806, i64 4
  %809 = bitcast float* %808 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %809, align 4, !tbaa !240
  %810 = or i32 %21, 512
  %811 = sext i32 %810 to i64
  %812 = getelementptr inbounds float, float* %4, i64 %811
  %813 = bitcast float* %812 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %813, align 4, !tbaa !240
  %814 = getelementptr float, float* %812, i64 4
  %815 = bitcast float* %814 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %815, align 4, !tbaa !240
  %816 = or i32 %21, 520
  %817 = sext i32 %816 to i64
  %818 = getelementptr inbounds float, float* %4, i64 %817
  %819 = bitcast float* %818 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %819, align 4, !tbaa !240
  %820 = getelementptr float, float* %818, i64 4
  %821 = bitcast float* %820 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %821, align 4, !tbaa !240
  %822 = or i32 %21, 528
  %823 = sext i32 %822 to i64
  %824 = getelementptr inbounds float, float* %4, i64 %823
  %825 = bitcast float* %824 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %825, align 4, !tbaa !240
  %826 = getelementptr float, float* %824, i64 4
  %827 = bitcast float* %826 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %827, align 4, !tbaa !240
  %828 = or i32 %21, 536
  %829 = sext i32 %828 to i64
  %830 = getelementptr inbounds float, float* %4, i64 %829
  %831 = bitcast float* %830 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %831, align 4, !tbaa !240
  %832 = getelementptr float, float* %830, i64 4
  %833 = bitcast float* %832 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %833, align 4, !tbaa !240
  %834 = or i32 %21, 544
  %835 = sext i32 %834 to i64
  %836 = getelementptr inbounds float, float* %4, i64 %835
  %837 = bitcast float* %836 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %837, align 4, !tbaa !240
  %838 = getelementptr float, float* %836, i64 4
  %839 = bitcast float* %838 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %839, align 4, !tbaa !240
  %840 = or i32 %21, 552
  %841 = sext i32 %840 to i64
  %842 = getelementptr inbounds float, float* %4, i64 %841
  %843 = bitcast float* %842 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %843, align 4, !tbaa !240
  %844 = getelementptr float, float* %842, i64 4
  %845 = bitcast float* %844 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %845, align 4, !tbaa !240
  %846 = or i32 %21, 560
  %847 = sext i32 %846 to i64
  %848 = getelementptr inbounds float, float* %4, i64 %847
  %849 = bitcast float* %848 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %849, align 4, !tbaa !240
  %850 = getelementptr float, float* %848, i64 4
  %851 = bitcast float* %850 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %851, align 4, !tbaa !240
  %852 = or i32 %21, 568
  %853 = sext i32 %852 to i64
  %854 = getelementptr inbounds float, float* %4, i64 %853
  %855 = bitcast float* %854 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %855, align 4, !tbaa !240
  %856 = getelementptr float, float* %854, i64 4
  %857 = bitcast float* %856 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %857, align 4, !tbaa !240
  %858 = or i32 %21, 576
  %859 = sext i32 %858 to i64
  %860 = getelementptr inbounds float, float* %4, i64 %859
  %861 = bitcast float* %860 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %861, align 4, !tbaa !240
  %862 = getelementptr float, float* %860, i64 4
  %863 = bitcast float* %862 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %863, align 4, !tbaa !240
  %864 = or i32 %21, 584
  %865 = sext i32 %864 to i64
  %866 = getelementptr inbounds float, float* %4, i64 %865
  %867 = bitcast float* %866 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %867, align 4, !tbaa !240
  %868 = getelementptr float, float* %866, i64 4
  %869 = bitcast float* %868 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %869, align 4, !tbaa !240
  %870 = or i32 %21, 592
  %871 = sext i32 %870 to i64
  %872 = getelementptr inbounds float, float* %4, i64 %871
  %873 = bitcast float* %872 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %873, align 4, !tbaa !240
  %874 = getelementptr float, float* %872, i64 4
  %875 = bitcast float* %874 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %875, align 4, !tbaa !240
  %876 = or i32 %21, 600
  %877 = sext i32 %876 to i64
  %878 = getelementptr inbounds float, float* %4, i64 %877
  %879 = bitcast float* %878 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %879, align 4, !tbaa !240
  %880 = getelementptr float, float* %878, i64 4
  %881 = bitcast float* %880 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %881, align 4, !tbaa !240
  %882 = or i32 %21, 608
  %883 = sext i32 %882 to i64
  %884 = getelementptr inbounds float, float* %4, i64 %883
  %885 = bitcast float* %884 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %885, align 4, !tbaa !240
  %886 = getelementptr float, float* %884, i64 4
  %887 = bitcast float* %886 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %887, align 4, !tbaa !240
  %888 = or i32 %21, 616
  %889 = sext i32 %888 to i64
  %890 = getelementptr inbounds float, float* %4, i64 %889
  %891 = bitcast float* %890 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %891, align 4, !tbaa !240
  %892 = getelementptr float, float* %890, i64 4
  %893 = bitcast float* %892 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %893, align 4, !tbaa !240
  %894 = or i32 %21, 624
  %895 = sext i32 %894 to i64
  %896 = getelementptr inbounds float, float* %4, i64 %895
  %897 = bitcast float* %896 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %897, align 4, !tbaa !240
  %898 = getelementptr float, float* %896, i64 4
  %899 = bitcast float* %898 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %899, align 4, !tbaa !240
  %900 = or i32 %21, 632
  %901 = sext i32 %900 to i64
  %902 = getelementptr inbounds float, float* %4, i64 %901
  %903 = bitcast float* %902 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %903, align 4, !tbaa !240
  %904 = getelementptr float, float* %902, i64 4
  %905 = bitcast float* %904 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %905, align 4, !tbaa !240
  %906 = or i32 %21, 640
  %907 = sext i32 %906 to i64
  %908 = getelementptr inbounds float, float* %4, i64 %907
  %909 = bitcast float* %908 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %909, align 4, !tbaa !240
  %910 = getelementptr float, float* %908, i64 4
  %911 = bitcast float* %910 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %911, align 4, !tbaa !240
  %912 = or i32 %21, 648
  %913 = sext i32 %912 to i64
  %914 = getelementptr inbounds float, float* %4, i64 %913
  %915 = bitcast float* %914 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %915, align 4, !tbaa !240
  %916 = getelementptr float, float* %914, i64 4
  %917 = bitcast float* %916 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %917, align 4, !tbaa !240
  %918 = or i32 %21, 656
  %919 = sext i32 %918 to i64
  %920 = getelementptr inbounds float, float* %4, i64 %919
  %921 = bitcast float* %920 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %921, align 4, !tbaa !240
  %922 = getelementptr float, float* %920, i64 4
  %923 = bitcast float* %922 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %923, align 4, !tbaa !240
  %924 = or i32 %21, 664
  %925 = sext i32 %924 to i64
  %926 = getelementptr inbounds float, float* %4, i64 %925
  %927 = bitcast float* %926 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %927, align 4, !tbaa !240
  %928 = getelementptr float, float* %926, i64 4
  %929 = bitcast float* %928 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %929, align 4, !tbaa !240
  %930 = or i32 %21, 672
  %931 = sext i32 %930 to i64
  %932 = getelementptr inbounds float, float* %4, i64 %931
  %933 = bitcast float* %932 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %933, align 4, !tbaa !240
  %934 = getelementptr float, float* %932, i64 4
  %935 = bitcast float* %934 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %935, align 4, !tbaa !240
  %936 = or i32 %21, 680
  %937 = sext i32 %936 to i64
  %938 = getelementptr inbounds float, float* %4, i64 %937
  %939 = bitcast float* %938 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %939, align 4, !tbaa !240
  %940 = getelementptr float, float* %938, i64 4
  %941 = bitcast float* %940 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %941, align 4, !tbaa !240
  %942 = or i32 %21, 688
  %943 = sext i32 %942 to i64
  %944 = getelementptr inbounds float, float* %4, i64 %943
  %945 = bitcast float* %944 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %945, align 4, !tbaa !240
  %946 = getelementptr float, float* %944, i64 4
  %947 = bitcast float* %946 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %947, align 4, !tbaa !240
  %948 = or i32 %21, 696
  %949 = sext i32 %948 to i64
  %950 = getelementptr inbounds float, float* %4, i64 %949
  %951 = bitcast float* %950 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %951, align 4, !tbaa !240
  %952 = getelementptr float, float* %950, i64 4
  %953 = bitcast float* %952 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %953, align 4, !tbaa !240
  %954 = or i32 %21, 704
  %955 = sext i32 %954 to i64
  %956 = getelementptr inbounds float, float* %4, i64 %955
  %957 = bitcast float* %956 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %957, align 4, !tbaa !240
  %958 = getelementptr float, float* %956, i64 4
  %959 = bitcast float* %958 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %959, align 4, !tbaa !240
  %960 = or i32 %21, 712
  %961 = sext i32 %960 to i64
  %962 = getelementptr inbounds float, float* %4, i64 %961
  %963 = bitcast float* %962 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %963, align 4, !tbaa !240
  %964 = getelementptr float, float* %962, i64 4
  %965 = bitcast float* %964 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %965, align 4, !tbaa !240
  %966 = or i32 %21, 720
  %967 = sext i32 %966 to i64
  %968 = getelementptr inbounds float, float* %4, i64 %967
  %969 = bitcast float* %968 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %969, align 4, !tbaa !240
  %970 = getelementptr float, float* %968, i64 4
  %971 = bitcast float* %970 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %971, align 4, !tbaa !240
  %972 = or i32 %21, 728
  %973 = sext i32 %972 to i64
  %974 = getelementptr inbounds float, float* %4, i64 %973
  %975 = bitcast float* %974 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %975, align 4, !tbaa !240
  %976 = getelementptr float, float* %974, i64 4
  %977 = bitcast float* %976 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %977, align 4, !tbaa !240
  %978 = or i32 %21, 736
  %979 = sext i32 %978 to i64
  %980 = getelementptr inbounds float, float* %4, i64 %979
  %981 = bitcast float* %980 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %981, align 4, !tbaa !240
  %982 = getelementptr float, float* %980, i64 4
  %983 = bitcast float* %982 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %983, align 4, !tbaa !240
  %984 = or i32 %21, 744
  %985 = sext i32 %984 to i64
  %986 = getelementptr inbounds float, float* %4, i64 %985
  %987 = bitcast float* %986 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %987, align 4, !tbaa !240
  %988 = getelementptr float, float* %986, i64 4
  %989 = bitcast float* %988 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %989, align 4, !tbaa !240
  %990 = or i32 %21, 752
  %991 = sext i32 %990 to i64
  %992 = getelementptr inbounds float, float* %4, i64 %991
  %993 = bitcast float* %992 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %993, align 4, !tbaa !240
  %994 = getelementptr float, float* %992, i64 4
  %995 = bitcast float* %994 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %995, align 4, !tbaa !240
  %996 = or i32 %21, 760
  %997 = sext i32 %996 to i64
  %998 = getelementptr inbounds float, float* %4, i64 %997
  %999 = bitcast float* %998 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %999, align 4, !tbaa !240
  %1000 = getelementptr float, float* %998, i64 4
  %1001 = bitcast float* %1000 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1001, align 4, !tbaa !240
  %1002 = or i32 %21, 768
  %1003 = sext i32 %1002 to i64
  %1004 = getelementptr inbounds float, float* %4, i64 %1003
  %1005 = bitcast float* %1004 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1005, align 4, !tbaa !240
  %1006 = getelementptr float, float* %1004, i64 4
  %1007 = bitcast float* %1006 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1007, align 4, !tbaa !240
  %1008 = or i32 %21, 776
  %1009 = sext i32 %1008 to i64
  %1010 = getelementptr inbounds float, float* %4, i64 %1009
  %1011 = bitcast float* %1010 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1011, align 4, !tbaa !240
  %1012 = getelementptr float, float* %1010, i64 4
  %1013 = bitcast float* %1012 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1013, align 4, !tbaa !240
  %1014 = or i32 %21, 784
  %1015 = sext i32 %1014 to i64
  %1016 = getelementptr inbounds float, float* %4, i64 %1015
  %1017 = bitcast float* %1016 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1017, align 4, !tbaa !240
  %1018 = getelementptr float, float* %1016, i64 4
  %1019 = bitcast float* %1018 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1019, align 4, !tbaa !240
  %1020 = or i32 %21, 792
  %1021 = sext i32 %1020 to i64
  %1022 = getelementptr inbounds float, float* %4, i64 %1021
  %1023 = bitcast float* %1022 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1023, align 4, !tbaa !240
  %1024 = getelementptr float, float* %1022, i64 4
  %1025 = bitcast float* %1024 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1025, align 4, !tbaa !240
  %1026 = or i32 %21, 800
  %1027 = sext i32 %1026 to i64
  %1028 = getelementptr inbounds float, float* %4, i64 %1027
  %1029 = bitcast float* %1028 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1029, align 4, !tbaa !240
  %1030 = getelementptr float, float* %1028, i64 4
  %1031 = bitcast float* %1030 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1031, align 4, !tbaa !240
  %1032 = or i32 %21, 808
  %1033 = sext i32 %1032 to i64
  %1034 = getelementptr inbounds float, float* %4, i64 %1033
  %1035 = bitcast float* %1034 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1035, align 4, !tbaa !240
  %1036 = getelementptr float, float* %1034, i64 4
  %1037 = bitcast float* %1036 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1037, align 4, !tbaa !240
  %1038 = or i32 %21, 816
  %1039 = sext i32 %1038 to i64
  %1040 = getelementptr inbounds float, float* %4, i64 %1039
  %1041 = bitcast float* %1040 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1041, align 4, !tbaa !240
  %1042 = getelementptr float, float* %1040, i64 4
  %1043 = bitcast float* %1042 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1043, align 4, !tbaa !240
  %1044 = or i32 %21, 824
  %1045 = sext i32 %1044 to i64
  %1046 = getelementptr inbounds float, float* %4, i64 %1045
  %1047 = bitcast float* %1046 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1047, align 4, !tbaa !240
  %1048 = getelementptr float, float* %1046, i64 4
  %1049 = bitcast float* %1048 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1049, align 4, !tbaa !240
  %1050 = or i32 %21, 832
  %1051 = sext i32 %1050 to i64
  %1052 = getelementptr inbounds float, float* %4, i64 %1051
  %1053 = bitcast float* %1052 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1053, align 4, !tbaa !240
  %1054 = getelementptr float, float* %1052, i64 4
  %1055 = bitcast float* %1054 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1055, align 4, !tbaa !240
  %1056 = or i32 %21, 840
  %1057 = sext i32 %1056 to i64
  %1058 = getelementptr inbounds float, float* %4, i64 %1057
  %1059 = bitcast float* %1058 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1059, align 4, !tbaa !240
  %1060 = getelementptr float, float* %1058, i64 4
  %1061 = bitcast float* %1060 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1061, align 4, !tbaa !240
  %1062 = or i32 %21, 848
  %1063 = sext i32 %1062 to i64
  %1064 = getelementptr inbounds float, float* %4, i64 %1063
  %1065 = bitcast float* %1064 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1065, align 4, !tbaa !240
  %1066 = getelementptr float, float* %1064, i64 4
  %1067 = bitcast float* %1066 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1067, align 4, !tbaa !240
  %1068 = or i32 %21, 856
  %1069 = sext i32 %1068 to i64
  %1070 = getelementptr inbounds float, float* %4, i64 %1069
  %1071 = bitcast float* %1070 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1071, align 4, !tbaa !240
  %1072 = getelementptr float, float* %1070, i64 4
  %1073 = bitcast float* %1072 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1073, align 4, !tbaa !240
  %1074 = or i32 %21, 864
  %1075 = sext i32 %1074 to i64
  %1076 = getelementptr inbounds float, float* %4, i64 %1075
  %1077 = bitcast float* %1076 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1077, align 4, !tbaa !240
  %1078 = getelementptr float, float* %1076, i64 4
  %1079 = bitcast float* %1078 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1079, align 4, !tbaa !240
  %1080 = or i32 %21, 872
  %1081 = sext i32 %1080 to i64
  %1082 = getelementptr inbounds float, float* %4, i64 %1081
  %1083 = bitcast float* %1082 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1083, align 4, !tbaa !240
  %1084 = getelementptr float, float* %1082, i64 4
  %1085 = bitcast float* %1084 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1085, align 4, !tbaa !240
  %1086 = or i32 %21, 880
  %1087 = sext i32 %1086 to i64
  %1088 = getelementptr inbounds float, float* %4, i64 %1087
  %1089 = bitcast float* %1088 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1089, align 4, !tbaa !240
  %1090 = getelementptr float, float* %1088, i64 4
  %1091 = bitcast float* %1090 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1091, align 4, !tbaa !240
  %1092 = or i32 %21, 888
  %1093 = sext i32 %1092 to i64
  %1094 = getelementptr inbounds float, float* %4, i64 %1093
  %1095 = bitcast float* %1094 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1095, align 4, !tbaa !240
  %1096 = getelementptr float, float* %1094, i64 4
  %1097 = bitcast float* %1096 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1097, align 4, !tbaa !240
  %1098 = or i32 %21, 896
  %1099 = sext i32 %1098 to i64
  %1100 = getelementptr inbounds float, float* %4, i64 %1099
  %1101 = bitcast float* %1100 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1101, align 4, !tbaa !240
  %1102 = getelementptr float, float* %1100, i64 4
  %1103 = bitcast float* %1102 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1103, align 4, !tbaa !240
  %1104 = or i32 %21, 904
  %1105 = sext i32 %1104 to i64
  %1106 = getelementptr inbounds float, float* %4, i64 %1105
  %1107 = bitcast float* %1106 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1107, align 4, !tbaa !240
  %1108 = getelementptr float, float* %1106, i64 4
  %1109 = bitcast float* %1108 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1109, align 4, !tbaa !240
  %1110 = or i32 %21, 912
  %1111 = sext i32 %1110 to i64
  %1112 = getelementptr inbounds float, float* %4, i64 %1111
  %1113 = bitcast float* %1112 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1113, align 4, !tbaa !240
  %1114 = getelementptr float, float* %1112, i64 4
  %1115 = bitcast float* %1114 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1115, align 4, !tbaa !240
  %1116 = or i32 %21, 920
  %1117 = sext i32 %1116 to i64
  %1118 = getelementptr inbounds float, float* %4, i64 %1117
  %1119 = bitcast float* %1118 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1119, align 4, !tbaa !240
  %1120 = getelementptr float, float* %1118, i64 4
  %1121 = bitcast float* %1120 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1121, align 4, !tbaa !240
  %1122 = or i32 %21, 928
  %1123 = sext i32 %1122 to i64
  %1124 = getelementptr inbounds float, float* %4, i64 %1123
  %1125 = bitcast float* %1124 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1125, align 4, !tbaa !240
  %1126 = getelementptr float, float* %1124, i64 4
  %1127 = bitcast float* %1126 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1127, align 4, !tbaa !240
  %1128 = or i32 %21, 936
  %1129 = sext i32 %1128 to i64
  %1130 = getelementptr inbounds float, float* %4, i64 %1129
  %1131 = bitcast float* %1130 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1131, align 4, !tbaa !240
  %1132 = getelementptr float, float* %1130, i64 4
  %1133 = bitcast float* %1132 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1133, align 4, !tbaa !240
  %1134 = or i32 %21, 944
  %1135 = sext i32 %1134 to i64
  %1136 = getelementptr inbounds float, float* %4, i64 %1135
  %1137 = bitcast float* %1136 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1137, align 4, !tbaa !240
  %1138 = getelementptr float, float* %1136, i64 4
  %1139 = bitcast float* %1138 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1139, align 4, !tbaa !240
  %1140 = or i32 %21, 952
  %1141 = sext i32 %1140 to i64
  %1142 = getelementptr inbounds float, float* %4, i64 %1141
  %1143 = bitcast float* %1142 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1143, align 4, !tbaa !240
  %1144 = getelementptr float, float* %1142, i64 4
  %1145 = bitcast float* %1144 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1145, align 4, !tbaa !240
  %1146 = or i32 %21, 960
  %1147 = sext i32 %1146 to i64
  %1148 = getelementptr inbounds float, float* %4, i64 %1147
  %1149 = bitcast float* %1148 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1149, align 4, !tbaa !240
  %1150 = getelementptr float, float* %1148, i64 4
  %1151 = bitcast float* %1150 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1151, align 4, !tbaa !240
  %1152 = or i32 %21, 968
  %1153 = sext i32 %1152 to i64
  %1154 = getelementptr inbounds float, float* %4, i64 %1153
  %1155 = bitcast float* %1154 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1155, align 4, !tbaa !240
  %1156 = getelementptr float, float* %1154, i64 4
  %1157 = bitcast float* %1156 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1157, align 4, !tbaa !240
  %1158 = or i32 %21, 976
  %1159 = sext i32 %1158 to i64
  %1160 = getelementptr inbounds float, float* %4, i64 %1159
  %1161 = bitcast float* %1160 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1161, align 4, !tbaa !240
  %1162 = getelementptr float, float* %1160, i64 4
  %1163 = bitcast float* %1162 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1163, align 4, !tbaa !240
  %1164 = or i32 %21, 984
  %1165 = sext i32 %1164 to i64
  %1166 = getelementptr inbounds float, float* %4, i64 %1165
  %1167 = bitcast float* %1166 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1167, align 4, !tbaa !240
  %1168 = getelementptr float, float* %1166, i64 4
  %1169 = bitcast float* %1168 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1169, align 4, !tbaa !240
  %1170 = or i32 %21, 992
  %1171 = sext i32 %1170 to i64
  %1172 = getelementptr inbounds float, float* %4, i64 %1171
  %1173 = bitcast float* %1172 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1173, align 4, !tbaa !240
  %1174 = getelementptr float, float* %1172, i64 4
  %1175 = bitcast float* %1174 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1175, align 4, !tbaa !240
  %1176 = or i32 %21, 1000
  %1177 = sext i32 %1176 to i64
  %1178 = getelementptr inbounds float, float* %4, i64 %1177
  %1179 = bitcast float* %1178 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1179, align 4, !tbaa !240
  %1180 = getelementptr float, float* %1178, i64 4
  %1181 = bitcast float* %1180 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1181, align 4, !tbaa !240
  %1182 = or i32 %21, 1008
  %1183 = sext i32 %1182 to i64
  %1184 = getelementptr inbounds float, float* %4, i64 %1183
  %1185 = bitcast float* %1184 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1185, align 4, !tbaa !240
  %1186 = getelementptr float, float* %1184, i64 4
  %1187 = bitcast float* %1186 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1187, align 4, !tbaa !240
  %1188 = or i32 %21, 1016
  %1189 = sext i32 %1188 to i64
  %1190 = getelementptr inbounds float, float* %4, i64 %1189
  %1191 = bitcast float* %1190 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1191, align 4, !tbaa !240
  %1192 = getelementptr float, float* %1190, i64 4
  %1193 = bitcast float* %1192 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1193, align 4, !tbaa !240
  %1194 = or i32 %21, 1024
  %1195 = sext i32 %1194 to i64
  %1196 = getelementptr inbounds float, float* %4, i64 %1195
  %1197 = bitcast float* %1196 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1197, align 4, !tbaa !240
  %1198 = getelementptr float, float* %1196, i64 4
  %1199 = bitcast float* %1198 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1199, align 4, !tbaa !240
  %1200 = or i32 %21, 1032
  %1201 = sext i32 %1200 to i64
  %1202 = getelementptr inbounds float, float* %4, i64 %1201
  %1203 = bitcast float* %1202 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1203, align 4, !tbaa !240
  %1204 = getelementptr float, float* %1202, i64 4
  %1205 = bitcast float* %1204 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1205, align 4, !tbaa !240
  %1206 = or i32 %21, 1040
  %1207 = sext i32 %1206 to i64
  %1208 = getelementptr inbounds float, float* %4, i64 %1207
  %1209 = bitcast float* %1208 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1209, align 4, !tbaa !240
  %1210 = getelementptr float, float* %1208, i64 4
  %1211 = bitcast float* %1210 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1211, align 4, !tbaa !240
  %1212 = or i32 %21, 1048
  %1213 = sext i32 %1212 to i64
  %1214 = getelementptr inbounds float, float* %4, i64 %1213
  %1215 = bitcast float* %1214 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1215, align 4, !tbaa !240
  %1216 = getelementptr float, float* %1214, i64 4
  %1217 = bitcast float* %1216 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1217, align 4, !tbaa !240
  %1218 = or i32 %21, 1056
  %1219 = sext i32 %1218 to i64
  %1220 = getelementptr inbounds float, float* %4, i64 %1219
  %1221 = bitcast float* %1220 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1221, align 4, !tbaa !240
  %1222 = getelementptr float, float* %1220, i64 4
  %1223 = bitcast float* %1222 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1223, align 4, !tbaa !240
  %1224 = or i32 %21, 1064
  %1225 = sext i32 %1224 to i64
  %1226 = getelementptr inbounds float, float* %4, i64 %1225
  %1227 = bitcast float* %1226 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1227, align 4, !tbaa !240
  %1228 = getelementptr float, float* %1226, i64 4
  %1229 = bitcast float* %1228 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1229, align 4, !tbaa !240
  %1230 = or i32 %21, 1072
  %1231 = sext i32 %1230 to i64
  %1232 = getelementptr inbounds float, float* %4, i64 %1231
  %1233 = bitcast float* %1232 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1233, align 4, !tbaa !240
  %1234 = getelementptr float, float* %1232, i64 4
  %1235 = bitcast float* %1234 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1235, align 4, !tbaa !240
  %1236 = or i32 %21, 1080
  %1237 = sext i32 %1236 to i64
  %1238 = getelementptr inbounds float, float* %4, i64 %1237
  %1239 = bitcast float* %1238 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1239, align 4, !tbaa !240
  %1240 = getelementptr float, float* %1238, i64 4
  %1241 = bitcast float* %1240 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1241, align 4, !tbaa !240
  %1242 = or i32 %21, 1088
  %1243 = sext i32 %1242 to i64
  %1244 = getelementptr inbounds float, float* %4, i64 %1243
  %1245 = bitcast float* %1244 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1245, align 4, !tbaa !240
  %1246 = getelementptr float, float* %1244, i64 4
  %1247 = bitcast float* %1246 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1247, align 4, !tbaa !240
  %1248 = or i32 %21, 1096
  %1249 = sext i32 %1248 to i64
  %1250 = getelementptr inbounds float, float* %4, i64 %1249
  %1251 = bitcast float* %1250 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1251, align 4, !tbaa !240
  %1252 = getelementptr float, float* %1250, i64 4
  %1253 = bitcast float* %1252 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1253, align 4, !tbaa !240
  %1254 = or i32 %21, 1104
  %1255 = sext i32 %1254 to i64
  %1256 = getelementptr inbounds float, float* %4, i64 %1255
  %1257 = bitcast float* %1256 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1257, align 4, !tbaa !240
  %1258 = getelementptr float, float* %1256, i64 4
  %1259 = bitcast float* %1258 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1259, align 4, !tbaa !240
  %1260 = or i32 %21, 1112
  %1261 = sext i32 %1260 to i64
  %1262 = getelementptr inbounds float, float* %4, i64 %1261
  %1263 = bitcast float* %1262 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1263, align 4, !tbaa !240
  %1264 = getelementptr float, float* %1262, i64 4
  %1265 = bitcast float* %1264 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1265, align 4, !tbaa !240
  %1266 = or i32 %21, 1120
  %1267 = sext i32 %1266 to i64
  %1268 = getelementptr inbounds float, float* %4, i64 %1267
  %1269 = bitcast float* %1268 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1269, align 4, !tbaa !240
  %1270 = getelementptr float, float* %1268, i64 4
  %1271 = bitcast float* %1270 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1271, align 4, !tbaa !240
  %1272 = or i32 %21, 1128
  %1273 = sext i32 %1272 to i64
  %1274 = getelementptr inbounds float, float* %4, i64 %1273
  %1275 = bitcast float* %1274 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1275, align 4, !tbaa !240
  %1276 = getelementptr float, float* %1274, i64 4
  %1277 = bitcast float* %1276 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1277, align 4, !tbaa !240
  %1278 = or i32 %21, 1136
  %1279 = sext i32 %1278 to i64
  %1280 = getelementptr inbounds float, float* %4, i64 %1279
  %1281 = bitcast float* %1280 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1281, align 4, !tbaa !240
  %1282 = getelementptr float, float* %1280, i64 4
  %1283 = bitcast float* %1282 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1283, align 4, !tbaa !240
  %1284 = or i32 %21, 1144
  %1285 = sext i32 %1284 to i64
  %1286 = getelementptr inbounds float, float* %4, i64 %1285
  %1287 = bitcast float* %1286 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1287, align 4, !tbaa !240
  %1288 = getelementptr float, float* %1286, i64 4
  %1289 = bitcast float* %1288 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1289, align 4, !tbaa !240
  %1290 = or i32 %21, 1152
  %1291 = sext i32 %1290 to i64
  %1292 = getelementptr inbounds float, float* %4, i64 %1291
  %1293 = bitcast float* %1292 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1293, align 4, !tbaa !240
  %1294 = getelementptr float, float* %1292, i64 4
  %1295 = bitcast float* %1294 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1295, align 4, !tbaa !240
  %1296 = or i32 %21, 1160
  %1297 = sext i32 %1296 to i64
  %1298 = getelementptr inbounds float, float* %4, i64 %1297
  %1299 = bitcast float* %1298 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1299, align 4, !tbaa !240
  %1300 = getelementptr float, float* %1298, i64 4
  %1301 = bitcast float* %1300 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1301, align 4, !tbaa !240
  %1302 = or i32 %21, 1168
  %1303 = sext i32 %1302 to i64
  %1304 = getelementptr inbounds float, float* %4, i64 %1303
  %1305 = bitcast float* %1304 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1305, align 4, !tbaa !240
  %1306 = getelementptr float, float* %1304, i64 4
  %1307 = bitcast float* %1306 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1307, align 4, !tbaa !240
  %1308 = or i32 %21, 1176
  %1309 = sext i32 %1308 to i64
  %1310 = getelementptr inbounds float, float* %4, i64 %1309
  %1311 = bitcast float* %1310 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1311, align 4, !tbaa !240
  %1312 = getelementptr float, float* %1310, i64 4
  %1313 = bitcast float* %1312 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1313, align 4, !tbaa !240
  %1314 = or i32 %21, 1184
  %1315 = sext i32 %1314 to i64
  %1316 = getelementptr inbounds float, float* %4, i64 %1315
  %1317 = bitcast float* %1316 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1317, align 4, !tbaa !240
  %1318 = getelementptr float, float* %1316, i64 4
  %1319 = bitcast float* %1318 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1319, align 4, !tbaa !240
  %1320 = or i32 %21, 1192
  %1321 = sext i32 %1320 to i64
  %1322 = getelementptr inbounds float, float* %4, i64 %1321
  %1323 = bitcast float* %1322 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1323, align 4, !tbaa !240
  %1324 = getelementptr float, float* %1322, i64 4
  %1325 = bitcast float* %1324 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1325, align 4, !tbaa !240
  %1326 = or i32 %21, 1200
  %1327 = sext i32 %1326 to i64
  %1328 = getelementptr inbounds float, float* %4, i64 %1327
  %1329 = bitcast float* %1328 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1329, align 4, !tbaa !240
  %1330 = getelementptr float, float* %1328, i64 4
  %1331 = bitcast float* %1330 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1331, align 4, !tbaa !240
  %1332 = or i32 %21, 1208
  %1333 = sext i32 %1332 to i64
  %1334 = getelementptr inbounds float, float* %4, i64 %1333
  %1335 = bitcast float* %1334 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1335, align 4, !tbaa !240
  %1336 = getelementptr float, float* %1334, i64 4
  %1337 = bitcast float* %1336 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1337, align 4, !tbaa !240
  %1338 = or i32 %21, 1216
  %1339 = sext i32 %1338 to i64
  %1340 = getelementptr inbounds float, float* %4, i64 %1339
  %1341 = bitcast float* %1340 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1341, align 4, !tbaa !240
  %1342 = getelementptr float, float* %1340, i64 4
  %1343 = bitcast float* %1342 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1343, align 4, !tbaa !240
  %1344 = or i32 %21, 1224
  %1345 = sext i32 %1344 to i64
  %1346 = getelementptr inbounds float, float* %4, i64 %1345
  %1347 = bitcast float* %1346 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1347, align 4, !tbaa !240
  %1348 = getelementptr float, float* %1346, i64 4
  %1349 = bitcast float* %1348 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1349, align 4, !tbaa !240
  %1350 = or i32 %21, 1232
  %1351 = sext i32 %1350 to i64
  %1352 = getelementptr inbounds float, float* %4, i64 %1351
  %1353 = bitcast float* %1352 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1353, align 4, !tbaa !240
  %1354 = getelementptr float, float* %1352, i64 4
  %1355 = bitcast float* %1354 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1355, align 4, !tbaa !240
  %1356 = or i32 %21, 1240
  %1357 = sext i32 %1356 to i64
  %1358 = getelementptr inbounds float, float* %4, i64 %1357
  %1359 = bitcast float* %1358 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1359, align 4, !tbaa !240
  %1360 = getelementptr float, float* %1358, i64 4
  %1361 = bitcast float* %1360 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1361, align 4, !tbaa !240
  %1362 = or i32 %21, 1248
  %1363 = sext i32 %1362 to i64
  %1364 = getelementptr inbounds float, float* %4, i64 %1363
  %1365 = bitcast float* %1364 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1365, align 4, !tbaa !240
  %1366 = getelementptr float, float* %1364, i64 4
  %1367 = bitcast float* %1366 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1367, align 4, !tbaa !240
  %1368 = or i32 %21, 1256
  %1369 = sext i32 %1368 to i64
  %1370 = getelementptr inbounds float, float* %4, i64 %1369
  %1371 = bitcast float* %1370 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1371, align 4, !tbaa !240
  %1372 = getelementptr float, float* %1370, i64 4
  %1373 = bitcast float* %1372 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1373, align 4, !tbaa !240
  %1374 = or i32 %21, 1264
  %1375 = sext i32 %1374 to i64
  %1376 = getelementptr inbounds float, float* %4, i64 %1375
  %1377 = bitcast float* %1376 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1377, align 4, !tbaa !240
  %1378 = getelementptr float, float* %1376, i64 4
  %1379 = bitcast float* %1378 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1379, align 4, !tbaa !240
  %1380 = or i32 %21, 1272
  %1381 = sext i32 %1380 to i64
  %1382 = getelementptr inbounds float, float* %4, i64 %1381
  %1383 = bitcast float* %1382 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1383, align 4, !tbaa !240
  %1384 = getelementptr float, float* %1382, i64 4
  %1385 = bitcast float* %1384 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1385, align 4, !tbaa !240
  %1386 = or i32 %21, 1280
  %1387 = sext i32 %1386 to i64
  %1388 = getelementptr inbounds float, float* %4, i64 %1387
  %1389 = bitcast float* %1388 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1389, align 4, !tbaa !240
  %1390 = getelementptr float, float* %1388, i64 4
  %1391 = bitcast float* %1390 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1391, align 4, !tbaa !240
  %1392 = or i32 %21, 1288
  %1393 = sext i32 %1392 to i64
  %1394 = getelementptr inbounds float, float* %4, i64 %1393
  %1395 = bitcast float* %1394 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1395, align 4, !tbaa !240
  %1396 = getelementptr float, float* %1394, i64 4
  %1397 = bitcast float* %1396 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1397, align 4, !tbaa !240
  %1398 = or i32 %21, 1296
  %1399 = sext i32 %1398 to i64
  %1400 = getelementptr inbounds float, float* %4, i64 %1399
  %1401 = bitcast float* %1400 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1401, align 4, !tbaa !240
  %1402 = getelementptr float, float* %1400, i64 4
  %1403 = bitcast float* %1402 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1403, align 4, !tbaa !240
  %1404 = or i32 %21, 1304
  %1405 = sext i32 %1404 to i64
  %1406 = getelementptr inbounds float, float* %4, i64 %1405
  %1407 = bitcast float* %1406 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1407, align 4, !tbaa !240
  %1408 = getelementptr float, float* %1406, i64 4
  %1409 = bitcast float* %1408 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1409, align 4, !tbaa !240
  %1410 = or i32 %21, 1312
  %1411 = sext i32 %1410 to i64
  %1412 = getelementptr inbounds float, float* %4, i64 %1411
  %1413 = bitcast float* %1412 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1413, align 4, !tbaa !240
  %1414 = getelementptr float, float* %1412, i64 4
  %1415 = bitcast float* %1414 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1415, align 4, !tbaa !240
  %1416 = or i32 %21, 1320
  %1417 = sext i32 %1416 to i64
  %1418 = getelementptr inbounds float, float* %4, i64 %1417
  %1419 = bitcast float* %1418 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1419, align 4, !tbaa !240
  %1420 = getelementptr float, float* %1418, i64 4
  %1421 = bitcast float* %1420 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1421, align 4, !tbaa !240
  %1422 = or i32 %21, 1328
  %1423 = sext i32 %1422 to i64
  %1424 = getelementptr inbounds float, float* %4, i64 %1423
  %1425 = bitcast float* %1424 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1425, align 4, !tbaa !240
  %1426 = getelementptr float, float* %1424, i64 4
  %1427 = bitcast float* %1426 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1427, align 4, !tbaa !240
  %1428 = or i32 %21, 1336
  %1429 = sext i32 %1428 to i64
  %1430 = getelementptr inbounds float, float* %4, i64 %1429
  %1431 = bitcast float* %1430 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1431, align 4, !tbaa !240
  %1432 = getelementptr float, float* %1430, i64 4
  %1433 = bitcast float* %1432 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1433, align 4, !tbaa !240
  %1434 = or i32 %21, 1344
  %1435 = sext i32 %1434 to i64
  %1436 = getelementptr inbounds float, float* %4, i64 %1435
  %1437 = bitcast float* %1436 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1437, align 4, !tbaa !240
  %1438 = getelementptr float, float* %1436, i64 4
  %1439 = bitcast float* %1438 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1439, align 4, !tbaa !240
  %1440 = or i32 %21, 1352
  %1441 = sext i32 %1440 to i64
  %1442 = getelementptr inbounds float, float* %4, i64 %1441
  %1443 = bitcast float* %1442 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1443, align 4, !tbaa !240
  %1444 = getelementptr float, float* %1442, i64 4
  %1445 = bitcast float* %1444 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1445, align 4, !tbaa !240
  %1446 = or i32 %21, 1360
  %1447 = sext i32 %1446 to i64
  %1448 = getelementptr inbounds float, float* %4, i64 %1447
  %1449 = bitcast float* %1448 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1449, align 4, !tbaa !240
  %1450 = getelementptr float, float* %1448, i64 4
  %1451 = bitcast float* %1450 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1451, align 4, !tbaa !240
  %1452 = or i32 %21, 1368
  %1453 = sext i32 %1452 to i64
  %1454 = getelementptr inbounds float, float* %4, i64 %1453
  %1455 = bitcast float* %1454 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1455, align 4, !tbaa !240
  %1456 = getelementptr float, float* %1454, i64 4
  %1457 = bitcast float* %1456 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1457, align 4, !tbaa !240
  %1458 = or i32 %21, 1376
  %1459 = sext i32 %1458 to i64
  %1460 = getelementptr inbounds float, float* %4, i64 %1459
  %1461 = bitcast float* %1460 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1461, align 4, !tbaa !240
  %1462 = getelementptr float, float* %1460, i64 4
  %1463 = bitcast float* %1462 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1463, align 4, !tbaa !240
  %1464 = or i32 %21, 1384
  %1465 = sext i32 %1464 to i64
  %1466 = getelementptr inbounds float, float* %4, i64 %1465
  %1467 = bitcast float* %1466 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1467, align 4, !tbaa !240
  %1468 = getelementptr float, float* %1466, i64 4
  %1469 = bitcast float* %1468 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1469, align 4, !tbaa !240
  %1470 = or i32 %21, 1392
  %1471 = sext i32 %1470 to i64
  %1472 = getelementptr inbounds float, float* %4, i64 %1471
  %1473 = bitcast float* %1472 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1473, align 4, !tbaa !240
  %1474 = getelementptr float, float* %1472, i64 4
  %1475 = bitcast float* %1474 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1475, align 4, !tbaa !240
  %1476 = or i32 %21, 1400
  %1477 = sext i32 %1476 to i64
  %1478 = getelementptr inbounds float, float* %4, i64 %1477
  %1479 = bitcast float* %1478 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1479, align 4, !tbaa !240
  %1480 = getelementptr float, float* %1478, i64 4
  %1481 = bitcast float* %1480 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1481, align 4, !tbaa !240
  %1482 = or i32 %21, 1408
  %1483 = sext i32 %1482 to i64
  %1484 = getelementptr inbounds float, float* %4, i64 %1483
  %1485 = bitcast float* %1484 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1485, align 4, !tbaa !240
  %1486 = getelementptr float, float* %1484, i64 4
  %1487 = bitcast float* %1486 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1487, align 4, !tbaa !240
  %1488 = or i32 %21, 1416
  %1489 = sext i32 %1488 to i64
  %1490 = getelementptr inbounds float, float* %4, i64 %1489
  %1491 = bitcast float* %1490 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1491, align 4, !tbaa !240
  %1492 = getelementptr float, float* %1490, i64 4
  %1493 = bitcast float* %1492 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1493, align 4, !tbaa !240
  %1494 = or i32 %21, 1424
  %1495 = sext i32 %1494 to i64
  %1496 = getelementptr inbounds float, float* %4, i64 %1495
  %1497 = bitcast float* %1496 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1497, align 4, !tbaa !240
  %1498 = getelementptr float, float* %1496, i64 4
  %1499 = bitcast float* %1498 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1499, align 4, !tbaa !240
  %1500 = or i32 %21, 1432
  %1501 = sext i32 %1500 to i64
  %1502 = getelementptr inbounds float, float* %4, i64 %1501
  %1503 = bitcast float* %1502 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1503, align 4, !tbaa !240
  %1504 = getelementptr float, float* %1502, i64 4
  %1505 = bitcast float* %1504 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1505, align 4, !tbaa !240
  %1506 = or i32 %21, 1440
  %1507 = sext i32 %1506 to i64
  %1508 = getelementptr inbounds float, float* %4, i64 %1507
  %1509 = bitcast float* %1508 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1509, align 4, !tbaa !240
  %1510 = getelementptr float, float* %1508, i64 4
  %1511 = bitcast float* %1510 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1511, align 4, !tbaa !240
  %1512 = or i32 %21, 1448
  %1513 = sext i32 %1512 to i64
  %1514 = getelementptr inbounds float, float* %4, i64 %1513
  %1515 = bitcast float* %1514 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1515, align 4, !tbaa !240
  %1516 = getelementptr float, float* %1514, i64 4
  %1517 = bitcast float* %1516 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1517, align 4, !tbaa !240
  %1518 = or i32 %21, 1456
  %1519 = sext i32 %1518 to i64
  %1520 = getelementptr inbounds float, float* %4, i64 %1519
  %1521 = bitcast float* %1520 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1521, align 4, !tbaa !240
  %1522 = getelementptr float, float* %1520, i64 4
  %1523 = bitcast float* %1522 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1523, align 4, !tbaa !240
  %1524 = or i32 %21, 1464
  %1525 = sext i32 %1524 to i64
  %1526 = getelementptr inbounds float, float* %4, i64 %1525
  %1527 = bitcast float* %1526 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1527, align 4, !tbaa !240
  %1528 = getelementptr float, float* %1526, i64 4
  %1529 = bitcast float* %1528 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1529, align 4, !tbaa !240
  %1530 = or i32 %21, 1472
  %1531 = sext i32 %1530 to i64
  %1532 = getelementptr inbounds float, float* %4, i64 %1531
  %1533 = bitcast float* %1532 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1533, align 4, !tbaa !240
  %1534 = getelementptr float, float* %1532, i64 4
  %1535 = bitcast float* %1534 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1535, align 4, !tbaa !240
  %1536 = or i32 %21, 1480
  %1537 = sext i32 %1536 to i64
  %1538 = getelementptr inbounds float, float* %4, i64 %1537
  %1539 = bitcast float* %1538 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1539, align 4, !tbaa !240
  %1540 = getelementptr float, float* %1538, i64 4
  %1541 = bitcast float* %1540 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1541, align 4, !tbaa !240
  %1542 = or i32 %21, 1488
  %1543 = sext i32 %1542 to i64
  %1544 = getelementptr inbounds float, float* %4, i64 %1543
  %1545 = bitcast float* %1544 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1545, align 4, !tbaa !240
  %1546 = getelementptr float, float* %1544, i64 4
  %1547 = bitcast float* %1546 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1547, align 4, !tbaa !240
  %1548 = or i32 %21, 1496
  %1549 = sext i32 %1548 to i64
  %1550 = getelementptr inbounds float, float* %4, i64 %1549
  %1551 = bitcast float* %1550 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1551, align 4, !tbaa !240
  %1552 = getelementptr float, float* %1550, i64 4
  %1553 = bitcast float* %1552 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1553, align 4, !tbaa !240
  %1554 = or i32 %21, 1504
  %1555 = sext i32 %1554 to i64
  %1556 = getelementptr inbounds float, float* %4, i64 %1555
  %1557 = bitcast float* %1556 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1557, align 4, !tbaa !240
  %1558 = getelementptr float, float* %1556, i64 4
  %1559 = bitcast float* %1558 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1559, align 4, !tbaa !240
  %1560 = or i32 %21, 1512
  %1561 = sext i32 %1560 to i64
  %1562 = getelementptr inbounds float, float* %4, i64 %1561
  %1563 = bitcast float* %1562 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1563, align 4, !tbaa !240
  %1564 = getelementptr float, float* %1562, i64 4
  %1565 = bitcast float* %1564 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1565, align 4, !tbaa !240
  %1566 = or i32 %21, 1520
  %1567 = sext i32 %1566 to i64
  %1568 = getelementptr inbounds float, float* %4, i64 %1567
  %1569 = bitcast float* %1568 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1569, align 4, !tbaa !240
  %1570 = getelementptr float, float* %1568, i64 4
  %1571 = bitcast float* %1570 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1571, align 4, !tbaa !240
  %1572 = or i32 %21, 1528
  %1573 = sext i32 %1572 to i64
  %1574 = getelementptr inbounds float, float* %4, i64 %1573
  %1575 = bitcast float* %1574 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1575, align 4, !tbaa !240
  %1576 = getelementptr float, float* %1574, i64 4
  %1577 = bitcast float* %1576 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1577, align 4, !tbaa !240
  %1578 = or i32 %21, 1536
  %1579 = sext i32 %1578 to i64
  %1580 = getelementptr inbounds float, float* %4, i64 %1579
  %1581 = bitcast float* %1580 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1581, align 4, !tbaa !240
  %1582 = getelementptr float, float* %1580, i64 4
  %1583 = bitcast float* %1582 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1583, align 4, !tbaa !240
  %1584 = or i32 %21, 1544
  %1585 = sext i32 %1584 to i64
  %1586 = getelementptr inbounds float, float* %4, i64 %1585
  %1587 = bitcast float* %1586 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1587, align 4, !tbaa !240
  %1588 = getelementptr float, float* %1586, i64 4
  %1589 = bitcast float* %1588 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1589, align 4, !tbaa !240
  %1590 = or i32 %21, 1552
  %1591 = sext i32 %1590 to i64
  %1592 = getelementptr inbounds float, float* %4, i64 %1591
  %1593 = bitcast float* %1592 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1593, align 4, !tbaa !240
  %1594 = getelementptr float, float* %1592, i64 4
  %1595 = bitcast float* %1594 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1595, align 4, !tbaa !240
  %1596 = or i32 %21, 1560
  %1597 = sext i32 %1596 to i64
  %1598 = getelementptr inbounds float, float* %4, i64 %1597
  %1599 = bitcast float* %1598 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1599, align 4, !tbaa !240
  %1600 = getelementptr float, float* %1598, i64 4
  %1601 = bitcast float* %1600 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1601, align 4, !tbaa !240
  %1602 = or i32 %21, 1568
  %1603 = sext i32 %1602 to i64
  %1604 = getelementptr inbounds float, float* %4, i64 %1603
  %1605 = bitcast float* %1604 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1605, align 4, !tbaa !240
  %1606 = getelementptr float, float* %1604, i64 4
  %1607 = bitcast float* %1606 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1607, align 4, !tbaa !240
  %1608 = or i32 %21, 1576
  %1609 = sext i32 %1608 to i64
  %1610 = getelementptr inbounds float, float* %4, i64 %1609
  %1611 = bitcast float* %1610 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1611, align 4, !tbaa !240
  %1612 = getelementptr float, float* %1610, i64 4
  %1613 = bitcast float* %1612 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1613, align 4, !tbaa !240
  %1614 = or i32 %21, 1584
  %1615 = sext i32 %1614 to i64
  %1616 = getelementptr inbounds float, float* %4, i64 %1615
  %1617 = bitcast float* %1616 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1617, align 4, !tbaa !240
  %1618 = getelementptr float, float* %1616, i64 4
  %1619 = bitcast float* %1618 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1619, align 4, !tbaa !240
  %1620 = or i32 %21, 1592
  %1621 = sext i32 %1620 to i64
  %1622 = getelementptr inbounds float, float* %4, i64 %1621
  %1623 = bitcast float* %1622 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1623, align 4, !tbaa !240
  %1624 = getelementptr float, float* %1622, i64 4
  %1625 = bitcast float* %1624 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1625, align 4, !tbaa !240
  %1626 = or i32 %21, 1600
  %1627 = sext i32 %1626 to i64
  %1628 = getelementptr inbounds float, float* %4, i64 %1627
  %1629 = bitcast float* %1628 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1629, align 4, !tbaa !240
  %1630 = getelementptr float, float* %1628, i64 4
  %1631 = bitcast float* %1630 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1631, align 4, !tbaa !240
  %1632 = or i32 %21, 1608
  %1633 = sext i32 %1632 to i64
  %1634 = getelementptr inbounds float, float* %4, i64 %1633
  %1635 = bitcast float* %1634 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1635, align 4, !tbaa !240
  %1636 = getelementptr float, float* %1634, i64 4
  %1637 = bitcast float* %1636 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1637, align 4, !tbaa !240
  %1638 = or i32 %21, 1616
  %1639 = sext i32 %1638 to i64
  %1640 = getelementptr inbounds float, float* %4, i64 %1639
  %1641 = bitcast float* %1640 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1641, align 4, !tbaa !240
  %1642 = getelementptr float, float* %1640, i64 4
  %1643 = bitcast float* %1642 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1643, align 4, !tbaa !240
  %1644 = or i32 %21, 1624
  %1645 = sext i32 %1644 to i64
  %1646 = getelementptr inbounds float, float* %4, i64 %1645
  %1647 = bitcast float* %1646 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1647, align 4, !tbaa !240
  %1648 = getelementptr float, float* %1646, i64 4
  %1649 = bitcast float* %1648 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1649, align 4, !tbaa !240
  %1650 = or i32 %21, 1632
  %1651 = sext i32 %1650 to i64
  %1652 = getelementptr inbounds float, float* %4, i64 %1651
  %1653 = bitcast float* %1652 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1653, align 4, !tbaa !240
  %1654 = getelementptr float, float* %1652, i64 4
  %1655 = bitcast float* %1654 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1655, align 4, !tbaa !240
  %1656 = or i32 %21, 1640
  %1657 = sext i32 %1656 to i64
  %1658 = getelementptr inbounds float, float* %4, i64 %1657
  %1659 = bitcast float* %1658 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1659, align 4, !tbaa !240
  %1660 = getelementptr float, float* %1658, i64 4
  %1661 = bitcast float* %1660 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1661, align 4, !tbaa !240
  %1662 = or i32 %21, 1648
  %1663 = sext i32 %1662 to i64
  %1664 = getelementptr inbounds float, float* %4, i64 %1663
  %1665 = bitcast float* %1664 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1665, align 4, !tbaa !240
  %1666 = getelementptr float, float* %1664, i64 4
  %1667 = bitcast float* %1666 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1667, align 4, !tbaa !240
  %1668 = or i32 %21, 1656
  %1669 = sext i32 %1668 to i64
  %1670 = getelementptr inbounds float, float* %4, i64 %1669
  %1671 = bitcast float* %1670 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1671, align 4, !tbaa !240
  %1672 = getelementptr float, float* %1670, i64 4
  %1673 = bitcast float* %1672 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1673, align 4, !tbaa !240
  %1674 = or i32 %21, 1664
  %1675 = sext i32 %1674 to i64
  %1676 = getelementptr inbounds float, float* %4, i64 %1675
  %1677 = bitcast float* %1676 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1677, align 4, !tbaa !240
  %1678 = getelementptr float, float* %1676, i64 4
  %1679 = bitcast float* %1678 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1679, align 4, !tbaa !240
  %1680 = or i32 %21, 1672
  %1681 = sext i32 %1680 to i64
  %1682 = getelementptr inbounds float, float* %4, i64 %1681
  %1683 = bitcast float* %1682 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1683, align 4, !tbaa !240
  %1684 = getelementptr float, float* %1682, i64 4
  %1685 = bitcast float* %1684 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1685, align 4, !tbaa !240
  %1686 = or i32 %21, 1680
  %1687 = sext i32 %1686 to i64
  %1688 = getelementptr inbounds float, float* %4, i64 %1687
  %1689 = bitcast float* %1688 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1689, align 4, !tbaa !240
  %1690 = getelementptr float, float* %1688, i64 4
  %1691 = bitcast float* %1690 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1691, align 4, !tbaa !240
  %1692 = or i32 %21, 1688
  %1693 = sext i32 %1692 to i64
  %1694 = getelementptr inbounds float, float* %4, i64 %1693
  %1695 = bitcast float* %1694 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1695, align 4, !tbaa !240
  %1696 = getelementptr float, float* %1694, i64 4
  %1697 = bitcast float* %1696 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1697, align 4, !tbaa !240
  %1698 = or i32 %21, 1696
  %1699 = sext i32 %1698 to i64
  %1700 = getelementptr inbounds float, float* %4, i64 %1699
  %1701 = bitcast float* %1700 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1701, align 4, !tbaa !240
  %1702 = getelementptr float, float* %1700, i64 4
  %1703 = bitcast float* %1702 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1703, align 4, !tbaa !240
  %1704 = or i32 %21, 1704
  %1705 = sext i32 %1704 to i64
  %1706 = getelementptr inbounds float, float* %4, i64 %1705
  %1707 = bitcast float* %1706 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1707, align 4, !tbaa !240
  %1708 = getelementptr float, float* %1706, i64 4
  %1709 = bitcast float* %1708 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1709, align 4, !tbaa !240
  %1710 = or i32 %21, 1712
  %1711 = sext i32 %1710 to i64
  %1712 = getelementptr inbounds float, float* %4, i64 %1711
  %1713 = bitcast float* %1712 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1713, align 4, !tbaa !240
  %1714 = getelementptr float, float* %1712, i64 4
  %1715 = bitcast float* %1714 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1715, align 4, !tbaa !240
  %1716 = or i32 %21, 1720
  %1717 = sext i32 %1716 to i64
  %1718 = getelementptr inbounds float, float* %4, i64 %1717
  %1719 = bitcast float* %1718 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1719, align 4, !tbaa !240
  %1720 = getelementptr float, float* %1718, i64 4
  %1721 = bitcast float* %1720 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1721, align 4, !tbaa !240
  %1722 = or i32 %21, 1728
  %1723 = sext i32 %1722 to i64
  %1724 = getelementptr inbounds float, float* %4, i64 %1723
  %1725 = bitcast float* %1724 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1725, align 4, !tbaa !240
  %1726 = getelementptr float, float* %1724, i64 4
  %1727 = bitcast float* %1726 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1727, align 4, !tbaa !240
  %1728 = or i32 %21, 1736
  %1729 = sext i32 %1728 to i64
  %1730 = getelementptr inbounds float, float* %4, i64 %1729
  %1731 = bitcast float* %1730 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1731, align 4, !tbaa !240
  %1732 = getelementptr float, float* %1730, i64 4
  %1733 = bitcast float* %1732 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1733, align 4, !tbaa !240
  %1734 = or i32 %21, 1744
  %1735 = sext i32 %1734 to i64
  %1736 = getelementptr inbounds float, float* %4, i64 %1735
  %1737 = bitcast float* %1736 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1737, align 4, !tbaa !240
  %1738 = getelementptr float, float* %1736, i64 4
  %1739 = bitcast float* %1738 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1739, align 4, !tbaa !240
  %1740 = or i32 %21, 1752
  %1741 = sext i32 %1740 to i64
  %1742 = getelementptr inbounds float, float* %4, i64 %1741
  %1743 = bitcast float* %1742 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1743, align 4, !tbaa !240
  %1744 = getelementptr float, float* %1742, i64 4
  %1745 = bitcast float* %1744 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1745, align 4, !tbaa !240
  %1746 = or i32 %21, 1760
  %1747 = sext i32 %1746 to i64
  %1748 = getelementptr inbounds float, float* %4, i64 %1747
  %1749 = bitcast float* %1748 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1749, align 4, !tbaa !240
  %1750 = getelementptr float, float* %1748, i64 4
  %1751 = bitcast float* %1750 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1751, align 4, !tbaa !240
  %1752 = or i32 %21, 1768
  %1753 = sext i32 %1752 to i64
  %1754 = getelementptr inbounds float, float* %4, i64 %1753
  %1755 = bitcast float* %1754 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1755, align 4, !tbaa !240
  %1756 = getelementptr float, float* %1754, i64 4
  %1757 = bitcast float* %1756 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1757, align 4, !tbaa !240
  %1758 = or i32 %21, 1776
  %1759 = sext i32 %1758 to i64
  %1760 = getelementptr inbounds float, float* %4, i64 %1759
  %1761 = bitcast float* %1760 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1761, align 4, !tbaa !240
  %1762 = getelementptr float, float* %1760, i64 4
  %1763 = bitcast float* %1762 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1763, align 4, !tbaa !240
  %1764 = or i32 %21, 1784
  %1765 = sext i32 %1764 to i64
  %1766 = getelementptr inbounds float, float* %4, i64 %1765
  %1767 = bitcast float* %1766 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1767, align 4, !tbaa !240
  %1768 = getelementptr float, float* %1766, i64 4
  %1769 = bitcast float* %1768 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1769, align 4, !tbaa !240
  %1770 = or i32 %21, 1792
  %1771 = sext i32 %1770 to i64
  %1772 = getelementptr inbounds float, float* %4, i64 %1771
  %1773 = bitcast float* %1772 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1773, align 4, !tbaa !240
  %1774 = getelementptr float, float* %1772, i64 4
  %1775 = bitcast float* %1774 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1775, align 4, !tbaa !240
  %1776 = or i32 %21, 1800
  %1777 = sext i32 %1776 to i64
  %1778 = getelementptr inbounds float, float* %4, i64 %1777
  %1779 = bitcast float* %1778 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1779, align 4, !tbaa !240
  %1780 = getelementptr float, float* %1778, i64 4
  %1781 = bitcast float* %1780 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1781, align 4, !tbaa !240
  %1782 = or i32 %21, 1808
  %1783 = sext i32 %1782 to i64
  %1784 = getelementptr inbounds float, float* %4, i64 %1783
  %1785 = bitcast float* %1784 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1785, align 4, !tbaa !240
  %1786 = getelementptr float, float* %1784, i64 4
  %1787 = bitcast float* %1786 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1787, align 4, !tbaa !240
  %1788 = or i32 %21, 1816
  %1789 = sext i32 %1788 to i64
  %1790 = getelementptr inbounds float, float* %4, i64 %1789
  %1791 = bitcast float* %1790 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1791, align 4, !tbaa !240
  %1792 = getelementptr float, float* %1790, i64 4
  %1793 = bitcast float* %1792 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1793, align 4, !tbaa !240
  %1794 = or i32 %21, 1824
  %1795 = sext i32 %1794 to i64
  %1796 = getelementptr inbounds float, float* %4, i64 %1795
  %1797 = bitcast float* %1796 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1797, align 4, !tbaa !240
  %1798 = getelementptr float, float* %1796, i64 4
  %1799 = bitcast float* %1798 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1799, align 4, !tbaa !240
  %1800 = or i32 %21, 1832
  %1801 = sext i32 %1800 to i64
  %1802 = getelementptr inbounds float, float* %4, i64 %1801
  %1803 = bitcast float* %1802 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1803, align 4, !tbaa !240
  %1804 = getelementptr float, float* %1802, i64 4
  %1805 = bitcast float* %1804 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1805, align 4, !tbaa !240
  %1806 = or i32 %21, 1840
  %1807 = sext i32 %1806 to i64
  %1808 = getelementptr inbounds float, float* %4, i64 %1807
  %1809 = bitcast float* %1808 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1809, align 4, !tbaa !240
  %1810 = getelementptr float, float* %1808, i64 4
  %1811 = bitcast float* %1810 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1811, align 4, !tbaa !240
  %1812 = or i32 %21, 1848
  %1813 = sext i32 %1812 to i64
  %1814 = getelementptr inbounds float, float* %4, i64 %1813
  %1815 = bitcast float* %1814 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1815, align 4, !tbaa !240
  %1816 = getelementptr float, float* %1814, i64 4
  %1817 = bitcast float* %1816 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1817, align 4, !tbaa !240
  %1818 = or i32 %21, 1856
  %1819 = sext i32 %1818 to i64
  %1820 = getelementptr inbounds float, float* %4, i64 %1819
  %1821 = bitcast float* %1820 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1821, align 4, !tbaa !240
  %1822 = getelementptr float, float* %1820, i64 4
  %1823 = bitcast float* %1822 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1823, align 4, !tbaa !240
  %1824 = or i32 %21, 1864
  %1825 = sext i32 %1824 to i64
  %1826 = getelementptr inbounds float, float* %4, i64 %1825
  %1827 = bitcast float* %1826 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1827, align 4, !tbaa !240
  %1828 = getelementptr float, float* %1826, i64 4
  %1829 = bitcast float* %1828 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1829, align 4, !tbaa !240
  %1830 = or i32 %21, 1872
  %1831 = sext i32 %1830 to i64
  %1832 = getelementptr inbounds float, float* %4, i64 %1831
  %1833 = bitcast float* %1832 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1833, align 4, !tbaa !240
  %1834 = getelementptr float, float* %1832, i64 4
  %1835 = bitcast float* %1834 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1835, align 4, !tbaa !240
  %1836 = or i32 %21, 1880
  %1837 = sext i32 %1836 to i64
  %1838 = getelementptr inbounds float, float* %4, i64 %1837
  %1839 = bitcast float* %1838 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1839, align 4, !tbaa !240
  %1840 = getelementptr float, float* %1838, i64 4
  %1841 = bitcast float* %1840 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1841, align 4, !tbaa !240
  %1842 = or i32 %21, 1888
  %1843 = sext i32 %1842 to i64
  %1844 = getelementptr inbounds float, float* %4, i64 %1843
  %1845 = bitcast float* %1844 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1845, align 4, !tbaa !240
  %1846 = getelementptr float, float* %1844, i64 4
  %1847 = bitcast float* %1846 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1847, align 4, !tbaa !240
  %1848 = or i32 %21, 1896
  %1849 = sext i32 %1848 to i64
  %1850 = getelementptr inbounds float, float* %4, i64 %1849
  %1851 = bitcast float* %1850 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1851, align 4, !tbaa !240
  %1852 = getelementptr float, float* %1850, i64 4
  %1853 = bitcast float* %1852 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1853, align 4, !tbaa !240
  %1854 = or i32 %21, 1904
  %1855 = sext i32 %1854 to i64
  %1856 = getelementptr inbounds float, float* %4, i64 %1855
  %1857 = bitcast float* %1856 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1857, align 4, !tbaa !240
  %1858 = getelementptr float, float* %1856, i64 4
  %1859 = bitcast float* %1858 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1859, align 4, !tbaa !240
  %1860 = or i32 %21, 1912
  %1861 = sext i32 %1860 to i64
  %1862 = getelementptr inbounds float, float* %4, i64 %1861
  %1863 = bitcast float* %1862 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1863, align 4, !tbaa !240
  %1864 = getelementptr float, float* %1862, i64 4
  %1865 = bitcast float* %1864 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1865, align 4, !tbaa !240
  %1866 = or i32 %21, 1920
  %1867 = sext i32 %1866 to i64
  %1868 = getelementptr inbounds float, float* %4, i64 %1867
  %1869 = bitcast float* %1868 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1869, align 4, !tbaa !240
  %1870 = getelementptr float, float* %1868, i64 4
  %1871 = bitcast float* %1870 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1871, align 4, !tbaa !240
  %1872 = or i32 %21, 1928
  %1873 = sext i32 %1872 to i64
  %1874 = getelementptr inbounds float, float* %4, i64 %1873
  %1875 = bitcast float* %1874 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1875, align 4, !tbaa !240
  %1876 = getelementptr float, float* %1874, i64 4
  %1877 = bitcast float* %1876 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1877, align 4, !tbaa !240
  %1878 = or i32 %21, 1936
  %1879 = sext i32 %1878 to i64
  %1880 = getelementptr inbounds float, float* %4, i64 %1879
  %1881 = bitcast float* %1880 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1881, align 4, !tbaa !240
  %1882 = getelementptr float, float* %1880, i64 4
  %1883 = bitcast float* %1882 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1883, align 4, !tbaa !240
  %1884 = or i32 %21, 1944
  %1885 = sext i32 %1884 to i64
  %1886 = getelementptr inbounds float, float* %4, i64 %1885
  %1887 = bitcast float* %1886 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1887, align 4, !tbaa !240
  %1888 = getelementptr float, float* %1886, i64 4
  %1889 = bitcast float* %1888 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1889, align 4, !tbaa !240
  %1890 = or i32 %21, 1952
  %1891 = sext i32 %1890 to i64
  %1892 = getelementptr inbounds float, float* %4, i64 %1891
  %1893 = bitcast float* %1892 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1893, align 4, !tbaa !240
  %1894 = getelementptr float, float* %1892, i64 4
  %1895 = bitcast float* %1894 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1895, align 4, !tbaa !240
  %1896 = or i32 %21, 1960
  %1897 = sext i32 %1896 to i64
  %1898 = getelementptr inbounds float, float* %4, i64 %1897
  %1899 = bitcast float* %1898 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1899, align 4, !tbaa !240
  %1900 = getelementptr float, float* %1898, i64 4
  %1901 = bitcast float* %1900 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1901, align 4, !tbaa !240
  %1902 = or i32 %21, 1968
  %1903 = sext i32 %1902 to i64
  %1904 = getelementptr inbounds float, float* %4, i64 %1903
  %1905 = bitcast float* %1904 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1905, align 4, !tbaa !240
  %1906 = getelementptr float, float* %1904, i64 4
  %1907 = bitcast float* %1906 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1907, align 4, !tbaa !240
  %1908 = or i32 %21, 1976
  %1909 = sext i32 %1908 to i64
  %1910 = getelementptr inbounds float, float* %4, i64 %1909
  %1911 = bitcast float* %1910 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1911, align 4, !tbaa !240
  %1912 = getelementptr float, float* %1910, i64 4
  %1913 = bitcast float* %1912 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1913, align 4, !tbaa !240
  %1914 = or i32 %21, 1984
  %1915 = sext i32 %1914 to i64
  %1916 = getelementptr inbounds float, float* %4, i64 %1915
  %1917 = bitcast float* %1916 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1917, align 4, !tbaa !240
  %1918 = getelementptr float, float* %1916, i64 4
  %1919 = bitcast float* %1918 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1919, align 4, !tbaa !240
  %1920 = or i32 %21, 1992
  %1921 = sext i32 %1920 to i64
  %1922 = getelementptr inbounds float, float* %4, i64 %1921
  %1923 = bitcast float* %1922 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1923, align 4, !tbaa !240
  %1924 = getelementptr float, float* %1922, i64 4
  %1925 = bitcast float* %1924 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1925, align 4, !tbaa !240
  %1926 = or i32 %21, 2000
  %1927 = sext i32 %1926 to i64
  %1928 = getelementptr inbounds float, float* %4, i64 %1927
  %1929 = bitcast float* %1928 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1929, align 4, !tbaa !240
  %1930 = getelementptr float, float* %1928, i64 4
  %1931 = bitcast float* %1930 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1931, align 4, !tbaa !240
  %1932 = or i32 %21, 2008
  %1933 = sext i32 %1932 to i64
  %1934 = getelementptr inbounds float, float* %4, i64 %1933
  %1935 = bitcast float* %1934 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1935, align 4, !tbaa !240
  %1936 = getelementptr float, float* %1934, i64 4
  %1937 = bitcast float* %1936 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1937, align 4, !tbaa !240
  %1938 = or i32 %21, 2016
  %1939 = sext i32 %1938 to i64
  %1940 = getelementptr inbounds float, float* %4, i64 %1939
  %1941 = bitcast float* %1940 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1941, align 4, !tbaa !240
  %1942 = getelementptr float, float* %1940, i64 4
  %1943 = bitcast float* %1942 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1943, align 4, !tbaa !240
  %1944 = or i32 %21, 2024
  %1945 = sext i32 %1944 to i64
  %1946 = getelementptr inbounds float, float* %4, i64 %1945
  %1947 = bitcast float* %1946 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1947, align 4, !tbaa !240
  %1948 = getelementptr float, float* %1946, i64 4
  %1949 = bitcast float* %1948 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1949, align 4, !tbaa !240
  %1950 = or i32 %21, 2032
  %1951 = sext i32 %1950 to i64
  %1952 = getelementptr inbounds float, float* %4, i64 %1951
  %1953 = bitcast float* %1952 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1953, align 4, !tbaa !240
  %1954 = getelementptr float, float* %1952, i64 4
  %1955 = bitcast float* %1954 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1955, align 4, !tbaa !240
  %1956 = or i32 %21, 2040
  %1957 = sext i32 %1956 to i64
  %1958 = getelementptr inbounds float, float* %4, i64 %1957
  %1959 = bitcast float* %1958 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1959, align 4, !tbaa !240
  %1960 = getelementptr float, float* %1958, i64 4
  %1961 = bitcast float* %1960 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %1961, align 4, !tbaa !240
  br label %for_end3

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %for_end6.us, %vector.body385
  %1962 = add nsw i32 %20, 1
  %1963 = icmp slt i32 %1962, %15
  br i1 %1963, label %for_body, label %for_end, !prof !19
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.16(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 223
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 224
  %21 = select i1 %20, i32 %19, i32 224
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 224
  %24 = select i1 %23, i32 %22, i32 224
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv115 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next116, %for_end6.1 ]
  %30 = trunc i64 %indvars.iv115 to i32
  %31 = srem i32 %30, 14
  %32 = sdiv i32 %30, 14
  %33 = mul nsw i32 %32, 36864
  %34 = sext i32 %33 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_body5:                                        ; preds = %for_end9, %for_body
  %indvars.iv104 = phi i64 [ 0, %for_body ], [ %indvars.iv.next105, %for_end9 ]
  %.lcssa3764 = phi <16 x float> [ zeroinitializer, %for_body ], [ %188, %for_end9 ]
  %.lcssa3562 = phi <16 x float> [ zeroinitializer, %for_body ], [ %182, %for_end9 ]
  %.lcssa3360 = phi <16 x float> [ zeroinitializer, %for_body ], [ %181, %for_end9 ]
  %.lcssa3158 = phi <16 x float> [ zeroinitializer, %for_body ], [ %180, %for_end9 ]
  %.lcssa2956 = phi <16 x float> [ zeroinitializer, %for_body ], [ %179, %for_end9 ]
  %.lcssa2754 = phi <16 x float> [ zeroinitializer, %for_body ], [ %178, %for_end9 ]
  %.lcssa2552 = phi <16 x float> [ zeroinitializer, %for_body ], [ %177, %for_end9 ]
  %.lcssa2350 = phi <16 x float> [ zeroinitializer, %for_body ], [ %176, %for_end9 ]
  %.lcssa2148 = phi <16 x float> [ zeroinitializer, %for_body ], [ %175, %for_end9 ]
  %.lcssa1946 = phi <16 x float> [ zeroinitializer, %for_body ], [ %174, %for_end9 ]
  %.lcssa1744 = phi <16 x float> [ zeroinitializer, %for_body ], [ %173, %for_end9 ]
  %.lcssa1542 = phi <16 x float> [ zeroinitializer, %for_body ], [ %172, %for_end9 ]
  %.lcssa1341 = phi <16 x float> [ zeroinitializer, %for_body ], [ %171, %for_end9 ]
  %.lcssa39 = phi <16 x float> [ zeroinitializer, %for_body ], [ %170, %for_end9 ]
  %35 = phi i32 [ 0, %for_body ], [ %189, %for_end9 ]
  %reass.add = add nsw i32 %35, %31
  %reass.mul = shl i32 %reass.add, 11
  %36 = mul nuw nsw i64 %indvars.iv104, 6144
  %37 = add nsw i64 %36, %34
  %38 = sext i32 %reass.mul to i64
  br label %for_body8

for_end6:                                         ; preds = %for_end9
  %39 = add nsw i64 %34, 18432
  br label %for_body5.1

for_body8:                                        ; preds = %for_body8, %for_body5
  %indvars.iv = phi i64 [ 0, %for_body5 ], [ %indvars.iv.next, %for_body8 ]
  %40 = phi <16 x float> [ %.lcssa3764, %for_body5 ], [ %188, %for_body8 ]
  %41 = phi <16 x float> [ %.lcssa3562, %for_body5 ], [ %182, %for_body8 ]
  %42 = phi <16 x float> [ %.lcssa3360, %for_body5 ], [ %181, %for_body8 ]
  %43 = phi <16 x float> [ %.lcssa3158, %for_body5 ], [ %180, %for_body8 ]
  %44 = phi <16 x float> [ %.lcssa2956, %for_body5 ], [ %179, %for_body8 ]
  %45 = phi <16 x float> [ %.lcssa2754, %for_body5 ], [ %178, %for_body8 ]
  %46 = phi <16 x float> [ %.lcssa2552, %for_body5 ], [ %177, %for_body8 ]
  %47 = phi <16 x float> [ %.lcssa2350, %for_body5 ], [ %176, %for_body8 ]
  %48 = phi <16 x float> [ %.lcssa2148, %for_body5 ], [ %175, %for_body8 ]
  %49 = phi <16 x float> [ %.lcssa1946, %for_body5 ], [ %174, %for_body8 ]
  %50 = phi <16 x float> [ %.lcssa1744, %for_body5 ], [ %173, %for_body8 ]
  %51 = phi <16 x float> [ %.lcssa1542, %for_body5 ], [ %172, %for_body8 ]
  %52 = phi <16 x float> [ %.lcssa1341, %for_body5 ], [ %171, %for_body8 ]
  %53 = phi <16 x float> [ %.lcssa39, %for_body5 ], [ %170, %for_body8 ]
  %54 = add nsw i64 %indvars.iv, %38
  %55 = getelementptr inbounds float, float* %4, i64 %54
  %56 = load float, float* %55, align 4, !tbaa !240
  %57 = insertelement <16 x float> undef, float %56, i32 0
  %58 = shufflevector <16 x float> %57, <16 x float> undef, <16 x i32> zeroinitializer
  %59 = shl nsw i64 %indvars.iv, 4
  %60 = add nsw i64 %37, %59
  %61 = getelementptr inbounds float, float* %7, i64 %60
  %62 = bitcast float* %61 to <16 x float>*
  %63 = load <16 x float>, <16 x float>* %62, align 64, !tbaa !243
  %64 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %58, <16 x float> %63, <16 x float> %53)
  %65 = add nsw i64 %54, 128
  %66 = getelementptr inbounds float, float* %4, i64 %65
  %67 = load float, float* %66, align 4, !tbaa !240
  %68 = insertelement <16 x float> undef, float %67, i32 0
  %69 = shufflevector <16 x float> %68, <16 x float> undef, <16 x i32> zeroinitializer
  %70 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %69, <16 x float> %63, <16 x float> %52)
  %71 = add nsw i64 %54, 256
  %72 = getelementptr inbounds float, float* %4, i64 %71
  %73 = load float, float* %72, align 4, !tbaa !240
  %74 = insertelement <16 x float> undef, float %73, i32 0
  %75 = shufflevector <16 x float> %74, <16 x float> undef, <16 x i32> zeroinitializer
  %76 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %75, <16 x float> %63, <16 x float> %51)
  %77 = add nsw i64 %54, 384
  %78 = getelementptr inbounds float, float* %4, i64 %77
  %79 = load float, float* %78, align 4, !tbaa !240
  %80 = insertelement <16 x float> undef, float %79, i32 0
  %81 = shufflevector <16 x float> %80, <16 x float> undef, <16 x i32> zeroinitializer
  %82 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %81, <16 x float> %63, <16 x float> %50)
  %83 = add nsw i64 %54, 512
  %84 = getelementptr inbounds float, float* %4, i64 %83
  %85 = load float, float* %84, align 4, !tbaa !240
  %86 = insertelement <16 x float> undef, float %85, i32 0
  %87 = shufflevector <16 x float> %86, <16 x float> undef, <16 x i32> zeroinitializer
  %88 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %87, <16 x float> %63, <16 x float> %49)
  %89 = add nsw i64 %54, 640
  %90 = getelementptr inbounds float, float* %4, i64 %89
  %91 = load float, float* %90, align 4, !tbaa !240
  %92 = insertelement <16 x float> undef, float %91, i32 0
  %93 = shufflevector <16 x float> %92, <16 x float> undef, <16 x i32> zeroinitializer
  %94 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %93, <16 x float> %63, <16 x float> %48)
  %95 = add nsw i64 %54, 768
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !240
  %98 = insertelement <16 x float> undef, float %97, i32 0
  %99 = shufflevector <16 x float> %98, <16 x float> undef, <16 x i32> zeroinitializer
  %100 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %99, <16 x float> %63, <16 x float> %47)
  %101 = add nsw i64 %54, 896
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !240
  %104 = insertelement <16 x float> undef, float %103, i32 0
  %105 = shufflevector <16 x float> %104, <16 x float> undef, <16 x i32> zeroinitializer
  %106 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %105, <16 x float> %63, <16 x float> %46)
  %107 = add nsw i64 %54, 1024
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !240
  %110 = insertelement <16 x float> undef, float %109, i32 0
  %111 = shufflevector <16 x float> %110, <16 x float> undef, <16 x i32> zeroinitializer
  %112 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %111, <16 x float> %63, <16 x float> %45)
  %113 = add nsw i64 %54, 1152
  %114 = getelementptr inbounds float, float* %4, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !240
  %116 = insertelement <16 x float> undef, float %115, i32 0
  %117 = shufflevector <16 x float> %116, <16 x float> undef, <16 x i32> zeroinitializer
  %118 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %117, <16 x float> %63, <16 x float> %44)
  %119 = add nsw i64 %54, 1280
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !240
  %122 = insertelement <16 x float> undef, float %121, i32 0
  %123 = shufflevector <16 x float> %122, <16 x float> undef, <16 x i32> zeroinitializer
  %124 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %123, <16 x float> %63, <16 x float> %43)
  %125 = add nsw i64 %54, 1408
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !240
  %128 = insertelement <16 x float> undef, float %127, i32 0
  %129 = shufflevector <16 x float> %128, <16 x float> undef, <16 x i32> zeroinitializer
  %130 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %129, <16 x float> %63, <16 x float> %42)
  %131 = add nsw i64 %54, 1536
  %132 = getelementptr inbounds float, float* %4, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !240
  %134 = insertelement <16 x float> undef, float %133, i32 0
  %135 = shufflevector <16 x float> %134, <16 x float> undef, <16 x i32> zeroinitializer
  %136 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %135, <16 x float> %63, <16 x float> %41)
  %137 = add nsw i64 %54, 1664
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !240
  %140 = insertelement <16 x float> undef, float %139, i32 0
  %141 = shufflevector <16 x float> %140, <16 x float> undef, <16 x i32> zeroinitializer
  %142 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %141, <16 x float> %63, <16 x float> %40)
  %143 = add nsw i64 %60, 2048
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <16 x float>*
  %146 = load <16 x float>, <16 x float>* %145, align 64, !tbaa !243
  %147 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %69, <16 x float> %146, <16 x float> %64)
  %148 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %75, <16 x float> %146, <16 x float> %70)
  %149 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %81, <16 x float> %146, <16 x float> %76)
  %150 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %87, <16 x float> %146, <16 x float> %82)
  %151 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %93, <16 x float> %146, <16 x float> %88)
  %152 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %99, <16 x float> %146, <16 x float> %94)
  %153 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %105, <16 x float> %146, <16 x float> %100)
  %154 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %111, <16 x float> %146, <16 x float> %106)
  %155 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %117, <16 x float> %146, <16 x float> %112)
  %156 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %123, <16 x float> %146, <16 x float> %118)
  %157 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %129, <16 x float> %146, <16 x float> %124)
  %158 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %135, <16 x float> %146, <16 x float> %130)
  %159 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %141, <16 x float> %146, <16 x float> %136)
  %160 = add nsw i64 %54, 1792
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !240
  %163 = insertelement <16 x float> undef, float %162, i32 0
  %164 = shufflevector <16 x float> %163, <16 x float> undef, <16 x i32> zeroinitializer
  %165 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %164, <16 x float> %146, <16 x float> %142)
  %166 = add nsw i64 %60, 4096
  %167 = getelementptr inbounds float, float* %7, i64 %166
  %168 = bitcast float* %167 to <16 x float>*
  %169 = load <16 x float>, <16 x float>* %168, align 64, !tbaa !243
  %170 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %75, <16 x float> %169, <16 x float> %147)
  %171 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %81, <16 x float> %169, <16 x float> %148)
  %172 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %87, <16 x float> %169, <16 x float> %149)
  %173 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %93, <16 x float> %169, <16 x float> %150)
  %174 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %99, <16 x float> %169, <16 x float> %151)
  %175 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %105, <16 x float> %169, <16 x float> %152)
  %176 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %111, <16 x float> %169, <16 x float> %153)
  %177 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %117, <16 x float> %169, <16 x float> %154)
  %178 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %123, <16 x float> %169, <16 x float> %155)
  %179 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %129, <16 x float> %169, <16 x float> %156)
  %180 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %135, <16 x float> %169, <16 x float> %157)
  %181 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %141, <16 x float> %169, <16 x float> %158)
  %182 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %164, <16 x float> %169, <16 x float> %159)
  %183 = add nsw i64 %54, 1920
  %184 = getelementptr inbounds float, float* %4, i64 %183
  %185 = load float, float* %184, align 4, !tbaa !240
  %186 = insertelement <16 x float> undef, float %185, i32 0
  %187 = shufflevector <16 x float> %186, <16 x float> undef, <16 x i32> zeroinitializer
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %187, <16 x float> %169, <16 x float> %165)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %indvars.iv.next105 = add nuw nsw i64 %indvars.iv104, 1
  %189 = add nuw nsw i32 %35, 1
  %exitcond108 = icmp eq i64 %indvars.iv.next105, 3
  br i1 %exitcond108, label %for_end6, label %for_body5, !prof !29

for_body5.1:                                      ; preds = %for_end9.1, %for_end6
  %indvars.iv104.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next105.1, %for_end9.1 ]
  %.lcssa3764.1 = phi <16 x float> [ %188, %for_end6 ], [ %343, %for_end9.1 ]
  %.lcssa3562.1 = phi <16 x float> [ %182, %for_end6 ], [ %337, %for_end9.1 ]
  %.lcssa3360.1 = phi <16 x float> [ %181, %for_end6 ], [ %336, %for_end9.1 ]
  %.lcssa3158.1 = phi <16 x float> [ %180, %for_end6 ], [ %335, %for_end9.1 ]
  %.lcssa2956.1 = phi <16 x float> [ %179, %for_end6 ], [ %334, %for_end9.1 ]
  %.lcssa2754.1 = phi <16 x float> [ %178, %for_end6 ], [ %333, %for_end9.1 ]
  %.lcssa2552.1 = phi <16 x float> [ %177, %for_end6 ], [ %332, %for_end9.1 ]
  %.lcssa2350.1 = phi <16 x float> [ %176, %for_end6 ], [ %331, %for_end9.1 ]
  %.lcssa2148.1 = phi <16 x float> [ %175, %for_end6 ], [ %330, %for_end9.1 ]
  %.lcssa1946.1 = phi <16 x float> [ %174, %for_end6 ], [ %329, %for_end9.1 ]
  %.lcssa1744.1 = phi <16 x float> [ %173, %for_end6 ], [ %328, %for_end9.1 ]
  %.lcssa1542.1 = phi <16 x float> [ %172, %for_end6 ], [ %327, %for_end9.1 ]
  %.lcssa1341.1 = phi <16 x float> [ %171, %for_end6 ], [ %326, %for_end9.1 ]
  %.lcssa39.1 = phi <16 x float> [ %170, %for_end6 ], [ %325, %for_end9.1 ]
  %190 = phi i32 [ 0, %for_end6 ], [ %344, %for_end9.1 ]
  %reass.add.1 = add nsw i32 %190, %31
  %reass.mul.1 = shl i32 %reass.add.1, 11
  %191 = add nsw i32 %reass.mul.1, 32768
  %192 = mul nuw nsw i64 %indvars.iv104.1, 6144
  %193 = add nsw i64 %39, %192
  %194 = sext i32 %191 to i64
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_body5.1
  %indvars.iv.1 = phi i64 [ 0, %for_body5.1 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %195 = phi <16 x float> [ %.lcssa3764.1, %for_body5.1 ], [ %343, %for_body8.1 ]
  %196 = phi <16 x float> [ %.lcssa3562.1, %for_body5.1 ], [ %337, %for_body8.1 ]
  %197 = phi <16 x float> [ %.lcssa3360.1, %for_body5.1 ], [ %336, %for_body8.1 ]
  %198 = phi <16 x float> [ %.lcssa3158.1, %for_body5.1 ], [ %335, %for_body8.1 ]
  %199 = phi <16 x float> [ %.lcssa2956.1, %for_body5.1 ], [ %334, %for_body8.1 ]
  %200 = phi <16 x float> [ %.lcssa2754.1, %for_body5.1 ], [ %333, %for_body8.1 ]
  %201 = phi <16 x float> [ %.lcssa2552.1, %for_body5.1 ], [ %332, %for_body8.1 ]
  %202 = phi <16 x float> [ %.lcssa2350.1, %for_body5.1 ], [ %331, %for_body8.1 ]
  %203 = phi <16 x float> [ %.lcssa2148.1, %for_body5.1 ], [ %330, %for_body8.1 ]
  %204 = phi <16 x float> [ %.lcssa1946.1, %for_body5.1 ], [ %329, %for_body8.1 ]
  %205 = phi <16 x float> [ %.lcssa1744.1, %for_body5.1 ], [ %328, %for_body8.1 ]
  %206 = phi <16 x float> [ %.lcssa1542.1, %for_body5.1 ], [ %327, %for_body8.1 ]
  %207 = phi <16 x float> [ %.lcssa1341.1, %for_body5.1 ], [ %326, %for_body8.1 ]
  %208 = phi <16 x float> [ %.lcssa39.1, %for_body5.1 ], [ %325, %for_body8.1 ]
  %209 = add nsw i64 %indvars.iv.1, %194
  %210 = getelementptr inbounds float, float* %4, i64 %209
  %211 = load float, float* %210, align 4, !tbaa !240
  %212 = insertelement <16 x float> undef, float %211, i32 0
  %213 = shufflevector <16 x float> %212, <16 x float> undef, <16 x i32> zeroinitializer
  %214 = shl nsw i64 %indvars.iv.1, 4
  %215 = add nsw i64 %193, %214
  %216 = getelementptr inbounds float, float* %7, i64 %215
  %217 = bitcast float* %216 to <16 x float>*
  %218 = load <16 x float>, <16 x float>* %217, align 64, !tbaa !243
  %219 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %213, <16 x float> %218, <16 x float> %208)
  %220 = add nsw i64 %209, 128
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !240
  %223 = insertelement <16 x float> undef, float %222, i32 0
  %224 = shufflevector <16 x float> %223, <16 x float> undef, <16 x i32> zeroinitializer
  %225 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %224, <16 x float> %218, <16 x float> %207)
  %226 = add nsw i64 %209, 256
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !240
  %229 = insertelement <16 x float> undef, float %228, i32 0
  %230 = shufflevector <16 x float> %229, <16 x float> undef, <16 x i32> zeroinitializer
  %231 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %230, <16 x float> %218, <16 x float> %206)
  %232 = add nsw i64 %209, 384
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !240
  %235 = insertelement <16 x float> undef, float %234, i32 0
  %236 = shufflevector <16 x float> %235, <16 x float> undef, <16 x i32> zeroinitializer
  %237 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %236, <16 x float> %218, <16 x float> %205)
  %238 = add nsw i64 %209, 512
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !240
  %241 = insertelement <16 x float> undef, float %240, i32 0
  %242 = shufflevector <16 x float> %241, <16 x float> undef, <16 x i32> zeroinitializer
  %243 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %242, <16 x float> %218, <16 x float> %204)
  %244 = add nsw i64 %209, 640
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !240
  %247 = insertelement <16 x float> undef, float %246, i32 0
  %248 = shufflevector <16 x float> %247, <16 x float> undef, <16 x i32> zeroinitializer
  %249 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %248, <16 x float> %218, <16 x float> %203)
  %250 = add nsw i64 %209, 768
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !240
  %253 = insertelement <16 x float> undef, float %252, i32 0
  %254 = shufflevector <16 x float> %253, <16 x float> undef, <16 x i32> zeroinitializer
  %255 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %254, <16 x float> %218, <16 x float> %202)
  %256 = add nsw i64 %209, 896
  %257 = getelementptr inbounds float, float* %4, i64 %256
  %258 = load float, float* %257, align 4, !tbaa !240
  %259 = insertelement <16 x float> undef, float %258, i32 0
  %260 = shufflevector <16 x float> %259, <16 x float> undef, <16 x i32> zeroinitializer
  %261 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %260, <16 x float> %218, <16 x float> %201)
  %262 = add nsw i64 %209, 1024
  %263 = getelementptr inbounds float, float* %4, i64 %262
  %264 = load float, float* %263, align 4, !tbaa !240
  %265 = insertelement <16 x float> undef, float %264, i32 0
  %266 = shufflevector <16 x float> %265, <16 x float> undef, <16 x i32> zeroinitializer
  %267 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %266, <16 x float> %218, <16 x float> %200)
  %268 = add nsw i64 %209, 1152
  %269 = getelementptr inbounds float, float* %4, i64 %268
  %270 = load float, float* %269, align 4, !tbaa !240
  %271 = insertelement <16 x float> undef, float %270, i32 0
  %272 = shufflevector <16 x float> %271, <16 x float> undef, <16 x i32> zeroinitializer
  %273 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %272, <16 x float> %218, <16 x float> %199)
  %274 = add nsw i64 %209, 1280
  %275 = getelementptr inbounds float, float* %4, i64 %274
  %276 = load float, float* %275, align 4, !tbaa !240
  %277 = insertelement <16 x float> undef, float %276, i32 0
  %278 = shufflevector <16 x float> %277, <16 x float> undef, <16 x i32> zeroinitializer
  %279 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %218, <16 x float> %198)
  %280 = add nsw i64 %209, 1408
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !240
  %283 = insertelement <16 x float> undef, float %282, i32 0
  %284 = shufflevector <16 x float> %283, <16 x float> undef, <16 x i32> zeroinitializer
  %285 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %284, <16 x float> %218, <16 x float> %197)
  %286 = add nsw i64 %209, 1536
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !240
  %289 = insertelement <16 x float> undef, float %288, i32 0
  %290 = shufflevector <16 x float> %289, <16 x float> undef, <16 x i32> zeroinitializer
  %291 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %290, <16 x float> %218, <16 x float> %196)
  %292 = add nsw i64 %209, 1664
  %293 = getelementptr inbounds float, float* %4, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !240
  %295 = insertelement <16 x float> undef, float %294, i32 0
  %296 = shufflevector <16 x float> %295, <16 x float> undef, <16 x i32> zeroinitializer
  %297 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %296, <16 x float> %218, <16 x float> %195)
  %298 = add nsw i64 %215, 2048
  %299 = getelementptr inbounds float, float* %7, i64 %298
  %300 = bitcast float* %299 to <16 x float>*
  %301 = load <16 x float>, <16 x float>* %300, align 64, !tbaa !243
  %302 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %224, <16 x float> %301, <16 x float> %219)
  %303 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %230, <16 x float> %301, <16 x float> %225)
  %304 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %236, <16 x float> %301, <16 x float> %231)
  %305 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %242, <16 x float> %301, <16 x float> %237)
  %306 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %248, <16 x float> %301, <16 x float> %243)
  %307 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %254, <16 x float> %301, <16 x float> %249)
  %308 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %260, <16 x float> %301, <16 x float> %255)
  %309 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %266, <16 x float> %301, <16 x float> %261)
  %310 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %272, <16 x float> %301, <16 x float> %267)
  %311 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %301, <16 x float> %273)
  %312 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %284, <16 x float> %301, <16 x float> %279)
  %313 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %290, <16 x float> %301, <16 x float> %285)
  %314 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %296, <16 x float> %301, <16 x float> %291)
  %315 = add nsw i64 %209, 1792
  %316 = getelementptr inbounds float, float* %4, i64 %315
  %317 = load float, float* %316, align 4, !tbaa !240
  %318 = insertelement <16 x float> undef, float %317, i32 0
  %319 = shufflevector <16 x float> %318, <16 x float> undef, <16 x i32> zeroinitializer
  %320 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %319, <16 x float> %301, <16 x float> %297)
  %321 = add nsw i64 %215, 4096
  %322 = getelementptr inbounds float, float* %7, i64 %321
  %323 = bitcast float* %322 to <16 x float>*
  %324 = load <16 x float>, <16 x float>* %323, align 64, !tbaa !243
  %325 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %230, <16 x float> %324, <16 x float> %302)
  %326 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %236, <16 x float> %324, <16 x float> %303)
  %327 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %242, <16 x float> %324, <16 x float> %304)
  %328 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %248, <16 x float> %324, <16 x float> %305)
  %329 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %254, <16 x float> %324, <16 x float> %306)
  %330 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %260, <16 x float> %324, <16 x float> %307)
  %331 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %266, <16 x float> %324, <16 x float> %308)
  %332 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %272, <16 x float> %324, <16 x float> %309)
  %333 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %324, <16 x float> %310)
  %334 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %284, <16 x float> %324, <16 x float> %311)
  %335 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %290, <16 x float> %324, <16 x float> %312)
  %336 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %296, <16 x float> %324, <16 x float> %313)
  %337 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %319, <16 x float> %324, <16 x float> %314)
  %338 = add nsw i64 %209, 1920
  %339 = getelementptr inbounds float, float* %4, i64 %338
  %340 = load float, float* %339, align 4, !tbaa !240
  %341 = insertelement <16 x float> undef, float %340, i32 0
  %342 = shufflevector <16 x float> %341, <16 x float> undef, <16 x i32> zeroinitializer
  %343 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %342, <16 x float> %324, <16 x float> %320)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !29

for_end9.1:                                       ; preds = %for_body8.1
  %indvars.iv.next105.1 = add nuw nsw i64 %indvars.iv104.1, 1
  %344 = add nuw nsw i32 %190, 1
  %exitcond108.1 = icmp eq i64 %indvars.iv.next105.1, 3
  br i1 %exitcond108.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_end9.1
  %345 = mul nsw i64 %indvars.iv115, 224
  %346 = shl nsw i32 %32, 4
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds float, float* %13, i64 %347
  %349 = bitcast float* %348 to <16 x float>*
  %350 = load <16 x float>, <16 x float>* %349, align 64, !tbaa !246
  %351 = fadd <16 x float> %350, %325
  %352 = fcmp ogt <16 x float> %351, zeroinitializer
  %353 = select <16 x i1> %352, <16 x float> %351, <16 x float> zeroinitializer
  %354 = getelementptr inbounds float, float* %10, i64 %345
  %355 = bitcast float* %354 to <16 x float>*
  store <16 x float> %353, <16 x float>* %355, align 64, !tbaa !249
  %356 = or i64 %345, 16
  %357 = fadd <16 x float> %350, %326
  %358 = fcmp ogt <16 x float> %357, zeroinitializer
  %359 = select <16 x i1> %358, <16 x float> %357, <16 x float> zeroinitializer
  %360 = getelementptr inbounds float, float* %10, i64 %356
  %361 = bitcast float* %360 to <16 x float>*
  store <16 x float> %359, <16 x float>* %361, align 64, !tbaa !249
  %362 = add nsw i64 %345, 32
  %363 = fadd <16 x float> %350, %327
  %364 = fcmp ogt <16 x float> %363, zeroinitializer
  %365 = select <16 x i1> %364, <16 x float> %363, <16 x float> zeroinitializer
  %366 = getelementptr inbounds float, float* %10, i64 %362
  %367 = bitcast float* %366 to <16 x float>*
  store <16 x float> %365, <16 x float>* %367, align 64, !tbaa !249
  %368 = add nsw i64 %345, 48
  %369 = fadd <16 x float> %350, %328
  %370 = fcmp ogt <16 x float> %369, zeroinitializer
  %371 = select <16 x i1> %370, <16 x float> %369, <16 x float> zeroinitializer
  %372 = getelementptr inbounds float, float* %10, i64 %368
  %373 = bitcast float* %372 to <16 x float>*
  store <16 x float> %371, <16 x float>* %373, align 64, !tbaa !249
  %374 = add nsw i64 %345, 64
  %375 = fadd <16 x float> %350, %329
  %376 = fcmp ogt <16 x float> %375, zeroinitializer
  %377 = select <16 x i1> %376, <16 x float> %375, <16 x float> zeroinitializer
  %378 = getelementptr inbounds float, float* %10, i64 %374
  %379 = bitcast float* %378 to <16 x float>*
  store <16 x float> %377, <16 x float>* %379, align 64, !tbaa !249
  %380 = add nsw i64 %345, 80
  %381 = fadd <16 x float> %350, %330
  %382 = fcmp ogt <16 x float> %381, zeroinitializer
  %383 = select <16 x i1> %382, <16 x float> %381, <16 x float> zeroinitializer
  %384 = getelementptr inbounds float, float* %10, i64 %380
  %385 = bitcast float* %384 to <16 x float>*
  store <16 x float> %383, <16 x float>* %385, align 64, !tbaa !249
  %386 = add nsw i64 %345, 96
  %387 = fadd <16 x float> %350, %331
  %388 = fcmp ogt <16 x float> %387, zeroinitializer
  %389 = select <16 x i1> %388, <16 x float> %387, <16 x float> zeroinitializer
  %390 = getelementptr inbounds float, float* %10, i64 %386
  %391 = bitcast float* %390 to <16 x float>*
  store <16 x float> %389, <16 x float>* %391, align 64, !tbaa !249
  %392 = add nsw i64 %345, 112
  %393 = fadd <16 x float> %350, %332
  %394 = fcmp ogt <16 x float> %393, zeroinitializer
  %395 = select <16 x i1> %394, <16 x float> %393, <16 x float> zeroinitializer
  %396 = getelementptr inbounds float, float* %10, i64 %392
  %397 = bitcast float* %396 to <16 x float>*
  store <16 x float> %395, <16 x float>* %397, align 64, !tbaa !249
  %398 = add nsw i64 %345, 128
  %399 = fadd <16 x float> %350, %333
  %400 = fcmp ogt <16 x float> %399, zeroinitializer
  %401 = select <16 x i1> %400, <16 x float> %399, <16 x float> zeroinitializer
  %402 = getelementptr inbounds float, float* %10, i64 %398
  %403 = bitcast float* %402 to <16 x float>*
  store <16 x float> %401, <16 x float>* %403, align 64, !tbaa !249
  %404 = add nsw i64 %345, 144
  %405 = fadd <16 x float> %350, %334
  %406 = fcmp ogt <16 x float> %405, zeroinitializer
  %407 = select <16 x i1> %406, <16 x float> %405, <16 x float> zeroinitializer
  %408 = getelementptr inbounds float, float* %10, i64 %404
  %409 = bitcast float* %408 to <16 x float>*
  store <16 x float> %407, <16 x float>* %409, align 64, !tbaa !249
  %410 = add nsw i64 %345, 160
  %411 = fadd <16 x float> %350, %335
  %412 = fcmp ogt <16 x float> %411, zeroinitializer
  %413 = select <16 x i1> %412, <16 x float> %411, <16 x float> zeroinitializer
  %414 = getelementptr inbounds float, float* %10, i64 %410
  %415 = bitcast float* %414 to <16 x float>*
  store <16 x float> %413, <16 x float>* %415, align 64, !tbaa !249
  %416 = add nsw i64 %345, 176
  %417 = fadd <16 x float> %350, %336
  %418 = fcmp ogt <16 x float> %417, zeroinitializer
  %419 = select <16 x i1> %418, <16 x float> %417, <16 x float> zeroinitializer
  %420 = getelementptr inbounds float, float* %10, i64 %416
  %421 = bitcast float* %420 to <16 x float>*
  store <16 x float> %419, <16 x float>* %421, align 64, !tbaa !249
  %422 = add nsw i64 %345, 192
  %423 = fadd <16 x float> %350, %337
  %424 = fcmp ogt <16 x float> %423, zeroinitializer
  %425 = select <16 x i1> %424, <16 x float> %423, <16 x float> zeroinitializer
  %426 = getelementptr inbounds float, float* %10, i64 %422
  %427 = bitcast float* %426 to <16 x float>*
  store <16 x float> %425, <16 x float>* %427, align 64, !tbaa !249
  %428 = add nsw i64 %345, 208
  %429 = fadd <16 x float> %350, %343
  %430 = fcmp ogt <16 x float> %429, zeroinitializer
  %431 = select <16 x i1> %430, <16 x float> %429, <16 x float> zeroinitializer
  %432 = getelementptr inbounds float, float* %10, i64 %428
  %433 = bitcast float* %432 to <16 x float>*
  store <16 x float> %431, <16 x float>* %433, align 64, !tbaa !249
  %indvars.iv.next116 = add nsw i64 %indvars.iv115, 1
  %434 = icmp slt i64 %indvars.iv.next116, %29
  br i1 %434, label %for_body, label %for_end, !prof !19
}

; Function Attrs: nounwind readnone speculatable
declare <16 x float> @llvm.fmuladd.v16f32(<16 x float>, <16 x float>, <16 x float>) #1

define dllexport i32 @fused_layout_transform_39(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !252 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !254, metadata !DIExpression()), !dbg !257
  call void @llvm.dbg.value(metadata i8* %1, metadata !255, metadata !DIExpression()), !dbg !257
  call void @llvm.dbg.value(metadata i32 %2, metadata !256, metadata !DIExpression()), !dbg !257
  %3 = bitcast i8* %0 to %1**, !dbg !257
  %4 = load %1*, %1** %3, align 8, !dbg !257
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !257
  %6 = bitcast i8* %5 to %1**, !dbg !257
  %7 = load %1*, %1** %6, align 8, !dbg !257
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !257
  %9 = load i8*, i8** %8, align 8, !dbg !257
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !257
  %11 = load i8*, i8** %10, align 8, !dbg !257
  %12 = tail call fastcc i32 @fused_layout_transform_39_compute_(i8* %11, i8* %9), !dbg !257
  ret i32 %12, !dbg !257
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_39_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %21, align 8
  %3 = getelementptr inbounds %21, %21* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %21, %21* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %21* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.17, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.17(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 1792
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 7
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 6
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 63
  %35 = lshr i32 %33, 6
  %36 = mul nsw i32 %35, 50176
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !258
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !261
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

; Function Attrs: nounwind
define dllexport i32 @fused_layout_transform_nn_batch_flatten_nn_batch_flatten_multiply(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr #3 !dbg !264 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !266, metadata !DIExpression()), !dbg !269
  call void @llvm.dbg.value(metadata i8* %1, metadata !267, metadata !DIExpression()), !dbg !269
  call void @llvm.dbg.value(metadata i32 %2, metadata !268, metadata !DIExpression()), !dbg !269
  %3 = bitcast i8* %0 to %1**, !dbg !269
  %4 = load %1*, %1** %3, align 8, !dbg !269
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !269
  %6 = bitcast i8* %5 to %1**, !dbg !269
  %7 = load %1*, %1** %6, align 8, !dbg !269
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !269
  %9 = load i8*, i8** %8, align 8, !dbg !269
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !269
  %11 = load i8*, i8** %10, align 8, !dbg !269
  tail call fastcc void @fused_layout_transform_nn_batch_flatten_nn_batch_flatten_multiply_compute_(i8* %11, i8* %9), !dbg !269
  ret i32 0, !dbg !269
}

; Function Attrs: noinline norecurse nounwind
define private fastcc void @fused_layout_transform_nn_batch_flatten_nn_batch_flatten_multiply_compute_(i8* noalias nocapture, i8* noalias nocapture readonly) unnamed_addr #4 {
entry:
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %0, i8* %1, i64 8192, i32 4, i1 false)
  ret void
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_2(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !270 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !272, metadata !DIExpression()), !dbg !275
  call void @llvm.dbg.value(metadata i8* %1, metadata !273, metadata !DIExpression()), !dbg !275
  call void @llvm.dbg.value(metadata i32 %2, metadata !274, metadata !DIExpression()), !dbg !275
  %3 = bitcast i8* %0 to %1**, !dbg !275
  %4 = load %1*, %1** %3, align 8, !dbg !275
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !275
  %6 = bitcast i8* %5 to %1**, !dbg !275
  %7 = load %1*, %1** %6, align 8, !dbg !275
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !275
  %9 = bitcast i8* %8 to %1**, !dbg !275
  %10 = load %1*, %1** %9, align 8, !dbg !275
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !275
  %12 = bitcast i8* %11 to %1**, !dbg !275
  %13 = load %1*, %1** %12, align 8, !dbg !275
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !275
  %15 = load i8*, i8** %14, align 8, !dbg !275
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !275
  %17 = load i32, i32* %16, align 4, !dbg !275
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !275
  %19 = load i8*, i8** %18, align 8, !dbg !275
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !275
  %21 = load i8*, i8** %20, align 8, !dbg !275
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !275
  %23 = load i8*, i8** %22, align 8, !dbg !275
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_2_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !275
  ret i32 %24, !dbg !275
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = alloca %22, align 8
  %6 = getelementptr inbounds %22, %22* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %22, %22* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %22, %22* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %22, %22* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %22, %22* %5, i64 0, i32 4
  store i32 %4, i32* %10, align 8
  %11 = bitcast %22* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.18, i8* nonnull %11, i32 0)
  ret i32 %13
}

define private i32 @__tvm_parallel_lambda.18(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.6
  %indvars.iv40 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next41, %for_end6.6 ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %34 = tail call i8* %33(i32 1, i32 %16, i64 7168, i32 2, i32 32)
  %35 = trunc i64 %indvars.iv40 to i32
  %36 = srem i32 %35, 7
  %37 = mul nsw i32 %36, 57344
  %38 = sdiv i32 %35, 7
  %39 = shl i32 %38, 15
  %40 = sext i32 %39 to i64
  %41 = sext i32 %37 to i64
  %42 = bitcast i8* %34 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %42, align 64, !tbaa !276
  %43 = getelementptr inbounds i8, i8* %34, i64 256
  %44 = bitcast i8* %43 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %44, align 64, !tbaa !276
  %45 = getelementptr inbounds i8, i8* %34, i64 3584
  %46 = bitcast i8* %45 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %46, align 64, !tbaa !276
  %47 = getelementptr inbounds i8, i8* %34, i64 3840
  %48 = bitcast i8* %47 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %48, align 64, !tbaa !276
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %49 = phi <64 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %50 = phi <64 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %51 = phi <64 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %52 = phi <64 x float> [ zeroinitializer, %for_body ], [ %63, %for_body5 ]
  %53 = add nsw i64 %indvars.iv, %41
  %54 = getelementptr inbounds float, float* %4, i64 %53
  %55 = load float, float* %54, align 4, !tbaa !279
  %56 = insertelement <64 x float> undef, float %55, i32 0
  %57 = shufflevector <64 x float> %56, <64 x float> undef, <64 x i32> zeroinitializer
  %58 = shl i64 %indvars.iv, 6
  %59 = add nuw nsw i64 %58, %40
  %60 = getelementptr inbounds float, float* %7, i64 %59
  %61 = bitcast float* %60 to <64 x float>*
  %62 = load <64 x float>, <64 x float>* %61, align 64, !tbaa !282
  %63 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %57, <64 x float> %62, <64 x float> %52)
  %64 = add nsw i64 %53, 1024
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !279
  %67 = insertelement <64 x float> undef, float %66, i32 0
  %68 = shufflevector <64 x float> %67, <64 x float> undef, <64 x i32> zeroinitializer
  %69 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %68, <64 x float> %62, <64 x float> %51)
  %70 = add nsw i64 %53, 28672
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !279
  %73 = insertelement <64 x float> undef, float %72, i32 0
  %74 = shufflevector <64 x float> %73, <64 x float> undef, <64 x i32> zeroinitializer
  %75 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %74, <64 x float> %62, <64 x float> %50)
  %76 = add nsw i64 %53, 29696
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !279
  %79 = insertelement <64 x float> undef, float %78, i32 0
  %80 = shufflevector <64 x float> %79, <64 x float> undef, <64 x i32> zeroinitializer
  %81 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %80, <64 x float> %62, <64 x float> %49)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <64 x float> %63, <64 x float>* %42, align 64, !tbaa !276
  store <64 x float> %69, <64 x float>* %44, align 64, !tbaa !276
  store <64 x float> %75, <64 x float>* %46, align 64, !tbaa !276
  store <64 x float> %81, <64 x float>* %48, align 64, !tbaa !276
  %82 = getelementptr inbounds i8, i8* %34, i64 512
  %83 = bitcast i8* %82 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %83, align 64, !tbaa !276
  %84 = getelementptr inbounds i8, i8* %34, i64 768
  %85 = bitcast i8* %84 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %85, align 64, !tbaa !276
  %86 = getelementptr inbounds i8, i8* %34, i64 4096
  %87 = bitcast i8* %86 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %87, align 64, !tbaa !276
  %88 = getelementptr inbounds i8, i8* %34, i64 4352
  %89 = bitcast i8* %88 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %89, align 64, !tbaa !276
  %90 = or i64 %41, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %91 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %123, %for_body5.1 ]
  %92 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %117, %for_body5.1 ]
  %93 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %111, %for_body5.1 ]
  %94 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %105, %for_body5.1 ]
  %95 = add nsw i64 %90, %indvars.iv.1
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !279
  %98 = insertelement <64 x float> undef, float %97, i32 0
  %99 = shufflevector <64 x float> %98, <64 x float> undef, <64 x i32> zeroinitializer
  %100 = shl i64 %indvars.iv.1, 6
  %101 = add nuw nsw i64 %100, %40
  %102 = getelementptr inbounds float, float* %7, i64 %101
  %103 = bitcast float* %102 to <64 x float>*
  %104 = load <64 x float>, <64 x float>* %103, align 64, !tbaa !282
  %105 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %99, <64 x float> %104, <64 x float> %94)
  %106 = add nsw i64 %95, 1024
  %107 = getelementptr inbounds float, float* %4, i64 %106
  %108 = load float, float* %107, align 4, !tbaa !279
  %109 = insertelement <64 x float> undef, float %108, i32 0
  %110 = shufflevector <64 x float> %109, <64 x float> undef, <64 x i32> zeroinitializer
  %111 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %110, <64 x float> %104, <64 x float> %93)
  %112 = add nsw i64 %95, 28672
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = load float, float* %113, align 4, !tbaa !279
  %115 = insertelement <64 x float> undef, float %114, i32 0
  %116 = shufflevector <64 x float> %115, <64 x float> undef, <64 x i32> zeroinitializer
  %117 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %116, <64 x float> %104, <64 x float> %92)
  %118 = add nsw i64 %95, 29696
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = load float, float* %119, align 4, !tbaa !279
  %121 = insertelement <64 x float> undef, float %120, i32 0
  %122 = shufflevector <64 x float> %121, <64 x float> undef, <64 x i32> zeroinitializer
  %123 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %122, <64 x float> %104, <64 x float> %91)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %105, <64 x float>* %83, align 64, !tbaa !276
  store <64 x float> %111, <64 x float>* %85, align 64, !tbaa !276
  store <64 x float> %117, <64 x float>* %87, align 64, !tbaa !276
  store <64 x float> %123, <64 x float>* %89, align 64, !tbaa !276
  %124 = getelementptr inbounds i8, i8* %34, i64 1024
  %125 = bitcast i8* %124 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %125, align 64, !tbaa !276
  %126 = getelementptr inbounds i8, i8* %34, i64 1280
  %127 = bitcast i8* %126 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %127, align 64, !tbaa !276
  %128 = getelementptr inbounds i8, i8* %34, i64 4608
  %129 = bitcast i8* %128 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %129, align 64, !tbaa !276
  %130 = getelementptr inbounds i8, i8* %34, i64 4864
  %131 = bitcast i8* %130 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %131, align 64, !tbaa !276
  %132 = or i64 %41, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %133 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %165, %for_body5.2 ]
  %134 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %159, %for_body5.2 ]
  %135 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %153, %for_body5.2 ]
  %136 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %147, %for_body5.2 ]
  %137 = add nsw i64 %132, %indvars.iv.2
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !279
  %140 = insertelement <64 x float> undef, float %139, i32 0
  %141 = shufflevector <64 x float> %140, <64 x float> undef, <64 x i32> zeroinitializer
  %142 = shl i64 %indvars.iv.2, 6
  %143 = add nuw nsw i64 %142, %40
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <64 x float>*
  %146 = load <64 x float>, <64 x float>* %145, align 64, !tbaa !282
  %147 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %141, <64 x float> %146, <64 x float> %136)
  %148 = add nsw i64 %137, 1024
  %149 = getelementptr inbounds float, float* %4, i64 %148
  %150 = load float, float* %149, align 4, !tbaa !279
  %151 = insertelement <64 x float> undef, float %150, i32 0
  %152 = shufflevector <64 x float> %151, <64 x float> undef, <64 x i32> zeroinitializer
  %153 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %152, <64 x float> %146, <64 x float> %135)
  %154 = add nsw i64 %137, 28672
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !279
  %157 = insertelement <64 x float> undef, float %156, i32 0
  %158 = shufflevector <64 x float> %157, <64 x float> undef, <64 x i32> zeroinitializer
  %159 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %158, <64 x float> %146, <64 x float> %134)
  %160 = add nsw i64 %137, 29696
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !279
  %163 = insertelement <64 x float> undef, float %162, i32 0
  %164 = shufflevector <64 x float> %163, <64 x float> undef, <64 x i32> zeroinitializer
  %165 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %164, <64 x float> %146, <64 x float> %133)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %147, <64 x float>* %125, align 64, !tbaa !276
  store <64 x float> %153, <64 x float>* %127, align 64, !tbaa !276
  store <64 x float> %159, <64 x float>* %129, align 64, !tbaa !276
  store <64 x float> %165, <64 x float>* %131, align 64, !tbaa !276
  %166 = getelementptr inbounds i8, i8* %34, i64 1536
  %167 = bitcast i8* %166 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %167, align 64, !tbaa !276
  %168 = getelementptr inbounds i8, i8* %34, i64 1792
  %169 = bitcast i8* %168 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %169, align 64, !tbaa !276
  %170 = getelementptr inbounds i8, i8* %34, i64 5120
  %171 = bitcast i8* %170 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %171, align 64, !tbaa !276
  %172 = getelementptr inbounds i8, i8* %34, i64 5376
  %173 = bitcast i8* %172 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %173, align 64, !tbaa !276
  %174 = or i64 %41, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %175 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %207, %for_body5.3 ]
  %176 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %201, %for_body5.3 ]
  %177 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %195, %for_body5.3 ]
  %178 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %189, %for_body5.3 ]
  %179 = add nsw i64 %174, %indvars.iv.3
  %180 = getelementptr inbounds float, float* %4, i64 %179
  %181 = load float, float* %180, align 4, !tbaa !279
  %182 = insertelement <64 x float> undef, float %181, i32 0
  %183 = shufflevector <64 x float> %182, <64 x float> undef, <64 x i32> zeroinitializer
  %184 = shl i64 %indvars.iv.3, 6
  %185 = add nuw nsw i64 %184, %40
  %186 = getelementptr inbounds float, float* %7, i64 %185
  %187 = bitcast float* %186 to <64 x float>*
  %188 = load <64 x float>, <64 x float>* %187, align 64, !tbaa !282
  %189 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %183, <64 x float> %188, <64 x float> %178)
  %190 = add nsw i64 %179, 1024
  %191 = getelementptr inbounds float, float* %4, i64 %190
  %192 = load float, float* %191, align 4, !tbaa !279
  %193 = insertelement <64 x float> undef, float %192, i32 0
  %194 = shufflevector <64 x float> %193, <64 x float> undef, <64 x i32> zeroinitializer
  %195 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %194, <64 x float> %188, <64 x float> %177)
  %196 = add nsw i64 %179, 28672
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !279
  %199 = insertelement <64 x float> undef, float %198, i32 0
  %200 = shufflevector <64 x float> %199, <64 x float> undef, <64 x i32> zeroinitializer
  %201 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %200, <64 x float> %188, <64 x float> %176)
  %202 = add nsw i64 %179, 29696
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !279
  %205 = insertelement <64 x float> undef, float %204, i32 0
  %206 = shufflevector <64 x float> %205, <64 x float> undef, <64 x i32> zeroinitializer
  %207 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %206, <64 x float> %188, <64 x float> %175)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %189, <64 x float>* %167, align 64, !tbaa !276
  store <64 x float> %195, <64 x float>* %169, align 64, !tbaa !276
  store <64 x float> %201, <64 x float>* %171, align 64, !tbaa !276
  store <64 x float> %207, <64 x float>* %173, align 64, !tbaa !276
  %208 = getelementptr inbounds i8, i8* %34, i64 2048
  %209 = bitcast i8* %208 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %209, align 64, !tbaa !276
  %210 = getelementptr inbounds i8, i8* %34, i64 2304
  %211 = bitcast i8* %210 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %211, align 64, !tbaa !276
  %212 = getelementptr inbounds i8, i8* %34, i64 5632
  %213 = bitcast i8* %212 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %213, align 64, !tbaa !276
  %214 = getelementptr inbounds i8, i8* %34, i64 5888
  %215 = bitcast i8* %214 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %215, align 64, !tbaa !276
  %216 = add nsw i64 %41, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %217 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %249, %for_body5.4 ]
  %218 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %243, %for_body5.4 ]
  %219 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %237, %for_body5.4 ]
  %220 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %231, %for_body5.4 ]
  %221 = add nsw i64 %216, %indvars.iv.4
  %222 = getelementptr inbounds float, float* %4, i64 %221
  %223 = load float, float* %222, align 4, !tbaa !279
  %224 = insertelement <64 x float> undef, float %223, i32 0
  %225 = shufflevector <64 x float> %224, <64 x float> undef, <64 x i32> zeroinitializer
  %226 = shl i64 %indvars.iv.4, 6
  %227 = add nuw nsw i64 %226, %40
  %228 = getelementptr inbounds float, float* %7, i64 %227
  %229 = bitcast float* %228 to <64 x float>*
  %230 = load <64 x float>, <64 x float>* %229, align 64, !tbaa !282
  %231 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %225, <64 x float> %230, <64 x float> %220)
  %232 = add nsw i64 %221, 1024
  %233 = getelementptr inbounds float, float* %4, i64 %232
  %234 = load float, float* %233, align 4, !tbaa !279
  %235 = insertelement <64 x float> undef, float %234, i32 0
  %236 = shufflevector <64 x float> %235, <64 x float> undef, <64 x i32> zeroinitializer
  %237 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %236, <64 x float> %230, <64 x float> %219)
  %238 = add nsw i64 %221, 28672
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !279
  %241 = insertelement <64 x float> undef, float %240, i32 0
  %242 = shufflevector <64 x float> %241, <64 x float> undef, <64 x i32> zeroinitializer
  %243 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %242, <64 x float> %230, <64 x float> %218)
  %244 = add nsw i64 %221, 29696
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !279
  %247 = insertelement <64 x float> undef, float %246, i32 0
  %248 = shufflevector <64 x float> %247, <64 x float> undef, <64 x i32> zeroinitializer
  %249 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %248, <64 x float> %230, <64 x float> %217)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %231, <64 x float>* %209, align 64, !tbaa !276
  store <64 x float> %237, <64 x float>* %211, align 64, !tbaa !276
  store <64 x float> %243, <64 x float>* %213, align 64, !tbaa !276
  store <64 x float> %249, <64 x float>* %215, align 64, !tbaa !276
  %250 = getelementptr inbounds i8, i8* %34, i64 2560
  %251 = bitcast i8* %250 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %251, align 64, !tbaa !276
  %252 = getelementptr inbounds i8, i8* %34, i64 2816
  %253 = bitcast i8* %252 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %253, align 64, !tbaa !276
  %254 = getelementptr inbounds i8, i8* %34, i64 6144
  %255 = bitcast i8* %254 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %255, align 64, !tbaa !276
  %256 = getelementptr inbounds i8, i8* %34, i64 6400
  %257 = bitcast i8* %256 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %257, align 64, !tbaa !276
  %258 = add nsw i64 %41, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %259 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %291, %for_body5.5 ]
  %260 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %285, %for_body5.5 ]
  %261 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %279, %for_body5.5 ]
  %262 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %273, %for_body5.5 ]
  %263 = add nsw i64 %258, %indvars.iv.5
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !279
  %266 = insertelement <64 x float> undef, float %265, i32 0
  %267 = shufflevector <64 x float> %266, <64 x float> undef, <64 x i32> zeroinitializer
  %268 = shl i64 %indvars.iv.5, 6
  %269 = add nuw nsw i64 %268, %40
  %270 = getelementptr inbounds float, float* %7, i64 %269
  %271 = bitcast float* %270 to <64 x float>*
  %272 = load <64 x float>, <64 x float>* %271, align 64, !tbaa !282
  %273 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %267, <64 x float> %272, <64 x float> %262)
  %274 = add nsw i64 %263, 1024
  %275 = getelementptr inbounds float, float* %4, i64 %274
  %276 = load float, float* %275, align 4, !tbaa !279
  %277 = insertelement <64 x float> undef, float %276, i32 0
  %278 = shufflevector <64 x float> %277, <64 x float> undef, <64 x i32> zeroinitializer
  %279 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %278, <64 x float> %272, <64 x float> %261)
  %280 = add nsw i64 %263, 28672
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !279
  %283 = insertelement <64 x float> undef, float %282, i32 0
  %284 = shufflevector <64 x float> %283, <64 x float> undef, <64 x i32> zeroinitializer
  %285 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %284, <64 x float> %272, <64 x float> %260)
  %286 = add nsw i64 %263, 29696
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !279
  %289 = insertelement <64 x float> undef, float %288, i32 0
  %290 = shufflevector <64 x float> %289, <64 x float> undef, <64 x i32> zeroinitializer
  %291 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %290, <64 x float> %272, <64 x float> %259)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %273, <64 x float>* %251, align 64, !tbaa !276
  store <64 x float> %279, <64 x float>* %253, align 64, !tbaa !276
  store <64 x float> %285, <64 x float>* %255, align 64, !tbaa !276
  store <64 x float> %291, <64 x float>* %257, align 64, !tbaa !276
  %292 = getelementptr inbounds i8, i8* %34, i64 3072
  %293 = bitcast i8* %292 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %293, align 64, !tbaa !276
  %294 = getelementptr inbounds i8, i8* %34, i64 3328
  %295 = bitcast i8* %294 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %295, align 64, !tbaa !276
  %296 = getelementptr inbounds i8, i8* %34, i64 6656
  %297 = bitcast i8* %296 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %297, align 64, !tbaa !276
  %298 = getelementptr inbounds i8, i8* %34, i64 6912
  %299 = bitcast i8* %298 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %299, align 64, !tbaa !276
  %300 = add nsw i64 %41, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %301 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %333, %for_body5.6 ]
  %302 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %327, %for_body5.6 ]
  %303 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %321, %for_body5.6 ]
  %304 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %315, %for_body5.6 ]
  %305 = add nsw i64 %300, %indvars.iv.6
  %306 = getelementptr inbounds float, float* %4, i64 %305
  %307 = load float, float* %306, align 4, !tbaa !279
  %308 = insertelement <64 x float> undef, float %307, i32 0
  %309 = shufflevector <64 x float> %308, <64 x float> undef, <64 x i32> zeroinitializer
  %310 = shl i64 %indvars.iv.6, 6
  %311 = add nuw nsw i64 %310, %40
  %312 = getelementptr inbounds float, float* %7, i64 %311
  %313 = bitcast float* %312 to <64 x float>*
  %314 = load <64 x float>, <64 x float>* %313, align 64, !tbaa !282
  %315 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %309, <64 x float> %314, <64 x float> %304)
  %316 = add nsw i64 %305, 1024
  %317 = getelementptr inbounds float, float* %4, i64 %316
  %318 = load float, float* %317, align 4, !tbaa !279
  %319 = insertelement <64 x float> undef, float %318, i32 0
  %320 = shufflevector <64 x float> %319, <64 x float> undef, <64 x i32> zeroinitializer
  %321 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %320, <64 x float> %314, <64 x float> %303)
  %322 = add nsw i64 %305, 28672
  %323 = getelementptr inbounds float, float* %4, i64 %322
  %324 = load float, float* %323, align 4, !tbaa !279
  %325 = insertelement <64 x float> undef, float %324, i32 0
  %326 = shufflevector <64 x float> %325, <64 x float> undef, <64 x i32> zeroinitializer
  %327 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %326, <64 x float> %314, <64 x float> %302)
  %328 = add nsw i64 %305, 29696
  %329 = getelementptr inbounds float, float* %4, i64 %328
  %330 = load float, float* %329, align 4, !tbaa !279
  %331 = insertelement <64 x float> undef, float %330, i32 0
  %332 = shufflevector <64 x float> %331, <64 x float> undef, <64 x i32> zeroinitializer
  %333 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %332, <64 x float> %314, <64 x float> %301)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %315, <64 x float>* %293, align 64, !tbaa !276
  store <64 x float> %321, <64 x float>* %295, align 64, !tbaa !276
  store <64 x float> %327, <64 x float>* %297, align 64, !tbaa !276
  store <64 x float> %333, <64 x float>* %299, align 64, !tbaa !276
  %334 = mul nsw i64 %indvars.iv40, 1792
  %335 = shl nsw i32 %38, 6
  %336 = sext i32 %335 to i64
  %337 = getelementptr inbounds float, float* %13, i64 %336
  %338 = bitcast float* %337 to <64 x float>*
  %339 = load <64 x float>, <64 x float>* %338, align 64, !tbaa !285
  %340 = bitcast i8* %34 to <64 x float>*
  %341 = load <64 x float>, <64 x float>* %340, align 64, !tbaa !276
  %342 = fadd <64 x float> %339, %341
  %343 = getelementptr inbounds float, float* %10, i64 %334
  %344 = bitcast float* %343 to <64 x float>*
  store <64 x float> %342, <64 x float>* %344, align 64, !tbaa !288
  %345 = getelementptr inbounds i8, i8* %34, i64 256
  %346 = bitcast i8* %345 to <64 x float>*
  %347 = load <64 x float>, <64 x float>* %346, align 64, !tbaa !276
  %348 = fadd <64 x float> %339, %347
  %349 = mul i64 %indvars.iv40, 7696581394432
  %sext = ashr exact i64 %349, 32
  %350 = or i64 %sext, 64
  %351 = getelementptr inbounds float, float* %10, i64 %350
  %352 = bitcast float* %351 to <64 x float>*
  store <64 x float> %348, <64 x float>* %352, align 64, !tbaa !288
  %353 = getelementptr inbounds i8, i8* %34, i64 3584
  %354 = bitcast i8* %353 to <64 x float>*
  %355 = load <64 x float>, <64 x float>* %354, align 64, !tbaa !276
  %356 = fadd <64 x float> %339, %355
  %357 = mul i64 %indvars.iv40, 7696581394432
  %sext55 = add i64 %357, 3848290697216
  %358 = ashr exact i64 %sext55, 32
  %359 = getelementptr inbounds float, float* %10, i64 %358
  %360 = bitcast float* %359 to <64 x float>*
  store <64 x float> %356, <64 x float>* %360, align 64, !tbaa !288
  %361 = getelementptr inbounds i8, i8* %34, i64 3840
  %362 = bitcast i8* %361 to <64 x float>*
  %363 = load <64 x float>, <64 x float>* %362, align 64, !tbaa !276
  %364 = fadd <64 x float> %339, %363
  %365 = mul i64 %indvars.iv40, 7696581394432
  %sext42 = add i64 %365, 4123168604160
  %366 = ashr exact i64 %sext42, 32
  %367 = getelementptr inbounds float, float* %10, i64 %366
  %368 = bitcast float* %367 to <64 x float>*
  store <64 x float> %364, <64 x float>* %368, align 64, !tbaa !288
  %369 = getelementptr inbounds i8, i8* %34, i64 512
  %370 = bitcast i8* %369 to <64 x float>*
  %371 = load <64 x float>, <64 x float>* %370, align 64, !tbaa !276
  %372 = fadd <64 x float> %339, %371
  %373 = mul i64 %indvars.iv40, 7696581394432
  %sext56 = ashr exact i64 %373, 32
  %374 = or i64 %sext56, 128
  %375 = getelementptr inbounds float, float* %10, i64 %374
  %376 = bitcast float* %375 to <64 x float>*
  store <64 x float> %372, <64 x float>* %376, align 64, !tbaa !288
  %377 = getelementptr inbounds i8, i8* %34, i64 768
  %378 = bitcast i8* %377 to <64 x float>*
  %379 = load <64 x float>, <64 x float>* %378, align 64, !tbaa !276
  %380 = fadd <64 x float> %339, %379
  %381 = mul i64 %indvars.iv40, 7696581394432
  %sext43 = ashr exact i64 %381, 32
  %382 = or i64 %sext43, 192
  %383 = getelementptr inbounds float, float* %10, i64 %382
  %384 = bitcast float* %383 to <64 x float>*
  store <64 x float> %380, <64 x float>* %384, align 64, !tbaa !288
  %385 = getelementptr inbounds i8, i8* %34, i64 4096
  %386 = bitcast i8* %385 to <64 x float>*
  %387 = load <64 x float>, <64 x float>* %386, align 64, !tbaa !276
  %388 = fadd <64 x float> %339, %387
  %389 = mul i64 %indvars.iv40, 7696581394432
  %sext57 = add i64 %389, 4398046511104
  %390 = ashr exact i64 %sext57, 32
  %391 = getelementptr inbounds float, float* %10, i64 %390
  %392 = bitcast float* %391 to <64 x float>*
  store <64 x float> %388, <64 x float>* %392, align 64, !tbaa !288
  %393 = getelementptr inbounds i8, i8* %34, i64 4352
  %394 = bitcast i8* %393 to <64 x float>*
  %395 = load <64 x float>, <64 x float>* %394, align 64, !tbaa !276
  %396 = fadd <64 x float> %339, %395
  %397 = mul i64 %indvars.iv40, 7696581394432
  %sext44 = add i64 %397, 4672924418048
  %398 = ashr exact i64 %sext44, 32
  %399 = getelementptr inbounds float, float* %10, i64 %398
  %400 = bitcast float* %399 to <64 x float>*
  store <64 x float> %396, <64 x float>* %400, align 64, !tbaa !288
  %401 = getelementptr inbounds i8, i8* %34, i64 1024
  %402 = bitcast i8* %401 to <64 x float>*
  %403 = load <64 x float>, <64 x float>* %402, align 64, !tbaa !276
  %404 = fadd <64 x float> %339, %403
  %405 = mul i64 %indvars.iv40, 7696581394432
  %sext58 = add i64 %405, 1099511627776
  %406 = ashr exact i64 %sext58, 32
  %407 = getelementptr inbounds float, float* %10, i64 %406
  %408 = bitcast float* %407 to <64 x float>*
  store <64 x float> %404, <64 x float>* %408, align 64, !tbaa !288
  %409 = getelementptr inbounds i8, i8* %34, i64 1280
  %410 = bitcast i8* %409 to <64 x float>*
  %411 = load <64 x float>, <64 x float>* %410, align 64, !tbaa !276
  %412 = fadd <64 x float> %339, %411
  %413 = mul i64 %indvars.iv40, 7696581394432
  %sext45 = add i64 %413, 1374389534720
  %414 = ashr exact i64 %sext45, 32
  %415 = getelementptr inbounds float, float* %10, i64 %414
  %416 = bitcast float* %415 to <64 x float>*
  store <64 x float> %412, <64 x float>* %416, align 64, !tbaa !288
  %417 = getelementptr inbounds i8, i8* %34, i64 4608
  %418 = bitcast i8* %417 to <64 x float>*
  %419 = load <64 x float>, <64 x float>* %418, align 64, !tbaa !276
  %420 = fadd <64 x float> %339, %419
  %421 = mul i64 %indvars.iv40, 7696581394432
  %sext59 = add i64 %421, 4947802324992
  %422 = ashr exact i64 %sext59, 32
  %423 = getelementptr inbounds float, float* %10, i64 %422
  %424 = bitcast float* %423 to <64 x float>*
  store <64 x float> %420, <64 x float>* %424, align 64, !tbaa !288
  %425 = getelementptr inbounds i8, i8* %34, i64 4864
  %426 = bitcast i8* %425 to <64 x float>*
  %427 = load <64 x float>, <64 x float>* %426, align 64, !tbaa !276
  %428 = fadd <64 x float> %339, %427
  %429 = mul i64 %indvars.iv40, 7696581394432
  %sext46 = add i64 %429, 5222680231936
  %430 = ashr exact i64 %sext46, 32
  %431 = getelementptr inbounds float, float* %10, i64 %430
  %432 = bitcast float* %431 to <64 x float>*
  store <64 x float> %428, <64 x float>* %432, align 64, !tbaa !288
  %433 = getelementptr inbounds i8, i8* %34, i64 1536
  %434 = bitcast i8* %433 to <64 x float>*
  %435 = load <64 x float>, <64 x float>* %434, align 64, !tbaa !276
  %436 = fadd <64 x float> %339, %435
  %437 = mul i64 %indvars.iv40, 7696581394432
  %sext60 = add i64 %437, 1649267441664
  %438 = ashr exact i64 %sext60, 32
  %439 = getelementptr inbounds float, float* %10, i64 %438
  %440 = bitcast float* %439 to <64 x float>*
  store <64 x float> %436, <64 x float>* %440, align 64, !tbaa !288
  %441 = getelementptr inbounds i8, i8* %34, i64 1792
  %442 = bitcast i8* %441 to <64 x float>*
  %443 = load <64 x float>, <64 x float>* %442, align 64, !tbaa !276
  %444 = fadd <64 x float> %339, %443
  %445 = mul i64 %indvars.iv40, 7696581394432
  %sext47 = add i64 %445, 1924145348608
  %446 = ashr exact i64 %sext47, 32
  %447 = getelementptr inbounds float, float* %10, i64 %446
  %448 = bitcast float* %447 to <64 x float>*
  store <64 x float> %444, <64 x float>* %448, align 64, !tbaa !288
  %449 = getelementptr inbounds i8, i8* %34, i64 5120
  %450 = bitcast i8* %449 to <64 x float>*
  %451 = load <64 x float>, <64 x float>* %450, align 64, !tbaa !276
  %452 = fadd <64 x float> %339, %451
  %453 = mul i64 %indvars.iv40, 7696581394432
  %sext61 = add i64 %453, 5497558138880
  %454 = ashr exact i64 %sext61, 32
  %455 = getelementptr inbounds float, float* %10, i64 %454
  %456 = bitcast float* %455 to <64 x float>*
  store <64 x float> %452, <64 x float>* %456, align 64, !tbaa !288
  %457 = getelementptr inbounds i8, i8* %34, i64 5376
  %458 = bitcast i8* %457 to <64 x float>*
  %459 = load <64 x float>, <64 x float>* %458, align 64, !tbaa !276
  %460 = fadd <64 x float> %339, %459
  %461 = mul i64 %indvars.iv40, 7696581394432
  %sext48 = add i64 %461, 5772436045824
  %462 = ashr exact i64 %sext48, 32
  %463 = getelementptr inbounds float, float* %10, i64 %462
  %464 = bitcast float* %463 to <64 x float>*
  store <64 x float> %460, <64 x float>* %464, align 64, !tbaa !288
  %465 = getelementptr inbounds i8, i8* %34, i64 2048
  %466 = bitcast i8* %465 to <64 x float>*
  %467 = load <64 x float>, <64 x float>* %466, align 64, !tbaa !276
  %468 = fadd <64 x float> %339, %467
  %469 = mul i64 %indvars.iv40, 7696581394432
  %sext62 = add i64 %469, 2199023255552
  %470 = ashr exact i64 %sext62, 32
  %471 = getelementptr inbounds float, float* %10, i64 %470
  %472 = bitcast float* %471 to <64 x float>*
  store <64 x float> %468, <64 x float>* %472, align 64, !tbaa !288
  %473 = getelementptr inbounds i8, i8* %34, i64 2304
  %474 = bitcast i8* %473 to <64 x float>*
  %475 = load <64 x float>, <64 x float>* %474, align 64, !tbaa !276
  %476 = fadd <64 x float> %339, %475
  %477 = mul i64 %indvars.iv40, 7696581394432
  %sext49 = add i64 %477, 2473901162496
  %478 = ashr exact i64 %sext49, 32
  %479 = getelementptr inbounds float, float* %10, i64 %478
  %480 = bitcast float* %479 to <64 x float>*
  store <64 x float> %476, <64 x float>* %480, align 64, !tbaa !288
  %481 = getelementptr inbounds i8, i8* %34, i64 5632
  %482 = bitcast i8* %481 to <64 x float>*
  %483 = load <64 x float>, <64 x float>* %482, align 64, !tbaa !276
  %484 = fadd <64 x float> %339, %483
  %485 = mul i64 %indvars.iv40, 7696581394432
  %sext63 = add i64 %485, 6047313952768
  %486 = ashr exact i64 %sext63, 32
  %487 = getelementptr inbounds float, float* %10, i64 %486
  %488 = bitcast float* %487 to <64 x float>*
  store <64 x float> %484, <64 x float>* %488, align 64, !tbaa !288
  %489 = getelementptr inbounds i8, i8* %34, i64 5888
  %490 = bitcast i8* %489 to <64 x float>*
  %491 = load <64 x float>, <64 x float>* %490, align 64, !tbaa !276
  %492 = fadd <64 x float> %339, %491
  %493 = mul i64 %indvars.iv40, 7696581394432
  %sext50 = add i64 %493, 6322191859712
  %494 = ashr exact i64 %sext50, 32
  %495 = getelementptr inbounds float, float* %10, i64 %494
  %496 = bitcast float* %495 to <64 x float>*
  store <64 x float> %492, <64 x float>* %496, align 64, !tbaa !288
  %497 = getelementptr inbounds i8, i8* %34, i64 2560
  %498 = bitcast i8* %497 to <64 x float>*
  %499 = load <64 x float>, <64 x float>* %498, align 64, !tbaa !276
  %500 = fadd <64 x float> %339, %499
  %501 = mul i64 %indvars.iv40, 7696581394432
  %sext64 = add i64 %501, 2748779069440
  %502 = ashr exact i64 %sext64, 32
  %503 = getelementptr inbounds float, float* %10, i64 %502
  %504 = bitcast float* %503 to <64 x float>*
  store <64 x float> %500, <64 x float>* %504, align 64, !tbaa !288
  %505 = getelementptr inbounds i8, i8* %34, i64 2816
  %506 = bitcast i8* %505 to <64 x float>*
  %507 = load <64 x float>, <64 x float>* %506, align 64, !tbaa !276
  %508 = fadd <64 x float> %339, %507
  %509 = mul i64 %indvars.iv40, 7696581394432
  %sext51 = add i64 %509, 3023656976384
  %510 = ashr exact i64 %sext51, 32
  %511 = getelementptr inbounds float, float* %10, i64 %510
  %512 = bitcast float* %511 to <64 x float>*
  store <64 x float> %508, <64 x float>* %512, align 64, !tbaa !288
  %513 = getelementptr inbounds i8, i8* %34, i64 6144
  %514 = bitcast i8* %513 to <64 x float>*
  %515 = load <64 x float>, <64 x float>* %514, align 64, !tbaa !276
  %516 = fadd <64 x float> %339, %515
  %517 = mul i64 %indvars.iv40, 7696581394432
  %sext65 = add i64 %517, 6597069766656
  %518 = ashr exact i64 %sext65, 32
  %519 = getelementptr inbounds float, float* %10, i64 %518
  %520 = bitcast float* %519 to <64 x float>*
  store <64 x float> %516, <64 x float>* %520, align 64, !tbaa !288
  %521 = getelementptr inbounds i8, i8* %34, i64 6400
  %522 = bitcast i8* %521 to <64 x float>*
  %523 = load <64 x float>, <64 x float>* %522, align 64, !tbaa !276
  %524 = fadd <64 x float> %339, %523
  %525 = mul i64 %indvars.iv40, 7696581394432
  %sext52 = add i64 %525, 6871947673600
  %526 = ashr exact i64 %sext52, 32
  %527 = getelementptr inbounds float, float* %10, i64 %526
  %528 = bitcast float* %527 to <64 x float>*
  store <64 x float> %524, <64 x float>* %528, align 64, !tbaa !288
  %529 = getelementptr inbounds i8, i8* %34, i64 3072
  %530 = bitcast i8* %529 to <64 x float>*
  %531 = load <64 x float>, <64 x float>* %530, align 64, !tbaa !276
  %532 = fadd <64 x float> %339, %531
  %533 = mul i64 %indvars.iv40, 7696581394432
  %sext66 = add i64 %533, 3298534883328
  %534 = ashr exact i64 %sext66, 32
  %535 = getelementptr inbounds float, float* %10, i64 %534
  %536 = bitcast float* %535 to <64 x float>*
  store <64 x float> %532, <64 x float>* %536, align 64, !tbaa !288
  %537 = getelementptr inbounds i8, i8* %34, i64 3328
  %538 = bitcast i8* %537 to <64 x float>*
  %539 = load <64 x float>, <64 x float>* %538, align 64, !tbaa !276
  %540 = fadd <64 x float> %339, %539
  %541 = mul i64 %indvars.iv40, 7696581394432
  %sext53 = add i64 %541, 3573412790272
  %542 = ashr exact i64 %sext53, 32
  %543 = getelementptr inbounds float, float* %10, i64 %542
  %544 = bitcast float* %543 to <64 x float>*
  store <64 x float> %540, <64 x float>* %544, align 64, !tbaa !288
  %545 = getelementptr inbounds i8, i8* %34, i64 6656
  %546 = bitcast i8* %545 to <64 x float>*
  %547 = load <64 x float>, <64 x float>* %546, align 64, !tbaa !276
  %548 = fadd <64 x float> %339, %547
  %549 = mul i64 %indvars.iv40, 7696581394432
  %sext67 = add i64 %549, 7146825580544
  %550 = ashr exact i64 %sext67, 32
  %551 = getelementptr inbounds float, float* %10, i64 %550
  %552 = bitcast float* %551 to <64 x float>*
  store <64 x float> %548, <64 x float>* %552, align 64, !tbaa !288
  %553 = getelementptr inbounds i8, i8* %34, i64 6912
  %554 = bitcast i8* %553 to <64 x float>*
  %555 = load <64 x float>, <64 x float>* %554, align 64, !tbaa !276
  %556 = fadd <64 x float> %339, %555
  %557 = mul i64 %indvars.iv40, 7696581394432
  %sext54 = add i64 %557, 7421703487488
  %558 = ashr exact i64 %sext54, 32
  %559 = getelementptr inbounds float, float* %10, i64 %558
  %560 = bitcast float* %559 to <64 x float>*
  store <64 x float> %556, <64 x float>* %560, align 64, !tbaa !288
  %561 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %562 = tail call i32 %561(i32 1, i32 %16, i8* nonnull %34)
  %indvars.iv.next41 = add nsw i64 %indvars.iv40, 1
  %563 = icmp slt i64 %indvars.iv.next41, %32
  br i1 %563, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_global_avg_pool2d(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !291 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !293, metadata !DIExpression()), !dbg !296
  call void @llvm.dbg.value(metadata i8* %1, metadata !294, metadata !DIExpression()), !dbg !296
  call void @llvm.dbg.value(metadata i32 %2, metadata !295, metadata !DIExpression()), !dbg !296
  %3 = bitcast i8* %0 to %1**, !dbg !296
  %4 = load %1*, %1** %3, align 8, !dbg !296
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !296
  %6 = bitcast i8* %5 to %1**, !dbg !296
  %7 = load %1*, %1** %6, align 8, !dbg !296
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !296
  %9 = load i8*, i8** %8, align 8, !dbg !296
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !296
  %11 = load i8*, i8** %10, align 8, !dbg !296
  %12 = tail call fastcc i32 @fused_nn_global_avg_pool2d_compute_(i8* %11, i8* %9), !dbg !296
  ret i32 %12, !dbg !296
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_global_avg_pool2d_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %23, align 8
  %3 = getelementptr inbounds %23, %23* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %23, %23* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %23* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.19, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.19(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 63
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 64
  %15 = select i1 %14, i32 %13, i32 64
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 64
  %18 = select i1 %17, i32 %16, i32 64
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv16 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next17, %for_end3 ]
  %24 = trunc i64 %indvars.iv16 to i32
  %25 = shl i32 %24, 5
  %26 = sext i32 %25 to i64
  %27 = trunc i64 %indvars.iv16 to i32
  %28 = mul i32 %27, 1568
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv12 = phi i64 [ 0, %for_body ], [ %indvars.iv.next13, %for_end6 ]
  %29 = add nsw i64 %indvars.iv12, %26
  %30 = getelementptr inbounds float, float* %4, i64 %29
  store float 0.000000e+00, float* %30, align 4, !tbaa !297
  %31 = trunc i64 %indvars.iv12 to i32
  %32 = add i32 %28, %31
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next17 = add nsw i64 %indvars.iv16, 1
  %33 = icmp slt i64 %indvars.iv.next17, %23
  br i1 %33, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %.lcssa11 = phi float [ 0.000000e+00, %for_body2 ], [ %80, %for_body5 ]
  %34 = trunc i64 %indvars.iv to i32
  %35 = mul i32 %34, 224
  %36 = add i32 %32, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds float, float* %7, i64 %37
  %39 = load float, float* %38, align 4, !tbaa !300
  %40 = fdiv float %39, 4.900000e+01
  %41 = fadd float %.lcssa11, %40
  %42 = add i32 %36, 32
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds float, float* %7, i64 %43
  %45 = load float, float* %44, align 4, !tbaa !300
  %46 = fdiv float %45, 4.900000e+01
  %47 = fadd float %41, %46
  %48 = add i32 %36, 64
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = load float, float* %50, align 4, !tbaa !300
  %52 = fdiv float %51, 4.900000e+01
  %53 = fadd float %47, %52
  %54 = add i32 %36, 96
  %55 = sext i32 %54 to i64
  %56 = getelementptr inbounds float, float* %7, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !300
  %58 = fdiv float %57, 4.900000e+01
  %59 = fadd float %53, %58
  %60 = add i32 %36, 128
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = load float, float* %62, align 4, !tbaa !300
  %64 = add i32 %36, 160
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = load float, float* %66, align 4, !tbaa !300
  %68 = insertelement <2 x float> undef, float %63, i32 0
  %69 = insertelement <2 x float> %68, float %67, i32 1
  %70 = fdiv <2 x float> %69, <float 4.900000e+01, float 4.900000e+01>
  %71 = extractelement <2 x float> %70, i32 0
  %72 = fadd float %59, %71
  %73 = extractelement <2 x float> %70, i32 1
  %74 = fadd float %72, %73
  %75 = add i32 %36, 192
  %76 = sext i32 %75 to i64
  %77 = getelementptr inbounds float, float* %7, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !300
  %79 = fdiv float %78, 4.900000e+01
  %80 = fadd float %74, %79
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 7
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store float %80, float* %30, align 4, !tbaa !297
  %indvars.iv.next13 = add nuw nsw i64 %indvars.iv12, 1
  %exitcond14 = icmp eq i64 %indvars.iv.next13, 32
  br i1 %exitcond14, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !303 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !305, metadata !DIExpression()), !dbg !308
  call void @llvm.dbg.value(metadata i8* %1, metadata !306, metadata !DIExpression()), !dbg !308
  call void @llvm.dbg.value(metadata i32 %2, metadata !307, metadata !DIExpression()), !dbg !308
  %3 = bitcast i8* %0 to %1**, !dbg !308
  %4 = load %1*, %1** %3, align 8, !dbg !308
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !308
  %6 = bitcast i8* %5 to %1**, !dbg !308
  %7 = load %1*, %1** %6, align 8, !dbg !308
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !308
  %9 = bitcast i8* %8 to %1**, !dbg !308
  %10 = load %1*, %1** %9, align 8, !dbg !308
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !308
  %12 = bitcast i8* %11 to %1**, !dbg !308
  %13 = load %1*, %1** %12, align 8, !dbg !308
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !308
  %15 = bitcast i8* %14 to %1**, !dbg !308
  %16 = load %1*, %1** %15, align 8, !dbg !308
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !308
  %18 = bitcast i8* %17 to %1**, !dbg !308
  %19 = load %1*, %1** %18, align 8, !dbg !308
  %20 = getelementptr inbounds i8, i8* %0, i64 48, !dbg !308
  %21 = bitcast i8* %20 to %1**, !dbg !308
  %22 = load %1*, %1** %21, align 8, !dbg !308
  %23 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !308
  %24 = load i8*, i8** %23, align 8, !dbg !308
  %25 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !308
  %26 = load i32, i32* %25, align 4, !dbg !308
  %27 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !308
  %28 = load i8*, i8** %27, align 8, !dbg !308
  %29 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !308
  %30 = load i8*, i8** %29, align 8, !dbg !308
  %31 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !308
  %32 = load i8*, i8** %31, align 8, !dbg !308
  %33 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !308
  %34 = load i8*, i8** %33, align 8, !dbg !308
  %35 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !308
  %36 = load i8*, i8** %35, align 8, !dbg !308
  %37 = getelementptr inbounds %1, %1* %22, i64 0, i32 0, !dbg !308
  %38 = load i8*, i8** %37, align 8, !dbg !308
  %39 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2_compute_(i8* %24, i8* %28, i8* %38, i8* %30, i8* %32, i8* %34, i8* %36, i32 %26), !dbg !308
  ret i32 %39, !dbg !308
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %8 = alloca %24, align 8
  %9 = getelementptr inbounds %24, %24* %8, i64 0, i32 0
  store i8* %0, i8** %9, align 8
  %10 = getelementptr inbounds %24, %24* %8, i64 0, i32 1
  store i8* %1, i8** %10, align 8
  %11 = getelementptr inbounds %24, %24* %8, i64 0, i32 2
  store i8* %2, i8** %11, align 8
  %12 = getelementptr inbounds %24, %24* %8, i64 0, i32 3
  store i8* %3, i8** %12, align 8
  %13 = getelementptr inbounds %24, %24* %8, i64 0, i32 4
  store i8* %4, i8** %13, align 8
  %14 = getelementptr inbounds %24, %24* %8, i64 0, i32 5
  store i8* %5, i8** %14, align 8
  %15 = getelementptr inbounds %24, %24* %8, i64 0, i32 6
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %24, %24* %8, i64 0, i32 7
  store i32 %7, i32* %16, align 8
  %17 = bitcast %24* %8 to i8*
  %18 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %19 = call i32 %18(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.20, i8* nonnull %17, i32 0)
  ret i32 %19
}

define private i32 @__tvm_parallel_lambda.20(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds i8, i8* %2, i64 56
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 447
  %29 = sdiv i32 %28, %27
  %30 = add nsw i32 %0, 1
  %31 = mul nsw i32 %29, %30
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = mul nsw i32 %29, %0
  %35 = icmp slt i32 %34, 448
  %36 = select i1 %35, i32 %34, i32 448
  %37 = icmp slt i32 %36, %33
  br i1 %37, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end12
  %38 = phi i32 [ %390, %for_end12 ], [ %36, %for_body.preheader ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %40 = tail call i8* %39(i32 1, i32 %25, i64 3584, i32 2, i32 32)
  %41 = bitcast i8* %40 to float*
  %42 = srem i32 %38, 28
  %43 = mul nsw i32 %42, 112
  %44 = sdiv i32 %38, 28
  %45 = shl i32 %44, 12
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end12, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv49 = phi i64 [ 0, %for_body ], [ %indvars.iv.next50, %for_end6 ]
  %48 = mul nuw nsw i64 %indvars.iv49, 224
  %49 = getelementptr inbounds float, float* %41, i64 %48
  %50 = bitcast float* %49 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %50, align 64, !tbaa !309
  %51 = add nuw nsw i64 %48, 32
  %52 = getelementptr inbounds float, float* %41, i64 %51
  %53 = bitcast float* %52 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %53, align 64, !tbaa !309
  %54 = add nuw nsw i64 %48, 64
  %55 = getelementptr inbounds float, float* %41, i64 %54
  %56 = bitcast float* %55 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %56, align 64, !tbaa !309
  %57 = add nuw nsw i64 %48, 96
  %58 = getelementptr inbounds float, float* %41, i64 %57
  %59 = bitcast float* %58 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %59, align 64, !tbaa !309
  %60 = add nuw nsw i64 %48, 128
  %61 = getelementptr inbounds float, float* %41, i64 %60
  %62 = bitcast float* %61 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %62, align 64, !tbaa !309
  %63 = add nuw nsw i64 %48, 160
  %64 = getelementptr inbounds float, float* %41, i64 %63
  %65 = bitcast float* %64 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %65, align 64, !tbaa !309
  %66 = add nuw nsw i64 %48, 192
  %67 = getelementptr inbounds float, float* %41, i64 %66
  %68 = bitcast float* %67 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %68, align 64, !tbaa !309
  %69 = mul nuw nsw i64 %indvars.iv49, 28
  %70 = add nsw i64 %69, %47
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %71 = mul nsw i32 %38, 896
  %72 = shl nsw i32 %44, 5
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %13, i64 %73
  %75 = bitcast float* %74 to <32 x float>*
  %76 = load <32 x float>, <32 x float>* %75, align 64, !tbaa !312
  %77 = getelementptr inbounds float, float* %16, i64 %73
  %78 = bitcast float* %77 to <32 x float>*
  %79 = load <32 x float>, <32 x float>* %78, align 64, !tbaa !315
  %80 = getelementptr inbounds float, float* %19, i64 %73
  %81 = bitcast float* %80 to <32 x float>*
  %82 = load <32 x float>, <32 x float>* %81, align 64, !tbaa !318
  br label %for_body11

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %.lcssa2942 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %268, %for_body5 ]
  %.lcssa2740 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %262, %for_body5 ]
  %.lcssa2538 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %256, %for_body5 ]
  %.lcssa2336 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %250, %for_body5 ]
  %.lcssa2134 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %244, %for_body5 ]
  %.lcssa1932 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %238, %for_body5 ]
  %.lcssa31 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %232, %for_body5 ]
  %83 = mul nuw nsw i64 %indvars.iv, 3136
  %84 = add nsw i64 %70, %83
  %85 = shl i64 %indvars.iv, 7
  %86 = add nuw nsw i64 %85, %46
  %87 = getelementptr inbounds float, float* %4, i64 %84
  %88 = load float, float* %87, align 4, !tbaa !321
  %89 = insertelement <32 x float> undef, float %88, i32 0
  %90 = shufflevector <32 x float> %89, <32 x float> undef, <32 x i32> zeroinitializer
  %91 = getelementptr inbounds float, float* %7, i64 %86
  %92 = bitcast float* %91 to <32 x float>*
  %93 = load <32 x float>, <32 x float>* %92, align 64, !tbaa !324
  %94 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %90, <32 x float> %93, <32 x float> %.lcssa31)
  %95 = add nsw i64 %84, 4
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !321
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %93, <32 x float> %.lcssa1932)
  %101 = add nsw i64 %84, 8
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !321
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %93, <32 x float> %.lcssa2134)
  %107 = add nsw i64 %84, 12
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !321
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %93, <32 x float> %.lcssa2336)
  %113 = add nsw i64 %84, 16
  %114 = getelementptr inbounds float, float* %4, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !321
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %93, <32 x float> %.lcssa2538)
  %119 = add nsw i64 %84, 20
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !321
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %93, <32 x float> %.lcssa2740)
  %125 = add nsw i64 %84, 24
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !321
  %128 = insertelement <32 x float> undef, float %127, i32 0
  %129 = shufflevector <32 x float> %128, <32 x float> undef, <32 x i32> zeroinitializer
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %93, <32 x float> %.lcssa2942)
  %131 = or i64 %84, 1
  %132 = getelementptr inbounds float, float* %4, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !321
  %134 = insertelement <32 x float> undef, float %133, i32 0
  %135 = shufflevector <32 x float> %134, <32 x float> undef, <32 x i32> zeroinitializer
  %136 = or i64 %86, 32
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = bitcast float* %137 to <32 x float>*
  %139 = load <32 x float>, <32 x float>* %138, align 64, !tbaa !324
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %135, <32 x float> %139, <32 x float> %94)
  %141 = add nsw i64 %131, 4
  %142 = getelementptr inbounds float, float* %4, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !321
  %144 = insertelement <32 x float> undef, float %143, i32 0
  %145 = shufflevector <32 x float> %144, <32 x float> undef, <32 x i32> zeroinitializer
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %145, <32 x float> %139, <32 x float> %100)
  %147 = add nsw i64 %131, 8
  %148 = getelementptr inbounds float, float* %4, i64 %147
  %149 = load float, float* %148, align 4, !tbaa !321
  %150 = insertelement <32 x float> undef, float %149, i32 0
  %151 = shufflevector <32 x float> %150, <32 x float> undef, <32 x i32> zeroinitializer
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %151, <32 x float> %139, <32 x float> %106)
  %153 = add nsw i64 %131, 12
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !321
  %156 = insertelement <32 x float> undef, float %155, i32 0
  %157 = shufflevector <32 x float> %156, <32 x float> undef, <32 x i32> zeroinitializer
  %158 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %157, <32 x float> %139, <32 x float> %112)
  %159 = add nsw i64 %131, 16
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !321
  %162 = insertelement <32 x float> undef, float %161, i32 0
  %163 = shufflevector <32 x float> %162, <32 x float> undef, <32 x i32> zeroinitializer
  %164 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %163, <32 x float> %139, <32 x float> %118)
  %165 = add nsw i64 %131, 20
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !321
  %168 = insertelement <32 x float> undef, float %167, i32 0
  %169 = shufflevector <32 x float> %168, <32 x float> undef, <32 x i32> zeroinitializer
  %170 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %169, <32 x float> %139, <32 x float> %124)
  %171 = add nsw i64 %131, 24
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !321
  %174 = insertelement <32 x float> undef, float %173, i32 0
  %175 = shufflevector <32 x float> %174, <32 x float> undef, <32 x i32> zeroinitializer
  %176 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %175, <32 x float> %139, <32 x float> %130)
  %177 = or i64 %84, 2
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !321
  %180 = insertelement <32 x float> undef, float %179, i32 0
  %181 = shufflevector <32 x float> %180, <32 x float> undef, <32 x i32> zeroinitializer
  %182 = or i64 %86, 64
  %183 = getelementptr inbounds float, float* %7, i64 %182
  %184 = bitcast float* %183 to <32 x float>*
  %185 = load <32 x float>, <32 x float>* %184, align 64, !tbaa !324
  %186 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %181, <32 x float> %185, <32 x float> %140)
  %187 = add nsw i64 %177, 4
  %188 = getelementptr inbounds float, float* %4, i64 %187
  %189 = load float, float* %188, align 4, !tbaa !321
  %190 = insertelement <32 x float> undef, float %189, i32 0
  %191 = shufflevector <32 x float> %190, <32 x float> undef, <32 x i32> zeroinitializer
  %192 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %191, <32 x float> %185, <32 x float> %146)
  %193 = add nsw i64 %177, 8
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = load float, float* %194, align 4, !tbaa !321
  %196 = insertelement <32 x float> undef, float %195, i32 0
  %197 = shufflevector <32 x float> %196, <32 x float> undef, <32 x i32> zeroinitializer
  %198 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %197, <32 x float> %185, <32 x float> %152)
  %199 = add nsw i64 %177, 12
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !321
  %202 = insertelement <32 x float> undef, float %201, i32 0
  %203 = shufflevector <32 x float> %202, <32 x float> undef, <32 x i32> zeroinitializer
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %203, <32 x float> %185, <32 x float> %158)
  %205 = add nsw i64 %177, 16
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !321
  %208 = insertelement <32 x float> undef, float %207, i32 0
  %209 = shufflevector <32 x float> %208, <32 x float> undef, <32 x i32> zeroinitializer
  %210 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %209, <32 x float> %185, <32 x float> %164)
  %211 = add nsw i64 %177, 20
  %212 = getelementptr inbounds float, float* %4, i64 %211
  %213 = load float, float* %212, align 4, !tbaa !321
  %214 = insertelement <32 x float> undef, float %213, i32 0
  %215 = shufflevector <32 x float> %214, <32 x float> undef, <32 x i32> zeroinitializer
  %216 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %215, <32 x float> %185, <32 x float> %170)
  %217 = add nsw i64 %177, 24
  %218 = getelementptr inbounds float, float* %4, i64 %217
  %219 = load float, float* %218, align 4, !tbaa !321
  %220 = insertelement <32 x float> undef, float %219, i32 0
  %221 = shufflevector <32 x float> %220, <32 x float> undef, <32 x i32> zeroinitializer
  %222 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %221, <32 x float> %185, <32 x float> %176)
  %223 = or i64 %84, 3
  %224 = getelementptr inbounds float, float* %4, i64 %223
  %225 = load float, float* %224, align 4, !tbaa !321
  %226 = insertelement <32 x float> undef, float %225, i32 0
  %227 = shufflevector <32 x float> %226, <32 x float> undef, <32 x i32> zeroinitializer
  %228 = or i64 %86, 96
  %229 = getelementptr inbounds float, float* %7, i64 %228
  %230 = bitcast float* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !324
  %232 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %227, <32 x float> %231, <32 x float> %186)
  %233 = add nsw i64 %223, 4
  %234 = getelementptr inbounds float, float* %4, i64 %233
  %235 = load float, float* %234, align 4, !tbaa !321
  %236 = insertelement <32 x float> undef, float %235, i32 0
  %237 = shufflevector <32 x float> %236, <32 x float> undef, <32 x i32> zeroinitializer
  %238 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %237, <32 x float> %231, <32 x float> %192)
  %239 = add nsw i64 %223, 8
  %240 = getelementptr inbounds float, float* %4, i64 %239
  %241 = load float, float* %240, align 4, !tbaa !321
  %242 = insertelement <32 x float> undef, float %241, i32 0
  %243 = shufflevector <32 x float> %242, <32 x float> undef, <32 x i32> zeroinitializer
  %244 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %243, <32 x float> %231, <32 x float> %198)
  %245 = add nsw i64 %223, 12
  %246 = getelementptr inbounds float, float* %4, i64 %245
  %247 = load float, float* %246, align 4, !tbaa !321
  %248 = insertelement <32 x float> undef, float %247, i32 0
  %249 = shufflevector <32 x float> %248, <32 x float> undef, <32 x i32> zeroinitializer
  %250 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %249, <32 x float> %231, <32 x float> %204)
  %251 = add nsw i64 %223, 16
  %252 = getelementptr inbounds float, float* %4, i64 %251
  %253 = load float, float* %252, align 4, !tbaa !321
  %254 = insertelement <32 x float> undef, float %253, i32 0
  %255 = shufflevector <32 x float> %254, <32 x float> undef, <32 x i32> zeroinitializer
  %256 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %255, <32 x float> %231, <32 x float> %210)
  %257 = add nsw i64 %223, 20
  %258 = getelementptr inbounds float, float* %4, i64 %257
  %259 = load float, float* %258, align 4, !tbaa !321
  %260 = insertelement <32 x float> undef, float %259, i32 0
  %261 = shufflevector <32 x float> %260, <32 x float> undef, <32 x i32> zeroinitializer
  %262 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %261, <32 x float> %231, <32 x float> %216)
  %263 = add nsw i64 %223, 24
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !321
  %266 = insertelement <32 x float> undef, float %265, i32 0
  %267 = shufflevector <32 x float> %266, <32 x float> undef, <32 x i32> zeroinitializer
  %268 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %267, <32 x float> %231, <32 x float> %222)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 32
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <32 x float> %232, <32 x float>* %50, align 64, !tbaa !309
  store <32 x float> %238, <32 x float>* %53, align 64, !tbaa !309
  store <32 x float> %244, <32 x float>* %56, align 64, !tbaa !309
  store <32 x float> %250, <32 x float>* %59, align 64, !tbaa !309
  store <32 x float> %256, <32 x float>* %62, align 64, !tbaa !309
  store <32 x float> %262, <32 x float>* %65, align 64, !tbaa !309
  store <32 x float> %268, <32 x float>* %68, align 64, !tbaa !309
  %indvars.iv.next50 = add nuw nsw i64 %indvars.iv49, 1
  %exitcond51 = icmp eq i64 %indvars.iv.next50, 4
  br i1 %exitcond51, label %for_end3, label %for_body2, !prof !29

for_body11:                                       ; preds = %for_body11, %for_end3
  %indvars.iv55 = phi i64 [ 0, %for_end3 ], [ %indvars.iv.next56, %for_body11 ]
  %269 = mul nuw nsw i64 %indvars.iv55, 224
  %270 = trunc i64 %269 to i32
  %271 = add i32 %71, %270
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds float, float* %22, i64 %272
  %274 = bitcast float* %273 to <32 x float>*
  %275 = load <32 x float>, <32 x float>* %274, align 64, !tbaa !327
  %276 = getelementptr inbounds float, float* %41, i64 %269
  %277 = bitcast float* %276 to <32 x float>*
  %278 = load <32 x float>, <32 x float>* %277, align 64, !tbaa !309
  %279 = fadd <32 x float> %76, %278
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %279, <32 x float> %79, <32 x float> %82)
  %281 = fadd <32 x float> %275, %280
  %282 = fcmp ogt <32 x float> %281, zeroinitializer
  %283 = select <32 x i1> %282, <32 x float> %281, <32 x float> zeroinitializer
  %284 = getelementptr inbounds float, float* %10, i64 %272
  %285 = bitcast float* %284 to <32 x float>*
  store <32 x float> %283, <32 x float>* %285, align 64, !tbaa !330
  %286 = add nuw nsw i64 %269, 32
  %287 = trunc i64 %286 to i32
  %288 = add i32 %71, %287
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds float, float* %22, i64 %289
  %291 = bitcast float* %290 to <32 x float>*
  %292 = load <32 x float>, <32 x float>* %291, align 64, !tbaa !327
  %293 = getelementptr inbounds float, float* %41, i64 %286
  %294 = bitcast float* %293 to <32 x float>*
  %295 = load <32 x float>, <32 x float>* %294, align 64, !tbaa !309
  %296 = fadd <32 x float> %76, %295
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %296, <32 x float> %79, <32 x float> %82)
  %298 = fadd <32 x float> %292, %297
  %299 = fcmp ogt <32 x float> %298, zeroinitializer
  %300 = select <32 x i1> %299, <32 x float> %298, <32 x float> zeroinitializer
  %301 = getelementptr inbounds float, float* %10, i64 %289
  %302 = bitcast float* %301 to <32 x float>*
  store <32 x float> %300, <32 x float>* %302, align 64, !tbaa !330
  %303 = add nuw nsw i64 %269, 64
  %304 = trunc i64 %303 to i32
  %305 = add i32 %71, %304
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds float, float* %22, i64 %306
  %308 = bitcast float* %307 to <32 x float>*
  %309 = load <32 x float>, <32 x float>* %308, align 64, !tbaa !327
  %310 = getelementptr inbounds float, float* %41, i64 %303
  %311 = bitcast float* %310 to <32 x float>*
  %312 = load <32 x float>, <32 x float>* %311, align 64, !tbaa !309
  %313 = fadd <32 x float> %76, %312
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %313, <32 x float> %79, <32 x float> %82)
  %315 = fadd <32 x float> %309, %314
  %316 = fcmp ogt <32 x float> %315, zeroinitializer
  %317 = select <32 x i1> %316, <32 x float> %315, <32 x float> zeroinitializer
  %318 = getelementptr inbounds float, float* %10, i64 %306
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %317, <32 x float>* %319, align 64, !tbaa !330
  %320 = add nuw nsw i64 %269, 96
  %321 = trunc i64 %320 to i32
  %322 = add i32 %71, %321
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds float, float* %22, i64 %323
  %325 = bitcast float* %324 to <32 x float>*
  %326 = load <32 x float>, <32 x float>* %325, align 64, !tbaa !327
  %327 = getelementptr inbounds float, float* %41, i64 %320
  %328 = bitcast float* %327 to <32 x float>*
  %329 = load <32 x float>, <32 x float>* %328, align 64, !tbaa !309
  %330 = fadd <32 x float> %76, %329
  %331 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %330, <32 x float> %79, <32 x float> %82)
  %332 = fadd <32 x float> %326, %331
  %333 = fcmp ogt <32 x float> %332, zeroinitializer
  %334 = select <32 x i1> %333, <32 x float> %332, <32 x float> zeroinitializer
  %335 = getelementptr inbounds float, float* %10, i64 %323
  %336 = bitcast float* %335 to <32 x float>*
  store <32 x float> %334, <32 x float>* %336, align 64, !tbaa !330
  %337 = add nuw nsw i64 %269, 128
  %338 = trunc i64 %337 to i32
  %339 = add i32 %71, %338
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds float, float* %22, i64 %340
  %342 = bitcast float* %341 to <32 x float>*
  %343 = load <32 x float>, <32 x float>* %342, align 64, !tbaa !327
  %344 = getelementptr inbounds float, float* %41, i64 %337
  %345 = bitcast float* %344 to <32 x float>*
  %346 = load <32 x float>, <32 x float>* %345, align 64, !tbaa !309
  %347 = fadd <32 x float> %76, %346
  %348 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %347, <32 x float> %79, <32 x float> %82)
  %349 = fadd <32 x float> %343, %348
  %350 = fcmp ogt <32 x float> %349, zeroinitializer
  %351 = select <32 x i1> %350, <32 x float> %349, <32 x float> zeroinitializer
  %352 = getelementptr inbounds float, float* %10, i64 %340
  %353 = bitcast float* %352 to <32 x float>*
  store <32 x float> %351, <32 x float>* %353, align 64, !tbaa !330
  %354 = add nuw nsw i64 %269, 160
  %355 = trunc i64 %354 to i32
  %356 = add i32 %71, %355
  %357 = sext i32 %356 to i64
  %358 = getelementptr inbounds float, float* %22, i64 %357
  %359 = bitcast float* %358 to <32 x float>*
  %360 = load <32 x float>, <32 x float>* %359, align 64, !tbaa !327
  %361 = getelementptr inbounds float, float* %41, i64 %354
  %362 = bitcast float* %361 to <32 x float>*
  %363 = load <32 x float>, <32 x float>* %362, align 64, !tbaa !309
  %364 = fadd <32 x float> %76, %363
  %365 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %364, <32 x float> %79, <32 x float> %82)
  %366 = fadd <32 x float> %360, %365
  %367 = fcmp ogt <32 x float> %366, zeroinitializer
  %368 = select <32 x i1> %367, <32 x float> %366, <32 x float> zeroinitializer
  %369 = getelementptr inbounds float, float* %10, i64 %357
  %370 = bitcast float* %369 to <32 x float>*
  store <32 x float> %368, <32 x float>* %370, align 64, !tbaa !330
  %371 = add nuw nsw i64 %269, 192
  %372 = trunc i64 %371 to i32
  %373 = add i32 %71, %372
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds float, float* %22, i64 %374
  %376 = bitcast float* %375 to <32 x float>*
  %377 = load <32 x float>, <32 x float>* %376, align 64, !tbaa !327
  %378 = getelementptr inbounds float, float* %41, i64 %371
  %379 = bitcast float* %378 to <32 x float>*
  %380 = load <32 x float>, <32 x float>* %379, align 64, !tbaa !309
  %381 = fadd <32 x float> %76, %380
  %382 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %79, <32 x float> %82)
  %383 = fadd <32 x float> %377, %382
  %384 = fcmp ogt <32 x float> %383, zeroinitializer
  %385 = select <32 x i1> %384, <32 x float> %383, <32 x float> zeroinitializer
  %386 = getelementptr inbounds float, float* %10, i64 %374
  %387 = bitcast float* %386 to <32 x float>*
  store <32 x float> %385, <32 x float>* %387, align 64, !tbaa !330
  %indvars.iv.next56 = add nuw nsw i64 %indvars.iv55, 1
  %exitcond57 = icmp eq i64 %indvars.iv.next56, 4
  br i1 %exitcond57, label %for_end12, label %for_body11, !prof !29

for_end12:                                        ; preds = %for_body11
  %388 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %389 = tail call i32 %388(i32 1, i32 %25, i8* nonnull %40)
  %390 = add nsw i32 %38, 1
  %391 = icmp slt i32 %390, %33
  br i1 %391, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !333 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !335, metadata !DIExpression()), !dbg !338
  call void @llvm.dbg.value(metadata i8* %1, metadata !336, metadata !DIExpression()), !dbg !338
  call void @llvm.dbg.value(metadata i32 %2, metadata !337, metadata !DIExpression()), !dbg !338
  %3 = bitcast i8* %0 to %1**, !dbg !338
  %4 = load %1*, %1** %3, align 8, !dbg !338
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !338
  %6 = bitcast i8* %5 to %1**, !dbg !338
  %7 = load %1*, %1** %6, align 8, !dbg !338
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !338
  %9 = bitcast i8* %8 to %1**, !dbg !338
  %10 = load %1*, %1** %9, align 8, !dbg !338
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !338
  %12 = bitcast i8* %11 to %1**, !dbg !338
  %13 = load %1*, %1** %12, align 8, !dbg !338
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !338
  %15 = bitcast i8* %14 to %1**, !dbg !338
  %16 = load %1*, %1** %15, align 8, !dbg !338
  %17 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !338
  %18 = load i8*, i8** %17, align 8, !dbg !338
  %19 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !338
  %20 = load i32, i32* %19, align 4, !dbg !338
  %21 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !338
  %22 = load i8*, i8** %21, align 8, !dbg !338
  %23 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !338
  %24 = load i8*, i8** %23, align 8, !dbg !338
  %25 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !338
  %26 = load i8*, i8** %25, align 8, !dbg !338
  %27 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !338
  %28 = load i8*, i8** %27, align 8, !dbg !338
  %29 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2_compute_(i8* %18, i8* %22, i8* %28, i8* %24, i8* %26, i32 %20), !dbg !338
  ret i32 %29, !dbg !338
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %25, align 8
  %7 = getelementptr inbounds %25, %25* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %25, %25* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %25, %25* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %25, %25* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %25, %25* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %25, %25* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %25* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.21, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.21(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 27
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 28
  %27 = select i1 %26, i32 %25, i32 28
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 28
  %30 = select i1 %29, i32 %28, i32 28
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv53 = phi i64 [ %34, %for_body.lr.ph ], [ %indvars.iv.next54, %for_end3 ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %37 = tail call i8* %36(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %38 = bitcast i8* %37 to float*
  %39 = trunc i64 %indvars.iv53 to i32
  %40 = srem i32 %39, 7
  %41 = mul nsw i32 %40, 14336
  %42 = sdiv i32 %39, 7
  %43 = shl i32 %42, 16
  %44 = sext i32 %43 to i64
  %45 = sext i32 %41 to i64
  %46 = or i64 %44, 32768
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end9.1, %for_body
  %indvars.iv40 = phi i64 [ 0, %for_body ], [ %indvars.iv.next41, %for_end9.1 ]
  %47 = shl nsw i64 %indvars.iv40, 7
  %48 = getelementptr inbounds float, float* %38, i64 %47
  %49 = bitcast float* %48 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %49, align 64, !tbaa !339
  %50 = or i64 %47, 64
  %51 = getelementptr inbounds float, float* %38, i64 %50
  %52 = bitcast float* %51 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %52, align 64, !tbaa !339
  %53 = add nuw nsw i64 %47, 896
  %54 = getelementptr inbounds float, float* %38, i64 %53
  %55 = bitcast float* %54 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %55, align 64, !tbaa !339
  %56 = add nuw nsw i64 %47, 960
  %57 = getelementptr inbounds float, float* %38, i64 %56
  %58 = bitcast float* %57 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %58, align 64, !tbaa !339
  %59 = shl i64 %indvars.iv40, 10
  %60 = add nsw i64 %59, %45
  br label %for_body8

for_end3:                                         ; preds = %for_end9.1
  %61 = mul nsw i64 %indvars.iv53, 1792
  %62 = shl nsw i32 %42, 6
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %16, i64 %63
  %65 = bitcast float* %64 to <64 x float>*
  %66 = load <64 x float>, <64 x float>* %65, align 64, !tbaa !342
  %67 = getelementptr inbounds float, float* %13, i64 %63
  %68 = bitcast float* %67 to <64 x float>*
  %69 = load <64 x float>, <64 x float>* %68, align 64, !tbaa !345
  %70 = bitcast i8* %37 to <64 x float>*
  %71 = load <64 x float>, <64 x float>* %70, align 64, !tbaa !339
  %72 = fadd <64 x float> %69, %71
  %73 = fadd <64 x float> %66, %72
  %74 = fcmp ogt <64 x float> %73, zeroinitializer
  %75 = select <64 x i1> %74, <64 x float> %73, <64 x float> zeroinitializer
  %76 = getelementptr inbounds float, float* %10, i64 %61
  %77 = bitcast float* %76 to <64 x float>*
  store <64 x float> %75, <64 x float>* %77, align 64, !tbaa !348
  %78 = getelementptr inbounds i8, i8* %37, i64 256
  %79 = bitcast i8* %78 to <64 x float>*
  %80 = load <64 x float>, <64 x float>* %79, align 64, !tbaa !339
  %81 = fadd <64 x float> %69, %80
  %82 = fadd <64 x float> %66, %81
  %83 = fcmp ogt <64 x float> %82, zeroinitializer
  %84 = select <64 x i1> %83, <64 x float> %82, <64 x float> zeroinitializer
  %85 = mul i64 %indvars.iv53, 7696581394432
  %sext = ashr exact i64 %85, 32
  %86 = or i64 %sext, 64
  %87 = getelementptr inbounds float, float* %10, i64 %86
  %88 = bitcast float* %87 to <64 x float>*
  store <64 x float> %84, <64 x float>* %88, align 64, !tbaa !348
  %89 = getelementptr inbounds i8, i8* %37, i64 3584
  %90 = bitcast i8* %89 to <64 x float>*
  %91 = load <64 x float>, <64 x float>* %90, align 64, !tbaa !339
  %92 = fadd <64 x float> %69, %91
  %93 = fadd <64 x float> %66, %92
  %94 = fcmp ogt <64 x float> %93, zeroinitializer
  %95 = select <64 x i1> %94, <64 x float> %93, <64 x float> zeroinitializer
  %96 = mul i64 %indvars.iv53, 7696581394432
  %sext68 = add i64 %96, 3848290697216
  %97 = ashr exact i64 %sext68, 32
  %98 = getelementptr inbounds float, float* %10, i64 %97
  %99 = bitcast float* %98 to <64 x float>*
  store <64 x float> %95, <64 x float>* %99, align 64, !tbaa !348
  %100 = getelementptr inbounds i8, i8* %37, i64 3840
  %101 = bitcast i8* %100 to <64 x float>*
  %102 = load <64 x float>, <64 x float>* %101, align 64, !tbaa !339
  %103 = fadd <64 x float> %69, %102
  %104 = fadd <64 x float> %66, %103
  %105 = fcmp ogt <64 x float> %104, zeroinitializer
  %106 = select <64 x i1> %105, <64 x float> %104, <64 x float> zeroinitializer
  %107 = mul i64 %indvars.iv53, 7696581394432
  %sext55 = add i64 %107, 4123168604160
  %108 = ashr exact i64 %sext55, 32
  %109 = getelementptr inbounds float, float* %10, i64 %108
  %110 = bitcast float* %109 to <64 x float>*
  store <64 x float> %106, <64 x float>* %110, align 64, !tbaa !348
  %111 = getelementptr inbounds i8, i8* %37, i64 512
  %112 = bitcast i8* %111 to <64 x float>*
  %113 = load <64 x float>, <64 x float>* %112, align 64, !tbaa !339
  %114 = fadd <64 x float> %69, %113
  %115 = fadd <64 x float> %66, %114
  %116 = fcmp ogt <64 x float> %115, zeroinitializer
  %117 = select <64 x i1> %116, <64 x float> %115, <64 x float> zeroinitializer
  %118 = mul i64 %indvars.iv53, 7696581394432
  %sext69 = ashr exact i64 %118, 32
  %119 = or i64 %sext69, 128
  %120 = getelementptr inbounds float, float* %10, i64 %119
  %121 = bitcast float* %120 to <64 x float>*
  store <64 x float> %117, <64 x float>* %121, align 64, !tbaa !348
  %122 = getelementptr inbounds i8, i8* %37, i64 768
  %123 = bitcast i8* %122 to <64 x float>*
  %124 = load <64 x float>, <64 x float>* %123, align 64, !tbaa !339
  %125 = fadd <64 x float> %69, %124
  %126 = fadd <64 x float> %66, %125
  %127 = fcmp ogt <64 x float> %126, zeroinitializer
  %128 = select <64 x i1> %127, <64 x float> %126, <64 x float> zeroinitializer
  %129 = mul i64 %indvars.iv53, 7696581394432
  %sext56 = ashr exact i64 %129, 32
  %130 = or i64 %sext56, 192
  %131 = getelementptr inbounds float, float* %10, i64 %130
  %132 = bitcast float* %131 to <64 x float>*
  store <64 x float> %128, <64 x float>* %132, align 64, !tbaa !348
  %133 = getelementptr inbounds i8, i8* %37, i64 4096
  %134 = bitcast i8* %133 to <64 x float>*
  %135 = load <64 x float>, <64 x float>* %134, align 64, !tbaa !339
  %136 = fadd <64 x float> %69, %135
  %137 = fadd <64 x float> %66, %136
  %138 = fcmp ogt <64 x float> %137, zeroinitializer
  %139 = select <64 x i1> %138, <64 x float> %137, <64 x float> zeroinitializer
  %140 = mul i64 %indvars.iv53, 7696581394432
  %sext70 = add i64 %140, 4398046511104
  %141 = ashr exact i64 %sext70, 32
  %142 = getelementptr inbounds float, float* %10, i64 %141
  %143 = bitcast float* %142 to <64 x float>*
  store <64 x float> %139, <64 x float>* %143, align 64, !tbaa !348
  %144 = getelementptr inbounds i8, i8* %37, i64 4352
  %145 = bitcast i8* %144 to <64 x float>*
  %146 = load <64 x float>, <64 x float>* %145, align 64, !tbaa !339
  %147 = fadd <64 x float> %69, %146
  %148 = fadd <64 x float> %66, %147
  %149 = fcmp ogt <64 x float> %148, zeroinitializer
  %150 = select <64 x i1> %149, <64 x float> %148, <64 x float> zeroinitializer
  %151 = mul i64 %indvars.iv53, 7696581394432
  %sext57 = add i64 %151, 4672924418048
  %152 = ashr exact i64 %sext57, 32
  %153 = getelementptr inbounds float, float* %10, i64 %152
  %154 = bitcast float* %153 to <64 x float>*
  store <64 x float> %150, <64 x float>* %154, align 64, !tbaa !348
  %155 = getelementptr inbounds i8, i8* %37, i64 1024
  %156 = bitcast i8* %155 to <64 x float>*
  %157 = load <64 x float>, <64 x float>* %156, align 64, !tbaa !339
  %158 = fadd <64 x float> %69, %157
  %159 = fadd <64 x float> %66, %158
  %160 = fcmp ogt <64 x float> %159, zeroinitializer
  %161 = select <64 x i1> %160, <64 x float> %159, <64 x float> zeroinitializer
  %162 = mul i64 %indvars.iv53, 7696581394432
  %sext71 = add i64 %162, 1099511627776
  %163 = ashr exact i64 %sext71, 32
  %164 = getelementptr inbounds float, float* %10, i64 %163
  %165 = bitcast float* %164 to <64 x float>*
  store <64 x float> %161, <64 x float>* %165, align 64, !tbaa !348
  %166 = getelementptr inbounds i8, i8* %37, i64 1280
  %167 = bitcast i8* %166 to <64 x float>*
  %168 = load <64 x float>, <64 x float>* %167, align 64, !tbaa !339
  %169 = fadd <64 x float> %69, %168
  %170 = fadd <64 x float> %66, %169
  %171 = fcmp ogt <64 x float> %170, zeroinitializer
  %172 = select <64 x i1> %171, <64 x float> %170, <64 x float> zeroinitializer
  %173 = mul i64 %indvars.iv53, 7696581394432
  %sext58 = add i64 %173, 1374389534720
  %174 = ashr exact i64 %sext58, 32
  %175 = getelementptr inbounds float, float* %10, i64 %174
  %176 = bitcast float* %175 to <64 x float>*
  store <64 x float> %172, <64 x float>* %176, align 64, !tbaa !348
  %177 = getelementptr inbounds i8, i8* %37, i64 4608
  %178 = bitcast i8* %177 to <64 x float>*
  %179 = load <64 x float>, <64 x float>* %178, align 64, !tbaa !339
  %180 = fadd <64 x float> %69, %179
  %181 = fadd <64 x float> %66, %180
  %182 = fcmp ogt <64 x float> %181, zeroinitializer
  %183 = select <64 x i1> %182, <64 x float> %181, <64 x float> zeroinitializer
  %184 = mul i64 %indvars.iv53, 7696581394432
  %sext72 = add i64 %184, 4947802324992
  %185 = ashr exact i64 %sext72, 32
  %186 = getelementptr inbounds float, float* %10, i64 %185
  %187 = bitcast float* %186 to <64 x float>*
  store <64 x float> %183, <64 x float>* %187, align 64, !tbaa !348
  %188 = getelementptr inbounds i8, i8* %37, i64 4864
  %189 = bitcast i8* %188 to <64 x float>*
  %190 = load <64 x float>, <64 x float>* %189, align 64, !tbaa !339
  %191 = fadd <64 x float> %69, %190
  %192 = fadd <64 x float> %66, %191
  %193 = fcmp ogt <64 x float> %192, zeroinitializer
  %194 = select <64 x i1> %193, <64 x float> %192, <64 x float> zeroinitializer
  %195 = mul i64 %indvars.iv53, 7696581394432
  %sext59 = add i64 %195, 5222680231936
  %196 = ashr exact i64 %sext59, 32
  %197 = getelementptr inbounds float, float* %10, i64 %196
  %198 = bitcast float* %197 to <64 x float>*
  store <64 x float> %194, <64 x float>* %198, align 64, !tbaa !348
  %199 = getelementptr inbounds i8, i8* %37, i64 1536
  %200 = bitcast i8* %199 to <64 x float>*
  %201 = load <64 x float>, <64 x float>* %200, align 64, !tbaa !339
  %202 = fadd <64 x float> %69, %201
  %203 = fadd <64 x float> %66, %202
  %204 = fcmp ogt <64 x float> %203, zeroinitializer
  %205 = select <64 x i1> %204, <64 x float> %203, <64 x float> zeroinitializer
  %206 = mul i64 %indvars.iv53, 7696581394432
  %sext73 = add i64 %206, 1649267441664
  %207 = ashr exact i64 %sext73, 32
  %208 = getelementptr inbounds float, float* %10, i64 %207
  %209 = bitcast float* %208 to <64 x float>*
  store <64 x float> %205, <64 x float>* %209, align 64, !tbaa !348
  %210 = getelementptr inbounds i8, i8* %37, i64 1792
  %211 = bitcast i8* %210 to <64 x float>*
  %212 = load <64 x float>, <64 x float>* %211, align 64, !tbaa !339
  %213 = fadd <64 x float> %69, %212
  %214 = fadd <64 x float> %66, %213
  %215 = fcmp ogt <64 x float> %214, zeroinitializer
  %216 = select <64 x i1> %215, <64 x float> %214, <64 x float> zeroinitializer
  %217 = mul i64 %indvars.iv53, 7696581394432
  %sext60 = add i64 %217, 1924145348608
  %218 = ashr exact i64 %sext60, 32
  %219 = getelementptr inbounds float, float* %10, i64 %218
  %220 = bitcast float* %219 to <64 x float>*
  store <64 x float> %216, <64 x float>* %220, align 64, !tbaa !348
  %221 = getelementptr inbounds i8, i8* %37, i64 5120
  %222 = bitcast i8* %221 to <64 x float>*
  %223 = load <64 x float>, <64 x float>* %222, align 64, !tbaa !339
  %224 = fadd <64 x float> %69, %223
  %225 = fadd <64 x float> %66, %224
  %226 = fcmp ogt <64 x float> %225, zeroinitializer
  %227 = select <64 x i1> %226, <64 x float> %225, <64 x float> zeroinitializer
  %228 = mul i64 %indvars.iv53, 7696581394432
  %sext74 = add i64 %228, 5497558138880
  %229 = ashr exact i64 %sext74, 32
  %230 = getelementptr inbounds float, float* %10, i64 %229
  %231 = bitcast float* %230 to <64 x float>*
  store <64 x float> %227, <64 x float>* %231, align 64, !tbaa !348
  %232 = getelementptr inbounds i8, i8* %37, i64 5376
  %233 = bitcast i8* %232 to <64 x float>*
  %234 = load <64 x float>, <64 x float>* %233, align 64, !tbaa !339
  %235 = fadd <64 x float> %69, %234
  %236 = fadd <64 x float> %66, %235
  %237 = fcmp ogt <64 x float> %236, zeroinitializer
  %238 = select <64 x i1> %237, <64 x float> %236, <64 x float> zeroinitializer
  %239 = mul i64 %indvars.iv53, 7696581394432
  %sext61 = add i64 %239, 5772436045824
  %240 = ashr exact i64 %sext61, 32
  %241 = getelementptr inbounds float, float* %10, i64 %240
  %242 = bitcast float* %241 to <64 x float>*
  store <64 x float> %238, <64 x float>* %242, align 64, !tbaa !348
  %243 = getelementptr inbounds i8, i8* %37, i64 2048
  %244 = bitcast i8* %243 to <64 x float>*
  %245 = load <64 x float>, <64 x float>* %244, align 64, !tbaa !339
  %246 = fadd <64 x float> %69, %245
  %247 = fadd <64 x float> %66, %246
  %248 = fcmp ogt <64 x float> %247, zeroinitializer
  %249 = select <64 x i1> %248, <64 x float> %247, <64 x float> zeroinitializer
  %250 = mul i64 %indvars.iv53, 7696581394432
  %sext75 = add i64 %250, 2199023255552
  %251 = ashr exact i64 %sext75, 32
  %252 = getelementptr inbounds float, float* %10, i64 %251
  %253 = bitcast float* %252 to <64 x float>*
  store <64 x float> %249, <64 x float>* %253, align 64, !tbaa !348
  %254 = getelementptr inbounds i8, i8* %37, i64 2304
  %255 = bitcast i8* %254 to <64 x float>*
  %256 = load <64 x float>, <64 x float>* %255, align 64, !tbaa !339
  %257 = fadd <64 x float> %69, %256
  %258 = fadd <64 x float> %66, %257
  %259 = fcmp ogt <64 x float> %258, zeroinitializer
  %260 = select <64 x i1> %259, <64 x float> %258, <64 x float> zeroinitializer
  %261 = mul i64 %indvars.iv53, 7696581394432
  %sext62 = add i64 %261, 2473901162496
  %262 = ashr exact i64 %sext62, 32
  %263 = getelementptr inbounds float, float* %10, i64 %262
  %264 = bitcast float* %263 to <64 x float>*
  store <64 x float> %260, <64 x float>* %264, align 64, !tbaa !348
  %265 = getelementptr inbounds i8, i8* %37, i64 5632
  %266 = bitcast i8* %265 to <64 x float>*
  %267 = load <64 x float>, <64 x float>* %266, align 64, !tbaa !339
  %268 = fadd <64 x float> %69, %267
  %269 = fadd <64 x float> %66, %268
  %270 = fcmp ogt <64 x float> %269, zeroinitializer
  %271 = select <64 x i1> %270, <64 x float> %269, <64 x float> zeroinitializer
  %272 = mul i64 %indvars.iv53, 7696581394432
  %sext76 = add i64 %272, 6047313952768
  %273 = ashr exact i64 %sext76, 32
  %274 = getelementptr inbounds float, float* %10, i64 %273
  %275 = bitcast float* %274 to <64 x float>*
  store <64 x float> %271, <64 x float>* %275, align 64, !tbaa !348
  %276 = getelementptr inbounds i8, i8* %37, i64 5888
  %277 = bitcast i8* %276 to <64 x float>*
  %278 = load <64 x float>, <64 x float>* %277, align 64, !tbaa !339
  %279 = fadd <64 x float> %69, %278
  %280 = fadd <64 x float> %66, %279
  %281 = fcmp ogt <64 x float> %280, zeroinitializer
  %282 = select <64 x i1> %281, <64 x float> %280, <64 x float> zeroinitializer
  %283 = mul i64 %indvars.iv53, 7696581394432
  %sext63 = add i64 %283, 6322191859712
  %284 = ashr exact i64 %sext63, 32
  %285 = getelementptr inbounds float, float* %10, i64 %284
  %286 = bitcast float* %285 to <64 x float>*
  store <64 x float> %282, <64 x float>* %286, align 64, !tbaa !348
  %287 = getelementptr inbounds i8, i8* %37, i64 2560
  %288 = bitcast i8* %287 to <64 x float>*
  %289 = load <64 x float>, <64 x float>* %288, align 64, !tbaa !339
  %290 = fadd <64 x float> %69, %289
  %291 = fadd <64 x float> %66, %290
  %292 = fcmp ogt <64 x float> %291, zeroinitializer
  %293 = select <64 x i1> %292, <64 x float> %291, <64 x float> zeroinitializer
  %294 = mul i64 %indvars.iv53, 7696581394432
  %sext77 = add i64 %294, 2748779069440
  %295 = ashr exact i64 %sext77, 32
  %296 = getelementptr inbounds float, float* %10, i64 %295
  %297 = bitcast float* %296 to <64 x float>*
  store <64 x float> %293, <64 x float>* %297, align 64, !tbaa !348
  %298 = getelementptr inbounds i8, i8* %37, i64 2816
  %299 = bitcast i8* %298 to <64 x float>*
  %300 = load <64 x float>, <64 x float>* %299, align 64, !tbaa !339
  %301 = fadd <64 x float> %69, %300
  %302 = fadd <64 x float> %66, %301
  %303 = fcmp ogt <64 x float> %302, zeroinitializer
  %304 = select <64 x i1> %303, <64 x float> %302, <64 x float> zeroinitializer
  %305 = mul i64 %indvars.iv53, 7696581394432
  %sext64 = add i64 %305, 3023656976384
  %306 = ashr exact i64 %sext64, 32
  %307 = getelementptr inbounds float, float* %10, i64 %306
  %308 = bitcast float* %307 to <64 x float>*
  store <64 x float> %304, <64 x float>* %308, align 64, !tbaa !348
  %309 = getelementptr inbounds i8, i8* %37, i64 6144
  %310 = bitcast i8* %309 to <64 x float>*
  %311 = load <64 x float>, <64 x float>* %310, align 64, !tbaa !339
  %312 = fadd <64 x float> %69, %311
  %313 = fadd <64 x float> %66, %312
  %314 = fcmp ogt <64 x float> %313, zeroinitializer
  %315 = select <64 x i1> %314, <64 x float> %313, <64 x float> zeroinitializer
  %316 = mul i64 %indvars.iv53, 7696581394432
  %sext78 = add i64 %316, 6597069766656
  %317 = ashr exact i64 %sext78, 32
  %318 = getelementptr inbounds float, float* %10, i64 %317
  %319 = bitcast float* %318 to <64 x float>*
  store <64 x float> %315, <64 x float>* %319, align 64, !tbaa !348
  %320 = getelementptr inbounds i8, i8* %37, i64 6400
  %321 = bitcast i8* %320 to <64 x float>*
  %322 = load <64 x float>, <64 x float>* %321, align 64, !tbaa !339
  %323 = fadd <64 x float> %69, %322
  %324 = fadd <64 x float> %66, %323
  %325 = fcmp ogt <64 x float> %324, zeroinitializer
  %326 = select <64 x i1> %325, <64 x float> %324, <64 x float> zeroinitializer
  %327 = mul i64 %indvars.iv53, 7696581394432
  %sext65 = add i64 %327, 6871947673600
  %328 = ashr exact i64 %sext65, 32
  %329 = getelementptr inbounds float, float* %10, i64 %328
  %330 = bitcast float* %329 to <64 x float>*
  store <64 x float> %326, <64 x float>* %330, align 64, !tbaa !348
  %331 = getelementptr inbounds i8, i8* %37, i64 3072
  %332 = bitcast i8* %331 to <64 x float>*
  %333 = load <64 x float>, <64 x float>* %332, align 64, !tbaa !339
  %334 = fadd <64 x float> %69, %333
  %335 = fadd <64 x float> %66, %334
  %336 = fcmp ogt <64 x float> %335, zeroinitializer
  %337 = select <64 x i1> %336, <64 x float> %335, <64 x float> zeroinitializer
  %338 = mul i64 %indvars.iv53, 7696581394432
  %sext79 = add i64 %338, 3298534883328
  %339 = ashr exact i64 %sext79, 32
  %340 = getelementptr inbounds float, float* %10, i64 %339
  %341 = bitcast float* %340 to <64 x float>*
  store <64 x float> %337, <64 x float>* %341, align 64, !tbaa !348
  %342 = getelementptr inbounds i8, i8* %37, i64 3328
  %343 = bitcast i8* %342 to <64 x float>*
  %344 = load <64 x float>, <64 x float>* %343, align 64, !tbaa !339
  %345 = fadd <64 x float> %69, %344
  %346 = fadd <64 x float> %66, %345
  %347 = fcmp ogt <64 x float> %346, zeroinitializer
  %348 = select <64 x i1> %347, <64 x float> %346, <64 x float> zeroinitializer
  %349 = mul i64 %indvars.iv53, 7696581394432
  %sext66 = add i64 %349, 3573412790272
  %350 = ashr exact i64 %sext66, 32
  %351 = getelementptr inbounds float, float* %10, i64 %350
  %352 = bitcast float* %351 to <64 x float>*
  store <64 x float> %348, <64 x float>* %352, align 64, !tbaa !348
  %353 = getelementptr inbounds i8, i8* %37, i64 6656
  %354 = bitcast i8* %353 to <64 x float>*
  %355 = load <64 x float>, <64 x float>* %354, align 64, !tbaa !339
  %356 = fadd <64 x float> %69, %355
  %357 = fadd <64 x float> %66, %356
  %358 = fcmp ogt <64 x float> %357, zeroinitializer
  %359 = select <64 x i1> %358, <64 x float> %357, <64 x float> zeroinitializer
  %360 = mul i64 %indvars.iv53, 7696581394432
  %sext80 = add i64 %360, 7146825580544
  %361 = ashr exact i64 %sext80, 32
  %362 = getelementptr inbounds float, float* %10, i64 %361
  %363 = bitcast float* %362 to <64 x float>*
  store <64 x float> %359, <64 x float>* %363, align 64, !tbaa !348
  %364 = getelementptr inbounds i8, i8* %37, i64 6912
  %365 = bitcast i8* %364 to <64 x float>*
  %366 = load <64 x float>, <64 x float>* %365, align 64, !tbaa !339
  %367 = fadd <64 x float> %69, %366
  %368 = fadd <64 x float> %66, %367
  %369 = fcmp ogt <64 x float> %368, zeroinitializer
  %370 = select <64 x i1> %369, <64 x float> %368, <64 x float> zeroinitializer
  %371 = mul i64 %indvars.iv53, 7696581394432
  %sext67 = add i64 %371, 7421703487488
  %372 = ashr exact i64 %sext67, 32
  %373 = getelementptr inbounds float, float* %10, i64 %372
  %374 = bitcast float* %373 to <64 x float>*
  store <64 x float> %370, <64 x float>* %374, align 64, !tbaa !348
  %375 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %376 = tail call i32 %375(i32 1, i32 %19, i8* nonnull %37)
  %indvars.iv.next54 = add nsw i64 %indvars.iv53, 1
  %377 = icmp slt i64 %indvars.iv.next54, %35
  br i1 %377, label %for_body, label %for_end, !prof !19

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %378 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %410, %for_body8 ]
  %379 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %404, %for_body8 ]
  %380 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %398, %for_body8 ]
  %381 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %392, %for_body8 ]
  %382 = add nsw i64 %60, %indvars.iv
  %383 = getelementptr inbounds float, float* %4, i64 %382
  %384 = load float, float* %383, align 4, !tbaa !351
  %385 = insertelement <64 x float> undef, float %384, i32 0
  %386 = shufflevector <64 x float> %385, <64 x float> undef, <64 x i32> zeroinitializer
  %387 = shl i64 %indvars.iv, 6
  %388 = add nsw i64 %387, %44
  %389 = getelementptr inbounds float, float* %7, i64 %388
  %390 = bitcast float* %389 to <64 x float>*
  %391 = load <64 x float>, <64 x float>* %390, align 64, !tbaa !354
  %392 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %386, <64 x float> %391, <64 x float> %381)
  %393 = add nsw i64 %382, 512
  %394 = getelementptr inbounds float, float* %4, i64 %393
  %395 = load float, float* %394, align 4, !tbaa !351
  %396 = insertelement <64 x float> undef, float %395, i32 0
  %397 = shufflevector <64 x float> %396, <64 x float> undef, <64 x i32> zeroinitializer
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %397, <64 x float> %391, <64 x float> %380)
  %399 = add nsw i64 %382, 7168
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = load float, float* %400, align 4, !tbaa !351
  %402 = insertelement <64 x float> undef, float %401, i32 0
  %403 = shufflevector <64 x float> %402, <64 x float> undef, <64 x i32> zeroinitializer
  %404 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %403, <64 x float> %391, <64 x float> %379)
  %405 = add nsw i64 %382, 7680
  %406 = getelementptr inbounds float, float* %4, i64 %405
  %407 = load float, float* %406, align 4, !tbaa !351
  %408 = insertelement <64 x float> undef, float %407, i32 0
  %409 = shufflevector <64 x float> %408, <64 x float> undef, <64 x i32> zeroinitializer
  %410 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %409, <64 x float> %391, <64 x float> %378)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %411 = add nsw i64 %60, 100352
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %412 = phi <64 x float> [ %410, %for_end9 ], [ %444, %for_body8.1 ]
  %413 = phi <64 x float> [ %404, %for_end9 ], [ %438, %for_body8.1 ]
  %414 = phi <64 x float> [ %398, %for_end9 ], [ %432, %for_body8.1 ]
  %415 = phi <64 x float> [ %392, %for_end9 ], [ %426, %for_body8.1 ]
  %416 = add nsw i64 %411, %indvars.iv.1
  %417 = getelementptr inbounds float, float* %4, i64 %416
  %418 = load float, float* %417, align 4, !tbaa !351
  %419 = insertelement <64 x float> undef, float %418, i32 0
  %420 = shufflevector <64 x float> %419, <64 x float> undef, <64 x i32> zeroinitializer
  %421 = shl i64 %indvars.iv.1, 6
  %422 = add nsw i64 %46, %421
  %423 = getelementptr inbounds float, float* %7, i64 %422
  %424 = bitcast float* %423 to <64 x float>*
  %425 = load <64 x float>, <64 x float>* %424, align 64, !tbaa !354
  %426 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %420, <64 x float> %425, <64 x float> %415)
  %427 = add nsw i64 %416, 512
  %428 = getelementptr inbounds float, float* %4, i64 %427
  %429 = load float, float* %428, align 4, !tbaa !351
  %430 = insertelement <64 x float> undef, float %429, i32 0
  %431 = shufflevector <64 x float> %430, <64 x float> undef, <64 x i32> zeroinitializer
  %432 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %431, <64 x float> %425, <64 x float> %414)
  %433 = add nsw i64 %416, 7168
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !351
  %436 = insertelement <64 x float> undef, float %435, i32 0
  %437 = shufflevector <64 x float> %436, <64 x float> undef, <64 x i32> zeroinitializer
  %438 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %437, <64 x float> %425, <64 x float> %413)
  %439 = add nsw i64 %416, 7680
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = load float, float* %440, align 4, !tbaa !351
  %442 = insertelement <64 x float> undef, float %441, i32 0
  %443 = shufflevector <64 x float> %442, <64 x float> undef, <64 x i32> zeroinitializer
  %444 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %443, <64 x float> %425, <64 x float> %412)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !29

for_end9.1:                                       ; preds = %for_body8.1
  store <64 x float> %426, <64 x float>* %49, align 64, !tbaa !339
  store <64 x float> %432, <64 x float>* %52, align 64, !tbaa !339
  store <64 x float> %438, <64 x float>* %55, align 64, !tbaa !339
  store <64 x float> %444, <64 x float>* %58, align 64, !tbaa !339
  %indvars.iv.next41 = add nuw nsw i64 %indvars.iv40, 1
  %exitcond42 = icmp eq i64 %indvars.iv.next41, 7
  br i1 %exitcond42, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_dense_add(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !357 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !359, metadata !DIExpression()), !dbg !362
  call void @llvm.dbg.value(metadata i8* %1, metadata !360, metadata !DIExpression()), !dbg !362
  call void @llvm.dbg.value(metadata i32 %2, metadata !361, metadata !DIExpression()), !dbg !362
  %3 = bitcast i8* %0 to %1**, !dbg !362
  %4 = load %1*, %1** %3, align 8, !dbg !362
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !362
  %6 = bitcast i8* %5 to %1**, !dbg !362
  %7 = load %1*, %1** %6, align 8, !dbg !362
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !362
  %9 = bitcast i8* %8 to %1**, !dbg !362
  %10 = load %1*, %1** %9, align 8, !dbg !362
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !362
  %12 = bitcast i8* %11 to %1**, !dbg !362
  %13 = load %1*, %1** %12, align 8, !dbg !362
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !362
  %15 = load i8*, i8** %14, align 8, !dbg !362
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !362
  %17 = load i32, i32* %16, align 4, !dbg !362
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !362
  %19 = load i8*, i8** %18, align 8, !dbg !362
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !362
  %21 = load i8*, i8** %20, align 8, !dbg !362
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !362
  %23 = load i8*, i8** %22, align 8, !dbg !362
  %24 = tail call fastcc i32 @fused_nn_dense_add_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !362
  ret i32 %24, !dbg !362
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_dense_add_compute_(i8* noalias, i8* noalias, i8* noalias nocapture, i8* noalias nocapture readonly, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %6 = tail call i8* %5(i32 1, i32 %4, i64 4000, i32 2, i32 32)
  %7 = alloca %26, align 8
  %8 = getelementptr inbounds %26, %26* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %26, %26* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %26, %26* %7, i64 0, i32 2
  store i8* %6, i8** %10, align 8
  %11 = bitcast %26* %7 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.22, i8* nonnull %11, i32 0)
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %call_end, label %call_fail, !prof !19

call_fail:                                        ; preds = %for_end, %entry
  %merge = phi i32 [ %13, %entry ], [ 0, %for_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %15 = bitcast i8* %3 to float*
  %16 = bitcast i8* %6 to float*
  %17 = bitcast i8* %2 to float*
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %call_end
  %index = phi i64 [ 0, %call_end ], [ %index.next, %vector.body ]
  %18 = getelementptr inbounds float, float* %15, i64 %index
  %19 = bitcast float* %18 to <4 x float>*
  %wide.load = load <4 x float>, <4 x float>* %19, align 4, !tbaa !363
  %20 = getelementptr float, float* %18, i64 4
  %21 = bitcast float* %20 to <4 x float>*
  %wide.load4 = load <4 x float>, <4 x float>* %21, align 4, !tbaa !363
  %22 = getelementptr inbounds float, float* %16, i64 %index
  %23 = bitcast float* %22 to <4 x float>*
  %wide.load5 = load <4 x float>, <4 x float>* %23, align 4, !tbaa !366
  %24 = getelementptr float, float* %22, i64 4
  %25 = bitcast float* %24 to <4 x float>*
  %wide.load6 = load <4 x float>, <4 x float>* %25, align 4, !tbaa !366
  %26 = fadd <4 x float> %wide.load, %wide.load5
  %27 = fadd <4 x float> %wide.load4, %wide.load6
  %28 = getelementptr inbounds float, float* %17, i64 %index
  %29 = bitcast float* %28 to <4 x float>*
  store <4 x float> %26, <4 x float>* %29, align 4, !tbaa !369
  %30 = getelementptr float, float* %28, i64 4
  %31 = bitcast float* %30 to <4 x float>*
  store <4 x float> %27, <4 x float>* %31, align 4, !tbaa !369
  %index.next = add i64 %index, 8
  %32 = icmp eq i64 %index.next, 1000
  br i1 %32, label %for_end, label %vector.body, !llvm.loop !372

for_end:                                          ; preds = %vector.body
  %33 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %34 = call i32 %33(i32 1, i32 %4, i8* nonnull %6)
  br label %call_fail
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.22(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = add nsw i32 %12, 999
  %14 = sdiv i32 %13, %12
  %15 = add nsw i32 %0, 1
  %16 = mul nsw i32 %14, %15
  %17 = icmp slt i32 %16, 1000
  %18 = select i1 %17, i32 %16, i32 1000
  %19 = mul nsw i32 %14, %0
  %20 = icmp slt i32 %19, 1000
  %21 = select i1 %20, i32 %19, i32 1000
  %22 = icmp slt i32 %21, %18
  br i1 %22, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %23 = add i32 %21, 1
  %24 = sext i32 %23 to i64
  %25 = add nsw i64 %24, -1
  %26 = sext i32 %18 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv6 = phi i64 [ %25, %for_body.lr.ph ], [ %indvars.iv.next7, %for_end3 ]
  %27 = trunc i64 %indvars.iv6 to i32
  %28 = shl i32 %27, 11
  %29 = sext i32 %28 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %.05 = phi <16 x float> [ zeroinitializer, %for_body ], [ %38, %for_body2 ]
  %30 = shl nsw i64 %indvars.iv, 4
  %31 = getelementptr inbounds float, float* %4, i64 %30
  %32 = bitcast float* %31 to <16 x float>*
  %33 = load <16 x float>, <16 x float>* %32, align 64, !tbaa !373
  %34 = add nsw i64 %30, %29
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to <16 x float>*
  %37 = load <16 x float>, <16 x float>* %36, align 64, !tbaa !376
  %38 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %33, <16 x float> %37, <16 x float> %.05)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %39 = getelementptr inbounds float, float* %10, i64 %indvars.iv6
  %.0.vec.extract = extractelement <16 x float> %38, i32 0
  %40 = fadd float %.0.vec.extract, 0.000000e+00
  %.4.vec.extract = extractelement <16 x float> %38, i32 1
  %41 = fadd float %.4.vec.extract, %40
  %.8.vec.extract = extractelement <16 x float> %38, i32 2
  %42 = fadd float %.8.vec.extract, %41
  %.12.vec.extract = extractelement <16 x float> %38, i32 3
  %43 = fadd float %.12.vec.extract, %42
  %.16.vec.extract = extractelement <16 x float> %38, i32 4
  %44 = fadd float %.16.vec.extract, %43
  %.20.vec.extract = extractelement <16 x float> %38, i32 5
  %45 = fadd float %.20.vec.extract, %44
  %.24.vec.extract = extractelement <16 x float> %38, i32 6
  %46 = fadd float %.24.vec.extract, %45
  %.28.vec.extract = extractelement <16 x float> %38, i32 7
  %47 = fadd float %.28.vec.extract, %46
  %.32.vec.extract = extractelement <16 x float> %38, i32 8
  %48 = fadd float %.32.vec.extract, %47
  %.36.vec.extract = extractelement <16 x float> %38, i32 9
  %49 = fadd float %.36.vec.extract, %48
  %.40.vec.extract = extractelement <16 x float> %38, i32 10
  %50 = fadd float %.40.vec.extract, %49
  %.44.vec.extract = extractelement <16 x float> %38, i32 11
  %51 = fadd float %.44.vec.extract, %50
  %.48.vec.extract = extractelement <16 x float> %38, i32 12
  %52 = fadd float %.48.vec.extract, %51
  %.52.vec.extract = extractelement <16 x float> %38, i32 13
  %53 = fadd float %.52.vec.extract, %52
  %.56.vec.extract = extractelement <16 x float> %38, i32 14
  %54 = fadd float %.56.vec.extract, %53
  %.60.vec.extract = extractelement <16 x float> %38, i32 15
  %55 = fadd float %.60.vec.extract, %54
  store float %55, float* %39, align 4, !tbaa !366
  %indvars.iv.next7 = add nsw i64 %indvars.iv6, 1
  %56 = icmp slt i64 %indvars.iv.next7, %26
  br i1 %56, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !379 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !381, metadata !DIExpression()), !dbg !384
  call void @llvm.dbg.value(metadata i8* %1, metadata !382, metadata !DIExpression()), !dbg !384
  call void @llvm.dbg.value(metadata i32 %2, metadata !383, metadata !DIExpression()), !dbg !384
  %3 = bitcast i8* %0 to %1**, !dbg !384
  %4 = load %1*, %1** %3, align 8, !dbg !384
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !384
  %6 = bitcast i8* %5 to %1**, !dbg !384
  %7 = load %1*, %1** %6, align 8, !dbg !384
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !384
  %9 = bitcast i8* %8 to %1**, !dbg !384
  %10 = load %1*, %1** %9, align 8, !dbg !384
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !384
  %12 = bitcast i8* %11 to %1**, !dbg !384
  %13 = load %1*, %1** %12, align 8, !dbg !384
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !384
  %15 = bitcast i8* %14 to %1**, !dbg !384
  %16 = load %1*, %1** %15, align 8, !dbg !384
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !384
  %18 = bitcast i8* %17 to %1**, !dbg !384
  %19 = load %1*, %1** %18, align 8, !dbg !384
  %20 = getelementptr inbounds i8, i8* %0, i64 48, !dbg !384
  %21 = bitcast i8* %20 to %1**, !dbg !384
  %22 = load %1*, %1** %21, align 8, !dbg !384
  %23 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !384
  %24 = load i8*, i8** %23, align 8, !dbg !384
  %25 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !384
  %26 = load i32, i32* %25, align 4, !dbg !384
  %27 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !384
  %28 = load i8*, i8** %27, align 8, !dbg !384
  %29 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !384
  %30 = load i8*, i8** %29, align 8, !dbg !384
  %31 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !384
  %32 = load i8*, i8** %31, align 8, !dbg !384
  %33 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !384
  %34 = load i8*, i8** %33, align 8, !dbg !384
  %35 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !384
  %36 = load i8*, i8** %35, align 8, !dbg !384
  %37 = getelementptr inbounds %1, %1* %22, i64 0, i32 0, !dbg !384
  %38 = load i8*, i8** %37, align 8, !dbg !384
  %39 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1_compute_(i8* %24, i8* %28, i8* %38, i8* %30, i8* %32, i8* %34, i8* %36, i32 %26), !dbg !384
  ret i32 %39, !dbg !384
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %8 = alloca %27, align 8
  %9 = getelementptr inbounds %27, %27* %8, i64 0, i32 0
  store i8* %0, i8** %9, align 8
  %10 = getelementptr inbounds %27, %27* %8, i64 0, i32 1
  store i8* %1, i8** %10, align 8
  %11 = getelementptr inbounds %27, %27* %8, i64 0, i32 2
  store i8* %2, i8** %11, align 8
  %12 = getelementptr inbounds %27, %27* %8, i64 0, i32 3
  store i8* %3, i8** %12, align 8
  %13 = getelementptr inbounds %27, %27* %8, i64 0, i32 4
  store i8* %4, i8** %13, align 8
  %14 = getelementptr inbounds %27, %27* %8, i64 0, i32 5
  store i8* %5, i8** %14, align 8
  %15 = getelementptr inbounds %27, %27* %8, i64 0, i32 6
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %27, %27* %8, i64 0, i32 7
  store i32 %7, i32* %16, align 8
  %17 = bitcast %27* %8 to i8*
  %18 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %19 = call i32 %18(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.23, i8* nonnull %17, i32 0)
  ret i32 %19
}

define private i32 @__tvm_parallel_lambda.23(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds i8, i8* %2, i64 56
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 111
  %29 = sdiv i32 %28, %27
  %30 = add nsw i32 %0, 1
  %31 = mul nsw i32 %29, %30
  %32 = icmp slt i32 %31, 112
  %33 = select i1 %32, i32 %31, i32 112
  %34 = mul nsw i32 %29, %0
  %35 = icmp slt i32 %34, 112
  %36 = select i1 %35, i32 %34, i32 112
  %37 = icmp slt i32 %36, %33
  br i1 %37, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end9
  %38 = phi i32 [ %165, %for_end9 ], [ %36, %for_body.preheader ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %40 = tail call i8* %39(i32 1, i32 %25, i64 7168, i32 2, i32 32)
  %41 = bitcast i8* %40 to float*
  %42 = srem i32 %38, 7
  %43 = mul nsw i32 %42, 7168
  %44 = sdiv i32 %38, 7
  %45 = shl i32 %44, 14
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  %48 = bitcast i8* %40 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %48, align 64, !tbaa !385
  %49 = getelementptr inbounds i8, i8* %40, i64 256
  %50 = bitcast i8* %49 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %50, align 64, !tbaa !385
  %51 = getelementptr inbounds i8, i8* %40, i64 3584
  %52 = bitcast i8* %51 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %52, align 64, !tbaa !385
  %53 = getelementptr inbounds i8, i8* %40, i64 3840
  %54 = bitcast i8* %53 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %54, align 64, !tbaa !385
  br label %for_body5

for_end:                                          ; preds = %for_end9, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %55 = phi <64 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %56 = phi <64 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %57 = phi <64 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %58 = phi <64 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %59 = add nsw i64 %indvars.iv, %47
  %60 = getelementptr inbounds float, float* %4, i64 %59
  %61 = load float, float* %60, align 4, !tbaa !388
  %62 = insertelement <64 x float> undef, float %61, i32 0
  %63 = shufflevector <64 x float> %62, <64 x float> undef, <64 x i32> zeroinitializer
  %64 = shl i64 %indvars.iv, 6
  %65 = add nuw nsw i64 %64, %46
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <64 x float>*
  %68 = load <64 x float>, <64 x float>* %67, align 64, !tbaa !391
  %69 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %63, <64 x float> %68, <64 x float> %58)
  %70 = add nsw i64 %59, 256
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !388
  %73 = insertelement <64 x float> undef, float %72, i32 0
  %74 = shufflevector <64 x float> %73, <64 x float> undef, <64 x i32> zeroinitializer
  %75 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %74, <64 x float> %68, <64 x float> %57)
  %76 = add nsw i64 %59, 3584
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !388
  %79 = insertelement <64 x float> undef, float %78, i32 0
  %80 = shufflevector <64 x float> %79, <64 x float> undef, <64 x i32> zeroinitializer
  %81 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %80, <64 x float> %68, <64 x float> %56)
  %82 = add nsw i64 %59, 3840
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !388
  %85 = insertelement <64 x float> undef, float %84, i32 0
  %86 = shufflevector <64 x float> %85, <64 x float> undef, <64 x i32> zeroinitializer
  %87 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %86, <64 x float> %68, <64 x float> %55)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <64 x float> %69, <64 x float>* %48, align 64, !tbaa !385
  store <64 x float> %75, <64 x float>* %50, align 64, !tbaa !385
  store <64 x float> %81, <64 x float>* %52, align 64, !tbaa !385
  store <64 x float> %87, <64 x float>* %54, align 64, !tbaa !385
  %88 = getelementptr inbounds i8, i8* %40, i64 512
  %89 = bitcast i8* %88 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %89, align 64, !tbaa !385
  %90 = getelementptr inbounds i8, i8* %40, i64 768
  %91 = bitcast i8* %90 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %91, align 64, !tbaa !385
  %92 = getelementptr inbounds i8, i8* %40, i64 4096
  %93 = bitcast i8* %92 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %93, align 64, !tbaa !385
  %94 = getelementptr inbounds i8, i8* %40, i64 4352
  %95 = bitcast i8* %94 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %95, align 64, !tbaa !385
  %96 = or i64 %47, 512
  br label %for_body5.1

for_body8:                                        ; preds = %for_body8, %for_end6.6
  %indvars.iv36 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next37, %for_body8 ]
  %97 = shl nsw i64 %indvars.iv36, 7
  %98 = trunc i64 %97 to i32
  %99 = add i32 %410, %98
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds float, float* %22, i64 %100
  %102 = bitcast float* %101 to <64 x float>*
  %103 = load <64 x float>, <64 x float>* %102, align 64, !tbaa !394
  %104 = getelementptr inbounds float, float* %41, i64 %97
  %105 = bitcast float* %104 to <64 x float>*
  %106 = load <64 x float>, <64 x float>* %105, align 64, !tbaa !385
  %107 = fadd <64 x float> %415, %106
  %108 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %107, <64 x float> %418, <64 x float> %421)
  %109 = fadd <64 x float> %103, %108
  %110 = fcmp ogt <64 x float> %109, zeroinitializer
  %111 = select <64 x i1> %110, <64 x float> %109, <64 x float> zeroinitializer
  %112 = getelementptr inbounds float, float* %10, i64 %100
  %113 = bitcast float* %112 to <64 x float>*
  store <64 x float> %111, <64 x float>* %113, align 64, !tbaa !397
  %114 = or i32 %99, 64
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds float, float* %22, i64 %115
  %117 = bitcast float* %116 to <64 x float>*
  %118 = load <64 x float>, <64 x float>* %117, align 64, !tbaa !394
  %119 = or i64 %97, 64
  %120 = getelementptr inbounds float, float* %41, i64 %119
  %121 = bitcast float* %120 to <64 x float>*
  %122 = load <64 x float>, <64 x float>* %121, align 64, !tbaa !385
  %123 = fadd <64 x float> %415, %122
  %124 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %123, <64 x float> %418, <64 x float> %421)
  %125 = fadd <64 x float> %118, %124
  %126 = fcmp ogt <64 x float> %125, zeroinitializer
  %127 = select <64 x i1> %126, <64 x float> %125, <64 x float> zeroinitializer
  %128 = getelementptr inbounds float, float* %10, i64 %115
  %129 = bitcast float* %128 to <64 x float>*
  store <64 x float> %127, <64 x float>* %129, align 64, !tbaa !397
  %130 = add nuw nsw i64 %97, 896
  %131 = trunc i64 %130 to i32
  %132 = add i32 %410, %131
  %133 = sext i32 %132 to i64
  %134 = getelementptr inbounds float, float* %22, i64 %133
  %135 = bitcast float* %134 to <64 x float>*
  %136 = load <64 x float>, <64 x float>* %135, align 64, !tbaa !394
  %137 = getelementptr inbounds float, float* %41, i64 %130
  %138 = bitcast float* %137 to <64 x float>*
  %139 = load <64 x float>, <64 x float>* %138, align 64, !tbaa !385
  %140 = fadd <64 x float> %415, %139
  %141 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %140, <64 x float> %418, <64 x float> %421)
  %142 = fadd <64 x float> %136, %141
  %143 = fcmp ogt <64 x float> %142, zeroinitializer
  %144 = select <64 x i1> %143, <64 x float> %142, <64 x float> zeroinitializer
  %145 = getelementptr inbounds float, float* %10, i64 %133
  %146 = bitcast float* %145 to <64 x float>*
  store <64 x float> %144, <64 x float>* %146, align 64, !tbaa !397
  %147 = or i32 %132, 64
  %148 = sext i32 %147 to i64
  %149 = getelementptr inbounds float, float* %22, i64 %148
  %150 = bitcast float* %149 to <64 x float>*
  %151 = load <64 x float>, <64 x float>* %150, align 64, !tbaa !394
  %152 = add nuw nsw i64 %97, 960
  %153 = getelementptr inbounds float, float* %41, i64 %152
  %154 = bitcast float* %153 to <64 x float>*
  %155 = load <64 x float>, <64 x float>* %154, align 64, !tbaa !385
  %156 = fadd <64 x float> %415, %155
  %157 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %156, <64 x float> %418, <64 x float> %421)
  %158 = fadd <64 x float> %151, %157
  %159 = fcmp ogt <64 x float> %158, zeroinitializer
  %160 = select <64 x i1> %159, <64 x float> %158, <64 x float> zeroinitializer
  %161 = getelementptr inbounds float, float* %10, i64 %148
  %162 = bitcast float* %161 to <64 x float>*
  store <64 x float> %160, <64 x float>* %162, align 64, !tbaa !397
  %indvars.iv.next37 = add nuw nsw i64 %indvars.iv36, 1
  %exitcond38 = icmp eq i64 %indvars.iv.next37, 7
  br i1 %exitcond38, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %163 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %164 = tail call i32 %163(i32 1, i32 %25, i8* nonnull %40)
  %165 = add nsw i32 %38, 1
  %166 = icmp slt i32 %165, %33
  br i1 %166, label %for_body, label %for_end, !prof !19

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %167 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %199, %for_body5.1 ]
  %168 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %193, %for_body5.1 ]
  %169 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %187, %for_body5.1 ]
  %170 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %181, %for_body5.1 ]
  %171 = add nsw i64 %96, %indvars.iv.1
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !388
  %174 = insertelement <64 x float> undef, float %173, i32 0
  %175 = shufflevector <64 x float> %174, <64 x float> undef, <64 x i32> zeroinitializer
  %176 = shl i64 %indvars.iv.1, 6
  %177 = add nuw nsw i64 %176, %46
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <64 x float>*
  %180 = load <64 x float>, <64 x float>* %179, align 64, !tbaa !391
  %181 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %175, <64 x float> %180, <64 x float> %170)
  %182 = add nsw i64 %171, 256
  %183 = getelementptr inbounds float, float* %4, i64 %182
  %184 = load float, float* %183, align 4, !tbaa !388
  %185 = insertelement <64 x float> undef, float %184, i32 0
  %186 = shufflevector <64 x float> %185, <64 x float> undef, <64 x i32> zeroinitializer
  %187 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %186, <64 x float> %180, <64 x float> %169)
  %188 = add nsw i64 %171, 3584
  %189 = getelementptr inbounds float, float* %4, i64 %188
  %190 = load float, float* %189, align 4, !tbaa !388
  %191 = insertelement <64 x float> undef, float %190, i32 0
  %192 = shufflevector <64 x float> %191, <64 x float> undef, <64 x i32> zeroinitializer
  %193 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %192, <64 x float> %180, <64 x float> %168)
  %194 = add nsw i64 %171, 3840
  %195 = getelementptr inbounds float, float* %4, i64 %194
  %196 = load float, float* %195, align 4, !tbaa !388
  %197 = insertelement <64 x float> undef, float %196, i32 0
  %198 = shufflevector <64 x float> %197, <64 x float> undef, <64 x i32> zeroinitializer
  %199 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %198, <64 x float> %180, <64 x float> %167)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %181, <64 x float>* %89, align 64, !tbaa !385
  store <64 x float> %187, <64 x float>* %91, align 64, !tbaa !385
  store <64 x float> %193, <64 x float>* %93, align 64, !tbaa !385
  store <64 x float> %199, <64 x float>* %95, align 64, !tbaa !385
  %200 = getelementptr inbounds i8, i8* %40, i64 1024
  %201 = bitcast i8* %200 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %201, align 64, !tbaa !385
  %202 = getelementptr inbounds i8, i8* %40, i64 1280
  %203 = bitcast i8* %202 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %203, align 64, !tbaa !385
  %204 = getelementptr inbounds i8, i8* %40, i64 4608
  %205 = bitcast i8* %204 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %205, align 64, !tbaa !385
  %206 = getelementptr inbounds i8, i8* %40, i64 4864
  %207 = bitcast i8* %206 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %207, align 64, !tbaa !385
  %208 = add nsw i64 %47, 1024
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %209 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %241, %for_body5.2 ]
  %210 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %235, %for_body5.2 ]
  %211 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %229, %for_body5.2 ]
  %212 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %223, %for_body5.2 ]
  %213 = add nsw i64 %208, %indvars.iv.2
  %214 = getelementptr inbounds float, float* %4, i64 %213
  %215 = load float, float* %214, align 4, !tbaa !388
  %216 = insertelement <64 x float> undef, float %215, i32 0
  %217 = shufflevector <64 x float> %216, <64 x float> undef, <64 x i32> zeroinitializer
  %218 = shl i64 %indvars.iv.2, 6
  %219 = add nuw nsw i64 %218, %46
  %220 = getelementptr inbounds float, float* %7, i64 %219
  %221 = bitcast float* %220 to <64 x float>*
  %222 = load <64 x float>, <64 x float>* %221, align 64, !tbaa !391
  %223 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %217, <64 x float> %222, <64 x float> %212)
  %224 = add nsw i64 %213, 256
  %225 = getelementptr inbounds float, float* %4, i64 %224
  %226 = load float, float* %225, align 4, !tbaa !388
  %227 = insertelement <64 x float> undef, float %226, i32 0
  %228 = shufflevector <64 x float> %227, <64 x float> undef, <64 x i32> zeroinitializer
  %229 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %228, <64 x float> %222, <64 x float> %211)
  %230 = add nsw i64 %213, 3584
  %231 = getelementptr inbounds float, float* %4, i64 %230
  %232 = load float, float* %231, align 4, !tbaa !388
  %233 = insertelement <64 x float> undef, float %232, i32 0
  %234 = shufflevector <64 x float> %233, <64 x float> undef, <64 x i32> zeroinitializer
  %235 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %234, <64 x float> %222, <64 x float> %210)
  %236 = add nsw i64 %213, 3840
  %237 = getelementptr inbounds float, float* %4, i64 %236
  %238 = load float, float* %237, align 4, !tbaa !388
  %239 = insertelement <64 x float> undef, float %238, i32 0
  %240 = shufflevector <64 x float> %239, <64 x float> undef, <64 x i32> zeroinitializer
  %241 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %240, <64 x float> %222, <64 x float> %209)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %223, <64 x float>* %201, align 64, !tbaa !385
  store <64 x float> %229, <64 x float>* %203, align 64, !tbaa !385
  store <64 x float> %235, <64 x float>* %205, align 64, !tbaa !385
  store <64 x float> %241, <64 x float>* %207, align 64, !tbaa !385
  %242 = getelementptr inbounds i8, i8* %40, i64 1536
  %243 = bitcast i8* %242 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %243, align 64, !tbaa !385
  %244 = getelementptr inbounds i8, i8* %40, i64 1792
  %245 = bitcast i8* %244 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %245, align 64, !tbaa !385
  %246 = getelementptr inbounds i8, i8* %40, i64 5120
  %247 = bitcast i8* %246 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %247, align 64, !tbaa !385
  %248 = getelementptr inbounds i8, i8* %40, i64 5376
  %249 = bitcast i8* %248 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %249, align 64, !tbaa !385
  %250 = add nsw i64 %47, 1536
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %251 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %283, %for_body5.3 ]
  %252 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %277, %for_body5.3 ]
  %253 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %271, %for_body5.3 ]
  %254 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %265, %for_body5.3 ]
  %255 = add nsw i64 %250, %indvars.iv.3
  %256 = getelementptr inbounds float, float* %4, i64 %255
  %257 = load float, float* %256, align 4, !tbaa !388
  %258 = insertelement <64 x float> undef, float %257, i32 0
  %259 = shufflevector <64 x float> %258, <64 x float> undef, <64 x i32> zeroinitializer
  %260 = shl i64 %indvars.iv.3, 6
  %261 = add nuw nsw i64 %260, %46
  %262 = getelementptr inbounds float, float* %7, i64 %261
  %263 = bitcast float* %262 to <64 x float>*
  %264 = load <64 x float>, <64 x float>* %263, align 64, !tbaa !391
  %265 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %259, <64 x float> %264, <64 x float> %254)
  %266 = add nsw i64 %255, 256
  %267 = getelementptr inbounds float, float* %4, i64 %266
  %268 = load float, float* %267, align 4, !tbaa !388
  %269 = insertelement <64 x float> undef, float %268, i32 0
  %270 = shufflevector <64 x float> %269, <64 x float> undef, <64 x i32> zeroinitializer
  %271 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %270, <64 x float> %264, <64 x float> %253)
  %272 = add nsw i64 %255, 3584
  %273 = getelementptr inbounds float, float* %4, i64 %272
  %274 = load float, float* %273, align 4, !tbaa !388
  %275 = insertelement <64 x float> undef, float %274, i32 0
  %276 = shufflevector <64 x float> %275, <64 x float> undef, <64 x i32> zeroinitializer
  %277 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %276, <64 x float> %264, <64 x float> %252)
  %278 = add nsw i64 %255, 3840
  %279 = getelementptr inbounds float, float* %4, i64 %278
  %280 = load float, float* %279, align 4, !tbaa !388
  %281 = insertelement <64 x float> undef, float %280, i32 0
  %282 = shufflevector <64 x float> %281, <64 x float> undef, <64 x i32> zeroinitializer
  %283 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %282, <64 x float> %264, <64 x float> %251)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %265, <64 x float>* %243, align 64, !tbaa !385
  store <64 x float> %271, <64 x float>* %245, align 64, !tbaa !385
  store <64 x float> %277, <64 x float>* %247, align 64, !tbaa !385
  store <64 x float> %283, <64 x float>* %249, align 64, !tbaa !385
  %284 = getelementptr inbounds i8, i8* %40, i64 2048
  %285 = bitcast i8* %284 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %285, align 64, !tbaa !385
  %286 = getelementptr inbounds i8, i8* %40, i64 2304
  %287 = bitcast i8* %286 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %287, align 64, !tbaa !385
  %288 = getelementptr inbounds i8, i8* %40, i64 5632
  %289 = bitcast i8* %288 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %289, align 64, !tbaa !385
  %290 = getelementptr inbounds i8, i8* %40, i64 5888
  %291 = bitcast i8* %290 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %291, align 64, !tbaa !385
  %292 = add nsw i64 %47, 2048
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %293 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %325, %for_body5.4 ]
  %294 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %319, %for_body5.4 ]
  %295 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %313, %for_body5.4 ]
  %296 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %307, %for_body5.4 ]
  %297 = add nsw i64 %292, %indvars.iv.4
  %298 = getelementptr inbounds float, float* %4, i64 %297
  %299 = load float, float* %298, align 4, !tbaa !388
  %300 = insertelement <64 x float> undef, float %299, i32 0
  %301 = shufflevector <64 x float> %300, <64 x float> undef, <64 x i32> zeroinitializer
  %302 = shl i64 %indvars.iv.4, 6
  %303 = add nuw nsw i64 %302, %46
  %304 = getelementptr inbounds float, float* %7, i64 %303
  %305 = bitcast float* %304 to <64 x float>*
  %306 = load <64 x float>, <64 x float>* %305, align 64, !tbaa !391
  %307 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %301, <64 x float> %306, <64 x float> %296)
  %308 = add nsw i64 %297, 256
  %309 = getelementptr inbounds float, float* %4, i64 %308
  %310 = load float, float* %309, align 4, !tbaa !388
  %311 = insertelement <64 x float> undef, float %310, i32 0
  %312 = shufflevector <64 x float> %311, <64 x float> undef, <64 x i32> zeroinitializer
  %313 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %312, <64 x float> %306, <64 x float> %295)
  %314 = add nsw i64 %297, 3584
  %315 = getelementptr inbounds float, float* %4, i64 %314
  %316 = load float, float* %315, align 4, !tbaa !388
  %317 = insertelement <64 x float> undef, float %316, i32 0
  %318 = shufflevector <64 x float> %317, <64 x float> undef, <64 x i32> zeroinitializer
  %319 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %318, <64 x float> %306, <64 x float> %294)
  %320 = add nsw i64 %297, 3840
  %321 = getelementptr inbounds float, float* %4, i64 %320
  %322 = load float, float* %321, align 4, !tbaa !388
  %323 = insertelement <64 x float> undef, float %322, i32 0
  %324 = shufflevector <64 x float> %323, <64 x float> undef, <64 x i32> zeroinitializer
  %325 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %324, <64 x float> %306, <64 x float> %293)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 256
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %307, <64 x float>* %285, align 64, !tbaa !385
  store <64 x float> %313, <64 x float>* %287, align 64, !tbaa !385
  store <64 x float> %319, <64 x float>* %289, align 64, !tbaa !385
  store <64 x float> %325, <64 x float>* %291, align 64, !tbaa !385
  %326 = getelementptr inbounds i8, i8* %40, i64 2560
  %327 = bitcast i8* %326 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %327, align 64, !tbaa !385
  %328 = getelementptr inbounds i8, i8* %40, i64 2816
  %329 = bitcast i8* %328 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %329, align 64, !tbaa !385
  %330 = getelementptr inbounds i8, i8* %40, i64 6144
  %331 = bitcast i8* %330 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %331, align 64, !tbaa !385
  %332 = getelementptr inbounds i8, i8* %40, i64 6400
  %333 = bitcast i8* %332 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %333, align 64, !tbaa !385
  %334 = add nsw i64 %47, 2560
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %335 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %367, %for_body5.5 ]
  %336 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %361, %for_body5.5 ]
  %337 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %355, %for_body5.5 ]
  %338 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %349, %for_body5.5 ]
  %339 = add nsw i64 %334, %indvars.iv.5
  %340 = getelementptr inbounds float, float* %4, i64 %339
  %341 = load float, float* %340, align 4, !tbaa !388
  %342 = insertelement <64 x float> undef, float %341, i32 0
  %343 = shufflevector <64 x float> %342, <64 x float> undef, <64 x i32> zeroinitializer
  %344 = shl i64 %indvars.iv.5, 6
  %345 = add nuw nsw i64 %344, %46
  %346 = getelementptr inbounds float, float* %7, i64 %345
  %347 = bitcast float* %346 to <64 x float>*
  %348 = load <64 x float>, <64 x float>* %347, align 64, !tbaa !391
  %349 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %343, <64 x float> %348, <64 x float> %338)
  %350 = add nsw i64 %339, 256
  %351 = getelementptr inbounds float, float* %4, i64 %350
  %352 = load float, float* %351, align 4, !tbaa !388
  %353 = insertelement <64 x float> undef, float %352, i32 0
  %354 = shufflevector <64 x float> %353, <64 x float> undef, <64 x i32> zeroinitializer
  %355 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %354, <64 x float> %348, <64 x float> %337)
  %356 = add nsw i64 %339, 3584
  %357 = getelementptr inbounds float, float* %4, i64 %356
  %358 = load float, float* %357, align 4, !tbaa !388
  %359 = insertelement <64 x float> undef, float %358, i32 0
  %360 = shufflevector <64 x float> %359, <64 x float> undef, <64 x i32> zeroinitializer
  %361 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %360, <64 x float> %348, <64 x float> %336)
  %362 = add nsw i64 %339, 3840
  %363 = getelementptr inbounds float, float* %4, i64 %362
  %364 = load float, float* %363, align 4, !tbaa !388
  %365 = insertelement <64 x float> undef, float %364, i32 0
  %366 = shufflevector <64 x float> %365, <64 x float> undef, <64 x i32> zeroinitializer
  %367 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %366, <64 x float> %348, <64 x float> %335)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 256
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %349, <64 x float>* %327, align 64, !tbaa !385
  store <64 x float> %355, <64 x float>* %329, align 64, !tbaa !385
  store <64 x float> %361, <64 x float>* %331, align 64, !tbaa !385
  store <64 x float> %367, <64 x float>* %333, align 64, !tbaa !385
  %368 = getelementptr inbounds i8, i8* %40, i64 3072
  %369 = bitcast i8* %368 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %369, align 64, !tbaa !385
  %370 = getelementptr inbounds i8, i8* %40, i64 3328
  %371 = bitcast i8* %370 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %371, align 64, !tbaa !385
  %372 = getelementptr inbounds i8, i8* %40, i64 6656
  %373 = bitcast i8* %372 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %373, align 64, !tbaa !385
  %374 = getelementptr inbounds i8, i8* %40, i64 6912
  %375 = bitcast i8* %374 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %375, align 64, !tbaa !385
  %376 = add nsw i64 %47, 3072
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %377 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %409, %for_body5.6 ]
  %378 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %403, %for_body5.6 ]
  %379 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %397, %for_body5.6 ]
  %380 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %391, %for_body5.6 ]
  %381 = add nsw i64 %376, %indvars.iv.6
  %382 = getelementptr inbounds float, float* %4, i64 %381
  %383 = load float, float* %382, align 4, !tbaa !388
  %384 = insertelement <64 x float> undef, float %383, i32 0
  %385 = shufflevector <64 x float> %384, <64 x float> undef, <64 x i32> zeroinitializer
  %386 = shl i64 %indvars.iv.6, 6
  %387 = add nuw nsw i64 %386, %46
  %388 = getelementptr inbounds float, float* %7, i64 %387
  %389 = bitcast float* %388 to <64 x float>*
  %390 = load <64 x float>, <64 x float>* %389, align 64, !tbaa !391
  %391 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %385, <64 x float> %390, <64 x float> %380)
  %392 = add nsw i64 %381, 256
  %393 = getelementptr inbounds float, float* %4, i64 %392
  %394 = load float, float* %393, align 4, !tbaa !388
  %395 = insertelement <64 x float> undef, float %394, i32 0
  %396 = shufflevector <64 x float> %395, <64 x float> undef, <64 x i32> zeroinitializer
  %397 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %396, <64 x float> %390, <64 x float> %379)
  %398 = add nsw i64 %381, 3584
  %399 = getelementptr inbounds float, float* %4, i64 %398
  %400 = load float, float* %399, align 4, !tbaa !388
  %401 = insertelement <64 x float> undef, float %400, i32 0
  %402 = shufflevector <64 x float> %401, <64 x float> undef, <64 x i32> zeroinitializer
  %403 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %402, <64 x float> %390, <64 x float> %378)
  %404 = add nsw i64 %381, 3840
  %405 = getelementptr inbounds float, float* %4, i64 %404
  %406 = load float, float* %405, align 4, !tbaa !388
  %407 = insertelement <64 x float> undef, float %406, i32 0
  %408 = shufflevector <64 x float> %407, <64 x float> undef, <64 x i32> zeroinitializer
  %409 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %408, <64 x float> %390, <64 x float> %377)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 256
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %391, <64 x float>* %369, align 64, !tbaa !385
  store <64 x float> %397, <64 x float>* %371, align 64, !tbaa !385
  store <64 x float> %403, <64 x float>* %373, align 64, !tbaa !385
  store <64 x float> %409, <64 x float>* %375, align 64, !tbaa !385
  %410 = mul nsw i32 %38, 1792
  %411 = shl nsw i32 %44, 6
  %412 = sext i32 %411 to i64
  %413 = getelementptr inbounds float, float* %13, i64 %412
  %414 = bitcast float* %413 to <64 x float>*
  %415 = load <64 x float>, <64 x float>* %414, align 64, !tbaa !400
  %416 = getelementptr inbounds float, float* %16, i64 %412
  %417 = bitcast float* %416 to <64 x float>*
  %418 = load <64 x float>, <64 x float>* %417, align 64, !tbaa !403
  %419 = getelementptr inbounds float, float* %19, i64 %412
  %420 = bitcast float* %419 to <64 x float>*
  %421 = load <64 x float>, <64 x float>* %420, align 64, !tbaa !406
  br label %for_body8
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !409 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !411, metadata !DIExpression()), !dbg !414
  call void @llvm.dbg.value(metadata i8* %1, metadata !412, metadata !DIExpression()), !dbg !414
  call void @llvm.dbg.value(metadata i32 %2, metadata !413, metadata !DIExpression()), !dbg !414
  %3 = bitcast i8* %0 to %1**, !dbg !414
  %4 = load %1*, %1** %3, align 8, !dbg !414
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !414
  %6 = bitcast i8* %5 to %1**, !dbg !414
  %7 = load %1*, %1** %6, align 8, !dbg !414
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !414
  %9 = bitcast i8* %8 to %1**, !dbg !414
  %10 = load %1*, %1** %9, align 8, !dbg !414
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !414
  %12 = bitcast i8* %11 to %1**, !dbg !414
  %13 = load %1*, %1** %12, align 8, !dbg !414
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !414
  %15 = bitcast i8* %14 to %1**, !dbg !414
  %16 = load %1*, %1** %15, align 8, !dbg !414
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !414
  %18 = bitcast i8* %17 to %1**, !dbg !414
  %19 = load %1*, %1** %18, align 8, !dbg !414
  %20 = getelementptr inbounds i8, i8* %0, i64 48, !dbg !414
  %21 = bitcast i8* %20 to %1**, !dbg !414
  %22 = load %1*, %1** %21, align 8, !dbg !414
  %23 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !414
  %24 = load i8*, i8** %23, align 8, !dbg !414
  %25 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !414
  %26 = load i8*, i8** %25, align 8, !dbg !414
  %27 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !414
  %28 = load i8*, i8** %27, align 8, !dbg !414
  %29 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !414
  %30 = load i8*, i8** %29, align 8, !dbg !414
  %31 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !414
  %32 = load i8*, i8** %31, align 8, !dbg !414
  %33 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !414
  %34 = load i8*, i8** %33, align 8, !dbg !414
  %35 = getelementptr inbounds %1, %1* %22, i64 0, i32 0, !dbg !414
  %36 = load i8*, i8** %35, align 8, !dbg !414
  %37 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_compute_(i8* %24, i8* %26, i8* %36, i8* %28, i8* %30, i8* %32, i8* %34), !dbg !414
  ret i32 %37, !dbg !414
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %7 = alloca %28, align 8
  %8 = getelementptr inbounds %28, %28* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %28, %28* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %28, %28* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %28, %28* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %28, %28* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %28, %28* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %28, %28* %7, i64 0, i32 6
  store i8* %6, i8** %14, align 8
  %15 = bitcast %28* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.24, i8* nonnull %15, i32 0)
  ret i32 %17
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.24(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 447
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 448
  %30 = select i1 %29, i32 %28, i32 448
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv43 = phi i64 [ %37, %for_body.lr.ph ], [ %indvars.iv.next44, %for_end3 ]
  %39 = trunc i64 %indvars.iv43 to i32
  %40 = srem i32 %39, 7
  %41 = mul nsw i32 %40, 28
  %42 = sdiv i32 %39, 7
  %43 = shl i32 %42, 14
  %44 = sext i32 %41 to i64
  %45 = sext i32 %43 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %.lcssa2033 = phi <32 x float> [ zeroinitializer, %for_body ], [ %231, %for_body2 ]
  %.lcssa1831 = phi <32 x float> [ zeroinitializer, %for_body ], [ %225, %for_body2 ]
  %.lcssa1629 = phi <32 x float> [ zeroinitializer, %for_body ], [ %219, %for_body2 ]
  %.lcssa1427 = phi <32 x float> [ zeroinitializer, %for_body ], [ %213, %for_body2 ]
  %.lcssa1225 = phi <32 x float> [ zeroinitializer, %for_body ], [ %207, %for_body2 ]
  %.lcssa1024 = phi <32 x float> [ zeroinitializer, %for_body ], [ %201, %for_body2 ]
  %.lcssa22 = phi <32 x float> [ zeroinitializer, %for_body ], [ %195, %for_body2 ]
  %46 = mul nuw nsw i64 %indvars.iv, 196
  %47 = add nsw i64 %46, %44
  %48 = shl i64 %indvars.iv, 7
  %49 = add nuw nsw i64 %48, %45
  %50 = getelementptr inbounds float, float* %4, i64 %47
  %51 = load float, float* %50, align 4, !tbaa !415
  %52 = insertelement <32 x float> undef, float %51, i32 0
  %53 = shufflevector <32 x float> %52, <32 x float> undef, <32 x i32> zeroinitializer
  %54 = getelementptr inbounds float, float* %7, i64 %49
  %55 = bitcast float* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !418
  %57 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %53, <32 x float> %56, <32 x float> %.lcssa22)
  %58 = add nsw i64 %47, 4
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = load float, float* %59, align 4, !tbaa !415
  %61 = insertelement <32 x float> undef, float %60, i32 0
  %62 = shufflevector <32 x float> %61, <32 x float> undef, <32 x i32> zeroinitializer
  %63 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %56, <32 x float> %.lcssa1024)
  %64 = add nsw i64 %47, 8
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !415
  %67 = insertelement <32 x float> undef, float %66, i32 0
  %68 = shufflevector <32 x float> %67, <32 x float> undef, <32 x i32> zeroinitializer
  %69 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %56, <32 x float> %.lcssa1225)
  %70 = add nsw i64 %47, 12
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !415
  %73 = insertelement <32 x float> undef, float %72, i32 0
  %74 = shufflevector <32 x float> %73, <32 x float> undef, <32 x i32> zeroinitializer
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %56, <32 x float> %.lcssa1427)
  %76 = add nsw i64 %47, 16
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !415
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %56, <32 x float> %.lcssa1629)
  %82 = add nsw i64 %47, 20
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !415
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %56, <32 x float> %.lcssa1831)
  %88 = add nsw i64 %47, 24
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !415
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %56, <32 x float> %.lcssa2033)
  %94 = or i64 %47, 1
  %95 = getelementptr inbounds float, float* %4, i64 %94
  %96 = load float, float* %95, align 4, !tbaa !415
  %97 = insertelement <32 x float> undef, float %96, i32 0
  %98 = shufflevector <32 x float> %97, <32 x float> undef, <32 x i32> zeroinitializer
  %99 = or i64 %49, 32
  %100 = getelementptr inbounds float, float* %7, i64 %99
  %101 = bitcast float* %100 to <32 x float>*
  %102 = load <32 x float>, <32 x float>* %101, align 64, !tbaa !418
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %98, <32 x float> %102, <32 x float> %57)
  %104 = add nsw i64 %94, 4
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !415
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %102, <32 x float> %63)
  %110 = add nsw i64 %94, 8
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !415
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %102, <32 x float> %69)
  %116 = add nsw i64 %94, 12
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !415
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %102, <32 x float> %75)
  %122 = add nsw i64 %94, 16
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !415
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %102, <32 x float> %81)
  %128 = add nsw i64 %94, 20
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !415
  %131 = insertelement <32 x float> undef, float %130, i32 0
  %132 = shufflevector <32 x float> %131, <32 x float> undef, <32 x i32> zeroinitializer
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %132, <32 x float> %102, <32 x float> %87)
  %134 = add nsw i64 %94, 24
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !415
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %102, <32 x float> %93)
  %140 = or i64 %47, 2
  %141 = getelementptr inbounds float, float* %4, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !415
  %143 = insertelement <32 x float> undef, float %142, i32 0
  %144 = shufflevector <32 x float> %143, <32 x float> undef, <32 x i32> zeroinitializer
  %145 = or i64 %49, 64
  %146 = getelementptr inbounds float, float* %7, i64 %145
  %147 = bitcast float* %146 to <32 x float>*
  %148 = load <32 x float>, <32 x float>* %147, align 64, !tbaa !418
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %144, <32 x float> %148, <32 x float> %103)
  %150 = add nsw i64 %140, 4
  %151 = getelementptr inbounds float, float* %4, i64 %150
  %152 = load float, float* %151, align 4, !tbaa !415
  %153 = insertelement <32 x float> undef, float %152, i32 0
  %154 = shufflevector <32 x float> %153, <32 x float> undef, <32 x i32> zeroinitializer
  %155 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %154, <32 x float> %148, <32 x float> %109)
  %156 = add nsw i64 %140, 8
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = load float, float* %157, align 4, !tbaa !415
  %159 = insertelement <32 x float> undef, float %158, i32 0
  %160 = shufflevector <32 x float> %159, <32 x float> undef, <32 x i32> zeroinitializer
  %161 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %160, <32 x float> %148, <32 x float> %115)
  %162 = add nsw i64 %140, 12
  %163 = getelementptr inbounds float, float* %4, i64 %162
  %164 = load float, float* %163, align 4, !tbaa !415
  %165 = insertelement <32 x float> undef, float %164, i32 0
  %166 = shufflevector <32 x float> %165, <32 x float> undef, <32 x i32> zeroinitializer
  %167 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %166, <32 x float> %148, <32 x float> %121)
  %168 = add nsw i64 %140, 16
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = load float, float* %169, align 4, !tbaa !415
  %171 = insertelement <32 x float> undef, float %170, i32 0
  %172 = shufflevector <32 x float> %171, <32 x float> undef, <32 x i32> zeroinitializer
  %173 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %172, <32 x float> %148, <32 x float> %127)
  %174 = add nsw i64 %140, 20
  %175 = getelementptr inbounds float, float* %4, i64 %174
  %176 = load float, float* %175, align 4, !tbaa !415
  %177 = insertelement <32 x float> undef, float %176, i32 0
  %178 = shufflevector <32 x float> %177, <32 x float> undef, <32 x i32> zeroinitializer
  %179 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %178, <32 x float> %148, <32 x float> %133)
  %180 = add nsw i64 %140, 24
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = load float, float* %181, align 4, !tbaa !415
  %183 = insertelement <32 x float> undef, float %182, i32 0
  %184 = shufflevector <32 x float> %183, <32 x float> undef, <32 x i32> zeroinitializer
  %185 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %184, <32 x float> %148, <32 x float> %139)
  %186 = or i64 %47, 3
  %187 = getelementptr inbounds float, float* %4, i64 %186
  %188 = load float, float* %187, align 4, !tbaa !415
  %189 = insertelement <32 x float> undef, float %188, i32 0
  %190 = shufflevector <32 x float> %189, <32 x float> undef, <32 x i32> zeroinitializer
  %191 = or i64 %49, 96
  %192 = getelementptr inbounds float, float* %7, i64 %191
  %193 = bitcast float* %192 to <32 x float>*
  %194 = load <32 x float>, <32 x float>* %193, align 64, !tbaa !418
  %195 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %190, <32 x float> %194, <32 x float> %149)
  %196 = add nsw i64 %186, 4
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !415
  %199 = insertelement <32 x float> undef, float %198, i32 0
  %200 = shufflevector <32 x float> %199, <32 x float> undef, <32 x i32> zeroinitializer
  %201 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %200, <32 x float> %194, <32 x float> %155)
  %202 = add nsw i64 %186, 8
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !415
  %205 = insertelement <32 x float> undef, float %204, i32 0
  %206 = shufflevector <32 x float> %205, <32 x float> undef, <32 x i32> zeroinitializer
  %207 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %206, <32 x float> %194, <32 x float> %161)
  %208 = add nsw i64 %186, 12
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !415
  %211 = insertelement <32 x float> undef, float %210, i32 0
  %212 = shufflevector <32 x float> %211, <32 x float> undef, <32 x i32> zeroinitializer
  %213 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %212, <32 x float> %194, <32 x float> %167)
  %214 = add nsw i64 %186, 16
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = load float, float* %215, align 4, !tbaa !415
  %217 = insertelement <32 x float> undef, float %216, i32 0
  %218 = shufflevector <32 x float> %217, <32 x float> undef, <32 x i32> zeroinitializer
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %194, <32 x float> %173)
  %220 = add nsw i64 %186, 20
  %221 = getelementptr inbounds float, float* %4, i64 %220
  %222 = load float, float* %221, align 4, !tbaa !415
  %223 = insertelement <32 x float> undef, float %222, i32 0
  %224 = shufflevector <32 x float> %223, <32 x float> undef, <32 x i32> zeroinitializer
  %225 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %224, <32 x float> %194, <32 x float> %179)
  %226 = add nsw i64 %186, 24
  %227 = getelementptr inbounds float, float* %4, i64 %226
  %228 = load float, float* %227, align 4, !tbaa !415
  %229 = insertelement <32 x float> undef, float %228, i32 0
  %230 = shufflevector <32 x float> %229, <32 x float> undef, <32 x i32> zeroinitializer
  %231 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %230, <32 x float> %194, <32 x float> %185)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %232 = mul nsw i64 %indvars.iv43, 224
  %233 = shl nsw i32 %42, 5
  %234 = sext i32 %233 to i64
  %235 = getelementptr inbounds float, float* %13, i64 %234
  %236 = bitcast float* %235 to <32 x float>*
  %237 = load <32 x float>, <32 x float>* %236, align 64, !tbaa !421
  %238 = getelementptr inbounds float, float* %16, i64 %234
  %239 = bitcast float* %238 to <32 x float>*
  %240 = load <32 x float>, <32 x float>* %239, align 64, !tbaa !424
  %241 = getelementptr inbounds float, float* %19, i64 %234
  %242 = bitcast float* %241 to <32 x float>*
  %243 = load <32 x float>, <32 x float>* %242, align 64, !tbaa !427
  %244 = getelementptr inbounds float, float* %22, i64 %232
  %245 = bitcast float* %244 to <32 x float>*
  %246 = load <32 x float>, <32 x float>* %245, align 64, !tbaa !430
  %247 = fadd <32 x float> %237, %195
  %248 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %247, <32 x float> %240, <32 x float> %243)
  %249 = fadd <32 x float> %246, %248
  %250 = fcmp ogt <32 x float> %249, zeroinitializer
  %251 = select <32 x i1> %250, <32 x float> %249, <32 x float> zeroinitializer
  %252 = getelementptr inbounds float, float* %10, i64 %232
  %253 = bitcast float* %252 to <32 x float>*
  store <32 x float> %251, <32 x float>* %253, align 64, !tbaa !433
  %254 = add nsw i64 %232, 32
  %255 = getelementptr inbounds float, float* %22, i64 %254
  %256 = bitcast float* %255 to <32 x float>*
  %257 = load <32 x float>, <32 x float>* %256, align 64, !tbaa !430
  %258 = fadd <32 x float> %237, %201
  %259 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %258, <32 x float> %240, <32 x float> %243)
  %260 = fadd <32 x float> %257, %259
  %261 = fcmp ogt <32 x float> %260, zeroinitializer
  %262 = select <32 x i1> %261, <32 x float> %260, <32 x float> zeroinitializer
  %263 = getelementptr inbounds float, float* %10, i64 %254
  %264 = bitcast float* %263 to <32 x float>*
  store <32 x float> %262, <32 x float>* %264, align 64, !tbaa !433
  %265 = add nsw i64 %232, 64
  %266 = getelementptr inbounds float, float* %22, i64 %265
  %267 = bitcast float* %266 to <32 x float>*
  %268 = load <32 x float>, <32 x float>* %267, align 64, !tbaa !430
  %269 = fadd <32 x float> %237, %207
  %270 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %240, <32 x float> %243)
  %271 = fadd <32 x float> %268, %270
  %272 = fcmp ogt <32 x float> %271, zeroinitializer
  %273 = select <32 x i1> %272, <32 x float> %271, <32 x float> zeroinitializer
  %274 = getelementptr inbounds float, float* %10, i64 %265
  %275 = bitcast float* %274 to <32 x float>*
  store <32 x float> %273, <32 x float>* %275, align 64, !tbaa !433
  %276 = add nsw i64 %232, 96
  %277 = getelementptr inbounds float, float* %22, i64 %276
  %278 = bitcast float* %277 to <32 x float>*
  %279 = load <32 x float>, <32 x float>* %278, align 64, !tbaa !430
  %280 = fadd <32 x float> %237, %213
  %281 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %240, <32 x float> %243)
  %282 = fadd <32 x float> %279, %281
  %283 = fcmp ogt <32 x float> %282, zeroinitializer
  %284 = select <32 x i1> %283, <32 x float> %282, <32 x float> zeroinitializer
  %285 = getelementptr inbounds float, float* %10, i64 %276
  %286 = bitcast float* %285 to <32 x float>*
  store <32 x float> %284, <32 x float>* %286, align 64, !tbaa !433
  %287 = add nsw i64 %232, 128
  %288 = getelementptr inbounds float, float* %22, i64 %287
  %289 = bitcast float* %288 to <32 x float>*
  %290 = load <32 x float>, <32 x float>* %289, align 64, !tbaa !430
  %291 = fadd <32 x float> %237, %219
  %292 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %291, <32 x float> %240, <32 x float> %243)
  %293 = fadd <32 x float> %290, %292
  %294 = fcmp ogt <32 x float> %293, zeroinitializer
  %295 = select <32 x i1> %294, <32 x float> %293, <32 x float> zeroinitializer
  %296 = getelementptr inbounds float, float* %10, i64 %287
  %297 = bitcast float* %296 to <32 x float>*
  store <32 x float> %295, <32 x float>* %297, align 64, !tbaa !433
  %298 = add nsw i64 %232, 160
  %299 = getelementptr inbounds float, float* %22, i64 %298
  %300 = bitcast float* %299 to <32 x float>*
  %301 = load <32 x float>, <32 x float>* %300, align 64, !tbaa !430
  %302 = fadd <32 x float> %237, %225
  %303 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %302, <32 x float> %240, <32 x float> %243)
  %304 = fadd <32 x float> %301, %303
  %305 = fcmp ogt <32 x float> %304, zeroinitializer
  %306 = select <32 x i1> %305, <32 x float> %304, <32 x float> zeroinitializer
  %307 = getelementptr inbounds float, float* %10, i64 %298
  %308 = bitcast float* %307 to <32 x float>*
  store <32 x float> %306, <32 x float>* %308, align 64, !tbaa !433
  %309 = add nsw i64 %232, 192
  %310 = getelementptr inbounds float, float* %22, i64 %309
  %311 = bitcast float* %310 to <32 x float>*
  %312 = load <32 x float>, <32 x float>* %311, align 64, !tbaa !430
  %313 = fadd <32 x float> %237, %231
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %313, <32 x float> %240, <32 x float> %243)
  %315 = fadd <32 x float> %312, %314
  %316 = fcmp ogt <32 x float> %315, zeroinitializer
  %317 = select <32 x i1> %316, <32 x float> %315, <32 x float> zeroinitializer
  %318 = getelementptr inbounds float, float* %10, i64 %309
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %317, <32 x float>* %319, align 64, !tbaa !433
  %indvars.iv.next44 = add nsw i64 %indvars.iv43, 1
  %320 = icmp slt i64 %indvars.iv.next44, %38
  br i1 %320, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_max_pool2d(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !436 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !438, metadata !DIExpression()), !dbg !441
  call void @llvm.dbg.value(metadata i8* %1, metadata !439, metadata !DIExpression()), !dbg !441
  call void @llvm.dbg.value(metadata i32 %2, metadata !440, metadata !DIExpression()), !dbg !441
  %3 = bitcast i8* %0 to %1**, !dbg !441
  %4 = load %1*, %1** %3, align 8, !dbg !441
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !441
  %6 = bitcast i8* %5 to %1**, !dbg !441
  %7 = load %1*, %1** %6, align 8, !dbg !441
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !441
  %9 = load i8*, i8** %8, align 8, !dbg !441
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !441
  %11 = load i8*, i8** %10, align 8, !dbg !441
  %12 = tail call fastcc i32 @fused_nn_max_pool2d_compute_(i8* %11, i8* %9), !dbg !441
  ret i32 %12, !dbg !441
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_max_pool2d_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %29, align 8
  %3 = getelementptr inbounds %29, %29* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %29, %29* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %29* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.25, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.25(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 111
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 112
  %15 = select i1 %14, i32 %13, i32 112
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 112
  %18 = select i1 %17, i32 %16, i32 112
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 1792
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = srem i32 %25, 56
  %27 = shl nsw i32 %26, 1
  %28 = trunc i64 %indvars.iv7 to i32
  %29 = mul i32 %28, 7168
  %30 = add i32 %29, -3616
  %31 = icmp sgt i32 %26, 0
  %32 = or i32 %27, 1
  %33 = icmp sgt i32 %32, 0
  %34 = icmp sgt i32 %26, -1
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %if_end.8, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %if_end.8 ]
  %35 = shl i64 %indvars.iv, 5
  %36 = add nsw i64 %35, %24
  %37 = getelementptr inbounds float, float* %4, i64 %36
  %38 = bitcast float* %37 to <32 x float>*
  store <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, <32 x float>* %38, align 64, !tbaa !442
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %39 = shl i32 %indvars.iv.tr, 6
  %40 = add i32 %30, %39
  %41 = icmp ne i64 %indvars.iv, 0
  %42 = and i1 %31, %41
  br i1 %42, label %if_then, label %if_end

for_end3:                                         ; preds = %if_end.8
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %43 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %43, label %for_body, label %for_end, !prof !19

if_then:                                          ; preds = %for_body2
  %44 = sext i32 %40 to i64
  %45 = getelementptr inbounds float, float* %7, i64 %44
  %46 = bitcast float* %45 to <32 x float>*
  %47 = load <32 x float>, <32 x float>* %46, align 64, !tbaa !445
  br label %if_end

if_end:                                           ; preds = %for_body2, %if_then
  %48 = phi <32 x float> [ %47, %if_then ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %for_body2 ]
  %49 = fcmp olt <32 x float> %48, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %50 = select <32 x i1> %49, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, <32 x float> %48
  br i1 %31, label %if_then.2, label %if_end.1

if_end.1:                                         ; preds = %if_end
  %51 = fcmp ogt <32 x float> %50, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %52 = select <32 x i1> %51, <32 x float> %50, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  br label %if_end.2

if_then.2:                                        ; preds = %if_end
  %53 = add i32 %40, 32
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds float, float* %7, i64 %54
  %56 = bitcast float* %55 to <32 x float>*
  %57 = load <32 x float>, <32 x float>* %56, align 64, !tbaa !445
  %58 = fcmp ogt <32 x float> %50, %57
  %59 = select <32 x i1> %58, <32 x float> %50, <32 x float> %57
  %60 = add i32 %40, 64
  %61 = sext i32 %60 to i64
  %62 = getelementptr inbounds float, float* %7, i64 %61
  %63 = bitcast float* %62 to <32 x float>*
  %64 = load <32 x float>, <32 x float>* %63, align 64, !tbaa !445
  br label %if_end.2

if_end.2:                                         ; preds = %if_end.1, %if_then.2
  %65 = phi <32 x float> [ %59, %if_then.2 ], [ %52, %if_end.1 ]
  %66 = phi <32 x float> [ %64, %if_then.2 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.1 ]
  %67 = fcmp ogt <32 x float> %65, %66
  %68 = select <32 x i1> %67, <32 x float> %65, <32 x float> %66
  %69 = and i1 %33, %41
  br i1 %69, label %if_then.3, label %if_end.3

if_then.3:                                        ; preds = %if_end.2
  %70 = add i32 %40, 3584
  %71 = sext i32 %70 to i64
  %72 = getelementptr inbounds float, float* %7, i64 %71
  %73 = bitcast float* %72 to <32 x float>*
  %74 = load <32 x float>, <32 x float>* %73, align 64, !tbaa !445
  br label %if_end.3

if_end.3:                                         ; preds = %if_then.3, %if_end.2
  %75 = phi <32 x float> [ %74, %if_then.3 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.2 ]
  %76 = fcmp ogt <32 x float> %68, %75
  %77 = select <32 x i1> %76, <32 x float> %68, <32 x float> %75
  br i1 %33, label %if_then.5, label %if_end.4

if_end.4:                                         ; preds = %if_end.3
  %78 = fcmp ogt <32 x float> %77, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %79 = select <32 x i1> %78, <32 x float> %77, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  br label %if_end.5

if_then.5:                                        ; preds = %if_end.3
  %80 = add i32 %29, %39
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <32 x float>*
  %84 = load <32 x float>, <32 x float>* %83, align 64, !tbaa !445
  %85 = fcmp ogt <32 x float> %77, %84
  %86 = select <32 x i1> %85, <32 x float> %77, <32 x float> %84
  %87 = add i32 %40, 3648
  %88 = sext i32 %87 to i64
  %89 = getelementptr inbounds float, float* %7, i64 %88
  %90 = bitcast float* %89 to <32 x float>*
  %91 = load <32 x float>, <32 x float>* %90, align 64, !tbaa !445
  br label %if_end.5

if_end.5:                                         ; preds = %if_end.4, %if_then.5
  %92 = phi <32 x float> [ %86, %if_then.5 ], [ %79, %if_end.4 ]
  %93 = phi <32 x float> [ %91, %if_then.5 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.4 ]
  %94 = fcmp ogt <32 x float> %92, %93
  %95 = select <32 x i1> %94, <32 x float> %92, <32 x float> %93
  %96 = and i1 %34, %41
  br i1 %96, label %if_then.6, label %if_end.6

if_then.6:                                        ; preds = %if_end.5
  %97 = add i32 %40, 7168
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = bitcast float* %99 to <32 x float>*
  %101 = load <32 x float>, <32 x float>* %100, align 64, !tbaa !445
  br label %if_end.6

if_end.6:                                         ; preds = %if_then.6, %if_end.5
  %102 = phi <32 x float> [ %101, %if_then.6 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.5 ]
  %103 = fcmp ogt <32 x float> %95, %102
  %104 = select <32 x i1> %103, <32 x float> %95, <32 x float> %102
  br i1 %34, label %if_then.8, label %if_end.7

if_end.7:                                         ; preds = %if_end.6
  %105 = fcmp ogt <32 x float> %104, <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  %106 = select <32 x i1> %105, <32 x float> %104, <32 x float> <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>
  br label %if_end.8

if_then.8:                                        ; preds = %if_end.6
  %107 = add i32 %40, 7200
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds float, float* %7, i64 %108
  %110 = bitcast float* %109 to <32 x float>*
  %111 = load <32 x float>, <32 x float>* %110, align 64, !tbaa !445
  %112 = fcmp ogt <32 x float> %104, %111
  %113 = select <32 x i1> %112, <32 x float> %104, <32 x float> %111
  %114 = add i32 %40, 7232
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds float, float* %7, i64 %115
  %117 = bitcast float* %116 to <32 x float>*
  %118 = load <32 x float>, <32 x float>* %117, align 64, !tbaa !445
  br label %if_end.8

if_end.8:                                         ; preds = %if_end.7, %if_then.8
  %119 = phi <32 x float> [ %113, %if_then.8 ], [ %106, %if_end.7 ]
  %120 = phi <32 x float> [ %118, %if_then.8 ], [ <float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000, float 0xC7EFFFFFE0000000>, %if_end.7 ]
  %121 = fcmp ogt <32 x float> %119, %120
  %122 = select <32 x i1> %121, <32 x float> %119, <32 x float> %120
  store <32 x float> %122, <32 x float>* %38, align 64, !tbaa !442
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !448 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !450, metadata !DIExpression()), !dbg !453
  call void @llvm.dbg.value(metadata i8* %1, metadata !451, metadata !DIExpression()), !dbg !453
  call void @llvm.dbg.value(metadata i32 %2, metadata !452, metadata !DIExpression()), !dbg !453
  %3 = bitcast i8* %0 to %1**, !dbg !453
  %4 = load %1*, %1** %3, align 8, !dbg !453
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !453
  %6 = bitcast i8* %5 to %1**, !dbg !453
  %7 = load %1*, %1** %6, align 8, !dbg !453
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !453
  %9 = bitcast i8* %8 to %1**, !dbg !453
  %10 = load %1*, %1** %9, align 8, !dbg !453
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !453
  %12 = bitcast i8* %11 to %1**, !dbg !453
  %13 = load %1*, %1** %12, align 8, !dbg !453
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !453
  %15 = load i8*, i8** %14, align 8, !dbg !453
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !453
  %17 = load i32, i32* %16, align 4, !dbg !453
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !453
  %19 = load i8*, i8** %18, align 8, !dbg !453
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !453
  %21 = load i8*, i8** %20, align 8, !dbg !453
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !453
  %23 = load i8*, i8** %22, align 8, !dbg !453
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !453
  ret i32 %24, !dbg !453
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %6 = tail call i8* %5(i32 1, i32 %4, i64 165888, i32 2, i32 32)
  %7 = alloca %30, align 8
  %8 = getelementptr inbounds %30, %30* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %30, %30* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %30* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.26, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !19

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %21, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %31, align 8
  %15 = getelementptr inbounds %31, %31* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %31, %31* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %31, %31* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %31, %31* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = bitcast %31* %14 to i8*
  %20 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %21 = call i32 %20(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.27, i8* nonnull %19, i32 0)
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %call_end2, label %call_fail, !prof !19

call_end2:                                        ; preds = %call_end
  %23 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %24 = call i32 %23(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.26(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 8
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 9
  %15 = select i1 %14, i32 %13, i32 9
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 9
  %18 = select i1 %17, i32 %16, i32 9
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end3
  %20 = phi i32 [ %40, %for_end3 ], [ %18, %for_body.preheader ]
  %21 = mul nsw i32 %20, 4608
  %.off = add i32 %20, -1
  %22 = icmp ult i32 %.off, 7
  %23 = mul nsw i32 %20, 3584
  br i1 %22, label %vector.body251.preheader, label %vector.body449.preheader

vector.body449.preheader:                         ; preds = %for_body
  br label %vector.body449

vector.body251.preheader:                         ; preds = %for_body
  br label %vector.body251

vector.body251:                                   ; preds = %vector.body251.preheader, %vector.body251
  %index261 = phi i64 [ %index.next262, %vector.body251 ], [ 0, %vector.body251.preheader ]
  %24 = trunc i64 %index261 to i32
  %25 = add i32 %21, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds float, float* %4, i64 %26
  %28 = bitcast float* %27 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %28, align 4, !tbaa !454
  %29 = getelementptr float, float* %27, i64 4
  %30 = bitcast float* %29 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %30, align 4, !tbaa !454
  %index.next262 = add i64 %index261, 8
  %31 = icmp eq i64 %index.next262, 512
  br i1 %31, label %vector.body220.preheader, label %vector.body251, !llvm.loop !457

vector.body220.preheader:                         ; preds = %vector.body251
  br label %vector.body220

vector.body449:                                   ; preds = %vector.body449.preheader, %vector.body449
  %index459 = phi i64 [ %index.next460, %vector.body449 ], [ 0, %vector.body449.preheader ]
  %32 = trunc i64 %index459 to i32
  %33 = add i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %4, i64 %34
  %36 = bitcast float* %35 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %36, align 4, !tbaa !454
  %37 = getelementptr float, float* %35, i64 4
  %38 = bitcast float* %37 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %38, align 4, !tbaa !454
  %index.next460 = add i64 %index459, 8
  %39 = icmp eq i64 %index.next460, 512
  br i1 %39, label %vector.body427.preheader, label %vector.body449, !llvm.loop !458

vector.body427.preheader:                         ; preds = %vector.body449
  br label %vector.body427

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_end3:                                         ; preds = %vector.body273, %vector.body
  %40 = add nsw i32 %20, 1
  %41 = icmp slt i32 %40, %15
  br i1 %41, label %for_body, label %for_end, !prof !19

vector.body427:                                   ; preds = %vector.body427.preheader, %vector.body427
  %index437 = phi i64 [ %index.next438, %vector.body427 ], [ 0, %vector.body427.preheader ]
  %42 = trunc i64 %index437 to i32
  %43 = add i32 %42, 512
  %44 = add i32 %43, %21
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %4, i64 %45
  %47 = bitcast float* %46 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %47, align 4, !tbaa !454
  %48 = getelementptr float, float* %46, i64 4
  %49 = bitcast float* %48 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %49, align 4, !tbaa !454
  %index.next438 = add i64 %index437, 8
  %50 = icmp eq i64 %index.next438, 512
  br i1 %50, label %vector.body405.preheader, label %vector.body427, !llvm.loop !459

vector.body405.preheader:                         ; preds = %vector.body427
  br label %vector.body405

vector.body405:                                   ; preds = %vector.body405.preheader, %vector.body405
  %index415 = phi i64 [ %index.next416, %vector.body405 ], [ 0, %vector.body405.preheader ]
  %51 = trunc i64 %index415 to i32
  %52 = add i32 %51, 1024
  %53 = add i32 %52, %21
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds float, float* %4, i64 %54
  %56 = bitcast float* %55 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %56, align 4, !tbaa !454
  %57 = getelementptr float, float* %55, i64 4
  %58 = bitcast float* %57 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %58, align 4, !tbaa !454
  %index.next416 = add i64 %index415, 8
  %59 = icmp eq i64 %index.next416, 512
  br i1 %59, label %vector.body383.preheader, label %vector.body405, !llvm.loop !460

vector.body383.preheader:                         ; preds = %vector.body405
  br label %vector.body383

vector.body383:                                   ; preds = %vector.body383.preheader, %vector.body383
  %index393 = phi i64 [ %index.next394, %vector.body383 ], [ 0, %vector.body383.preheader ]
  %60 = trunc i64 %index393 to i32
  %61 = add i32 %60, 1536
  %62 = add i32 %61, %21
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %4, i64 %63
  %65 = bitcast float* %64 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %65, align 4, !tbaa !454
  %66 = getelementptr float, float* %64, i64 4
  %67 = bitcast float* %66 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %67, align 4, !tbaa !454
  %index.next394 = add i64 %index393, 8
  %68 = icmp eq i64 %index.next394, 512
  br i1 %68, label %vector.body361.preheader, label %vector.body383, !llvm.loop !461

vector.body361.preheader:                         ; preds = %vector.body383
  br label %vector.body361

vector.body361:                                   ; preds = %vector.body361.preheader, %vector.body361
  %index371 = phi i64 [ %index.next372, %vector.body361 ], [ 0, %vector.body361.preheader ]
  %69 = trunc i64 %index371 to i32
  %70 = add i32 %69, 2048
  %71 = add i32 %70, %21
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds float, float* %4, i64 %72
  %74 = bitcast float* %73 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %74, align 4, !tbaa !454
  %75 = getelementptr float, float* %73, i64 4
  %76 = bitcast float* %75 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %76, align 4, !tbaa !454
  %index.next372 = add i64 %index371, 8
  %77 = icmp eq i64 %index.next372, 512
  br i1 %77, label %vector.body339.preheader, label %vector.body361, !llvm.loop !462

vector.body339.preheader:                         ; preds = %vector.body361
  br label %vector.body339

vector.body339:                                   ; preds = %vector.body339.preheader, %vector.body339
  %index349 = phi i64 [ %index.next350, %vector.body339 ], [ 0, %vector.body339.preheader ]
  %78 = trunc i64 %index349 to i32
  %79 = add i32 %78, 2560
  %80 = add i32 %79, %21
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %4, i64 %81
  %83 = bitcast float* %82 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %83, align 4, !tbaa !454
  %84 = getelementptr float, float* %82, i64 4
  %85 = bitcast float* %84 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %85, align 4, !tbaa !454
  %index.next350 = add i64 %index349, 8
  %86 = icmp eq i64 %index.next350, 512
  br i1 %86, label %vector.body317.preheader, label %vector.body339, !llvm.loop !463

vector.body317.preheader:                         ; preds = %vector.body339
  br label %vector.body317

vector.body317:                                   ; preds = %vector.body317.preheader, %vector.body317
  %index327 = phi i64 [ %index.next328, %vector.body317 ], [ 0, %vector.body317.preheader ]
  %87 = trunc i64 %index327 to i32
  %88 = add i32 %87, 3072
  %89 = add i32 %88, %21
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds float, float* %4, i64 %90
  %92 = bitcast float* %91 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %92, align 4, !tbaa !454
  %93 = getelementptr float, float* %91, i64 4
  %94 = bitcast float* %93 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %94, align 4, !tbaa !454
  %index.next328 = add i64 %index327, 8
  %95 = icmp eq i64 %index.next328, 512
  br i1 %95, label %vector.body295.preheader, label %vector.body317, !llvm.loop !464

vector.body295.preheader:                         ; preds = %vector.body317
  br label %vector.body295

vector.body295:                                   ; preds = %vector.body295.preheader, %vector.body295
  %index305 = phi i64 [ %index.next306, %vector.body295 ], [ 0, %vector.body295.preheader ]
  %96 = trunc i64 %index305 to i32
  %97 = add i32 %96, 3584
  %98 = add i32 %97, %21
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds float, float* %4, i64 %99
  %101 = bitcast float* %100 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %101, align 4, !tbaa !454
  %102 = getelementptr float, float* %100, i64 4
  %103 = bitcast float* %102 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %103, align 4, !tbaa !454
  %index.next306 = add i64 %index305, 8
  %104 = icmp eq i64 %index.next306, 512
  br i1 %104, label %vector.body273.preheader, label %vector.body295, !llvm.loop !465

vector.body273.preheader:                         ; preds = %vector.body295
  br label %vector.body273

vector.body273:                                   ; preds = %vector.body273.preheader, %vector.body273
  %index283 = phi i64 [ %index.next284, %vector.body273 ], [ 0, %vector.body273.preheader ]
  %105 = trunc i64 %index283 to i32
  %106 = add i32 %105, 4096
  %107 = add i32 %106, %21
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds float, float* %4, i64 %108
  %110 = bitcast float* %109 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %110, align 4, !tbaa !454
  %111 = getelementptr float, float* %109, i64 4
  %112 = bitcast float* %111 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %112, align 4, !tbaa !454
  %index.next284 = add i64 %index283, 8
  %113 = icmp eq i64 %index.next284, 512
  br i1 %113, label %for_end3, label %vector.body273, !llvm.loop !466

vector.body220:                                   ; preds = %vector.body220.preheader, %vector.body220
  %index233 = phi i64 [ %index.next234, %vector.body220 ], [ 0, %vector.body220.preheader ]
  %114 = trunc i64 %index233 to i32
  %115 = add i32 %114, 512
  %116 = add i32 %21, %115
  %117 = trunc i64 %index233 to i32
  %118 = add i32 %117, -3584
  %119 = add i32 %118, %23
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds float, float* %7, i64 %120
  %122 = bitcast float* %121 to <4 x i32>*
  %wide.load249 = load <4 x i32>, <4 x i32>* %122, align 4, !tbaa !467
  %123 = getelementptr float, float* %121, i64 4
  %124 = bitcast float* %123 to <4 x i32>*
  %wide.load250 = load <4 x i32>, <4 x i32>* %124, align 4, !tbaa !467
  %125 = sext i32 %116 to i64
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = bitcast float* %126 to <4 x i32>*
  store <4 x i32> %wide.load249, <4 x i32>* %127, align 4, !tbaa !454
  %128 = getelementptr float, float* %126, i64 4
  %129 = bitcast float* %128 to <4 x i32>*
  store <4 x i32> %wide.load250, <4 x i32>* %129, align 4, !tbaa !454
  %index.next234 = add i64 %index233, 8
  %130 = icmp eq i64 %index.next234, 512
  br i1 %130, label %vector.body189.preheader, label %vector.body220, !llvm.loop !470

vector.body189.preheader:                         ; preds = %vector.body220
  br label %vector.body189

vector.body189:                                   ; preds = %vector.body189.preheader, %vector.body189
  %index202 = phi i64 [ %index.next203, %vector.body189 ], [ 0, %vector.body189.preheader ]
  %131 = trunc i64 %index202 to i32
  %132 = add i32 %131, 1024
  %133 = add i32 %21, %132
  %134 = trunc i64 %index202 to i32
  %135 = add i32 %134, -3072
  %136 = add i32 %135, %23
  %137 = sext i32 %136 to i64
  %138 = getelementptr inbounds float, float* %7, i64 %137
  %139 = bitcast float* %138 to <4 x i32>*
  %wide.load218 = load <4 x i32>, <4 x i32>* %139, align 4, !tbaa !467
  %140 = getelementptr float, float* %138, i64 4
  %141 = bitcast float* %140 to <4 x i32>*
  %wide.load219 = load <4 x i32>, <4 x i32>* %141, align 4, !tbaa !467
  %142 = sext i32 %133 to i64
  %143 = getelementptr inbounds float, float* %4, i64 %142
  %144 = bitcast float* %143 to <4 x i32>*
  store <4 x i32> %wide.load218, <4 x i32>* %144, align 4, !tbaa !454
  %145 = getelementptr float, float* %143, i64 4
  %146 = bitcast float* %145 to <4 x i32>*
  store <4 x i32> %wide.load219, <4 x i32>* %146, align 4, !tbaa !454
  %index.next203 = add i64 %index202, 8
  %147 = icmp eq i64 %index.next203, 512
  br i1 %147, label %vector.body158.preheader, label %vector.body189, !llvm.loop !471

vector.body158.preheader:                         ; preds = %vector.body189
  br label %vector.body158

vector.body158:                                   ; preds = %vector.body158.preheader, %vector.body158
  %index171 = phi i64 [ %index.next172, %vector.body158 ], [ 0, %vector.body158.preheader ]
  %148 = trunc i64 %index171 to i32
  %149 = add i32 %148, 1536
  %150 = add i32 %21, %149
  %151 = trunc i64 %index171 to i32
  %152 = add i32 %151, -2560
  %153 = add i32 %152, %23
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to <4 x i32>*
  %wide.load187 = load <4 x i32>, <4 x i32>* %156, align 4, !tbaa !467
  %157 = getelementptr float, float* %155, i64 4
  %158 = bitcast float* %157 to <4 x i32>*
  %wide.load188 = load <4 x i32>, <4 x i32>* %158, align 4, !tbaa !467
  %159 = sext i32 %150 to i64
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = bitcast float* %160 to <4 x i32>*
  store <4 x i32> %wide.load187, <4 x i32>* %161, align 4, !tbaa !454
  %162 = getelementptr float, float* %160, i64 4
  %163 = bitcast float* %162 to <4 x i32>*
  store <4 x i32> %wide.load188, <4 x i32>* %163, align 4, !tbaa !454
  %index.next172 = add i64 %index171, 8
  %164 = icmp eq i64 %index.next172, 512
  br i1 %164, label %vector.body127.preheader, label %vector.body158, !llvm.loop !472

vector.body127.preheader:                         ; preds = %vector.body158
  br label %vector.body127

vector.body127:                                   ; preds = %vector.body127.preheader, %vector.body127
  %index140 = phi i64 [ %index.next141, %vector.body127 ], [ 0, %vector.body127.preheader ]
  %165 = trunc i64 %index140 to i32
  %166 = add i32 %165, 2048
  %167 = add i32 %21, %166
  %168 = trunc i64 %index140 to i32
  %169 = add i32 %168, -2048
  %170 = add i32 %169, %23
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds float, float* %7, i64 %171
  %173 = bitcast float* %172 to <4 x i32>*
  %wide.load156 = load <4 x i32>, <4 x i32>* %173, align 4, !tbaa !467
  %174 = getelementptr float, float* %172, i64 4
  %175 = bitcast float* %174 to <4 x i32>*
  %wide.load157 = load <4 x i32>, <4 x i32>* %175, align 4, !tbaa !467
  %176 = sext i32 %167 to i64
  %177 = getelementptr inbounds float, float* %4, i64 %176
  %178 = bitcast float* %177 to <4 x i32>*
  store <4 x i32> %wide.load156, <4 x i32>* %178, align 4, !tbaa !454
  %179 = getelementptr float, float* %177, i64 4
  %180 = bitcast float* %179 to <4 x i32>*
  store <4 x i32> %wide.load157, <4 x i32>* %180, align 4, !tbaa !454
  %index.next141 = add i64 %index140, 8
  %181 = icmp eq i64 %index.next141, 512
  br i1 %181, label %vector.body96.preheader, label %vector.body127, !llvm.loop !473

vector.body96.preheader:                          ; preds = %vector.body127
  br label %vector.body96

vector.body96:                                    ; preds = %vector.body96.preheader, %vector.body96
  %index109 = phi i64 [ %index.next110, %vector.body96 ], [ 0, %vector.body96.preheader ]
  %182 = trunc i64 %index109 to i32
  %183 = add i32 %182, 2560
  %184 = add i32 %21, %183
  %185 = trunc i64 %index109 to i32
  %186 = add i32 %185, -1536
  %187 = add i32 %186, %23
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to <4 x i32>*
  %wide.load125 = load <4 x i32>, <4 x i32>* %190, align 4, !tbaa !467
  %191 = getelementptr float, float* %189, i64 4
  %192 = bitcast float* %191 to <4 x i32>*
  %wide.load126 = load <4 x i32>, <4 x i32>* %192, align 4, !tbaa !467
  %193 = sext i32 %184 to i64
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = bitcast float* %194 to <4 x i32>*
  store <4 x i32> %wide.load125, <4 x i32>* %195, align 4, !tbaa !454
  %196 = getelementptr float, float* %194, i64 4
  %197 = bitcast float* %196 to <4 x i32>*
  store <4 x i32> %wide.load126, <4 x i32>* %197, align 4, !tbaa !454
  %index.next110 = add i64 %index109, 8
  %198 = icmp eq i64 %index.next110, 512
  br i1 %198, label %vector.body65.preheader, label %vector.body96, !llvm.loop !474

vector.body65.preheader:                          ; preds = %vector.body96
  br label %vector.body65

vector.body65:                                    ; preds = %vector.body65.preheader, %vector.body65
  %index78 = phi i64 [ %index.next79, %vector.body65 ], [ 0, %vector.body65.preheader ]
  %199 = trunc i64 %index78 to i32
  %200 = add i32 %199, 3072
  %201 = add i32 %21, %200
  %202 = trunc i64 %index78 to i32
  %203 = add i32 %202, -1024
  %204 = add i32 %203, %23
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds float, float* %7, i64 %205
  %207 = bitcast float* %206 to <4 x i32>*
  %wide.load94 = load <4 x i32>, <4 x i32>* %207, align 4, !tbaa !467
  %208 = getelementptr float, float* %206, i64 4
  %209 = bitcast float* %208 to <4 x i32>*
  %wide.load95 = load <4 x i32>, <4 x i32>* %209, align 4, !tbaa !467
  %210 = sext i32 %201 to i64
  %211 = getelementptr inbounds float, float* %4, i64 %210
  %212 = bitcast float* %211 to <4 x i32>*
  store <4 x i32> %wide.load94, <4 x i32>* %212, align 4, !tbaa !454
  %213 = getelementptr float, float* %211, i64 4
  %214 = bitcast float* %213 to <4 x i32>*
  store <4 x i32> %wide.load95, <4 x i32>* %214, align 4, !tbaa !454
  %index.next79 = add i64 %index78, 8
  %215 = icmp eq i64 %index.next79, 512
  br i1 %215, label %vector.body35.preheader, label %vector.body65, !llvm.loop !475

vector.body35.preheader:                          ; preds = %vector.body65
  br label %vector.body35

vector.body35:                                    ; preds = %vector.body35.preheader, %vector.body35
  %index48 = phi i64 [ %index.next49, %vector.body35 ], [ 0, %vector.body35.preheader ]
  %216 = trunc i64 %index48 to i32
  %217 = add i32 %216, 3584
  %218 = add i32 %21, %217
  %219 = trunc i64 %index48 to i32
  %220 = add i32 %219, -512
  %221 = add i32 %220, %23
  %222 = sext i32 %221 to i64
  %223 = getelementptr inbounds float, float* %7, i64 %222
  %224 = bitcast float* %223 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %224, align 4, !tbaa !467
  %225 = getelementptr float, float* %223, i64 4
  %226 = bitcast float* %225 to <4 x i32>*
  %wide.load64 = load <4 x i32>, <4 x i32>* %226, align 4, !tbaa !467
  %227 = sext i32 %218 to i64
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = bitcast float* %228 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %229, align 4, !tbaa !454
  %230 = getelementptr float, float* %228, i64 4
  %231 = bitcast float* %230 to <4 x i32>*
  store <4 x i32> %wide.load64, <4 x i32>* %231, align 4, !tbaa !454
  %index.next49 = add i64 %index48, 8
  %232 = icmp eq i64 %index.next49, 512
  br i1 %232, label %vector.body.preheader, label %vector.body35, !llvm.loop !476

vector.body.preheader:                            ; preds = %vector.body35
  br label %vector.body

vector.body:                                      ; preds = %vector.body.preheader, %vector.body
  %index = phi i64 [ %index.next, %vector.body ], [ 0, %vector.body.preheader ]
  %233 = trunc i64 %index to i32
  %234 = add i32 %233, 4096
  %235 = add i32 %234, %21
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds float, float* %4, i64 %236
  %238 = bitcast float* %237 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %238, align 4, !tbaa !454
  %239 = getelementptr float, float* %237, i64 4
  %240 = bitcast float* %239 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %240, align 4, !tbaa !454
  %index.next = add i64 %index, 8
  %241 = icmp eq i64 %index.next, 512
  br i1 %241, label %for_end3, label %vector.body, !llvm.loop !477
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.27(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = add nsw i32 %15, 111
  %17 = sdiv i32 %16, %15
  %18 = add nsw i32 %0, 1
  %19 = mul nsw i32 %17, %18
  %20 = icmp slt i32 %19, 112
  %21 = select i1 %20, i32 %19, i32 112
  %22 = mul nsw i32 %17, %0
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = icmp slt i32 %24, %21
  br i1 %25, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %26 = add i32 %24, 1
  %27 = sext i32 %26 to i64
  %28 = add nsw i64 %27, -1
  %29 = sext i32 %21 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.2
  %indvars.iv46 = phi i64 [ %28, %for_body.lr.ph ], [ %indvars.iv.next47, %for_end6.2 ]
  %30 = trunc i64 %indvars.iv46 to i32
  %31 = srem i32 %30, 7
  %32 = sdiv i32 %30, 7
  %33 = mul nsw i32 %32, 147456
  %34 = sext i32 %33 to i64
  %35 = mul nsw i32 %31, 4608
  %36 = sext i32 %35 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.2, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %37 = phi <32 x float> [ zeroinitializer, %for_body ], [ %122, %for_body5 ]
  %38 = phi <32 x float> [ zeroinitializer, %for_body ], [ %116, %for_body5 ]
  %39 = phi <32 x float> [ zeroinitializer, %for_body ], [ %115, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %114, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %113, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %112, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %111, %for_body5 ]
  %44 = add nsw i64 %indvars.iv, %36
  %45 = getelementptr inbounds float, float* %4, i64 %44
  %46 = load float, float* %45, align 4, !tbaa !454
  %47 = insertelement <32 x float> undef, float %46, i32 0
  %48 = shufflevector <32 x float> %47, <32 x float> undef, <32 x i32> zeroinitializer
  %49 = shl nsw i64 %indvars.iv, 5
  %50 = add nsw i64 %49, %34
  %51 = getelementptr inbounds float, float* %7, i64 %50
  %52 = bitcast float* %51 to <32 x float>*
  %53 = load <32 x float>, <32 x float>* %52, align 64, !tbaa !478
  %54 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %48, <32 x float> %53, <32 x float> %43)
  %55 = add nsw i64 %44, 512
  %56 = getelementptr inbounds float, float* %4, i64 %55
  %57 = load float, float* %56, align 4, !tbaa !454
  %58 = insertelement <32 x float> undef, float %57, i32 0
  %59 = shufflevector <32 x float> %58, <32 x float> undef, <32 x i32> zeroinitializer
  %60 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %59, <32 x float> %53, <32 x float> %42)
  %61 = add nsw i64 %44, 1024
  %62 = getelementptr inbounds float, float* %4, i64 %61
  %63 = load float, float* %62, align 4, !tbaa !454
  %64 = insertelement <32 x float> undef, float %63, i32 0
  %65 = shufflevector <32 x float> %64, <32 x float> undef, <32 x i32> zeroinitializer
  %66 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %53, <32 x float> %41)
  %67 = add nsw i64 %44, 1536
  %68 = getelementptr inbounds float, float* %4, i64 %67
  %69 = load float, float* %68, align 4, !tbaa !454
  %70 = insertelement <32 x float> undef, float %69, i32 0
  %71 = shufflevector <32 x float> %70, <32 x float> undef, <32 x i32> zeroinitializer
  %72 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %53, <32 x float> %40)
  %73 = add nsw i64 %44, 2048
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !454
  %76 = insertelement <32 x float> undef, float %75, i32 0
  %77 = shufflevector <32 x float> %76, <32 x float> undef, <32 x i32> zeroinitializer
  %78 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %53, <32 x float> %39)
  %79 = add nsw i64 %44, 2560
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !454
  %82 = insertelement <32 x float> undef, float %81, i32 0
  %83 = shufflevector <32 x float> %82, <32 x float> undef, <32 x i32> zeroinitializer
  %84 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %53, <32 x float> %38)
  %85 = add nsw i64 %44, 3072
  %86 = getelementptr inbounds float, float* %4, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !454
  %88 = insertelement <32 x float> undef, float %87, i32 0
  %89 = shufflevector <32 x float> %88, <32 x float> undef, <32 x i32> zeroinitializer
  %90 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %53, <32 x float> %37)
  %91 = add nsw i64 %50, 16384
  %92 = getelementptr inbounds float, float* %7, i64 %91
  %93 = bitcast float* %92 to <32 x float>*
  %94 = load <32 x float>, <32 x float>* %93, align 64, !tbaa !478
  %95 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %59, <32 x float> %94, <32 x float> %54)
  %96 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %94, <32 x float> %60)
  %97 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %94, <32 x float> %66)
  %98 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %94, <32 x float> %72)
  %99 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %94, <32 x float> %78)
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %94, <32 x float> %84)
  %101 = add nsw i64 %44, 3584
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !454
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %94, <32 x float> %90)
  %107 = add nsw i64 %50, 32768
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <32 x float>*
  %110 = load <32 x float>, <32 x float>* %109, align 64, !tbaa !478
  %111 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %65, <32 x float> %110, <32 x float> %95)
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %71, <32 x float> %110, <32 x float> %96)
  %113 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %77, <32 x float> %110, <32 x float> %97)
  %114 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %110, <32 x float> %98)
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %110, <32 x float> %99)
  %116 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %110, <32 x float> %100)
  %117 = add nsw i64 %44, 4096
  %118 = getelementptr inbounds float, float* %4, i64 %117
  %119 = load float, float* %118, align 4, !tbaa !454
  %120 = insertelement <32 x float> undef, float %119, i32 0
  %121 = shufflevector <32 x float> %120, <32 x float> undef, <32 x i32> zeroinitializer
  %122 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %121, <32 x float> %110, <32 x float> %106)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %123 = mul nsw i32 %31, 4608
  %124 = add nsw i32 %123, 4608
  %125 = add nsw i64 %34, 49152
  %126 = sext i32 %124 to i64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %127 = phi <32 x float> [ %122, %for_end6 ], [ %212, %for_body5.1 ]
  %128 = phi <32 x float> [ %116, %for_end6 ], [ %206, %for_body5.1 ]
  %129 = phi <32 x float> [ %115, %for_end6 ], [ %205, %for_body5.1 ]
  %130 = phi <32 x float> [ %114, %for_end6 ], [ %204, %for_body5.1 ]
  %131 = phi <32 x float> [ %113, %for_end6 ], [ %203, %for_body5.1 ]
  %132 = phi <32 x float> [ %112, %for_end6 ], [ %202, %for_body5.1 ]
  %133 = phi <32 x float> [ %111, %for_end6 ], [ %201, %for_body5.1 ]
  %134 = add nsw i64 %indvars.iv.1, %126
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = load float, float* %135, align 4, !tbaa !454
  %137 = insertelement <32 x float> undef, float %136, i32 0
  %138 = shufflevector <32 x float> %137, <32 x float> undef, <32 x i32> zeroinitializer
  %139 = shl nsw i64 %indvars.iv.1, 5
  %140 = add nsw i64 %125, %139
  %141 = getelementptr inbounds float, float* %7, i64 %140
  %142 = bitcast float* %141 to <32 x float>*
  %143 = load <32 x float>, <32 x float>* %142, align 64, !tbaa !478
  %144 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %138, <32 x float> %143, <32 x float> %133)
  %145 = add nsw i64 %134, 512
  %146 = getelementptr inbounds float, float* %4, i64 %145
  %147 = load float, float* %146, align 4, !tbaa !454
  %148 = insertelement <32 x float> undef, float %147, i32 0
  %149 = shufflevector <32 x float> %148, <32 x float> undef, <32 x i32> zeroinitializer
  %150 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %149, <32 x float> %143, <32 x float> %132)
  %151 = add nsw i64 %134, 1024
  %152 = getelementptr inbounds float, float* %4, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !454
  %154 = insertelement <32 x float> undef, float %153, i32 0
  %155 = shufflevector <32 x float> %154, <32 x float> undef, <32 x i32> zeroinitializer
  %156 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %143, <32 x float> %131)
  %157 = add nsw i64 %134, 1536
  %158 = getelementptr inbounds float, float* %4, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !454
  %160 = insertelement <32 x float> undef, float %159, i32 0
  %161 = shufflevector <32 x float> %160, <32 x float> undef, <32 x i32> zeroinitializer
  %162 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %143, <32 x float> %130)
  %163 = add nsw i64 %134, 2048
  %164 = getelementptr inbounds float, float* %4, i64 %163
  %165 = load float, float* %164, align 4, !tbaa !454
  %166 = insertelement <32 x float> undef, float %165, i32 0
  %167 = shufflevector <32 x float> %166, <32 x float> undef, <32 x i32> zeroinitializer
  %168 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %143, <32 x float> %129)
  %169 = add nsw i64 %134, 2560
  %170 = getelementptr inbounds float, float* %4, i64 %169
  %171 = load float, float* %170, align 4, !tbaa !454
  %172 = insertelement <32 x float> undef, float %171, i32 0
  %173 = shufflevector <32 x float> %172, <32 x float> undef, <32 x i32> zeroinitializer
  %174 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %143, <32 x float> %128)
  %175 = add nsw i64 %134, 3072
  %176 = getelementptr inbounds float, float* %4, i64 %175
  %177 = load float, float* %176, align 4, !tbaa !454
  %178 = insertelement <32 x float> undef, float %177, i32 0
  %179 = shufflevector <32 x float> %178, <32 x float> undef, <32 x i32> zeroinitializer
  %180 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %143, <32 x float> %127)
  %181 = add nsw i64 %140, 16384
  %182 = getelementptr inbounds float, float* %7, i64 %181
  %183 = bitcast float* %182 to <32 x float>*
  %184 = load <32 x float>, <32 x float>* %183, align 64, !tbaa !478
  %185 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %149, <32 x float> %184, <32 x float> %144)
  %186 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %184, <32 x float> %150)
  %187 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %184, <32 x float> %156)
  %188 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %184, <32 x float> %162)
  %189 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %184, <32 x float> %168)
  %190 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %184, <32 x float> %174)
  %191 = add nsw i64 %134, 3584
  %192 = getelementptr inbounds float, float* %4, i64 %191
  %193 = load float, float* %192, align 4, !tbaa !454
  %194 = insertelement <32 x float> undef, float %193, i32 0
  %195 = shufflevector <32 x float> %194, <32 x float> undef, <32 x i32> zeroinitializer
  %196 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %195, <32 x float> %184, <32 x float> %180)
  %197 = add nsw i64 %140, 32768
  %198 = getelementptr inbounds float, float* %7, i64 %197
  %199 = bitcast float* %198 to <32 x float>*
  %200 = load <32 x float>, <32 x float>* %199, align 64, !tbaa !478
  %201 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %200, <32 x float> %185)
  %202 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %161, <32 x float> %200, <32 x float> %186)
  %203 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %167, <32 x float> %200, <32 x float> %187)
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %173, <32 x float> %200, <32 x float> %188)
  %205 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %200, <32 x float> %189)
  %206 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %195, <32 x float> %200, <32 x float> %190)
  %207 = add nsw i64 %134, 4096
  %208 = getelementptr inbounds float, float* %4, i64 %207
  %209 = load float, float* %208, align 4, !tbaa !454
  %210 = insertelement <32 x float> undef, float %209, i32 0
  %211 = shufflevector <32 x float> %210, <32 x float> undef, <32 x i32> zeroinitializer
  %212 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %211, <32 x float> %200, <32 x float> %196)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %213 = mul nsw i32 %31, 4608
  %214 = add nsw i32 %213, 9216
  %215 = add nsw i64 %34, 98304
  %216 = sext i32 %214 to i64
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %217 = phi <32 x float> [ %212, %for_end6.1 ], [ %302, %for_body5.2 ]
  %218 = phi <32 x float> [ %206, %for_end6.1 ], [ %296, %for_body5.2 ]
  %219 = phi <32 x float> [ %205, %for_end6.1 ], [ %295, %for_body5.2 ]
  %220 = phi <32 x float> [ %204, %for_end6.1 ], [ %294, %for_body5.2 ]
  %221 = phi <32 x float> [ %203, %for_end6.1 ], [ %293, %for_body5.2 ]
  %222 = phi <32 x float> [ %202, %for_end6.1 ], [ %292, %for_body5.2 ]
  %223 = phi <32 x float> [ %201, %for_end6.1 ], [ %291, %for_body5.2 ]
  %224 = add nsw i64 %indvars.iv.2, %216
  %225 = getelementptr inbounds float, float* %4, i64 %224
  %226 = load float, float* %225, align 4, !tbaa !454
  %227 = insertelement <32 x float> undef, float %226, i32 0
  %228 = shufflevector <32 x float> %227, <32 x float> undef, <32 x i32> zeroinitializer
  %229 = shl nsw i64 %indvars.iv.2, 5
  %230 = add nsw i64 %215, %229
  %231 = getelementptr inbounds float, float* %7, i64 %230
  %232 = bitcast float* %231 to <32 x float>*
  %233 = load <32 x float>, <32 x float>* %232, align 64, !tbaa !478
  %234 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %228, <32 x float> %233, <32 x float> %223)
  %235 = add nsw i64 %224, 512
  %236 = getelementptr inbounds float, float* %4, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !454
  %238 = insertelement <32 x float> undef, float %237, i32 0
  %239 = shufflevector <32 x float> %238, <32 x float> undef, <32 x i32> zeroinitializer
  %240 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %239, <32 x float> %233, <32 x float> %222)
  %241 = add nsw i64 %224, 1024
  %242 = getelementptr inbounds float, float* %4, i64 %241
  %243 = load float, float* %242, align 4, !tbaa !454
  %244 = insertelement <32 x float> undef, float %243, i32 0
  %245 = shufflevector <32 x float> %244, <32 x float> undef, <32 x i32> zeroinitializer
  %246 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %233, <32 x float> %221)
  %247 = add nsw i64 %224, 1536
  %248 = getelementptr inbounds float, float* %4, i64 %247
  %249 = load float, float* %248, align 4, !tbaa !454
  %250 = insertelement <32 x float> undef, float %249, i32 0
  %251 = shufflevector <32 x float> %250, <32 x float> undef, <32 x i32> zeroinitializer
  %252 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %233, <32 x float> %220)
  %253 = add nsw i64 %224, 2048
  %254 = getelementptr inbounds float, float* %4, i64 %253
  %255 = load float, float* %254, align 4, !tbaa !454
  %256 = insertelement <32 x float> undef, float %255, i32 0
  %257 = shufflevector <32 x float> %256, <32 x float> undef, <32 x i32> zeroinitializer
  %258 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %233, <32 x float> %219)
  %259 = add nsw i64 %224, 2560
  %260 = getelementptr inbounds float, float* %4, i64 %259
  %261 = load float, float* %260, align 4, !tbaa !454
  %262 = insertelement <32 x float> undef, float %261, i32 0
  %263 = shufflevector <32 x float> %262, <32 x float> undef, <32 x i32> zeroinitializer
  %264 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %263, <32 x float> %233, <32 x float> %218)
  %265 = add nsw i64 %224, 3072
  %266 = getelementptr inbounds float, float* %4, i64 %265
  %267 = load float, float* %266, align 4, !tbaa !454
  %268 = insertelement <32 x float> undef, float %267, i32 0
  %269 = shufflevector <32 x float> %268, <32 x float> undef, <32 x i32> zeroinitializer
  %270 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %233, <32 x float> %217)
  %271 = add nsw i64 %230, 16384
  %272 = getelementptr inbounds float, float* %7, i64 %271
  %273 = bitcast float* %272 to <32 x float>*
  %274 = load <32 x float>, <32 x float>* %273, align 64, !tbaa !478
  %275 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %239, <32 x float> %274, <32 x float> %234)
  %276 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %274, <32 x float> %240)
  %277 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %274, <32 x float> %246)
  %278 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %274, <32 x float> %252)
  %279 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %263, <32 x float> %274, <32 x float> %258)
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %274, <32 x float> %264)
  %281 = add nsw i64 %224, 3584
  %282 = getelementptr inbounds float, float* %4, i64 %281
  %283 = load float, float* %282, align 4, !tbaa !454
  %284 = insertelement <32 x float> undef, float %283, i32 0
  %285 = shufflevector <32 x float> %284, <32 x float> undef, <32 x i32> zeroinitializer
  %286 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %285, <32 x float> %274, <32 x float> %270)
  %287 = add nsw i64 %230, 32768
  %288 = getelementptr inbounds float, float* %7, i64 %287
  %289 = bitcast float* %288 to <32 x float>*
  %290 = load <32 x float>, <32 x float>* %289, align 64, !tbaa !478
  %291 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %290, <32 x float> %275)
  %292 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %290, <32 x float> %276)
  %293 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %290, <32 x float> %277)
  %294 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %263, <32 x float> %290, <32 x float> %278)
  %295 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %269, <32 x float> %290, <32 x float> %279)
  %296 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %285, <32 x float> %290, <32 x float> %280)
  %297 = add nsw i64 %224, 4096
  %298 = getelementptr inbounds float, float* %4, i64 %297
  %299 = load float, float* %298, align 4, !tbaa !454
  %300 = insertelement <32 x float> undef, float %299, i32 0
  %301 = shufflevector <32 x float> %300, <32 x float> undef, <32 x i32> zeroinitializer
  %302 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %301, <32 x float> %290, <32 x float> %286)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  %303 = mul nsw i64 %indvars.iv46, 224
  %304 = shl nsw i32 %32, 5
  %305 = sext i32 %304 to i64
  %306 = getelementptr inbounds float, float* %13, i64 %305
  %307 = bitcast float* %306 to <32 x float>*
  %308 = load <32 x float>, <32 x float>* %307, align 64, !tbaa !481
  %309 = fadd <32 x float> %308, %291
  %310 = fcmp ogt <32 x float> %309, zeroinitializer
  %311 = select <32 x i1> %310, <32 x float> %309, <32 x float> zeroinitializer
  %312 = getelementptr inbounds float, float* %10, i64 %303
  %313 = bitcast float* %312 to <32 x float>*
  store <32 x float> %311, <32 x float>* %313, align 64, !tbaa !484
  %314 = add nsw i64 %303, 32
  %315 = fadd <32 x float> %308, %292
  %316 = fcmp ogt <32 x float> %315, zeroinitializer
  %317 = select <32 x i1> %316, <32 x float> %315, <32 x float> zeroinitializer
  %318 = getelementptr inbounds float, float* %10, i64 %314
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %317, <32 x float>* %319, align 64, !tbaa !484
  %320 = add nsw i64 %303, 64
  %321 = fadd <32 x float> %308, %293
  %322 = fcmp ogt <32 x float> %321, zeroinitializer
  %323 = select <32 x i1> %322, <32 x float> %321, <32 x float> zeroinitializer
  %324 = getelementptr inbounds float, float* %10, i64 %320
  %325 = bitcast float* %324 to <32 x float>*
  store <32 x float> %323, <32 x float>* %325, align 64, !tbaa !484
  %326 = add nsw i64 %303, 96
  %327 = fadd <32 x float> %308, %294
  %328 = fcmp ogt <32 x float> %327, zeroinitializer
  %329 = select <32 x i1> %328, <32 x float> %327, <32 x float> zeroinitializer
  %330 = getelementptr inbounds float, float* %10, i64 %326
  %331 = bitcast float* %330 to <32 x float>*
  store <32 x float> %329, <32 x float>* %331, align 64, !tbaa !484
  %332 = add nsw i64 %303, 128
  %333 = fadd <32 x float> %308, %295
  %334 = fcmp ogt <32 x float> %333, zeroinitializer
  %335 = select <32 x i1> %334, <32 x float> %333, <32 x float> zeroinitializer
  %336 = getelementptr inbounds float, float* %10, i64 %332
  %337 = bitcast float* %336 to <32 x float>*
  store <32 x float> %335, <32 x float>* %337, align 64, !tbaa !484
  %338 = add nsw i64 %303, 160
  %339 = fadd <32 x float> %308, %296
  %340 = fcmp ogt <32 x float> %339, zeroinitializer
  %341 = select <32 x i1> %340, <32 x float> %339, <32 x float> zeroinitializer
  %342 = getelementptr inbounds float, float* %10, i64 %338
  %343 = bitcast float* %342 to <32 x float>*
  store <32 x float> %341, <32 x float>* %343, align 64, !tbaa !484
  %344 = add nsw i64 %303, 192
  %345 = fadd <32 x float> %308, %302
  %346 = fcmp ogt <32 x float> %345, zeroinitializer
  %347 = select <32 x i1> %346, <32 x float> %345, <32 x float> zeroinitializer
  %348 = getelementptr inbounds float, float* %10, i64 %344
  %349 = bitcast float* %348 to <32 x float>*
  store <32 x float> %347, <32 x float>* %349, align 64, !tbaa !484
  %indvars.iv.next47 = add nsw i64 %indvars.iv46, 1
  %350 = icmp slt i64 %indvars.iv.next47, %29
  br i1 %350, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !487 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !489, metadata !DIExpression()), !dbg !492
  call void @llvm.dbg.value(metadata i8* %1, metadata !490, metadata !DIExpression()), !dbg !492
  call void @llvm.dbg.value(metadata i32 %2, metadata !491, metadata !DIExpression()), !dbg !492
  %3 = bitcast i8* %0 to %1**, !dbg !492
  %4 = load %1*, %1** %3, align 8, !dbg !492
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !492
  %6 = bitcast i8* %5 to %1**, !dbg !492
  %7 = load %1*, %1** %6, align 8, !dbg !492
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !492
  %9 = bitcast i8* %8 to %1**, !dbg !492
  %10 = load %1*, %1** %9, align 8, !dbg !492
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !492
  %12 = bitcast i8* %11 to %1**, !dbg !492
  %13 = load %1*, %1** %12, align 8, !dbg !492
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !492
  %15 = bitcast i8* %14 to %1**, !dbg !492
  %16 = load %1*, %1** %15, align 8, !dbg !492
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !492
  %18 = bitcast i8* %17 to %1**, !dbg !492
  %19 = load %1*, %1** %18, align 8, !dbg !492
  %20 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !492
  %21 = load i8*, i8** %20, align 8, !dbg !492
  %22 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !492
  %23 = load i32, i32* %22, align 4, !dbg !492
  %24 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !492
  %25 = load i8*, i8** %24, align 8, !dbg !492
  %26 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !492
  %27 = load i8*, i8** %26, align 8, !dbg !492
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !492
  %29 = load i8*, i8** %28, align 8, !dbg !492
  %30 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !492
  %31 = load i8*, i8** %30, align 8, !dbg !492
  %32 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !492
  %33 = load i8*, i8** %32, align 8, !dbg !492
  %34 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_compute_(i8* %21, i8* %25, i8* %33, i8* %27, i8* %29, i8* %31, i32 %23), !dbg !492
  ret i32 %34, !dbg !492
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %32, align 8
  %8 = getelementptr inbounds %32, %32* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %32, %32* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %32, %32* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %32, %32* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %32, %32* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %32, %32* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %32, %32* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %32* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.28, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.28(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 27
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 28
  %30 = select i1 %29, i32 %28, i32 28
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 28
  %33 = select i1 %32, i32 %31, i32 28
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv53 = phi i64 [ %37, %for_body.lr.ph ], [ %indvars.iv.next54, %for_end3 ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %40 = tail call i8* %39(i32 1, i32 %22, i64 7168, i32 2, i32 32)
  %41 = bitcast i8* %40 to float*
  %42 = trunc i64 %indvars.iv53 to i32
  %43 = srem i32 %42, 7
  %44 = mul nsw i32 %43, 14336
  %45 = sdiv i32 %42, 7
  %46 = shl i32 %45, 16
  %47 = sext i32 %46 to i64
  %48 = sext i32 %44 to i64
  %49 = or i64 %47, 32768
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end9.1, %for_body
  %indvars.iv40 = phi i64 [ 0, %for_body ], [ %indvars.iv.next41, %for_end9.1 ]
  %50 = shl nsw i64 %indvars.iv40, 7
  %51 = getelementptr inbounds float, float* %41, i64 %50
  %52 = bitcast float* %51 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %52, align 64, !tbaa !493
  %53 = or i64 %50, 64
  %54 = getelementptr inbounds float, float* %41, i64 %53
  %55 = bitcast float* %54 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %55, align 64, !tbaa !493
  %56 = add nuw nsw i64 %50, 896
  %57 = getelementptr inbounds float, float* %41, i64 %56
  %58 = bitcast float* %57 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %58, align 64, !tbaa !493
  %59 = add nuw nsw i64 %50, 960
  %60 = getelementptr inbounds float, float* %41, i64 %59
  %61 = bitcast float* %60 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %61, align 64, !tbaa !493
  %62 = shl i64 %indvars.iv40, 10
  %63 = add nsw i64 %62, %48
  br label %for_body8

for_end3:                                         ; preds = %for_end9.1
  %64 = mul nsw i64 %indvars.iv53, 1792
  %65 = shl nsw i32 %45, 6
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds float, float* %13, i64 %66
  %68 = bitcast float* %67 to <64 x float>*
  %69 = load <64 x float>, <64 x float>* %68, align 64, !tbaa !496
  %70 = getelementptr inbounds float, float* %16, i64 %66
  %71 = bitcast float* %70 to <64 x float>*
  %72 = load <64 x float>, <64 x float>* %71, align 64, !tbaa !499
  %73 = getelementptr inbounds float, float* %19, i64 %66
  %74 = bitcast float* %73 to <64 x float>*
  %75 = load <64 x float>, <64 x float>* %74, align 64, !tbaa !502
  %76 = bitcast i8* %40 to <64 x float>*
  %77 = load <64 x float>, <64 x float>* %76, align 64, !tbaa !493
  %78 = fadd <64 x float> %69, %77
  %79 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %78, <64 x float> %72, <64 x float> %75)
  %80 = fcmp ogt <64 x float> %79, zeroinitializer
  %81 = select <64 x i1> %80, <64 x float> %79, <64 x float> zeroinitializer
  %82 = getelementptr inbounds float, float* %10, i64 %64
  %83 = bitcast float* %82 to <64 x float>*
  store <64 x float> %81, <64 x float>* %83, align 64, !tbaa !505
  %84 = getelementptr inbounds i8, i8* %40, i64 256
  %85 = bitcast i8* %84 to <64 x float>*
  %86 = load <64 x float>, <64 x float>* %85, align 64, !tbaa !493
  %87 = fadd <64 x float> %69, %86
  %88 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %87, <64 x float> %72, <64 x float> %75)
  %89 = fcmp ogt <64 x float> %88, zeroinitializer
  %90 = select <64 x i1> %89, <64 x float> %88, <64 x float> zeroinitializer
  %91 = mul i64 %indvars.iv53, 7696581394432
  %sext = ashr exact i64 %91, 32
  %92 = or i64 %sext, 64
  %93 = getelementptr inbounds float, float* %10, i64 %92
  %94 = bitcast float* %93 to <64 x float>*
  store <64 x float> %90, <64 x float>* %94, align 64, !tbaa !505
  %95 = getelementptr inbounds i8, i8* %40, i64 3584
  %96 = bitcast i8* %95 to <64 x float>*
  %97 = load <64 x float>, <64 x float>* %96, align 64, !tbaa !493
  %98 = fadd <64 x float> %69, %97
  %99 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %98, <64 x float> %72, <64 x float> %75)
  %100 = fcmp ogt <64 x float> %99, zeroinitializer
  %101 = select <64 x i1> %100, <64 x float> %99, <64 x float> zeroinitializer
  %102 = mul i64 %indvars.iv53, 7696581394432
  %sext68 = add i64 %102, 3848290697216
  %103 = ashr exact i64 %sext68, 32
  %104 = getelementptr inbounds float, float* %10, i64 %103
  %105 = bitcast float* %104 to <64 x float>*
  store <64 x float> %101, <64 x float>* %105, align 64, !tbaa !505
  %106 = getelementptr inbounds i8, i8* %40, i64 3840
  %107 = bitcast i8* %106 to <64 x float>*
  %108 = load <64 x float>, <64 x float>* %107, align 64, !tbaa !493
  %109 = fadd <64 x float> %69, %108
  %110 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %109, <64 x float> %72, <64 x float> %75)
  %111 = fcmp ogt <64 x float> %110, zeroinitializer
  %112 = select <64 x i1> %111, <64 x float> %110, <64 x float> zeroinitializer
  %113 = mul i64 %indvars.iv53, 7696581394432
  %sext55 = add i64 %113, 4123168604160
  %114 = ashr exact i64 %sext55, 32
  %115 = getelementptr inbounds float, float* %10, i64 %114
  %116 = bitcast float* %115 to <64 x float>*
  store <64 x float> %112, <64 x float>* %116, align 64, !tbaa !505
  %117 = getelementptr inbounds i8, i8* %40, i64 512
  %118 = bitcast i8* %117 to <64 x float>*
  %119 = load <64 x float>, <64 x float>* %118, align 64, !tbaa !493
  %120 = fadd <64 x float> %69, %119
  %121 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %120, <64 x float> %72, <64 x float> %75)
  %122 = fcmp ogt <64 x float> %121, zeroinitializer
  %123 = select <64 x i1> %122, <64 x float> %121, <64 x float> zeroinitializer
  %124 = mul i64 %indvars.iv53, 7696581394432
  %sext69 = ashr exact i64 %124, 32
  %125 = or i64 %sext69, 128
  %126 = getelementptr inbounds float, float* %10, i64 %125
  %127 = bitcast float* %126 to <64 x float>*
  store <64 x float> %123, <64 x float>* %127, align 64, !tbaa !505
  %128 = getelementptr inbounds i8, i8* %40, i64 768
  %129 = bitcast i8* %128 to <64 x float>*
  %130 = load <64 x float>, <64 x float>* %129, align 64, !tbaa !493
  %131 = fadd <64 x float> %69, %130
  %132 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %131, <64 x float> %72, <64 x float> %75)
  %133 = fcmp ogt <64 x float> %132, zeroinitializer
  %134 = select <64 x i1> %133, <64 x float> %132, <64 x float> zeroinitializer
  %135 = mul i64 %indvars.iv53, 7696581394432
  %sext56 = ashr exact i64 %135, 32
  %136 = or i64 %sext56, 192
  %137 = getelementptr inbounds float, float* %10, i64 %136
  %138 = bitcast float* %137 to <64 x float>*
  store <64 x float> %134, <64 x float>* %138, align 64, !tbaa !505
  %139 = getelementptr inbounds i8, i8* %40, i64 4096
  %140 = bitcast i8* %139 to <64 x float>*
  %141 = load <64 x float>, <64 x float>* %140, align 64, !tbaa !493
  %142 = fadd <64 x float> %69, %141
  %143 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %142, <64 x float> %72, <64 x float> %75)
  %144 = fcmp ogt <64 x float> %143, zeroinitializer
  %145 = select <64 x i1> %144, <64 x float> %143, <64 x float> zeroinitializer
  %146 = mul i64 %indvars.iv53, 7696581394432
  %sext70 = add i64 %146, 4398046511104
  %147 = ashr exact i64 %sext70, 32
  %148 = getelementptr inbounds float, float* %10, i64 %147
  %149 = bitcast float* %148 to <64 x float>*
  store <64 x float> %145, <64 x float>* %149, align 64, !tbaa !505
  %150 = getelementptr inbounds i8, i8* %40, i64 4352
  %151 = bitcast i8* %150 to <64 x float>*
  %152 = load <64 x float>, <64 x float>* %151, align 64, !tbaa !493
  %153 = fadd <64 x float> %69, %152
  %154 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %153, <64 x float> %72, <64 x float> %75)
  %155 = fcmp ogt <64 x float> %154, zeroinitializer
  %156 = select <64 x i1> %155, <64 x float> %154, <64 x float> zeroinitializer
  %157 = mul i64 %indvars.iv53, 7696581394432
  %sext57 = add i64 %157, 4672924418048
  %158 = ashr exact i64 %sext57, 32
  %159 = getelementptr inbounds float, float* %10, i64 %158
  %160 = bitcast float* %159 to <64 x float>*
  store <64 x float> %156, <64 x float>* %160, align 64, !tbaa !505
  %161 = getelementptr inbounds i8, i8* %40, i64 1024
  %162 = bitcast i8* %161 to <64 x float>*
  %163 = load <64 x float>, <64 x float>* %162, align 64, !tbaa !493
  %164 = fadd <64 x float> %69, %163
  %165 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %164, <64 x float> %72, <64 x float> %75)
  %166 = fcmp ogt <64 x float> %165, zeroinitializer
  %167 = select <64 x i1> %166, <64 x float> %165, <64 x float> zeroinitializer
  %168 = mul i64 %indvars.iv53, 7696581394432
  %sext71 = add i64 %168, 1099511627776
  %169 = ashr exact i64 %sext71, 32
  %170 = getelementptr inbounds float, float* %10, i64 %169
  %171 = bitcast float* %170 to <64 x float>*
  store <64 x float> %167, <64 x float>* %171, align 64, !tbaa !505
  %172 = getelementptr inbounds i8, i8* %40, i64 1280
  %173 = bitcast i8* %172 to <64 x float>*
  %174 = load <64 x float>, <64 x float>* %173, align 64, !tbaa !493
  %175 = fadd <64 x float> %69, %174
  %176 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %175, <64 x float> %72, <64 x float> %75)
  %177 = fcmp ogt <64 x float> %176, zeroinitializer
  %178 = select <64 x i1> %177, <64 x float> %176, <64 x float> zeroinitializer
  %179 = mul i64 %indvars.iv53, 7696581394432
  %sext58 = add i64 %179, 1374389534720
  %180 = ashr exact i64 %sext58, 32
  %181 = getelementptr inbounds float, float* %10, i64 %180
  %182 = bitcast float* %181 to <64 x float>*
  store <64 x float> %178, <64 x float>* %182, align 64, !tbaa !505
  %183 = getelementptr inbounds i8, i8* %40, i64 4608
  %184 = bitcast i8* %183 to <64 x float>*
  %185 = load <64 x float>, <64 x float>* %184, align 64, !tbaa !493
  %186 = fadd <64 x float> %69, %185
  %187 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %186, <64 x float> %72, <64 x float> %75)
  %188 = fcmp ogt <64 x float> %187, zeroinitializer
  %189 = select <64 x i1> %188, <64 x float> %187, <64 x float> zeroinitializer
  %190 = mul i64 %indvars.iv53, 7696581394432
  %sext72 = add i64 %190, 4947802324992
  %191 = ashr exact i64 %sext72, 32
  %192 = getelementptr inbounds float, float* %10, i64 %191
  %193 = bitcast float* %192 to <64 x float>*
  store <64 x float> %189, <64 x float>* %193, align 64, !tbaa !505
  %194 = getelementptr inbounds i8, i8* %40, i64 4864
  %195 = bitcast i8* %194 to <64 x float>*
  %196 = load <64 x float>, <64 x float>* %195, align 64, !tbaa !493
  %197 = fadd <64 x float> %69, %196
  %198 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %197, <64 x float> %72, <64 x float> %75)
  %199 = fcmp ogt <64 x float> %198, zeroinitializer
  %200 = select <64 x i1> %199, <64 x float> %198, <64 x float> zeroinitializer
  %201 = mul i64 %indvars.iv53, 7696581394432
  %sext59 = add i64 %201, 5222680231936
  %202 = ashr exact i64 %sext59, 32
  %203 = getelementptr inbounds float, float* %10, i64 %202
  %204 = bitcast float* %203 to <64 x float>*
  store <64 x float> %200, <64 x float>* %204, align 64, !tbaa !505
  %205 = getelementptr inbounds i8, i8* %40, i64 1536
  %206 = bitcast i8* %205 to <64 x float>*
  %207 = load <64 x float>, <64 x float>* %206, align 64, !tbaa !493
  %208 = fadd <64 x float> %69, %207
  %209 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %208, <64 x float> %72, <64 x float> %75)
  %210 = fcmp ogt <64 x float> %209, zeroinitializer
  %211 = select <64 x i1> %210, <64 x float> %209, <64 x float> zeroinitializer
  %212 = mul i64 %indvars.iv53, 7696581394432
  %sext73 = add i64 %212, 1649267441664
  %213 = ashr exact i64 %sext73, 32
  %214 = getelementptr inbounds float, float* %10, i64 %213
  %215 = bitcast float* %214 to <64 x float>*
  store <64 x float> %211, <64 x float>* %215, align 64, !tbaa !505
  %216 = getelementptr inbounds i8, i8* %40, i64 1792
  %217 = bitcast i8* %216 to <64 x float>*
  %218 = load <64 x float>, <64 x float>* %217, align 64, !tbaa !493
  %219 = fadd <64 x float> %69, %218
  %220 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %219, <64 x float> %72, <64 x float> %75)
  %221 = fcmp ogt <64 x float> %220, zeroinitializer
  %222 = select <64 x i1> %221, <64 x float> %220, <64 x float> zeroinitializer
  %223 = mul i64 %indvars.iv53, 7696581394432
  %sext60 = add i64 %223, 1924145348608
  %224 = ashr exact i64 %sext60, 32
  %225 = getelementptr inbounds float, float* %10, i64 %224
  %226 = bitcast float* %225 to <64 x float>*
  store <64 x float> %222, <64 x float>* %226, align 64, !tbaa !505
  %227 = getelementptr inbounds i8, i8* %40, i64 5120
  %228 = bitcast i8* %227 to <64 x float>*
  %229 = load <64 x float>, <64 x float>* %228, align 64, !tbaa !493
  %230 = fadd <64 x float> %69, %229
  %231 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %230, <64 x float> %72, <64 x float> %75)
  %232 = fcmp ogt <64 x float> %231, zeroinitializer
  %233 = select <64 x i1> %232, <64 x float> %231, <64 x float> zeroinitializer
  %234 = mul i64 %indvars.iv53, 7696581394432
  %sext74 = add i64 %234, 5497558138880
  %235 = ashr exact i64 %sext74, 32
  %236 = getelementptr inbounds float, float* %10, i64 %235
  %237 = bitcast float* %236 to <64 x float>*
  store <64 x float> %233, <64 x float>* %237, align 64, !tbaa !505
  %238 = getelementptr inbounds i8, i8* %40, i64 5376
  %239 = bitcast i8* %238 to <64 x float>*
  %240 = load <64 x float>, <64 x float>* %239, align 64, !tbaa !493
  %241 = fadd <64 x float> %69, %240
  %242 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %241, <64 x float> %72, <64 x float> %75)
  %243 = fcmp ogt <64 x float> %242, zeroinitializer
  %244 = select <64 x i1> %243, <64 x float> %242, <64 x float> zeroinitializer
  %245 = mul i64 %indvars.iv53, 7696581394432
  %sext61 = add i64 %245, 5772436045824
  %246 = ashr exact i64 %sext61, 32
  %247 = getelementptr inbounds float, float* %10, i64 %246
  %248 = bitcast float* %247 to <64 x float>*
  store <64 x float> %244, <64 x float>* %248, align 64, !tbaa !505
  %249 = getelementptr inbounds i8, i8* %40, i64 2048
  %250 = bitcast i8* %249 to <64 x float>*
  %251 = load <64 x float>, <64 x float>* %250, align 64, !tbaa !493
  %252 = fadd <64 x float> %69, %251
  %253 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %252, <64 x float> %72, <64 x float> %75)
  %254 = fcmp ogt <64 x float> %253, zeroinitializer
  %255 = select <64 x i1> %254, <64 x float> %253, <64 x float> zeroinitializer
  %256 = mul i64 %indvars.iv53, 7696581394432
  %sext75 = add i64 %256, 2199023255552
  %257 = ashr exact i64 %sext75, 32
  %258 = getelementptr inbounds float, float* %10, i64 %257
  %259 = bitcast float* %258 to <64 x float>*
  store <64 x float> %255, <64 x float>* %259, align 64, !tbaa !505
  %260 = getelementptr inbounds i8, i8* %40, i64 2304
  %261 = bitcast i8* %260 to <64 x float>*
  %262 = load <64 x float>, <64 x float>* %261, align 64, !tbaa !493
  %263 = fadd <64 x float> %69, %262
  %264 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %263, <64 x float> %72, <64 x float> %75)
  %265 = fcmp ogt <64 x float> %264, zeroinitializer
  %266 = select <64 x i1> %265, <64 x float> %264, <64 x float> zeroinitializer
  %267 = mul i64 %indvars.iv53, 7696581394432
  %sext62 = add i64 %267, 2473901162496
  %268 = ashr exact i64 %sext62, 32
  %269 = getelementptr inbounds float, float* %10, i64 %268
  %270 = bitcast float* %269 to <64 x float>*
  store <64 x float> %266, <64 x float>* %270, align 64, !tbaa !505
  %271 = getelementptr inbounds i8, i8* %40, i64 5632
  %272 = bitcast i8* %271 to <64 x float>*
  %273 = load <64 x float>, <64 x float>* %272, align 64, !tbaa !493
  %274 = fadd <64 x float> %69, %273
  %275 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %274, <64 x float> %72, <64 x float> %75)
  %276 = fcmp ogt <64 x float> %275, zeroinitializer
  %277 = select <64 x i1> %276, <64 x float> %275, <64 x float> zeroinitializer
  %278 = mul i64 %indvars.iv53, 7696581394432
  %sext76 = add i64 %278, 6047313952768
  %279 = ashr exact i64 %sext76, 32
  %280 = getelementptr inbounds float, float* %10, i64 %279
  %281 = bitcast float* %280 to <64 x float>*
  store <64 x float> %277, <64 x float>* %281, align 64, !tbaa !505
  %282 = getelementptr inbounds i8, i8* %40, i64 5888
  %283 = bitcast i8* %282 to <64 x float>*
  %284 = load <64 x float>, <64 x float>* %283, align 64, !tbaa !493
  %285 = fadd <64 x float> %69, %284
  %286 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %285, <64 x float> %72, <64 x float> %75)
  %287 = fcmp ogt <64 x float> %286, zeroinitializer
  %288 = select <64 x i1> %287, <64 x float> %286, <64 x float> zeroinitializer
  %289 = mul i64 %indvars.iv53, 7696581394432
  %sext63 = add i64 %289, 6322191859712
  %290 = ashr exact i64 %sext63, 32
  %291 = getelementptr inbounds float, float* %10, i64 %290
  %292 = bitcast float* %291 to <64 x float>*
  store <64 x float> %288, <64 x float>* %292, align 64, !tbaa !505
  %293 = getelementptr inbounds i8, i8* %40, i64 2560
  %294 = bitcast i8* %293 to <64 x float>*
  %295 = load <64 x float>, <64 x float>* %294, align 64, !tbaa !493
  %296 = fadd <64 x float> %69, %295
  %297 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %296, <64 x float> %72, <64 x float> %75)
  %298 = fcmp ogt <64 x float> %297, zeroinitializer
  %299 = select <64 x i1> %298, <64 x float> %297, <64 x float> zeroinitializer
  %300 = mul i64 %indvars.iv53, 7696581394432
  %sext77 = add i64 %300, 2748779069440
  %301 = ashr exact i64 %sext77, 32
  %302 = getelementptr inbounds float, float* %10, i64 %301
  %303 = bitcast float* %302 to <64 x float>*
  store <64 x float> %299, <64 x float>* %303, align 64, !tbaa !505
  %304 = getelementptr inbounds i8, i8* %40, i64 2816
  %305 = bitcast i8* %304 to <64 x float>*
  %306 = load <64 x float>, <64 x float>* %305, align 64, !tbaa !493
  %307 = fadd <64 x float> %69, %306
  %308 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %307, <64 x float> %72, <64 x float> %75)
  %309 = fcmp ogt <64 x float> %308, zeroinitializer
  %310 = select <64 x i1> %309, <64 x float> %308, <64 x float> zeroinitializer
  %311 = mul i64 %indvars.iv53, 7696581394432
  %sext64 = add i64 %311, 3023656976384
  %312 = ashr exact i64 %sext64, 32
  %313 = getelementptr inbounds float, float* %10, i64 %312
  %314 = bitcast float* %313 to <64 x float>*
  store <64 x float> %310, <64 x float>* %314, align 64, !tbaa !505
  %315 = getelementptr inbounds i8, i8* %40, i64 6144
  %316 = bitcast i8* %315 to <64 x float>*
  %317 = load <64 x float>, <64 x float>* %316, align 64, !tbaa !493
  %318 = fadd <64 x float> %69, %317
  %319 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %318, <64 x float> %72, <64 x float> %75)
  %320 = fcmp ogt <64 x float> %319, zeroinitializer
  %321 = select <64 x i1> %320, <64 x float> %319, <64 x float> zeroinitializer
  %322 = mul i64 %indvars.iv53, 7696581394432
  %sext78 = add i64 %322, 6597069766656
  %323 = ashr exact i64 %sext78, 32
  %324 = getelementptr inbounds float, float* %10, i64 %323
  %325 = bitcast float* %324 to <64 x float>*
  store <64 x float> %321, <64 x float>* %325, align 64, !tbaa !505
  %326 = getelementptr inbounds i8, i8* %40, i64 6400
  %327 = bitcast i8* %326 to <64 x float>*
  %328 = load <64 x float>, <64 x float>* %327, align 64, !tbaa !493
  %329 = fadd <64 x float> %69, %328
  %330 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %329, <64 x float> %72, <64 x float> %75)
  %331 = fcmp ogt <64 x float> %330, zeroinitializer
  %332 = select <64 x i1> %331, <64 x float> %330, <64 x float> zeroinitializer
  %333 = mul i64 %indvars.iv53, 7696581394432
  %sext65 = add i64 %333, 6871947673600
  %334 = ashr exact i64 %sext65, 32
  %335 = getelementptr inbounds float, float* %10, i64 %334
  %336 = bitcast float* %335 to <64 x float>*
  store <64 x float> %332, <64 x float>* %336, align 64, !tbaa !505
  %337 = getelementptr inbounds i8, i8* %40, i64 3072
  %338 = bitcast i8* %337 to <64 x float>*
  %339 = load <64 x float>, <64 x float>* %338, align 64, !tbaa !493
  %340 = fadd <64 x float> %69, %339
  %341 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %340, <64 x float> %72, <64 x float> %75)
  %342 = fcmp ogt <64 x float> %341, zeroinitializer
  %343 = select <64 x i1> %342, <64 x float> %341, <64 x float> zeroinitializer
  %344 = mul i64 %indvars.iv53, 7696581394432
  %sext79 = add i64 %344, 3298534883328
  %345 = ashr exact i64 %sext79, 32
  %346 = getelementptr inbounds float, float* %10, i64 %345
  %347 = bitcast float* %346 to <64 x float>*
  store <64 x float> %343, <64 x float>* %347, align 64, !tbaa !505
  %348 = getelementptr inbounds i8, i8* %40, i64 3328
  %349 = bitcast i8* %348 to <64 x float>*
  %350 = load <64 x float>, <64 x float>* %349, align 64, !tbaa !493
  %351 = fadd <64 x float> %69, %350
  %352 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %351, <64 x float> %72, <64 x float> %75)
  %353 = fcmp ogt <64 x float> %352, zeroinitializer
  %354 = select <64 x i1> %353, <64 x float> %352, <64 x float> zeroinitializer
  %355 = mul i64 %indvars.iv53, 7696581394432
  %sext66 = add i64 %355, 3573412790272
  %356 = ashr exact i64 %sext66, 32
  %357 = getelementptr inbounds float, float* %10, i64 %356
  %358 = bitcast float* %357 to <64 x float>*
  store <64 x float> %354, <64 x float>* %358, align 64, !tbaa !505
  %359 = getelementptr inbounds i8, i8* %40, i64 6656
  %360 = bitcast i8* %359 to <64 x float>*
  %361 = load <64 x float>, <64 x float>* %360, align 64, !tbaa !493
  %362 = fadd <64 x float> %69, %361
  %363 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %362, <64 x float> %72, <64 x float> %75)
  %364 = fcmp ogt <64 x float> %363, zeroinitializer
  %365 = select <64 x i1> %364, <64 x float> %363, <64 x float> zeroinitializer
  %366 = mul i64 %indvars.iv53, 7696581394432
  %sext80 = add i64 %366, 7146825580544
  %367 = ashr exact i64 %sext80, 32
  %368 = getelementptr inbounds float, float* %10, i64 %367
  %369 = bitcast float* %368 to <64 x float>*
  store <64 x float> %365, <64 x float>* %369, align 64, !tbaa !505
  %370 = getelementptr inbounds i8, i8* %40, i64 6912
  %371 = bitcast i8* %370 to <64 x float>*
  %372 = load <64 x float>, <64 x float>* %371, align 64, !tbaa !493
  %373 = fadd <64 x float> %69, %372
  %374 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %373, <64 x float> %72, <64 x float> %75)
  %375 = fcmp ogt <64 x float> %374, zeroinitializer
  %376 = select <64 x i1> %375, <64 x float> %374, <64 x float> zeroinitializer
  %377 = mul i64 %indvars.iv53, 7696581394432
  %sext67 = add i64 %377, 7421703487488
  %378 = ashr exact i64 %sext67, 32
  %379 = getelementptr inbounds float, float* %10, i64 %378
  %380 = bitcast float* %379 to <64 x float>*
  store <64 x float> %376, <64 x float>* %380, align 64, !tbaa !505
  %381 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %382 = tail call i32 %381(i32 1, i32 %22, i8* nonnull %40)
  %indvars.iv.next54 = add nsw i64 %indvars.iv53, 1
  %383 = icmp slt i64 %indvars.iv.next54, %38
  br i1 %383, label %for_body, label %for_end, !prof !19

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %384 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %416, %for_body8 ]
  %385 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %410, %for_body8 ]
  %386 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %404, %for_body8 ]
  %387 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %398, %for_body8 ]
  %388 = add nsw i64 %63, %indvars.iv
  %389 = getelementptr inbounds float, float* %4, i64 %388
  %390 = load float, float* %389, align 4, !tbaa !508
  %391 = insertelement <64 x float> undef, float %390, i32 0
  %392 = shufflevector <64 x float> %391, <64 x float> undef, <64 x i32> zeroinitializer
  %393 = shl i64 %indvars.iv, 6
  %394 = add nsw i64 %393, %47
  %395 = getelementptr inbounds float, float* %7, i64 %394
  %396 = bitcast float* %395 to <64 x float>*
  %397 = load <64 x float>, <64 x float>* %396, align 64, !tbaa !511
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %392, <64 x float> %397, <64 x float> %387)
  %399 = add nsw i64 %388, 512
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = load float, float* %400, align 4, !tbaa !508
  %402 = insertelement <64 x float> undef, float %401, i32 0
  %403 = shufflevector <64 x float> %402, <64 x float> undef, <64 x i32> zeroinitializer
  %404 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %403, <64 x float> %397, <64 x float> %386)
  %405 = add nsw i64 %388, 7168
  %406 = getelementptr inbounds float, float* %4, i64 %405
  %407 = load float, float* %406, align 4, !tbaa !508
  %408 = insertelement <64 x float> undef, float %407, i32 0
  %409 = shufflevector <64 x float> %408, <64 x float> undef, <64 x i32> zeroinitializer
  %410 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %409, <64 x float> %397, <64 x float> %385)
  %411 = add nsw i64 %388, 7680
  %412 = getelementptr inbounds float, float* %4, i64 %411
  %413 = load float, float* %412, align 4, !tbaa !508
  %414 = insertelement <64 x float> undef, float %413, i32 0
  %415 = shufflevector <64 x float> %414, <64 x float> undef, <64 x i32> zeroinitializer
  %416 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %415, <64 x float> %397, <64 x float> %384)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %417 = add nsw i64 %63, 100352
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %418 = phi <64 x float> [ %416, %for_end9 ], [ %450, %for_body8.1 ]
  %419 = phi <64 x float> [ %410, %for_end9 ], [ %444, %for_body8.1 ]
  %420 = phi <64 x float> [ %404, %for_end9 ], [ %438, %for_body8.1 ]
  %421 = phi <64 x float> [ %398, %for_end9 ], [ %432, %for_body8.1 ]
  %422 = add nsw i64 %417, %indvars.iv.1
  %423 = getelementptr inbounds float, float* %4, i64 %422
  %424 = load float, float* %423, align 4, !tbaa !508
  %425 = insertelement <64 x float> undef, float %424, i32 0
  %426 = shufflevector <64 x float> %425, <64 x float> undef, <64 x i32> zeroinitializer
  %427 = shl i64 %indvars.iv.1, 6
  %428 = add nsw i64 %49, %427
  %429 = getelementptr inbounds float, float* %7, i64 %428
  %430 = bitcast float* %429 to <64 x float>*
  %431 = load <64 x float>, <64 x float>* %430, align 64, !tbaa !511
  %432 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %426, <64 x float> %431, <64 x float> %421)
  %433 = add nsw i64 %422, 512
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !508
  %436 = insertelement <64 x float> undef, float %435, i32 0
  %437 = shufflevector <64 x float> %436, <64 x float> undef, <64 x i32> zeroinitializer
  %438 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %437, <64 x float> %431, <64 x float> %420)
  %439 = add nsw i64 %422, 7168
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = load float, float* %440, align 4, !tbaa !508
  %442 = insertelement <64 x float> undef, float %441, i32 0
  %443 = shufflevector <64 x float> %442, <64 x float> undef, <64 x i32> zeroinitializer
  %444 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %443, <64 x float> %431, <64 x float> %419)
  %445 = add nsw i64 %422, 7680
  %446 = getelementptr inbounds float, float* %4, i64 %445
  %447 = load float, float* %446, align 4, !tbaa !508
  %448 = insertelement <64 x float> undef, float %447, i32 0
  %449 = shufflevector <64 x float> %448, <64 x float> undef, <64 x i32> zeroinitializer
  %450 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %449, <64 x float> %431, <64 x float> %418)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !29

for_end9.1:                                       ; preds = %for_body8.1
  store <64 x float> %432, <64 x float>* %52, align 64, !tbaa !493
  store <64 x float> %438, <64 x float>* %55, align 64, !tbaa !493
  store <64 x float> %444, <64 x float>* %58, align 64, !tbaa !493
  store <64 x float> %450, <64 x float>* %61, align 64, !tbaa !493
  %indvars.iv.next41 = add nuw nsw i64 %indvars.iv40, 1
  %exitcond42 = icmp eq i64 %indvars.iv.next41, 7
  br i1 %exitcond42, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !514 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !516, metadata !DIExpression()), !dbg !519
  call void @llvm.dbg.value(metadata i8* %1, metadata !517, metadata !DIExpression()), !dbg !519
  call void @llvm.dbg.value(metadata i32 %2, metadata !518, metadata !DIExpression()), !dbg !519
  %3 = bitcast i8* %0 to %1**, !dbg !519
  %4 = load %1*, %1** %3, align 8, !dbg !519
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !519
  %6 = bitcast i8* %5 to %1**, !dbg !519
  %7 = load %1*, %1** %6, align 8, !dbg !519
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !519
  %9 = bitcast i8* %8 to %1**, !dbg !519
  %10 = load %1*, %1** %9, align 8, !dbg !519
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !519
  %12 = bitcast i8* %11 to %1**, !dbg !519
  %13 = load %1*, %1** %12, align 8, !dbg !519
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !519
  %15 = bitcast i8* %14 to %1**, !dbg !519
  %16 = load %1*, %1** %15, align 8, !dbg !519
  %17 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !519
  %18 = load i8*, i8** %17, align 8, !dbg !519
  %19 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !519
  %20 = load i32, i32* %19, align 4, !dbg !519
  %21 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !519
  %22 = load i8*, i8** %21, align 8, !dbg !519
  %23 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !519
  %24 = load i8*, i8** %23, align 8, !dbg !519
  %25 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !519
  %26 = load i8*, i8** %25, align 8, !dbg !519
  %27 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !519
  %28 = load i8*, i8** %27, align 8, !dbg !519
  %29 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3_compute_(i8* %18, i8* %22, i8* %28, i8* %24, i8* %26, i32 %20), !dbg !519
  ret i32 %29, !dbg !519
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %33, align 8
  %7 = getelementptr inbounds %33, %33* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %33, %33* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %33, %33* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %33, %33* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %33, %33* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %33, %33* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %33* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.29, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.29(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 27
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 28
  %27 = select i1 %26, i32 %25, i32 28
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 28
  %30 = select i1 %29, i32 %28, i32 28
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv53 = phi i64 [ %34, %for_body.lr.ph ], [ %indvars.iv.next54, %for_end3 ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %37 = tail call i8* %36(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %38 = bitcast i8* %37 to float*
  %39 = trunc i64 %indvars.iv53 to i32
  %40 = srem i32 %39, 7
  %41 = mul nsw i32 %40, 7168
  %42 = sdiv i32 %39, 7
  %43 = shl i32 %42, 15
  %44 = sext i32 %43 to i64
  %45 = sext i32 %41 to i64
  %46 = or i64 %44, 4096
  %47 = or i64 %44, 8192
  %48 = or i64 %44, 12288
  %49 = or i64 %44, 16384
  %50 = or i64 %44, 20480
  %51 = or i64 %44, 24576
  %52 = or i64 %44, 28672
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end9.7, %for_body
  %indvars.iv40 = phi i64 [ 0, %for_body ], [ %indvars.iv.next41, %for_end9.7 ]
  %53 = shl nsw i64 %indvars.iv40, 7
  %54 = getelementptr inbounds float, float* %38, i64 %53
  %55 = bitcast float* %54 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %55, align 64, !tbaa !520
  %56 = or i64 %53, 64
  %57 = getelementptr inbounds float, float* %38, i64 %56
  %58 = bitcast float* %57 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %58, align 64, !tbaa !520
  %59 = add nuw nsw i64 %53, 896
  %60 = getelementptr inbounds float, float* %38, i64 %59
  %61 = bitcast float* %60 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %61, align 64, !tbaa !520
  %62 = add nuw nsw i64 %53, 960
  %63 = getelementptr inbounds float, float* %38, i64 %62
  %64 = bitcast float* %63 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %64, align 64, !tbaa !520
  %65 = shl i64 %indvars.iv40, 8
  %66 = add nsw i64 %65, %45
  br label %for_body8

for_end3:                                         ; preds = %for_end9.7
  %67 = mul nsw i64 %indvars.iv53, 1792
  %68 = shl nsw i32 %42, 6
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %16, i64 %69
  %71 = bitcast float* %70 to <64 x float>*
  %72 = load <64 x float>, <64 x float>* %71, align 64, !tbaa !523
  %73 = getelementptr inbounds float, float* %13, i64 %69
  %74 = bitcast float* %73 to <64 x float>*
  %75 = load <64 x float>, <64 x float>* %74, align 64, !tbaa !526
  %76 = bitcast i8* %37 to <64 x float>*
  %77 = load <64 x float>, <64 x float>* %76, align 64, !tbaa !520
  %78 = fadd <64 x float> %75, %77
  %79 = fadd <64 x float> %72, %78
  %80 = fcmp ogt <64 x float> %79, zeroinitializer
  %81 = select <64 x i1> %80, <64 x float> %79, <64 x float> zeroinitializer
  %82 = getelementptr inbounds float, float* %10, i64 %67
  %83 = bitcast float* %82 to <64 x float>*
  store <64 x float> %81, <64 x float>* %83, align 64, !tbaa !529
  %84 = getelementptr inbounds i8, i8* %37, i64 256
  %85 = bitcast i8* %84 to <64 x float>*
  %86 = load <64 x float>, <64 x float>* %85, align 64, !tbaa !520
  %87 = fadd <64 x float> %75, %86
  %88 = fadd <64 x float> %72, %87
  %89 = fcmp ogt <64 x float> %88, zeroinitializer
  %90 = select <64 x i1> %89, <64 x float> %88, <64 x float> zeroinitializer
  %91 = mul i64 %indvars.iv53, 7696581394432
  %sext = ashr exact i64 %91, 32
  %92 = or i64 %sext, 64
  %93 = getelementptr inbounds float, float* %10, i64 %92
  %94 = bitcast float* %93 to <64 x float>*
  store <64 x float> %90, <64 x float>* %94, align 64, !tbaa !529
  %95 = getelementptr inbounds i8, i8* %37, i64 3584
  %96 = bitcast i8* %95 to <64 x float>*
  %97 = load <64 x float>, <64 x float>* %96, align 64, !tbaa !520
  %98 = fadd <64 x float> %75, %97
  %99 = fadd <64 x float> %72, %98
  %100 = fcmp ogt <64 x float> %99, zeroinitializer
  %101 = select <64 x i1> %100, <64 x float> %99, <64 x float> zeroinitializer
  %102 = mul i64 %indvars.iv53, 7696581394432
  %sext68 = add i64 %102, 3848290697216
  %103 = ashr exact i64 %sext68, 32
  %104 = getelementptr inbounds float, float* %10, i64 %103
  %105 = bitcast float* %104 to <64 x float>*
  store <64 x float> %101, <64 x float>* %105, align 64, !tbaa !529
  %106 = getelementptr inbounds i8, i8* %37, i64 3840
  %107 = bitcast i8* %106 to <64 x float>*
  %108 = load <64 x float>, <64 x float>* %107, align 64, !tbaa !520
  %109 = fadd <64 x float> %75, %108
  %110 = fadd <64 x float> %72, %109
  %111 = fcmp ogt <64 x float> %110, zeroinitializer
  %112 = select <64 x i1> %111, <64 x float> %110, <64 x float> zeroinitializer
  %113 = mul i64 %indvars.iv53, 7696581394432
  %sext55 = add i64 %113, 4123168604160
  %114 = ashr exact i64 %sext55, 32
  %115 = getelementptr inbounds float, float* %10, i64 %114
  %116 = bitcast float* %115 to <64 x float>*
  store <64 x float> %112, <64 x float>* %116, align 64, !tbaa !529
  %117 = getelementptr inbounds i8, i8* %37, i64 512
  %118 = bitcast i8* %117 to <64 x float>*
  %119 = load <64 x float>, <64 x float>* %118, align 64, !tbaa !520
  %120 = fadd <64 x float> %75, %119
  %121 = fadd <64 x float> %72, %120
  %122 = fcmp ogt <64 x float> %121, zeroinitializer
  %123 = select <64 x i1> %122, <64 x float> %121, <64 x float> zeroinitializer
  %124 = mul i64 %indvars.iv53, 7696581394432
  %sext69 = ashr exact i64 %124, 32
  %125 = or i64 %sext69, 128
  %126 = getelementptr inbounds float, float* %10, i64 %125
  %127 = bitcast float* %126 to <64 x float>*
  store <64 x float> %123, <64 x float>* %127, align 64, !tbaa !529
  %128 = getelementptr inbounds i8, i8* %37, i64 768
  %129 = bitcast i8* %128 to <64 x float>*
  %130 = load <64 x float>, <64 x float>* %129, align 64, !tbaa !520
  %131 = fadd <64 x float> %75, %130
  %132 = fadd <64 x float> %72, %131
  %133 = fcmp ogt <64 x float> %132, zeroinitializer
  %134 = select <64 x i1> %133, <64 x float> %132, <64 x float> zeroinitializer
  %135 = mul i64 %indvars.iv53, 7696581394432
  %sext56 = ashr exact i64 %135, 32
  %136 = or i64 %sext56, 192
  %137 = getelementptr inbounds float, float* %10, i64 %136
  %138 = bitcast float* %137 to <64 x float>*
  store <64 x float> %134, <64 x float>* %138, align 64, !tbaa !529
  %139 = getelementptr inbounds i8, i8* %37, i64 4096
  %140 = bitcast i8* %139 to <64 x float>*
  %141 = load <64 x float>, <64 x float>* %140, align 64, !tbaa !520
  %142 = fadd <64 x float> %75, %141
  %143 = fadd <64 x float> %72, %142
  %144 = fcmp ogt <64 x float> %143, zeroinitializer
  %145 = select <64 x i1> %144, <64 x float> %143, <64 x float> zeroinitializer
  %146 = mul i64 %indvars.iv53, 7696581394432
  %sext70 = add i64 %146, 4398046511104
  %147 = ashr exact i64 %sext70, 32
  %148 = getelementptr inbounds float, float* %10, i64 %147
  %149 = bitcast float* %148 to <64 x float>*
  store <64 x float> %145, <64 x float>* %149, align 64, !tbaa !529
  %150 = getelementptr inbounds i8, i8* %37, i64 4352
  %151 = bitcast i8* %150 to <64 x float>*
  %152 = load <64 x float>, <64 x float>* %151, align 64, !tbaa !520
  %153 = fadd <64 x float> %75, %152
  %154 = fadd <64 x float> %72, %153
  %155 = fcmp ogt <64 x float> %154, zeroinitializer
  %156 = select <64 x i1> %155, <64 x float> %154, <64 x float> zeroinitializer
  %157 = mul i64 %indvars.iv53, 7696581394432
  %sext57 = add i64 %157, 4672924418048
  %158 = ashr exact i64 %sext57, 32
  %159 = getelementptr inbounds float, float* %10, i64 %158
  %160 = bitcast float* %159 to <64 x float>*
  store <64 x float> %156, <64 x float>* %160, align 64, !tbaa !529
  %161 = getelementptr inbounds i8, i8* %37, i64 1024
  %162 = bitcast i8* %161 to <64 x float>*
  %163 = load <64 x float>, <64 x float>* %162, align 64, !tbaa !520
  %164 = fadd <64 x float> %75, %163
  %165 = fadd <64 x float> %72, %164
  %166 = fcmp ogt <64 x float> %165, zeroinitializer
  %167 = select <64 x i1> %166, <64 x float> %165, <64 x float> zeroinitializer
  %168 = mul i64 %indvars.iv53, 7696581394432
  %sext71 = add i64 %168, 1099511627776
  %169 = ashr exact i64 %sext71, 32
  %170 = getelementptr inbounds float, float* %10, i64 %169
  %171 = bitcast float* %170 to <64 x float>*
  store <64 x float> %167, <64 x float>* %171, align 64, !tbaa !529
  %172 = getelementptr inbounds i8, i8* %37, i64 1280
  %173 = bitcast i8* %172 to <64 x float>*
  %174 = load <64 x float>, <64 x float>* %173, align 64, !tbaa !520
  %175 = fadd <64 x float> %75, %174
  %176 = fadd <64 x float> %72, %175
  %177 = fcmp ogt <64 x float> %176, zeroinitializer
  %178 = select <64 x i1> %177, <64 x float> %176, <64 x float> zeroinitializer
  %179 = mul i64 %indvars.iv53, 7696581394432
  %sext58 = add i64 %179, 1374389534720
  %180 = ashr exact i64 %sext58, 32
  %181 = getelementptr inbounds float, float* %10, i64 %180
  %182 = bitcast float* %181 to <64 x float>*
  store <64 x float> %178, <64 x float>* %182, align 64, !tbaa !529
  %183 = getelementptr inbounds i8, i8* %37, i64 4608
  %184 = bitcast i8* %183 to <64 x float>*
  %185 = load <64 x float>, <64 x float>* %184, align 64, !tbaa !520
  %186 = fadd <64 x float> %75, %185
  %187 = fadd <64 x float> %72, %186
  %188 = fcmp ogt <64 x float> %187, zeroinitializer
  %189 = select <64 x i1> %188, <64 x float> %187, <64 x float> zeroinitializer
  %190 = mul i64 %indvars.iv53, 7696581394432
  %sext72 = add i64 %190, 4947802324992
  %191 = ashr exact i64 %sext72, 32
  %192 = getelementptr inbounds float, float* %10, i64 %191
  %193 = bitcast float* %192 to <64 x float>*
  store <64 x float> %189, <64 x float>* %193, align 64, !tbaa !529
  %194 = getelementptr inbounds i8, i8* %37, i64 4864
  %195 = bitcast i8* %194 to <64 x float>*
  %196 = load <64 x float>, <64 x float>* %195, align 64, !tbaa !520
  %197 = fadd <64 x float> %75, %196
  %198 = fadd <64 x float> %72, %197
  %199 = fcmp ogt <64 x float> %198, zeroinitializer
  %200 = select <64 x i1> %199, <64 x float> %198, <64 x float> zeroinitializer
  %201 = mul i64 %indvars.iv53, 7696581394432
  %sext59 = add i64 %201, 5222680231936
  %202 = ashr exact i64 %sext59, 32
  %203 = getelementptr inbounds float, float* %10, i64 %202
  %204 = bitcast float* %203 to <64 x float>*
  store <64 x float> %200, <64 x float>* %204, align 64, !tbaa !529
  %205 = getelementptr inbounds i8, i8* %37, i64 1536
  %206 = bitcast i8* %205 to <64 x float>*
  %207 = load <64 x float>, <64 x float>* %206, align 64, !tbaa !520
  %208 = fadd <64 x float> %75, %207
  %209 = fadd <64 x float> %72, %208
  %210 = fcmp ogt <64 x float> %209, zeroinitializer
  %211 = select <64 x i1> %210, <64 x float> %209, <64 x float> zeroinitializer
  %212 = mul i64 %indvars.iv53, 7696581394432
  %sext73 = add i64 %212, 1649267441664
  %213 = ashr exact i64 %sext73, 32
  %214 = getelementptr inbounds float, float* %10, i64 %213
  %215 = bitcast float* %214 to <64 x float>*
  store <64 x float> %211, <64 x float>* %215, align 64, !tbaa !529
  %216 = getelementptr inbounds i8, i8* %37, i64 1792
  %217 = bitcast i8* %216 to <64 x float>*
  %218 = load <64 x float>, <64 x float>* %217, align 64, !tbaa !520
  %219 = fadd <64 x float> %75, %218
  %220 = fadd <64 x float> %72, %219
  %221 = fcmp ogt <64 x float> %220, zeroinitializer
  %222 = select <64 x i1> %221, <64 x float> %220, <64 x float> zeroinitializer
  %223 = mul i64 %indvars.iv53, 7696581394432
  %sext60 = add i64 %223, 1924145348608
  %224 = ashr exact i64 %sext60, 32
  %225 = getelementptr inbounds float, float* %10, i64 %224
  %226 = bitcast float* %225 to <64 x float>*
  store <64 x float> %222, <64 x float>* %226, align 64, !tbaa !529
  %227 = getelementptr inbounds i8, i8* %37, i64 5120
  %228 = bitcast i8* %227 to <64 x float>*
  %229 = load <64 x float>, <64 x float>* %228, align 64, !tbaa !520
  %230 = fadd <64 x float> %75, %229
  %231 = fadd <64 x float> %72, %230
  %232 = fcmp ogt <64 x float> %231, zeroinitializer
  %233 = select <64 x i1> %232, <64 x float> %231, <64 x float> zeroinitializer
  %234 = mul i64 %indvars.iv53, 7696581394432
  %sext74 = add i64 %234, 5497558138880
  %235 = ashr exact i64 %sext74, 32
  %236 = getelementptr inbounds float, float* %10, i64 %235
  %237 = bitcast float* %236 to <64 x float>*
  store <64 x float> %233, <64 x float>* %237, align 64, !tbaa !529
  %238 = getelementptr inbounds i8, i8* %37, i64 5376
  %239 = bitcast i8* %238 to <64 x float>*
  %240 = load <64 x float>, <64 x float>* %239, align 64, !tbaa !520
  %241 = fadd <64 x float> %75, %240
  %242 = fadd <64 x float> %72, %241
  %243 = fcmp ogt <64 x float> %242, zeroinitializer
  %244 = select <64 x i1> %243, <64 x float> %242, <64 x float> zeroinitializer
  %245 = mul i64 %indvars.iv53, 7696581394432
  %sext61 = add i64 %245, 5772436045824
  %246 = ashr exact i64 %sext61, 32
  %247 = getelementptr inbounds float, float* %10, i64 %246
  %248 = bitcast float* %247 to <64 x float>*
  store <64 x float> %244, <64 x float>* %248, align 64, !tbaa !529
  %249 = getelementptr inbounds i8, i8* %37, i64 2048
  %250 = bitcast i8* %249 to <64 x float>*
  %251 = load <64 x float>, <64 x float>* %250, align 64, !tbaa !520
  %252 = fadd <64 x float> %75, %251
  %253 = fadd <64 x float> %72, %252
  %254 = fcmp ogt <64 x float> %253, zeroinitializer
  %255 = select <64 x i1> %254, <64 x float> %253, <64 x float> zeroinitializer
  %256 = mul i64 %indvars.iv53, 7696581394432
  %sext75 = add i64 %256, 2199023255552
  %257 = ashr exact i64 %sext75, 32
  %258 = getelementptr inbounds float, float* %10, i64 %257
  %259 = bitcast float* %258 to <64 x float>*
  store <64 x float> %255, <64 x float>* %259, align 64, !tbaa !529
  %260 = getelementptr inbounds i8, i8* %37, i64 2304
  %261 = bitcast i8* %260 to <64 x float>*
  %262 = load <64 x float>, <64 x float>* %261, align 64, !tbaa !520
  %263 = fadd <64 x float> %75, %262
  %264 = fadd <64 x float> %72, %263
  %265 = fcmp ogt <64 x float> %264, zeroinitializer
  %266 = select <64 x i1> %265, <64 x float> %264, <64 x float> zeroinitializer
  %267 = mul i64 %indvars.iv53, 7696581394432
  %sext62 = add i64 %267, 2473901162496
  %268 = ashr exact i64 %sext62, 32
  %269 = getelementptr inbounds float, float* %10, i64 %268
  %270 = bitcast float* %269 to <64 x float>*
  store <64 x float> %266, <64 x float>* %270, align 64, !tbaa !529
  %271 = getelementptr inbounds i8, i8* %37, i64 5632
  %272 = bitcast i8* %271 to <64 x float>*
  %273 = load <64 x float>, <64 x float>* %272, align 64, !tbaa !520
  %274 = fadd <64 x float> %75, %273
  %275 = fadd <64 x float> %72, %274
  %276 = fcmp ogt <64 x float> %275, zeroinitializer
  %277 = select <64 x i1> %276, <64 x float> %275, <64 x float> zeroinitializer
  %278 = mul i64 %indvars.iv53, 7696581394432
  %sext76 = add i64 %278, 6047313952768
  %279 = ashr exact i64 %sext76, 32
  %280 = getelementptr inbounds float, float* %10, i64 %279
  %281 = bitcast float* %280 to <64 x float>*
  store <64 x float> %277, <64 x float>* %281, align 64, !tbaa !529
  %282 = getelementptr inbounds i8, i8* %37, i64 5888
  %283 = bitcast i8* %282 to <64 x float>*
  %284 = load <64 x float>, <64 x float>* %283, align 64, !tbaa !520
  %285 = fadd <64 x float> %75, %284
  %286 = fadd <64 x float> %72, %285
  %287 = fcmp ogt <64 x float> %286, zeroinitializer
  %288 = select <64 x i1> %287, <64 x float> %286, <64 x float> zeroinitializer
  %289 = mul i64 %indvars.iv53, 7696581394432
  %sext63 = add i64 %289, 6322191859712
  %290 = ashr exact i64 %sext63, 32
  %291 = getelementptr inbounds float, float* %10, i64 %290
  %292 = bitcast float* %291 to <64 x float>*
  store <64 x float> %288, <64 x float>* %292, align 64, !tbaa !529
  %293 = getelementptr inbounds i8, i8* %37, i64 2560
  %294 = bitcast i8* %293 to <64 x float>*
  %295 = load <64 x float>, <64 x float>* %294, align 64, !tbaa !520
  %296 = fadd <64 x float> %75, %295
  %297 = fadd <64 x float> %72, %296
  %298 = fcmp ogt <64 x float> %297, zeroinitializer
  %299 = select <64 x i1> %298, <64 x float> %297, <64 x float> zeroinitializer
  %300 = mul i64 %indvars.iv53, 7696581394432
  %sext77 = add i64 %300, 2748779069440
  %301 = ashr exact i64 %sext77, 32
  %302 = getelementptr inbounds float, float* %10, i64 %301
  %303 = bitcast float* %302 to <64 x float>*
  store <64 x float> %299, <64 x float>* %303, align 64, !tbaa !529
  %304 = getelementptr inbounds i8, i8* %37, i64 2816
  %305 = bitcast i8* %304 to <64 x float>*
  %306 = load <64 x float>, <64 x float>* %305, align 64, !tbaa !520
  %307 = fadd <64 x float> %75, %306
  %308 = fadd <64 x float> %72, %307
  %309 = fcmp ogt <64 x float> %308, zeroinitializer
  %310 = select <64 x i1> %309, <64 x float> %308, <64 x float> zeroinitializer
  %311 = mul i64 %indvars.iv53, 7696581394432
  %sext64 = add i64 %311, 3023656976384
  %312 = ashr exact i64 %sext64, 32
  %313 = getelementptr inbounds float, float* %10, i64 %312
  %314 = bitcast float* %313 to <64 x float>*
  store <64 x float> %310, <64 x float>* %314, align 64, !tbaa !529
  %315 = getelementptr inbounds i8, i8* %37, i64 6144
  %316 = bitcast i8* %315 to <64 x float>*
  %317 = load <64 x float>, <64 x float>* %316, align 64, !tbaa !520
  %318 = fadd <64 x float> %75, %317
  %319 = fadd <64 x float> %72, %318
  %320 = fcmp ogt <64 x float> %319, zeroinitializer
  %321 = select <64 x i1> %320, <64 x float> %319, <64 x float> zeroinitializer
  %322 = mul i64 %indvars.iv53, 7696581394432
  %sext78 = add i64 %322, 6597069766656
  %323 = ashr exact i64 %sext78, 32
  %324 = getelementptr inbounds float, float* %10, i64 %323
  %325 = bitcast float* %324 to <64 x float>*
  store <64 x float> %321, <64 x float>* %325, align 64, !tbaa !529
  %326 = getelementptr inbounds i8, i8* %37, i64 6400
  %327 = bitcast i8* %326 to <64 x float>*
  %328 = load <64 x float>, <64 x float>* %327, align 64, !tbaa !520
  %329 = fadd <64 x float> %75, %328
  %330 = fadd <64 x float> %72, %329
  %331 = fcmp ogt <64 x float> %330, zeroinitializer
  %332 = select <64 x i1> %331, <64 x float> %330, <64 x float> zeroinitializer
  %333 = mul i64 %indvars.iv53, 7696581394432
  %sext65 = add i64 %333, 6871947673600
  %334 = ashr exact i64 %sext65, 32
  %335 = getelementptr inbounds float, float* %10, i64 %334
  %336 = bitcast float* %335 to <64 x float>*
  store <64 x float> %332, <64 x float>* %336, align 64, !tbaa !529
  %337 = getelementptr inbounds i8, i8* %37, i64 3072
  %338 = bitcast i8* %337 to <64 x float>*
  %339 = load <64 x float>, <64 x float>* %338, align 64, !tbaa !520
  %340 = fadd <64 x float> %75, %339
  %341 = fadd <64 x float> %72, %340
  %342 = fcmp ogt <64 x float> %341, zeroinitializer
  %343 = select <64 x i1> %342, <64 x float> %341, <64 x float> zeroinitializer
  %344 = mul i64 %indvars.iv53, 7696581394432
  %sext79 = add i64 %344, 3298534883328
  %345 = ashr exact i64 %sext79, 32
  %346 = getelementptr inbounds float, float* %10, i64 %345
  %347 = bitcast float* %346 to <64 x float>*
  store <64 x float> %343, <64 x float>* %347, align 64, !tbaa !529
  %348 = getelementptr inbounds i8, i8* %37, i64 3328
  %349 = bitcast i8* %348 to <64 x float>*
  %350 = load <64 x float>, <64 x float>* %349, align 64, !tbaa !520
  %351 = fadd <64 x float> %75, %350
  %352 = fadd <64 x float> %72, %351
  %353 = fcmp ogt <64 x float> %352, zeroinitializer
  %354 = select <64 x i1> %353, <64 x float> %352, <64 x float> zeroinitializer
  %355 = mul i64 %indvars.iv53, 7696581394432
  %sext66 = add i64 %355, 3573412790272
  %356 = ashr exact i64 %sext66, 32
  %357 = getelementptr inbounds float, float* %10, i64 %356
  %358 = bitcast float* %357 to <64 x float>*
  store <64 x float> %354, <64 x float>* %358, align 64, !tbaa !529
  %359 = getelementptr inbounds i8, i8* %37, i64 6656
  %360 = bitcast i8* %359 to <64 x float>*
  %361 = load <64 x float>, <64 x float>* %360, align 64, !tbaa !520
  %362 = fadd <64 x float> %75, %361
  %363 = fadd <64 x float> %72, %362
  %364 = fcmp ogt <64 x float> %363, zeroinitializer
  %365 = select <64 x i1> %364, <64 x float> %363, <64 x float> zeroinitializer
  %366 = mul i64 %indvars.iv53, 7696581394432
  %sext80 = add i64 %366, 7146825580544
  %367 = ashr exact i64 %sext80, 32
  %368 = getelementptr inbounds float, float* %10, i64 %367
  %369 = bitcast float* %368 to <64 x float>*
  store <64 x float> %365, <64 x float>* %369, align 64, !tbaa !529
  %370 = getelementptr inbounds i8, i8* %37, i64 6912
  %371 = bitcast i8* %370 to <64 x float>*
  %372 = load <64 x float>, <64 x float>* %371, align 64, !tbaa !520
  %373 = fadd <64 x float> %75, %372
  %374 = fadd <64 x float> %72, %373
  %375 = fcmp ogt <64 x float> %374, zeroinitializer
  %376 = select <64 x i1> %375, <64 x float> %374, <64 x float> zeroinitializer
  %377 = mul i64 %indvars.iv53, 7696581394432
  %sext67 = add i64 %377, 7421703487488
  %378 = ashr exact i64 %sext67, 32
  %379 = getelementptr inbounds float, float* %10, i64 %378
  %380 = bitcast float* %379 to <64 x float>*
  store <64 x float> %376, <64 x float>* %380, align 64, !tbaa !529
  %381 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %382 = tail call i32 %381(i32 1, i32 %19, i8* nonnull %37)
  %indvars.iv.next54 = add nsw i64 %indvars.iv53, 1
  %383 = icmp slt i64 %indvars.iv.next54, %35
  br i1 %383, label %for_body, label %for_end, !prof !19

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %384 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %416, %for_body8 ]
  %385 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %410, %for_body8 ]
  %386 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %404, %for_body8 ]
  %387 = phi <64 x float> [ zeroinitializer, %for_body2 ], [ %398, %for_body8 ]
  %388 = add nsw i64 %66, %indvars.iv
  %389 = getelementptr inbounds float, float* %4, i64 %388
  %390 = load float, float* %389, align 4, !tbaa !532
  %391 = insertelement <64 x float> undef, float %390, i32 0
  %392 = shufflevector <64 x float> %391, <64 x float> undef, <64 x i32> zeroinitializer
  %393 = shl i64 %indvars.iv, 6
  %394 = add nsw i64 %393, %44
  %395 = getelementptr inbounds float, float* %7, i64 %394
  %396 = bitcast float* %395 to <64 x float>*
  %397 = load <64 x float>, <64 x float>* %396, align 64, !tbaa !535
  %398 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %392, <64 x float> %397, <64 x float> %387)
  %399 = add nsw i64 %388, 128
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = load float, float* %400, align 4, !tbaa !532
  %402 = insertelement <64 x float> undef, float %401, i32 0
  %403 = shufflevector <64 x float> %402, <64 x float> undef, <64 x i32> zeroinitializer
  %404 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %403, <64 x float> %397, <64 x float> %386)
  %405 = add nsw i64 %388, 3584
  %406 = getelementptr inbounds float, float* %4, i64 %405
  %407 = load float, float* %406, align 4, !tbaa !532
  %408 = insertelement <64 x float> undef, float %407, i32 0
  %409 = shufflevector <64 x float> %408, <64 x float> undef, <64 x i32> zeroinitializer
  %410 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %409, <64 x float> %397, <64 x float> %385)
  %411 = add nsw i64 %388, 3712
  %412 = getelementptr inbounds float, float* %4, i64 %411
  %413 = load float, float* %412, align 4, !tbaa !532
  %414 = insertelement <64 x float> undef, float %413, i32 0
  %415 = shufflevector <64 x float> %414, <64 x float> undef, <64 x i32> zeroinitializer
  %416 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %415, <64 x float> %397, <64 x float> %384)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %417 = add nsw i64 %66, 50176
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %418 = phi <64 x float> [ %416, %for_end9 ], [ %450, %for_body8.1 ]
  %419 = phi <64 x float> [ %410, %for_end9 ], [ %444, %for_body8.1 ]
  %420 = phi <64 x float> [ %404, %for_end9 ], [ %438, %for_body8.1 ]
  %421 = phi <64 x float> [ %398, %for_end9 ], [ %432, %for_body8.1 ]
  %422 = add nsw i64 %417, %indvars.iv.1
  %423 = getelementptr inbounds float, float* %4, i64 %422
  %424 = load float, float* %423, align 4, !tbaa !532
  %425 = insertelement <64 x float> undef, float %424, i32 0
  %426 = shufflevector <64 x float> %425, <64 x float> undef, <64 x i32> zeroinitializer
  %427 = shl i64 %indvars.iv.1, 6
  %428 = add nsw i64 %46, %427
  %429 = getelementptr inbounds float, float* %7, i64 %428
  %430 = bitcast float* %429 to <64 x float>*
  %431 = load <64 x float>, <64 x float>* %430, align 64, !tbaa !535
  %432 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %426, <64 x float> %431, <64 x float> %421)
  %433 = add nsw i64 %422, 128
  %434 = getelementptr inbounds float, float* %4, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !532
  %436 = insertelement <64 x float> undef, float %435, i32 0
  %437 = shufflevector <64 x float> %436, <64 x float> undef, <64 x i32> zeroinitializer
  %438 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %437, <64 x float> %431, <64 x float> %420)
  %439 = add nsw i64 %422, 3584
  %440 = getelementptr inbounds float, float* %4, i64 %439
  %441 = load float, float* %440, align 4, !tbaa !532
  %442 = insertelement <64 x float> undef, float %441, i32 0
  %443 = shufflevector <64 x float> %442, <64 x float> undef, <64 x i32> zeroinitializer
  %444 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %443, <64 x float> %431, <64 x float> %419)
  %445 = add nsw i64 %422, 3712
  %446 = getelementptr inbounds float, float* %4, i64 %445
  %447 = load float, float* %446, align 4, !tbaa !532
  %448 = insertelement <64 x float> undef, float %447, i32 0
  %449 = shufflevector <64 x float> %448, <64 x float> undef, <64 x i32> zeroinitializer
  %450 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %449, <64 x float> %431, <64 x float> %418)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !29

for_end9.1:                                       ; preds = %for_body8.1
  %451 = add nsw i64 %66, 100352
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %452 = phi <64 x float> [ %450, %for_end9.1 ], [ %484, %for_body8.2 ]
  %453 = phi <64 x float> [ %444, %for_end9.1 ], [ %478, %for_body8.2 ]
  %454 = phi <64 x float> [ %438, %for_end9.1 ], [ %472, %for_body8.2 ]
  %455 = phi <64 x float> [ %432, %for_end9.1 ], [ %466, %for_body8.2 ]
  %456 = add nuw nsw i64 %451, %indvars.iv.2
  %457 = getelementptr inbounds float, float* %4, i64 %456
  %458 = load float, float* %457, align 4, !tbaa !532
  %459 = insertelement <64 x float> undef, float %458, i32 0
  %460 = shufflevector <64 x float> %459, <64 x float> undef, <64 x i32> zeroinitializer
  %461 = shl i64 %indvars.iv.2, 6
  %462 = add nsw i64 %47, %461
  %463 = getelementptr inbounds float, float* %7, i64 %462
  %464 = bitcast float* %463 to <64 x float>*
  %465 = load <64 x float>, <64 x float>* %464, align 64, !tbaa !535
  %466 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %460, <64 x float> %465, <64 x float> %455)
  %467 = add nsw i64 %456, 128
  %468 = getelementptr inbounds float, float* %4, i64 %467
  %469 = load float, float* %468, align 4, !tbaa !532
  %470 = insertelement <64 x float> undef, float %469, i32 0
  %471 = shufflevector <64 x float> %470, <64 x float> undef, <64 x i32> zeroinitializer
  %472 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %471, <64 x float> %465, <64 x float> %454)
  %473 = add nsw i64 %456, 3584
  %474 = getelementptr inbounds float, float* %4, i64 %473
  %475 = load float, float* %474, align 4, !tbaa !532
  %476 = insertelement <64 x float> undef, float %475, i32 0
  %477 = shufflevector <64 x float> %476, <64 x float> undef, <64 x i32> zeroinitializer
  %478 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %477, <64 x float> %465, <64 x float> %453)
  %479 = add nsw i64 %456, 3712
  %480 = getelementptr inbounds float, float* %4, i64 %479
  %481 = load float, float* %480, align 4, !tbaa !532
  %482 = insertelement <64 x float> undef, float %481, i32 0
  %483 = shufflevector <64 x float> %482, <64 x float> undef, <64 x i32> zeroinitializer
  %484 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %483, <64 x float> %465, <64 x float> %452)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 64
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !29

for_end9.2:                                       ; preds = %for_body8.2
  %485 = add nsw i64 %66, 150528
  br label %for_body8.3

for_body8.3:                                      ; preds = %for_body8.3, %for_end9.2
  %indvars.iv.3 = phi i64 [ 0, %for_end9.2 ], [ %indvars.iv.next.3, %for_body8.3 ]
  %486 = phi <64 x float> [ %484, %for_end9.2 ], [ %518, %for_body8.3 ]
  %487 = phi <64 x float> [ %478, %for_end9.2 ], [ %512, %for_body8.3 ]
  %488 = phi <64 x float> [ %472, %for_end9.2 ], [ %506, %for_body8.3 ]
  %489 = phi <64 x float> [ %466, %for_end9.2 ], [ %500, %for_body8.3 ]
  %490 = add nuw nsw i64 %485, %indvars.iv.3
  %491 = getelementptr inbounds float, float* %4, i64 %490
  %492 = load float, float* %491, align 4, !tbaa !532
  %493 = insertelement <64 x float> undef, float %492, i32 0
  %494 = shufflevector <64 x float> %493, <64 x float> undef, <64 x i32> zeroinitializer
  %495 = shl i64 %indvars.iv.3, 6
  %496 = add nsw i64 %48, %495
  %497 = getelementptr inbounds float, float* %7, i64 %496
  %498 = bitcast float* %497 to <64 x float>*
  %499 = load <64 x float>, <64 x float>* %498, align 64, !tbaa !535
  %500 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %494, <64 x float> %499, <64 x float> %489)
  %501 = add nsw i64 %490, 128
  %502 = getelementptr inbounds float, float* %4, i64 %501
  %503 = load float, float* %502, align 4, !tbaa !532
  %504 = insertelement <64 x float> undef, float %503, i32 0
  %505 = shufflevector <64 x float> %504, <64 x float> undef, <64 x i32> zeroinitializer
  %506 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %505, <64 x float> %499, <64 x float> %488)
  %507 = add nsw i64 %490, 3584
  %508 = getelementptr inbounds float, float* %4, i64 %507
  %509 = load float, float* %508, align 4, !tbaa !532
  %510 = insertelement <64 x float> undef, float %509, i32 0
  %511 = shufflevector <64 x float> %510, <64 x float> undef, <64 x i32> zeroinitializer
  %512 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %511, <64 x float> %499, <64 x float> %487)
  %513 = add nsw i64 %490, 3712
  %514 = getelementptr inbounds float, float* %4, i64 %513
  %515 = load float, float* %514, align 4, !tbaa !532
  %516 = insertelement <64 x float> undef, float %515, i32 0
  %517 = shufflevector <64 x float> %516, <64 x float> undef, <64 x i32> zeroinitializer
  %518 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %517, <64 x float> %499, <64 x float> %486)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 64
  br i1 %exitcond.3, label %for_end9.3, label %for_body8.3, !prof !29

for_end9.3:                                       ; preds = %for_body8.3
  %519 = add nsw i64 %66, 200704
  br label %for_body8.4

for_body8.4:                                      ; preds = %for_body8.4, %for_end9.3
  %indvars.iv.4 = phi i64 [ 0, %for_end9.3 ], [ %indvars.iv.next.4, %for_body8.4 ]
  %520 = phi <64 x float> [ %518, %for_end9.3 ], [ %552, %for_body8.4 ]
  %521 = phi <64 x float> [ %512, %for_end9.3 ], [ %546, %for_body8.4 ]
  %522 = phi <64 x float> [ %506, %for_end9.3 ], [ %540, %for_body8.4 ]
  %523 = phi <64 x float> [ %500, %for_end9.3 ], [ %534, %for_body8.4 ]
  %524 = add nuw nsw i64 %519, %indvars.iv.4
  %525 = getelementptr inbounds float, float* %4, i64 %524
  %526 = load float, float* %525, align 4, !tbaa !532
  %527 = insertelement <64 x float> undef, float %526, i32 0
  %528 = shufflevector <64 x float> %527, <64 x float> undef, <64 x i32> zeroinitializer
  %529 = shl i64 %indvars.iv.4, 6
  %530 = add nsw i64 %49, %529
  %531 = getelementptr inbounds float, float* %7, i64 %530
  %532 = bitcast float* %531 to <64 x float>*
  %533 = load <64 x float>, <64 x float>* %532, align 64, !tbaa !535
  %534 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %528, <64 x float> %533, <64 x float> %523)
  %535 = add nsw i64 %524, 128
  %536 = getelementptr inbounds float, float* %4, i64 %535
  %537 = load float, float* %536, align 4, !tbaa !532
  %538 = insertelement <64 x float> undef, float %537, i32 0
  %539 = shufflevector <64 x float> %538, <64 x float> undef, <64 x i32> zeroinitializer
  %540 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %539, <64 x float> %533, <64 x float> %522)
  %541 = add nsw i64 %524, 3584
  %542 = getelementptr inbounds float, float* %4, i64 %541
  %543 = load float, float* %542, align 4, !tbaa !532
  %544 = insertelement <64 x float> undef, float %543, i32 0
  %545 = shufflevector <64 x float> %544, <64 x float> undef, <64 x i32> zeroinitializer
  %546 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %545, <64 x float> %533, <64 x float> %521)
  %547 = add nsw i64 %524, 3712
  %548 = getelementptr inbounds float, float* %4, i64 %547
  %549 = load float, float* %548, align 4, !tbaa !532
  %550 = insertelement <64 x float> undef, float %549, i32 0
  %551 = shufflevector <64 x float> %550, <64 x float> undef, <64 x i32> zeroinitializer
  %552 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %551, <64 x float> %533, <64 x float> %520)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 64
  br i1 %exitcond.4, label %for_end9.4, label %for_body8.4, !prof !29

for_end9.4:                                       ; preds = %for_body8.4
  %553 = add nsw i64 %66, 250880
  br label %for_body8.5

for_body8.5:                                      ; preds = %for_body8.5, %for_end9.4
  %indvars.iv.5 = phi i64 [ 0, %for_end9.4 ], [ %indvars.iv.next.5, %for_body8.5 ]
  %554 = phi <64 x float> [ %552, %for_end9.4 ], [ %586, %for_body8.5 ]
  %555 = phi <64 x float> [ %546, %for_end9.4 ], [ %580, %for_body8.5 ]
  %556 = phi <64 x float> [ %540, %for_end9.4 ], [ %574, %for_body8.5 ]
  %557 = phi <64 x float> [ %534, %for_end9.4 ], [ %568, %for_body8.5 ]
  %558 = add nuw nsw i64 %553, %indvars.iv.5
  %559 = getelementptr inbounds float, float* %4, i64 %558
  %560 = load float, float* %559, align 4, !tbaa !532
  %561 = insertelement <64 x float> undef, float %560, i32 0
  %562 = shufflevector <64 x float> %561, <64 x float> undef, <64 x i32> zeroinitializer
  %563 = shl i64 %indvars.iv.5, 6
  %564 = add nsw i64 %50, %563
  %565 = getelementptr inbounds float, float* %7, i64 %564
  %566 = bitcast float* %565 to <64 x float>*
  %567 = load <64 x float>, <64 x float>* %566, align 64, !tbaa !535
  %568 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %562, <64 x float> %567, <64 x float> %557)
  %569 = add nsw i64 %558, 128
  %570 = getelementptr inbounds float, float* %4, i64 %569
  %571 = load float, float* %570, align 4, !tbaa !532
  %572 = insertelement <64 x float> undef, float %571, i32 0
  %573 = shufflevector <64 x float> %572, <64 x float> undef, <64 x i32> zeroinitializer
  %574 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %573, <64 x float> %567, <64 x float> %556)
  %575 = add nsw i64 %558, 3584
  %576 = getelementptr inbounds float, float* %4, i64 %575
  %577 = load float, float* %576, align 4, !tbaa !532
  %578 = insertelement <64 x float> undef, float %577, i32 0
  %579 = shufflevector <64 x float> %578, <64 x float> undef, <64 x i32> zeroinitializer
  %580 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %579, <64 x float> %567, <64 x float> %555)
  %581 = add nsw i64 %558, 3712
  %582 = getelementptr inbounds float, float* %4, i64 %581
  %583 = load float, float* %582, align 4, !tbaa !532
  %584 = insertelement <64 x float> undef, float %583, i32 0
  %585 = shufflevector <64 x float> %584, <64 x float> undef, <64 x i32> zeroinitializer
  %586 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %585, <64 x float> %567, <64 x float> %554)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 64
  br i1 %exitcond.5, label %for_end9.5, label %for_body8.5, !prof !29

for_end9.5:                                       ; preds = %for_body8.5
  %587 = add nsw i64 %66, 301056
  br label %for_body8.6

for_body8.6:                                      ; preds = %for_body8.6, %for_end9.5
  %indvars.iv.6 = phi i64 [ 0, %for_end9.5 ], [ %indvars.iv.next.6, %for_body8.6 ]
  %588 = phi <64 x float> [ %586, %for_end9.5 ], [ %620, %for_body8.6 ]
  %589 = phi <64 x float> [ %580, %for_end9.5 ], [ %614, %for_body8.6 ]
  %590 = phi <64 x float> [ %574, %for_end9.5 ], [ %608, %for_body8.6 ]
  %591 = phi <64 x float> [ %568, %for_end9.5 ], [ %602, %for_body8.6 ]
  %592 = add nuw nsw i64 %587, %indvars.iv.6
  %593 = getelementptr inbounds float, float* %4, i64 %592
  %594 = load float, float* %593, align 4, !tbaa !532
  %595 = insertelement <64 x float> undef, float %594, i32 0
  %596 = shufflevector <64 x float> %595, <64 x float> undef, <64 x i32> zeroinitializer
  %597 = shl i64 %indvars.iv.6, 6
  %598 = add nsw i64 %51, %597
  %599 = getelementptr inbounds float, float* %7, i64 %598
  %600 = bitcast float* %599 to <64 x float>*
  %601 = load <64 x float>, <64 x float>* %600, align 64, !tbaa !535
  %602 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %596, <64 x float> %601, <64 x float> %591)
  %603 = add nsw i64 %592, 128
  %604 = getelementptr inbounds float, float* %4, i64 %603
  %605 = load float, float* %604, align 4, !tbaa !532
  %606 = insertelement <64 x float> undef, float %605, i32 0
  %607 = shufflevector <64 x float> %606, <64 x float> undef, <64 x i32> zeroinitializer
  %608 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %607, <64 x float> %601, <64 x float> %590)
  %609 = add nsw i64 %592, 3584
  %610 = getelementptr inbounds float, float* %4, i64 %609
  %611 = load float, float* %610, align 4, !tbaa !532
  %612 = insertelement <64 x float> undef, float %611, i32 0
  %613 = shufflevector <64 x float> %612, <64 x float> undef, <64 x i32> zeroinitializer
  %614 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %613, <64 x float> %601, <64 x float> %589)
  %615 = add nsw i64 %592, 3712
  %616 = getelementptr inbounds float, float* %4, i64 %615
  %617 = load float, float* %616, align 4, !tbaa !532
  %618 = insertelement <64 x float> undef, float %617, i32 0
  %619 = shufflevector <64 x float> %618, <64 x float> undef, <64 x i32> zeroinitializer
  %620 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %619, <64 x float> %601, <64 x float> %588)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 64
  br i1 %exitcond.6, label %for_end9.6, label %for_body8.6, !prof !29

for_end9.6:                                       ; preds = %for_body8.6
  %621 = add nsw i64 %66, 351232
  br label %for_body8.7

for_body8.7:                                      ; preds = %for_body8.7, %for_end9.6
  %indvars.iv.7 = phi i64 [ 0, %for_end9.6 ], [ %indvars.iv.next.7, %for_body8.7 ]
  %622 = phi <64 x float> [ %620, %for_end9.6 ], [ %654, %for_body8.7 ]
  %623 = phi <64 x float> [ %614, %for_end9.6 ], [ %648, %for_body8.7 ]
  %624 = phi <64 x float> [ %608, %for_end9.6 ], [ %642, %for_body8.7 ]
  %625 = phi <64 x float> [ %602, %for_end9.6 ], [ %636, %for_body8.7 ]
  %626 = add nuw nsw i64 %621, %indvars.iv.7
  %627 = getelementptr inbounds float, float* %4, i64 %626
  %628 = load float, float* %627, align 4, !tbaa !532
  %629 = insertelement <64 x float> undef, float %628, i32 0
  %630 = shufflevector <64 x float> %629, <64 x float> undef, <64 x i32> zeroinitializer
  %631 = shl i64 %indvars.iv.7, 6
  %632 = add nsw i64 %52, %631
  %633 = getelementptr inbounds float, float* %7, i64 %632
  %634 = bitcast float* %633 to <64 x float>*
  %635 = load <64 x float>, <64 x float>* %634, align 64, !tbaa !535
  %636 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %630, <64 x float> %635, <64 x float> %625)
  %637 = add nsw i64 %626, 128
  %638 = getelementptr inbounds float, float* %4, i64 %637
  %639 = load float, float* %638, align 4, !tbaa !532
  %640 = insertelement <64 x float> undef, float %639, i32 0
  %641 = shufflevector <64 x float> %640, <64 x float> undef, <64 x i32> zeroinitializer
  %642 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %641, <64 x float> %635, <64 x float> %624)
  %643 = add nsw i64 %626, 3584
  %644 = getelementptr inbounds float, float* %4, i64 %643
  %645 = load float, float* %644, align 4, !tbaa !532
  %646 = insertelement <64 x float> undef, float %645, i32 0
  %647 = shufflevector <64 x float> %646, <64 x float> undef, <64 x i32> zeroinitializer
  %648 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %647, <64 x float> %635, <64 x float> %623)
  %649 = add nsw i64 %626, 3712
  %650 = getelementptr inbounds float, float* %4, i64 %649
  %651 = load float, float* %650, align 4, !tbaa !532
  %652 = insertelement <64 x float> undef, float %651, i32 0
  %653 = shufflevector <64 x float> %652, <64 x float> undef, <64 x i32> zeroinitializer
  %654 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %653, <64 x float> %635, <64 x float> %622)
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 64
  br i1 %exitcond.7, label %for_end9.7, label %for_body8.7, !prof !29

for_end9.7:                                       ; preds = %for_body8.7
  store <64 x float> %636, <64 x float>* %55, align 64, !tbaa !520
  store <64 x float> %642, <64 x float>* %58, align 64, !tbaa !520
  store <64 x float> %648, <64 x float>* %61, align 64, !tbaa !520
  store <64 x float> %654, <64 x float>* %64, align 64, !tbaa !520
  %indvars.iv.next41 = add nuw nsw i64 %indvars.iv40, 1
  %exitcond42 = icmp eq i64 %indvars.iv.next41, 7
  br i1 %exitcond42, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_layout_transform_38(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !538 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !540, metadata !DIExpression()), !dbg !543
  call void @llvm.dbg.value(metadata i8* %1, metadata !541, metadata !DIExpression()), !dbg !543
  call void @llvm.dbg.value(metadata i32 %2, metadata !542, metadata !DIExpression()), !dbg !543
  %3 = bitcast i8* %0 to %1**, !dbg !543
  %4 = load %1*, %1** %3, align 8, !dbg !543
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !543
  %6 = bitcast i8* %5 to %1**, !dbg !543
  %7 = load %1*, %1** %6, align 8, !dbg !543
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !543
  %9 = load i8*, i8** %8, align 8, !dbg !543
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !543
  %11 = load i8*, i8** %10, align 8, !dbg !543
  %12 = tail call fastcc i32 @fused_layout_transform_38_compute_(i8* %11, i8* %9), !dbg !543
  ret i32 %12, !dbg !543
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_38_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %34, align 8
  %3 = getelementptr inbounds %34, %34* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %34, %34* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %34* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.30, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.30(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 112
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 28
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 28
  %29 = mul nsw i32 %28, 896
  %30 = srem i32 %27, 32
  %31 = sdiv i32 %25, 224
  %32 = mul nsw i32 %31, 25088
  %33 = or i32 %27, 1
  %34 = srem i32 %33, 32
  %35 = sdiv i32 %33, 32
  %36 = mul nsw i32 %35, 25088
  %37 = or i32 %27, 2
  %38 = srem i32 %37, 32
  %39 = sdiv i32 %37, 32
  %40 = mul nsw i32 %39, 25088
  %41 = or i32 %27, 3
  %42 = srem i32 %41, 32
  %43 = sdiv i32 %41, 32
  %44 = mul nsw i32 %43, 25088
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %45 = phi i32 [ 0, %for_body ], [ %87, %for_body2 ]
  %46 = shl i64 %indvars.iv, 2
  %47 = add nsw i64 %46, %24
  %48 = shl i32 %45, 5
  %49 = add nsw i32 %48, %29
  %50 = add i32 %49, %30
  %51 = add i32 %50, %32
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds float, float* %7, i64 %52
  %54 = bitcast float* %53 to i32*
  %55 = load i32, i32* %54, align 4, !tbaa !544
  %56 = getelementptr inbounds float, float* %4, i64 %47
  %57 = bitcast float* %56 to i32*
  store i32 %55, i32* %57, align 4, !tbaa !547
  %58 = or i64 %47, 1
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %59 = shl i32 %indvars.iv.tr, 5
  %60 = add i32 %29, %59
  %61 = add i32 %60, %34
  %62 = add i32 %61, %36
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %7, i64 %63
  %65 = bitcast float* %64 to i32*
  %66 = load i32, i32* %65, align 4, !tbaa !544
  %67 = getelementptr inbounds float, float* %4, i64 %58
  %68 = bitcast float* %67 to i32*
  store i32 %66, i32* %68, align 4, !tbaa !547
  %69 = or i64 %47, 2
  %70 = add i32 %60, %38
  %71 = add i32 %70, %40
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds float, float* %7, i64 %72
  %74 = bitcast float* %73 to i32*
  %75 = load i32, i32* %74, align 4, !tbaa !544
  %76 = getelementptr inbounds float, float* %4, i64 %69
  %77 = bitcast float* %76 to i32*
  store i32 %75, i32* %77, align 4, !tbaa !547
  %78 = or i64 %47, 3
  %79 = add i32 %60, %42
  %80 = add i32 %79, %44
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to i32*
  %84 = load i32, i32* %83, align 4, !tbaa !544
  %85 = getelementptr inbounds float, float* %4, i64 %78
  %86 = bitcast float* %85 to i32*
  store i32 %84, i32* %86, align 4, !tbaa !547
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %87 = add nuw nsw i32 %45, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 28
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %88 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %88, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !550 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !552, metadata !DIExpression()), !dbg !555
  call void @llvm.dbg.value(metadata i8* %1, metadata !553, metadata !DIExpression()), !dbg !555
  call void @llvm.dbg.value(metadata i32 %2, metadata !554, metadata !DIExpression()), !dbg !555
  %3 = bitcast i8* %0 to %1**, !dbg !555
  %4 = load %1*, %1** %3, align 8, !dbg !555
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !555
  %6 = bitcast i8* %5 to %1**, !dbg !555
  %7 = load %1*, %1** %6, align 8, !dbg !555
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !555
  %9 = bitcast i8* %8 to %1**, !dbg !555
  %10 = load %1*, %1** %9, align 8, !dbg !555
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !555
  %12 = bitcast i8* %11 to %1**, !dbg !555
  %13 = load %1*, %1** %12, align 8, !dbg !555
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !555
  %15 = bitcast i8* %14 to %1**, !dbg !555
  %16 = load %1*, %1** %15, align 8, !dbg !555
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !555
  %18 = bitcast i8* %17 to %1**, !dbg !555
  %19 = load %1*, %1** %18, align 8, !dbg !555
  %20 = getelementptr inbounds i8, i8* %0, i64 48, !dbg !555
  %21 = bitcast i8* %20 to %1**, !dbg !555
  %22 = load %1*, %1** %21, align 8, !dbg !555
  %23 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !555
  %24 = load i8*, i8** %23, align 8, !dbg !555
  %25 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !555
  %26 = load i32, i32* %25, align 4, !dbg !555
  %27 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !555
  %28 = load i8*, i8** %27, align 8, !dbg !555
  %29 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !555
  %30 = load i8*, i8** %29, align 8, !dbg !555
  %31 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !555
  %32 = load i8*, i8** %31, align 8, !dbg !555
  %33 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !555
  %34 = load i8*, i8** %33, align 8, !dbg !555
  %35 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !555
  %36 = load i8*, i8** %35, align 8, !dbg !555
  %37 = getelementptr inbounds %1, %1* %22, i64 0, i32 0, !dbg !555
  %38 = load i8*, i8** %37, align 8, !dbg !555
  %39 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3_compute_(i8* %24, i8* %28, i8* %38, i8* %30, i8* %32, i8* %34, i8* %36, i32 %26), !dbg !555
  ret i32 %39, !dbg !555
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %8 = alloca %35, align 8
  %9 = getelementptr inbounds %35, %35* %8, i64 0, i32 0
  store i8* %0, i8** %9, align 8
  %10 = getelementptr inbounds %35, %35* %8, i64 0, i32 1
  store i8* %1, i8** %10, align 8
  %11 = getelementptr inbounds %35, %35* %8, i64 0, i32 2
  store i8* %2, i8** %11, align 8
  %12 = getelementptr inbounds %35, %35* %8, i64 0, i32 3
  store i8* %3, i8** %12, align 8
  %13 = getelementptr inbounds %35, %35* %8, i64 0, i32 4
  store i8* %4, i8** %13, align 8
  %14 = getelementptr inbounds %35, %35* %8, i64 0, i32 5
  store i8* %5, i8** %14, align 8
  %15 = getelementptr inbounds %35, %35* %8, i64 0, i32 6
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %35, %35* %8, i64 0, i32 7
  store i32 %7, i32* %16, align 8
  %17 = bitcast %35* %8 to i8*
  %18 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %19 = call i32 %18(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.31, i8* nonnull %17, i32 0)
  ret i32 %19
}

define private i32 @__tvm_parallel_lambda.31(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to float**
  %22 = load float*, float** %21, align 8
  %23 = getelementptr inbounds i8, i8* %2, i64 56
  %24 = bitcast i8* %23 to i32*
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %27 = load i32, i32* %26, align 4
  %28 = add nsw i32 %27, 447
  %29 = sdiv i32 %28, %27
  %30 = add nsw i32 %0, 1
  %31 = mul nsw i32 %29, %30
  %32 = icmp slt i32 %31, 448
  %33 = select i1 %32, i32 %31, i32 448
  %34 = mul nsw i32 %29, %0
  %35 = icmp slt i32 %34, 448
  %36 = select i1 %35, i32 %34, i32 448
  %37 = icmp slt i32 %36, %33
  br i1 %37, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end12
  %38 = phi i32 [ %390, %for_end12 ], [ %36, %for_body.preheader ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %40 = tail call i8* %39(i32 1, i32 %25, i64 7168, i32 2, i32 32)
  %41 = bitcast i8* %40 to float*
  %42 = srem i32 %38, 56
  %43 = mul nsw i32 %42, 224
  %44 = sdiv i32 %38, 56
  %45 = shl i32 %44, 11
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end12, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv49 = phi i64 [ 0, %for_body ], [ %indvars.iv.next50, %for_end6 ]
  %48 = mul nuw nsw i64 %indvars.iv49, 224
  %49 = getelementptr inbounds float, float* %41, i64 %48
  %50 = bitcast float* %49 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %50, align 64, !tbaa !556
  %51 = add nuw nsw i64 %48, 32
  %52 = getelementptr inbounds float, float* %41, i64 %51
  %53 = bitcast float* %52 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %53, align 64, !tbaa !556
  %54 = add nuw nsw i64 %48, 64
  %55 = getelementptr inbounds float, float* %41, i64 %54
  %56 = bitcast float* %55 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %56, align 64, !tbaa !556
  %57 = add nuw nsw i64 %48, 96
  %58 = getelementptr inbounds float, float* %41, i64 %57
  %59 = bitcast float* %58 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %59, align 64, !tbaa !556
  %60 = add nuw nsw i64 %48, 128
  %61 = getelementptr inbounds float, float* %41, i64 %60
  %62 = bitcast float* %61 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %62, align 64, !tbaa !556
  %63 = add nuw nsw i64 %48, 160
  %64 = getelementptr inbounds float, float* %41, i64 %63
  %65 = bitcast float* %64 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %65, align 64, !tbaa !556
  %66 = add nuw nsw i64 %48, 192
  %67 = getelementptr inbounds float, float* %41, i64 %66
  %68 = bitcast float* %67 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %68, align 64, !tbaa !556
  %69 = mul nuw nsw i64 %indvars.iv49, 28
  %70 = add nsw i64 %69, %47
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %71 = mul nsw i32 %38, 1792
  %72 = shl nsw i32 %44, 5
  %73 = sext i32 %72 to i64
  %74 = getelementptr inbounds float, float* %13, i64 %73
  %75 = bitcast float* %74 to <32 x float>*
  %76 = load <32 x float>, <32 x float>* %75, align 64, !tbaa !559
  %77 = getelementptr inbounds float, float* %16, i64 %73
  %78 = bitcast float* %77 to <32 x float>*
  %79 = load <32 x float>, <32 x float>* %78, align 64, !tbaa !562
  %80 = getelementptr inbounds float, float* %19, i64 %73
  %81 = bitcast float* %80 to <32 x float>*
  %82 = load <32 x float>, <32 x float>* %81, align 64, !tbaa !565
  br label %for_body11

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %.lcssa2942 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %268, %for_body5 ]
  %.lcssa2740 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %262, %for_body5 ]
  %.lcssa2538 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %256, %for_body5 ]
  %.lcssa2336 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %250, %for_body5 ]
  %.lcssa2134 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %244, %for_body5 ]
  %.lcssa1932 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %238, %for_body5 ]
  %.lcssa31 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %232, %for_body5 ]
  %83 = mul nuw nsw i64 %indvars.iv, 12544
  %84 = add nsw i64 %70, %83
  %85 = shl i64 %indvars.iv, 7
  %86 = add nuw nsw i64 %85, %46
  %87 = getelementptr inbounds float, float* %4, i64 %84
  %88 = load float, float* %87, align 4, !tbaa !568
  %89 = insertelement <32 x float> undef, float %88, i32 0
  %90 = shufflevector <32 x float> %89, <32 x float> undef, <32 x i32> zeroinitializer
  %91 = getelementptr inbounds float, float* %7, i64 %86
  %92 = bitcast float* %91 to <32 x float>*
  %93 = load <32 x float>, <32 x float>* %92, align 64, !tbaa !571
  %94 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %90, <32 x float> %93, <32 x float> %.lcssa31)
  %95 = add nsw i64 %84, 4
  %96 = getelementptr inbounds float, float* %4, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !568
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %93, <32 x float> %.lcssa1932)
  %101 = add nsw i64 %84, 8
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !568
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %93, <32 x float> %.lcssa2134)
  %107 = add nsw i64 %84, 12
  %108 = getelementptr inbounds float, float* %4, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !568
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %93, <32 x float> %.lcssa2336)
  %113 = add nsw i64 %84, 16
  %114 = getelementptr inbounds float, float* %4, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !568
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %93, <32 x float> %.lcssa2538)
  %119 = add nsw i64 %84, 20
  %120 = getelementptr inbounds float, float* %4, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !568
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %93, <32 x float> %.lcssa2740)
  %125 = add nsw i64 %84, 24
  %126 = getelementptr inbounds float, float* %4, i64 %125
  %127 = load float, float* %126, align 4, !tbaa !568
  %128 = insertelement <32 x float> undef, float %127, i32 0
  %129 = shufflevector <32 x float> %128, <32 x float> undef, <32 x i32> zeroinitializer
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %129, <32 x float> %93, <32 x float> %.lcssa2942)
  %131 = or i64 %84, 1
  %132 = getelementptr inbounds float, float* %4, i64 %131
  %133 = load float, float* %132, align 4, !tbaa !568
  %134 = insertelement <32 x float> undef, float %133, i32 0
  %135 = shufflevector <32 x float> %134, <32 x float> undef, <32 x i32> zeroinitializer
  %136 = or i64 %86, 32
  %137 = getelementptr inbounds float, float* %7, i64 %136
  %138 = bitcast float* %137 to <32 x float>*
  %139 = load <32 x float>, <32 x float>* %138, align 64, !tbaa !571
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %135, <32 x float> %139, <32 x float> %94)
  %141 = add nsw i64 %131, 4
  %142 = getelementptr inbounds float, float* %4, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !568
  %144 = insertelement <32 x float> undef, float %143, i32 0
  %145 = shufflevector <32 x float> %144, <32 x float> undef, <32 x i32> zeroinitializer
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %145, <32 x float> %139, <32 x float> %100)
  %147 = add nsw i64 %131, 8
  %148 = getelementptr inbounds float, float* %4, i64 %147
  %149 = load float, float* %148, align 4, !tbaa !568
  %150 = insertelement <32 x float> undef, float %149, i32 0
  %151 = shufflevector <32 x float> %150, <32 x float> undef, <32 x i32> zeroinitializer
  %152 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %151, <32 x float> %139, <32 x float> %106)
  %153 = add nsw i64 %131, 12
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !568
  %156 = insertelement <32 x float> undef, float %155, i32 0
  %157 = shufflevector <32 x float> %156, <32 x float> undef, <32 x i32> zeroinitializer
  %158 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %157, <32 x float> %139, <32 x float> %112)
  %159 = add nsw i64 %131, 16
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !568
  %162 = insertelement <32 x float> undef, float %161, i32 0
  %163 = shufflevector <32 x float> %162, <32 x float> undef, <32 x i32> zeroinitializer
  %164 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %163, <32 x float> %139, <32 x float> %118)
  %165 = add nsw i64 %131, 20
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !568
  %168 = insertelement <32 x float> undef, float %167, i32 0
  %169 = shufflevector <32 x float> %168, <32 x float> undef, <32 x i32> zeroinitializer
  %170 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %169, <32 x float> %139, <32 x float> %124)
  %171 = add nsw i64 %131, 24
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !568
  %174 = insertelement <32 x float> undef, float %173, i32 0
  %175 = shufflevector <32 x float> %174, <32 x float> undef, <32 x i32> zeroinitializer
  %176 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %175, <32 x float> %139, <32 x float> %130)
  %177 = or i64 %84, 2
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !568
  %180 = insertelement <32 x float> undef, float %179, i32 0
  %181 = shufflevector <32 x float> %180, <32 x float> undef, <32 x i32> zeroinitializer
  %182 = or i64 %86, 64
  %183 = getelementptr inbounds float, float* %7, i64 %182
  %184 = bitcast float* %183 to <32 x float>*
  %185 = load <32 x float>, <32 x float>* %184, align 64, !tbaa !571
  %186 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %181, <32 x float> %185, <32 x float> %140)
  %187 = add nsw i64 %177, 4
  %188 = getelementptr inbounds float, float* %4, i64 %187
  %189 = load float, float* %188, align 4, !tbaa !568
  %190 = insertelement <32 x float> undef, float %189, i32 0
  %191 = shufflevector <32 x float> %190, <32 x float> undef, <32 x i32> zeroinitializer
  %192 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %191, <32 x float> %185, <32 x float> %146)
  %193 = add nsw i64 %177, 8
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = load float, float* %194, align 4, !tbaa !568
  %196 = insertelement <32 x float> undef, float %195, i32 0
  %197 = shufflevector <32 x float> %196, <32 x float> undef, <32 x i32> zeroinitializer
  %198 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %197, <32 x float> %185, <32 x float> %152)
  %199 = add nsw i64 %177, 12
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !568
  %202 = insertelement <32 x float> undef, float %201, i32 0
  %203 = shufflevector <32 x float> %202, <32 x float> undef, <32 x i32> zeroinitializer
  %204 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %203, <32 x float> %185, <32 x float> %158)
  %205 = add nsw i64 %177, 16
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !568
  %208 = insertelement <32 x float> undef, float %207, i32 0
  %209 = shufflevector <32 x float> %208, <32 x float> undef, <32 x i32> zeroinitializer
  %210 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %209, <32 x float> %185, <32 x float> %164)
  %211 = add nsw i64 %177, 20
  %212 = getelementptr inbounds float, float* %4, i64 %211
  %213 = load float, float* %212, align 4, !tbaa !568
  %214 = insertelement <32 x float> undef, float %213, i32 0
  %215 = shufflevector <32 x float> %214, <32 x float> undef, <32 x i32> zeroinitializer
  %216 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %215, <32 x float> %185, <32 x float> %170)
  %217 = add nsw i64 %177, 24
  %218 = getelementptr inbounds float, float* %4, i64 %217
  %219 = load float, float* %218, align 4, !tbaa !568
  %220 = insertelement <32 x float> undef, float %219, i32 0
  %221 = shufflevector <32 x float> %220, <32 x float> undef, <32 x i32> zeroinitializer
  %222 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %221, <32 x float> %185, <32 x float> %176)
  %223 = or i64 %84, 3
  %224 = getelementptr inbounds float, float* %4, i64 %223
  %225 = load float, float* %224, align 4, !tbaa !568
  %226 = insertelement <32 x float> undef, float %225, i32 0
  %227 = shufflevector <32 x float> %226, <32 x float> undef, <32 x i32> zeroinitializer
  %228 = or i64 %86, 96
  %229 = getelementptr inbounds float, float* %7, i64 %228
  %230 = bitcast float* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !571
  %232 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %227, <32 x float> %231, <32 x float> %186)
  %233 = add nsw i64 %223, 4
  %234 = getelementptr inbounds float, float* %4, i64 %233
  %235 = load float, float* %234, align 4, !tbaa !568
  %236 = insertelement <32 x float> undef, float %235, i32 0
  %237 = shufflevector <32 x float> %236, <32 x float> undef, <32 x i32> zeroinitializer
  %238 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %237, <32 x float> %231, <32 x float> %192)
  %239 = add nsw i64 %223, 8
  %240 = getelementptr inbounds float, float* %4, i64 %239
  %241 = load float, float* %240, align 4, !tbaa !568
  %242 = insertelement <32 x float> undef, float %241, i32 0
  %243 = shufflevector <32 x float> %242, <32 x float> undef, <32 x i32> zeroinitializer
  %244 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %243, <32 x float> %231, <32 x float> %198)
  %245 = add nsw i64 %223, 12
  %246 = getelementptr inbounds float, float* %4, i64 %245
  %247 = load float, float* %246, align 4, !tbaa !568
  %248 = insertelement <32 x float> undef, float %247, i32 0
  %249 = shufflevector <32 x float> %248, <32 x float> undef, <32 x i32> zeroinitializer
  %250 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %249, <32 x float> %231, <32 x float> %204)
  %251 = add nsw i64 %223, 16
  %252 = getelementptr inbounds float, float* %4, i64 %251
  %253 = load float, float* %252, align 4, !tbaa !568
  %254 = insertelement <32 x float> undef, float %253, i32 0
  %255 = shufflevector <32 x float> %254, <32 x float> undef, <32 x i32> zeroinitializer
  %256 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %255, <32 x float> %231, <32 x float> %210)
  %257 = add nsw i64 %223, 20
  %258 = getelementptr inbounds float, float* %4, i64 %257
  %259 = load float, float* %258, align 4, !tbaa !568
  %260 = insertelement <32 x float> undef, float %259, i32 0
  %261 = shufflevector <32 x float> %260, <32 x float> undef, <32 x i32> zeroinitializer
  %262 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %261, <32 x float> %231, <32 x float> %216)
  %263 = add nsw i64 %223, 24
  %264 = getelementptr inbounds float, float* %4, i64 %263
  %265 = load float, float* %264, align 4, !tbaa !568
  %266 = insertelement <32 x float> undef, float %265, i32 0
  %267 = shufflevector <32 x float> %266, <32 x float> undef, <32 x i32> zeroinitializer
  %268 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %267, <32 x float> %231, <32 x float> %222)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <32 x float> %232, <32 x float>* %50, align 64, !tbaa !556
  store <32 x float> %238, <32 x float>* %53, align 64, !tbaa !556
  store <32 x float> %244, <32 x float>* %56, align 64, !tbaa !556
  store <32 x float> %250, <32 x float>* %59, align 64, !tbaa !556
  store <32 x float> %256, <32 x float>* %62, align 64, !tbaa !556
  store <32 x float> %262, <32 x float>* %65, align 64, !tbaa !556
  store <32 x float> %268, <32 x float>* %68, align 64, !tbaa !556
  %indvars.iv.next50 = add nuw nsw i64 %indvars.iv49, 1
  %exitcond51 = icmp eq i64 %indvars.iv.next50, 8
  br i1 %exitcond51, label %for_end3, label %for_body2, !prof !29

for_body11:                                       ; preds = %for_body11, %for_end3
  %indvars.iv55 = phi i64 [ 0, %for_end3 ], [ %indvars.iv.next56, %for_body11 ]
  %269 = mul nuw nsw i64 %indvars.iv55, 224
  %270 = trunc i64 %269 to i32
  %271 = add i32 %71, %270
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds float, float* %22, i64 %272
  %274 = bitcast float* %273 to <32 x float>*
  %275 = load <32 x float>, <32 x float>* %274, align 64, !tbaa !574
  %276 = getelementptr inbounds float, float* %41, i64 %269
  %277 = bitcast float* %276 to <32 x float>*
  %278 = load <32 x float>, <32 x float>* %277, align 64, !tbaa !556
  %279 = fadd <32 x float> %76, %278
  %280 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %279, <32 x float> %79, <32 x float> %82)
  %281 = fadd <32 x float> %275, %280
  %282 = fcmp ogt <32 x float> %281, zeroinitializer
  %283 = select <32 x i1> %282, <32 x float> %281, <32 x float> zeroinitializer
  %284 = getelementptr inbounds float, float* %10, i64 %272
  %285 = bitcast float* %284 to <32 x float>*
  store <32 x float> %283, <32 x float>* %285, align 64, !tbaa !577
  %286 = add nuw nsw i64 %269, 32
  %287 = trunc i64 %286 to i32
  %288 = add i32 %71, %287
  %289 = sext i32 %288 to i64
  %290 = getelementptr inbounds float, float* %22, i64 %289
  %291 = bitcast float* %290 to <32 x float>*
  %292 = load <32 x float>, <32 x float>* %291, align 64, !tbaa !574
  %293 = getelementptr inbounds float, float* %41, i64 %286
  %294 = bitcast float* %293 to <32 x float>*
  %295 = load <32 x float>, <32 x float>* %294, align 64, !tbaa !556
  %296 = fadd <32 x float> %76, %295
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %296, <32 x float> %79, <32 x float> %82)
  %298 = fadd <32 x float> %292, %297
  %299 = fcmp ogt <32 x float> %298, zeroinitializer
  %300 = select <32 x i1> %299, <32 x float> %298, <32 x float> zeroinitializer
  %301 = getelementptr inbounds float, float* %10, i64 %289
  %302 = bitcast float* %301 to <32 x float>*
  store <32 x float> %300, <32 x float>* %302, align 64, !tbaa !577
  %303 = add nuw nsw i64 %269, 64
  %304 = trunc i64 %303 to i32
  %305 = add i32 %71, %304
  %306 = sext i32 %305 to i64
  %307 = getelementptr inbounds float, float* %22, i64 %306
  %308 = bitcast float* %307 to <32 x float>*
  %309 = load <32 x float>, <32 x float>* %308, align 64, !tbaa !574
  %310 = getelementptr inbounds float, float* %41, i64 %303
  %311 = bitcast float* %310 to <32 x float>*
  %312 = load <32 x float>, <32 x float>* %311, align 64, !tbaa !556
  %313 = fadd <32 x float> %76, %312
  %314 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %313, <32 x float> %79, <32 x float> %82)
  %315 = fadd <32 x float> %309, %314
  %316 = fcmp ogt <32 x float> %315, zeroinitializer
  %317 = select <32 x i1> %316, <32 x float> %315, <32 x float> zeroinitializer
  %318 = getelementptr inbounds float, float* %10, i64 %306
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %317, <32 x float>* %319, align 64, !tbaa !577
  %320 = add nuw nsw i64 %269, 96
  %321 = trunc i64 %320 to i32
  %322 = add i32 %71, %321
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds float, float* %22, i64 %323
  %325 = bitcast float* %324 to <32 x float>*
  %326 = load <32 x float>, <32 x float>* %325, align 64, !tbaa !574
  %327 = getelementptr inbounds float, float* %41, i64 %320
  %328 = bitcast float* %327 to <32 x float>*
  %329 = load <32 x float>, <32 x float>* %328, align 64, !tbaa !556
  %330 = fadd <32 x float> %76, %329
  %331 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %330, <32 x float> %79, <32 x float> %82)
  %332 = fadd <32 x float> %326, %331
  %333 = fcmp ogt <32 x float> %332, zeroinitializer
  %334 = select <32 x i1> %333, <32 x float> %332, <32 x float> zeroinitializer
  %335 = getelementptr inbounds float, float* %10, i64 %323
  %336 = bitcast float* %335 to <32 x float>*
  store <32 x float> %334, <32 x float>* %336, align 64, !tbaa !577
  %337 = add nuw nsw i64 %269, 128
  %338 = trunc i64 %337 to i32
  %339 = add i32 %71, %338
  %340 = sext i32 %339 to i64
  %341 = getelementptr inbounds float, float* %22, i64 %340
  %342 = bitcast float* %341 to <32 x float>*
  %343 = load <32 x float>, <32 x float>* %342, align 64, !tbaa !574
  %344 = getelementptr inbounds float, float* %41, i64 %337
  %345 = bitcast float* %344 to <32 x float>*
  %346 = load <32 x float>, <32 x float>* %345, align 64, !tbaa !556
  %347 = fadd <32 x float> %76, %346
  %348 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %347, <32 x float> %79, <32 x float> %82)
  %349 = fadd <32 x float> %343, %348
  %350 = fcmp ogt <32 x float> %349, zeroinitializer
  %351 = select <32 x i1> %350, <32 x float> %349, <32 x float> zeroinitializer
  %352 = getelementptr inbounds float, float* %10, i64 %340
  %353 = bitcast float* %352 to <32 x float>*
  store <32 x float> %351, <32 x float>* %353, align 64, !tbaa !577
  %354 = add nuw nsw i64 %269, 160
  %355 = trunc i64 %354 to i32
  %356 = add i32 %71, %355
  %357 = sext i32 %356 to i64
  %358 = getelementptr inbounds float, float* %22, i64 %357
  %359 = bitcast float* %358 to <32 x float>*
  %360 = load <32 x float>, <32 x float>* %359, align 64, !tbaa !574
  %361 = getelementptr inbounds float, float* %41, i64 %354
  %362 = bitcast float* %361 to <32 x float>*
  %363 = load <32 x float>, <32 x float>* %362, align 64, !tbaa !556
  %364 = fadd <32 x float> %76, %363
  %365 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %364, <32 x float> %79, <32 x float> %82)
  %366 = fadd <32 x float> %360, %365
  %367 = fcmp ogt <32 x float> %366, zeroinitializer
  %368 = select <32 x i1> %367, <32 x float> %366, <32 x float> zeroinitializer
  %369 = getelementptr inbounds float, float* %10, i64 %357
  %370 = bitcast float* %369 to <32 x float>*
  store <32 x float> %368, <32 x float>* %370, align 64, !tbaa !577
  %371 = add nuw nsw i64 %269, 192
  %372 = trunc i64 %371 to i32
  %373 = add i32 %71, %372
  %374 = sext i32 %373 to i64
  %375 = getelementptr inbounds float, float* %22, i64 %374
  %376 = bitcast float* %375 to <32 x float>*
  %377 = load <32 x float>, <32 x float>* %376, align 64, !tbaa !574
  %378 = getelementptr inbounds float, float* %41, i64 %371
  %379 = bitcast float* %378 to <32 x float>*
  %380 = load <32 x float>, <32 x float>* %379, align 64, !tbaa !556
  %381 = fadd <32 x float> %76, %380
  %382 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %79, <32 x float> %82)
  %383 = fadd <32 x float> %377, %382
  %384 = fcmp ogt <32 x float> %383, zeroinitializer
  %385 = select <32 x i1> %384, <32 x float> %383, <32 x float> zeroinitializer
  %386 = getelementptr inbounds float, float* %10, i64 %374
  %387 = bitcast float* %386 to <32 x float>*
  store <32 x float> %385, <32 x float>* %387, align 64, !tbaa !577
  %indvars.iv.next56 = add nuw nsw i64 %indvars.iv55, 1
  %exitcond57 = icmp eq i64 %indvars.iv.next56, 8
  br i1 %exitcond57, label %for_end12, label %for_body11, !prof !29

for_end12:                                        ; preds = %for_body11
  %388 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %389 = tail call i32 %388(i32 1, i32 %25, i8* nonnull %40)
  %390 = add nsw i32 %38, 1
  %391 = icmp slt i32 %390, %33
  br i1 %391, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !580 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !582, metadata !DIExpression()), !dbg !585
  call void @llvm.dbg.value(metadata i8* %1, metadata !583, metadata !DIExpression()), !dbg !585
  call void @llvm.dbg.value(metadata i32 %2, metadata !584, metadata !DIExpression()), !dbg !585
  %3 = bitcast i8* %0 to %1**, !dbg !585
  %4 = load %1*, %1** %3, align 8, !dbg !585
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !585
  %6 = bitcast i8* %5 to %1**, !dbg !585
  %7 = load %1*, %1** %6, align 8, !dbg !585
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !585
  %9 = bitcast i8* %8 to %1**, !dbg !585
  %10 = load %1*, %1** %9, align 8, !dbg !585
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !585
  %12 = bitcast i8* %11 to %1**, !dbg !585
  %13 = load %1*, %1** %12, align 8, !dbg !585
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !585
  %15 = bitcast i8* %14 to %1**, !dbg !585
  %16 = load %1*, %1** %15, align 8, !dbg !585
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !585
  %18 = bitcast i8* %17 to %1**, !dbg !585
  %19 = load %1*, %1** %18, align 8, !dbg !585
  %20 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !585
  %21 = load i8*, i8** %20, align 8, !dbg !585
  %22 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !585
  %23 = load i32, i32* %22, align 4, !dbg !585
  %24 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !585
  %25 = load i8*, i8** %24, align 8, !dbg !585
  %26 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !585
  %27 = load i8*, i8** %26, align 8, !dbg !585
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !585
  %29 = load i8*, i8** %28, align 8, !dbg !585
  %30 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !585
  %31 = load i8*, i8** %30, align 8, !dbg !585
  %32 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !585
  %33 = load i8*, i8** %32, align 8, !dbg !585
  %34 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4_compute_(i8* %21, i8* %25, i8* %33, i8* %27, i8* %29, i8* %31, i32 %23), !dbg !585
  ret i32 %34, !dbg !585
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %36, align 8
  %8 = getelementptr inbounds %36, %36* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %36, %36* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %36, %36* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %36, %36* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %36, %36* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %36, %36* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %36, %36* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %36* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.32, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.32(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 223
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 224
  %30 = select i1 %29, i32 %28, i32 224
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 224
  %33 = select i1 %32, i32 %31, i32 224
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end12
  %35 = phi i32 [ %391, %for_end12 ], [ %33, %for_body.preheader ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %37 = tail call i8* %36(i32 1, i32 %22, i64 3584, i32 2, i32 32)
  %38 = bitcast i8* %37 to float*
  %39 = srem i32 %35, 56
  %40 = mul nsw i32 %39, 896
  %41 = sdiv i32 %35, 56
  %42 = shl i32 %41, 10
  %43 = sext i32 %42 to i64
  %44 = sext i32 %40 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end12, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv87 = phi i64 [ 0, %for_body ], [ %indvars.iv.next88, %for_end6 ]
  %45 = mul nuw nsw i64 %indvars.iv87, 224
  %46 = getelementptr inbounds float, float* %38, i64 %45
  %47 = bitcast float* %46 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %47, align 64, !tbaa !586
  %48 = or i64 %45, 16
  %49 = getelementptr inbounds float, float* %38, i64 %48
  %50 = bitcast float* %49 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %50, align 64, !tbaa !586
  %51 = add nuw nsw i64 %45, 32
  %52 = getelementptr inbounds float, float* %38, i64 %51
  %53 = bitcast float* %52 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %53, align 64, !tbaa !586
  %54 = add nuw nsw i64 %45, 48
  %55 = getelementptr inbounds float, float* %38, i64 %54
  %56 = bitcast float* %55 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %56, align 64, !tbaa !586
  %57 = add nuw nsw i64 %45, 64
  %58 = getelementptr inbounds float, float* %38, i64 %57
  %59 = bitcast float* %58 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %59, align 64, !tbaa !586
  %60 = add nuw nsw i64 %45, 80
  %61 = getelementptr inbounds float, float* %38, i64 %60
  %62 = bitcast float* %61 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %62, align 64, !tbaa !586
  %63 = add nuw nsw i64 %45, 96
  %64 = getelementptr inbounds float, float* %38, i64 %63
  %65 = bitcast float* %64 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %65, align 64, !tbaa !586
  %66 = add nuw nsw i64 %45, 112
  %67 = getelementptr inbounds float, float* %38, i64 %66
  %68 = bitcast float* %67 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %68, align 64, !tbaa !586
  %69 = add nuw nsw i64 %45, 128
  %70 = getelementptr inbounds float, float* %38, i64 %69
  %71 = bitcast float* %70 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %71, align 64, !tbaa !586
  %72 = add nuw nsw i64 %45, 144
  %73 = getelementptr inbounds float, float* %38, i64 %72
  %74 = bitcast float* %73 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %74, align 64, !tbaa !586
  %75 = add nuw nsw i64 %45, 160
  %76 = getelementptr inbounds float, float* %38, i64 %75
  %77 = bitcast float* %76 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %77, align 64, !tbaa !586
  %78 = add nuw nsw i64 %45, 176
  %79 = getelementptr inbounds float, float* %38, i64 %78
  %80 = bitcast float* %79 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %80, align 64, !tbaa !586
  %81 = add nuw nsw i64 %45, 192
  %82 = getelementptr inbounds float, float* %38, i64 %81
  %83 = bitcast float* %82 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %83, align 64, !tbaa !586
  %84 = add nuw nsw i64 %45, 208
  %85 = getelementptr inbounds float, float* %38, i64 %84
  %86 = bitcast float* %85 to <16 x float>*
  store <16 x float> zeroinitializer, <16 x float>* %86, align 64, !tbaa !586
  %87 = add nsw i64 %45, %44
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %88 = mul nsw i32 %35, 896
  %89 = shl nsw i32 %41, 4
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds float, float* %13, i64 %90
  %92 = bitcast float* %91 to <16 x float>*
  %93 = load <16 x float>, <16 x float>* %92, align 64, !tbaa !589
  %94 = getelementptr inbounds float, float* %16, i64 %90
  %95 = bitcast float* %94 to <16 x float>*
  %96 = load <16 x float>, <16 x float>* %95, align 64, !tbaa !592
  %97 = getelementptr inbounds float, float* %19, i64 %90
  %98 = bitcast float* %97 to <16 x float>*
  %99 = load <16 x float>, <16 x float>* %98, align 64, !tbaa !595
  br label %for_body11

for_body5:                                        ; preds = %for_end9, %for_body2
  %indvars.iv84 = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next85, %for_end9 ]
  %.lcssa4370 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %206, %for_end9 ]
  %.lcssa4168 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %200, %for_end9 ]
  %.lcssa3966 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %194, %for_end9 ]
  %.lcssa3764 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %188, %for_end9 ]
  %.lcssa3562 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %182, %for_end9 ]
  %.lcssa3360 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %176, %for_end9 ]
  %.lcssa3158 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %170, %for_end9 ]
  %.lcssa2956 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %164, %for_end9 ]
  %.lcssa2754 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %158, %for_end9 ]
  %.lcssa2552 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %152, %for_end9 ]
  %.lcssa2350 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %146, %for_end9 ]
  %.lcssa2148 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %140, %for_end9 ]
  %.lcssa1946 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %134, %for_end9 ]
  %.lcssa45 = phi <16 x float> [ zeroinitializer, %for_body2 ], [ %128, %for_end9 ]
  %100 = mul nuw nsw i64 %indvars.iv84, 50176
  %101 = add nsw i64 %87, %100
  %102 = shl i64 %indvars.iv84, 8
  %103 = add nuw nsw i64 %102, %43
  br label %for_body8

for_end6:                                         ; preds = %for_end9
  store <16 x float> %128, <16 x float>* %47, align 64, !tbaa !586
  store <16 x float> %134, <16 x float>* %50, align 64, !tbaa !586
  store <16 x float> %140, <16 x float>* %53, align 64, !tbaa !586
  store <16 x float> %146, <16 x float>* %56, align 64, !tbaa !586
  store <16 x float> %152, <16 x float>* %59, align 64, !tbaa !586
  store <16 x float> %158, <16 x float>* %62, align 64, !tbaa !586
  store <16 x float> %164, <16 x float>* %65, align 64, !tbaa !586
  store <16 x float> %170, <16 x float>* %68, align 64, !tbaa !586
  store <16 x float> %176, <16 x float>* %71, align 64, !tbaa !586
  store <16 x float> %182, <16 x float>* %74, align 64, !tbaa !586
  store <16 x float> %188, <16 x float>* %77, align 64, !tbaa !586
  store <16 x float> %194, <16 x float>* %80, align 64, !tbaa !586
  store <16 x float> %200, <16 x float>* %83, align 64, !tbaa !586
  store <16 x float> %206, <16 x float>* %86, align 64, !tbaa !586
  %indvars.iv.next88 = add nuw nsw i64 %indvars.iv87, 1
  %exitcond89 = icmp eq i64 %indvars.iv.next88, 4
  br i1 %exitcond89, label %for_end3, label %for_body2, !prof !29

for_body8:                                        ; preds = %for_body8, %for_body5
  %indvars.iv = phi i64 [ 0, %for_body5 ], [ %indvars.iv.next, %for_body8 ]
  %104 = phi <16 x float> [ %.lcssa4370, %for_body5 ], [ %206, %for_body8 ]
  %105 = phi <16 x float> [ %.lcssa4168, %for_body5 ], [ %200, %for_body8 ]
  %106 = phi <16 x float> [ %.lcssa3966, %for_body5 ], [ %194, %for_body8 ]
  %107 = phi <16 x float> [ %.lcssa3764, %for_body5 ], [ %188, %for_body8 ]
  %108 = phi <16 x float> [ %.lcssa3562, %for_body5 ], [ %182, %for_body8 ]
  %109 = phi <16 x float> [ %.lcssa3360, %for_body5 ], [ %176, %for_body8 ]
  %110 = phi <16 x float> [ %.lcssa3158, %for_body5 ], [ %170, %for_body8 ]
  %111 = phi <16 x float> [ %.lcssa2956, %for_body5 ], [ %164, %for_body8 ]
  %112 = phi <16 x float> [ %.lcssa2754, %for_body5 ], [ %158, %for_body8 ]
  %113 = phi <16 x float> [ %.lcssa2552, %for_body5 ], [ %152, %for_body8 ]
  %114 = phi <16 x float> [ %.lcssa2350, %for_body5 ], [ %146, %for_body8 ]
  %115 = phi <16 x float> [ %.lcssa2148, %for_body5 ], [ %140, %for_body8 ]
  %116 = phi <16 x float> [ %.lcssa1946, %for_body5 ], [ %134, %for_body8 ]
  %117 = phi <16 x float> [ %.lcssa45, %for_body5 ], [ %128, %for_body8 ]
  %118 = add nsw i64 %101, %indvars.iv
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = load float, float* %119, align 4, !tbaa !598
  %121 = insertelement <16 x float> undef, float %120, i32 0
  %122 = shufflevector <16 x float> %121, <16 x float> undef, <16 x i32> zeroinitializer
  %123 = shl i64 %indvars.iv, 4
  %124 = add nsw i64 %103, %123
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to <16 x float>*
  %127 = load <16 x float>, <16 x float>* %126, align 64, !tbaa !601
  %128 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %122, <16 x float> %127, <16 x float> %117)
  %129 = add nsw i64 %118, 16
  %130 = getelementptr inbounds float, float* %4, i64 %129
  %131 = load float, float* %130, align 4, !tbaa !598
  %132 = insertelement <16 x float> undef, float %131, i32 0
  %133 = shufflevector <16 x float> %132, <16 x float> undef, <16 x i32> zeroinitializer
  %134 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %133, <16 x float> %127, <16 x float> %116)
  %135 = add nsw i64 %118, 32
  %136 = getelementptr inbounds float, float* %4, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !598
  %138 = insertelement <16 x float> undef, float %137, i32 0
  %139 = shufflevector <16 x float> %138, <16 x float> undef, <16 x i32> zeroinitializer
  %140 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %139, <16 x float> %127, <16 x float> %115)
  %141 = add nsw i64 %118, 48
  %142 = getelementptr inbounds float, float* %4, i64 %141
  %143 = load float, float* %142, align 4, !tbaa !598
  %144 = insertelement <16 x float> undef, float %143, i32 0
  %145 = shufflevector <16 x float> %144, <16 x float> undef, <16 x i32> zeroinitializer
  %146 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %145, <16 x float> %127, <16 x float> %114)
  %147 = add nsw i64 %118, 64
  %148 = getelementptr inbounds float, float* %4, i64 %147
  %149 = load float, float* %148, align 4, !tbaa !598
  %150 = insertelement <16 x float> undef, float %149, i32 0
  %151 = shufflevector <16 x float> %150, <16 x float> undef, <16 x i32> zeroinitializer
  %152 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %151, <16 x float> %127, <16 x float> %113)
  %153 = add nsw i64 %118, 80
  %154 = getelementptr inbounds float, float* %4, i64 %153
  %155 = load float, float* %154, align 4, !tbaa !598
  %156 = insertelement <16 x float> undef, float %155, i32 0
  %157 = shufflevector <16 x float> %156, <16 x float> undef, <16 x i32> zeroinitializer
  %158 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %157, <16 x float> %127, <16 x float> %112)
  %159 = add nsw i64 %118, 96
  %160 = getelementptr inbounds float, float* %4, i64 %159
  %161 = load float, float* %160, align 4, !tbaa !598
  %162 = insertelement <16 x float> undef, float %161, i32 0
  %163 = shufflevector <16 x float> %162, <16 x float> undef, <16 x i32> zeroinitializer
  %164 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %163, <16 x float> %127, <16 x float> %111)
  %165 = add nsw i64 %118, 112
  %166 = getelementptr inbounds float, float* %4, i64 %165
  %167 = load float, float* %166, align 4, !tbaa !598
  %168 = insertelement <16 x float> undef, float %167, i32 0
  %169 = shufflevector <16 x float> %168, <16 x float> undef, <16 x i32> zeroinitializer
  %170 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %169, <16 x float> %127, <16 x float> %110)
  %171 = add nsw i64 %118, 128
  %172 = getelementptr inbounds float, float* %4, i64 %171
  %173 = load float, float* %172, align 4, !tbaa !598
  %174 = insertelement <16 x float> undef, float %173, i32 0
  %175 = shufflevector <16 x float> %174, <16 x float> undef, <16 x i32> zeroinitializer
  %176 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %175, <16 x float> %127, <16 x float> %109)
  %177 = add nsw i64 %118, 144
  %178 = getelementptr inbounds float, float* %4, i64 %177
  %179 = load float, float* %178, align 4, !tbaa !598
  %180 = insertelement <16 x float> undef, float %179, i32 0
  %181 = shufflevector <16 x float> %180, <16 x float> undef, <16 x i32> zeroinitializer
  %182 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %181, <16 x float> %127, <16 x float> %108)
  %183 = add nsw i64 %118, 160
  %184 = getelementptr inbounds float, float* %4, i64 %183
  %185 = load float, float* %184, align 4, !tbaa !598
  %186 = insertelement <16 x float> undef, float %185, i32 0
  %187 = shufflevector <16 x float> %186, <16 x float> undef, <16 x i32> zeroinitializer
  %188 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %187, <16 x float> %127, <16 x float> %107)
  %189 = add nsw i64 %118, 176
  %190 = getelementptr inbounds float, float* %4, i64 %189
  %191 = load float, float* %190, align 4, !tbaa !598
  %192 = insertelement <16 x float> undef, float %191, i32 0
  %193 = shufflevector <16 x float> %192, <16 x float> undef, <16 x i32> zeroinitializer
  %194 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %193, <16 x float> %127, <16 x float> %106)
  %195 = add nsw i64 %118, 192
  %196 = getelementptr inbounds float, float* %4, i64 %195
  %197 = load float, float* %196, align 4, !tbaa !598
  %198 = insertelement <16 x float> undef, float %197, i32 0
  %199 = shufflevector <16 x float> %198, <16 x float> undef, <16 x i32> zeroinitializer
  %200 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %199, <16 x float> %127, <16 x float> %105)
  %201 = add nsw i64 %118, 208
  %202 = getelementptr inbounds float, float* %4, i64 %201
  %203 = load float, float* %202, align 4, !tbaa !598
  %204 = insertelement <16 x float> undef, float %203, i32 0
  %205 = shufflevector <16 x float> %204, <16 x float> undef, <16 x i32> zeroinitializer
  %206 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %205, <16 x float> %127, <16 x float> %104)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %indvars.iv.next85 = add nuw nsw i64 %indvars.iv84, 1
  %exitcond86 = icmp eq i64 %indvars.iv.next85, 4
  br i1 %exitcond86, label %for_end6, label %for_body5, !prof !29

for_body11:                                       ; preds = %for_body11, %for_end3
  %indvars.iv93 = phi i64 [ 0, %for_end3 ], [ %indvars.iv.next94, %for_body11 ]
  %207 = mul nuw nsw i64 %indvars.iv93, 224
  %208 = trunc i64 %207 to i32
  %209 = add i32 %88, %208
  %210 = getelementptr inbounds float, float* %38, i64 %207
  %211 = bitcast float* %210 to <16 x float>*
  %212 = load <16 x float>, <16 x float>* %211, align 64, !tbaa !586
  %213 = fadd <16 x float> %93, %212
  %214 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %213, <16 x float> %96, <16 x float> %99)
  %215 = fcmp ogt <16 x float> %214, zeroinitializer
  %216 = select <16 x i1> %215, <16 x float> %214, <16 x float> zeroinitializer
  %217 = sext i32 %209 to i64
  %218 = getelementptr inbounds float, float* %10, i64 %217
  %219 = bitcast float* %218 to <16 x float>*
  store <16 x float> %216, <16 x float>* %219, align 64, !tbaa !604
  %220 = or i64 %207, 16
  %221 = trunc i64 %220 to i32
  %222 = add i32 %88, %221
  %223 = getelementptr inbounds float, float* %38, i64 %220
  %224 = bitcast float* %223 to <16 x float>*
  %225 = load <16 x float>, <16 x float>* %224, align 64, !tbaa !586
  %226 = fadd <16 x float> %93, %225
  %227 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %226, <16 x float> %96, <16 x float> %99)
  %228 = fcmp ogt <16 x float> %227, zeroinitializer
  %229 = select <16 x i1> %228, <16 x float> %227, <16 x float> zeroinitializer
  %230 = sext i32 %222 to i64
  %231 = getelementptr inbounds float, float* %10, i64 %230
  %232 = bitcast float* %231 to <16 x float>*
  store <16 x float> %229, <16 x float>* %232, align 64, !tbaa !604
  %233 = add nuw nsw i64 %207, 32
  %234 = trunc i64 %233 to i32
  %235 = add i32 %88, %234
  %236 = getelementptr inbounds float, float* %38, i64 %233
  %237 = bitcast float* %236 to <16 x float>*
  %238 = load <16 x float>, <16 x float>* %237, align 64, !tbaa !586
  %239 = fadd <16 x float> %93, %238
  %240 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %239, <16 x float> %96, <16 x float> %99)
  %241 = fcmp ogt <16 x float> %240, zeroinitializer
  %242 = select <16 x i1> %241, <16 x float> %240, <16 x float> zeroinitializer
  %243 = sext i32 %235 to i64
  %244 = getelementptr inbounds float, float* %10, i64 %243
  %245 = bitcast float* %244 to <16 x float>*
  store <16 x float> %242, <16 x float>* %245, align 64, !tbaa !604
  %246 = add nuw nsw i64 %207, 48
  %247 = trunc i64 %246 to i32
  %248 = add i32 %88, %247
  %249 = getelementptr inbounds float, float* %38, i64 %246
  %250 = bitcast float* %249 to <16 x float>*
  %251 = load <16 x float>, <16 x float>* %250, align 64, !tbaa !586
  %252 = fadd <16 x float> %93, %251
  %253 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %252, <16 x float> %96, <16 x float> %99)
  %254 = fcmp ogt <16 x float> %253, zeroinitializer
  %255 = select <16 x i1> %254, <16 x float> %253, <16 x float> zeroinitializer
  %256 = sext i32 %248 to i64
  %257 = getelementptr inbounds float, float* %10, i64 %256
  %258 = bitcast float* %257 to <16 x float>*
  store <16 x float> %255, <16 x float>* %258, align 64, !tbaa !604
  %259 = add nuw nsw i64 %207, 64
  %260 = trunc i64 %259 to i32
  %261 = add i32 %88, %260
  %262 = getelementptr inbounds float, float* %38, i64 %259
  %263 = bitcast float* %262 to <16 x float>*
  %264 = load <16 x float>, <16 x float>* %263, align 64, !tbaa !586
  %265 = fadd <16 x float> %93, %264
  %266 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %265, <16 x float> %96, <16 x float> %99)
  %267 = fcmp ogt <16 x float> %266, zeroinitializer
  %268 = select <16 x i1> %267, <16 x float> %266, <16 x float> zeroinitializer
  %269 = sext i32 %261 to i64
  %270 = getelementptr inbounds float, float* %10, i64 %269
  %271 = bitcast float* %270 to <16 x float>*
  store <16 x float> %268, <16 x float>* %271, align 64, !tbaa !604
  %272 = add nuw nsw i64 %207, 80
  %273 = trunc i64 %272 to i32
  %274 = add i32 %88, %273
  %275 = getelementptr inbounds float, float* %38, i64 %272
  %276 = bitcast float* %275 to <16 x float>*
  %277 = load <16 x float>, <16 x float>* %276, align 64, !tbaa !586
  %278 = fadd <16 x float> %93, %277
  %279 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %278, <16 x float> %96, <16 x float> %99)
  %280 = fcmp ogt <16 x float> %279, zeroinitializer
  %281 = select <16 x i1> %280, <16 x float> %279, <16 x float> zeroinitializer
  %282 = sext i32 %274 to i64
  %283 = getelementptr inbounds float, float* %10, i64 %282
  %284 = bitcast float* %283 to <16 x float>*
  store <16 x float> %281, <16 x float>* %284, align 64, !tbaa !604
  %285 = add nuw nsw i64 %207, 96
  %286 = trunc i64 %285 to i32
  %287 = add i32 %88, %286
  %288 = getelementptr inbounds float, float* %38, i64 %285
  %289 = bitcast float* %288 to <16 x float>*
  %290 = load <16 x float>, <16 x float>* %289, align 64, !tbaa !586
  %291 = fadd <16 x float> %93, %290
  %292 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %291, <16 x float> %96, <16 x float> %99)
  %293 = fcmp ogt <16 x float> %292, zeroinitializer
  %294 = select <16 x i1> %293, <16 x float> %292, <16 x float> zeroinitializer
  %295 = sext i32 %287 to i64
  %296 = getelementptr inbounds float, float* %10, i64 %295
  %297 = bitcast float* %296 to <16 x float>*
  store <16 x float> %294, <16 x float>* %297, align 64, !tbaa !604
  %298 = add nuw nsw i64 %207, 112
  %299 = trunc i64 %298 to i32
  %300 = add i32 %88, %299
  %301 = getelementptr inbounds float, float* %38, i64 %298
  %302 = bitcast float* %301 to <16 x float>*
  %303 = load <16 x float>, <16 x float>* %302, align 64, !tbaa !586
  %304 = fadd <16 x float> %93, %303
  %305 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %304, <16 x float> %96, <16 x float> %99)
  %306 = fcmp ogt <16 x float> %305, zeroinitializer
  %307 = select <16 x i1> %306, <16 x float> %305, <16 x float> zeroinitializer
  %308 = sext i32 %300 to i64
  %309 = getelementptr inbounds float, float* %10, i64 %308
  %310 = bitcast float* %309 to <16 x float>*
  store <16 x float> %307, <16 x float>* %310, align 64, !tbaa !604
  %311 = add nuw nsw i64 %207, 128
  %312 = trunc i64 %311 to i32
  %313 = add i32 %88, %312
  %314 = getelementptr inbounds float, float* %38, i64 %311
  %315 = bitcast float* %314 to <16 x float>*
  %316 = load <16 x float>, <16 x float>* %315, align 64, !tbaa !586
  %317 = fadd <16 x float> %93, %316
  %318 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %317, <16 x float> %96, <16 x float> %99)
  %319 = fcmp ogt <16 x float> %318, zeroinitializer
  %320 = select <16 x i1> %319, <16 x float> %318, <16 x float> zeroinitializer
  %321 = sext i32 %313 to i64
  %322 = getelementptr inbounds float, float* %10, i64 %321
  %323 = bitcast float* %322 to <16 x float>*
  store <16 x float> %320, <16 x float>* %323, align 64, !tbaa !604
  %324 = add nuw nsw i64 %207, 144
  %325 = trunc i64 %324 to i32
  %326 = add i32 %88, %325
  %327 = getelementptr inbounds float, float* %38, i64 %324
  %328 = bitcast float* %327 to <16 x float>*
  %329 = load <16 x float>, <16 x float>* %328, align 64, !tbaa !586
  %330 = fadd <16 x float> %93, %329
  %331 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %330, <16 x float> %96, <16 x float> %99)
  %332 = fcmp ogt <16 x float> %331, zeroinitializer
  %333 = select <16 x i1> %332, <16 x float> %331, <16 x float> zeroinitializer
  %334 = sext i32 %326 to i64
  %335 = getelementptr inbounds float, float* %10, i64 %334
  %336 = bitcast float* %335 to <16 x float>*
  store <16 x float> %333, <16 x float>* %336, align 64, !tbaa !604
  %337 = add nuw nsw i64 %207, 160
  %338 = trunc i64 %337 to i32
  %339 = add i32 %88, %338
  %340 = getelementptr inbounds float, float* %38, i64 %337
  %341 = bitcast float* %340 to <16 x float>*
  %342 = load <16 x float>, <16 x float>* %341, align 64, !tbaa !586
  %343 = fadd <16 x float> %93, %342
  %344 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %343, <16 x float> %96, <16 x float> %99)
  %345 = fcmp ogt <16 x float> %344, zeroinitializer
  %346 = select <16 x i1> %345, <16 x float> %344, <16 x float> zeroinitializer
  %347 = sext i32 %339 to i64
  %348 = getelementptr inbounds float, float* %10, i64 %347
  %349 = bitcast float* %348 to <16 x float>*
  store <16 x float> %346, <16 x float>* %349, align 64, !tbaa !604
  %350 = add nuw nsw i64 %207, 176
  %351 = trunc i64 %350 to i32
  %352 = add i32 %88, %351
  %353 = getelementptr inbounds float, float* %38, i64 %350
  %354 = bitcast float* %353 to <16 x float>*
  %355 = load <16 x float>, <16 x float>* %354, align 64, !tbaa !586
  %356 = fadd <16 x float> %93, %355
  %357 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %356, <16 x float> %96, <16 x float> %99)
  %358 = fcmp ogt <16 x float> %357, zeroinitializer
  %359 = select <16 x i1> %358, <16 x float> %357, <16 x float> zeroinitializer
  %360 = sext i32 %352 to i64
  %361 = getelementptr inbounds float, float* %10, i64 %360
  %362 = bitcast float* %361 to <16 x float>*
  store <16 x float> %359, <16 x float>* %362, align 64, !tbaa !604
  %363 = add nuw nsw i64 %207, 192
  %364 = trunc i64 %363 to i32
  %365 = add i32 %88, %364
  %366 = getelementptr inbounds float, float* %38, i64 %363
  %367 = bitcast float* %366 to <16 x float>*
  %368 = load <16 x float>, <16 x float>* %367, align 64, !tbaa !586
  %369 = fadd <16 x float> %93, %368
  %370 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %369, <16 x float> %96, <16 x float> %99)
  %371 = fcmp ogt <16 x float> %370, zeroinitializer
  %372 = select <16 x i1> %371, <16 x float> %370, <16 x float> zeroinitializer
  %373 = sext i32 %365 to i64
  %374 = getelementptr inbounds float, float* %10, i64 %373
  %375 = bitcast float* %374 to <16 x float>*
  store <16 x float> %372, <16 x float>* %375, align 64, !tbaa !604
  %376 = add nuw nsw i64 %207, 208
  %377 = trunc i64 %376 to i32
  %378 = add i32 %88, %377
  %379 = getelementptr inbounds float, float* %38, i64 %376
  %380 = bitcast float* %379 to <16 x float>*
  %381 = load <16 x float>, <16 x float>* %380, align 64, !tbaa !586
  %382 = fadd <16 x float> %93, %381
  %383 = tail call <16 x float> @llvm.fmuladd.v16f32(<16 x float> %382, <16 x float> %96, <16 x float> %99)
  %384 = fcmp ogt <16 x float> %383, zeroinitializer
  %385 = select <16 x i1> %384, <16 x float> %383, <16 x float> zeroinitializer
  %386 = sext i32 %378 to i64
  %387 = getelementptr inbounds float, float* %10, i64 %386
  %388 = bitcast float* %387 to <16 x float>*
  store <16 x float> %385, <16 x float>* %388, align 64, !tbaa !604
  %indvars.iv.next94 = add nuw nsw i64 %indvars.iv93, 1
  %exitcond95 = icmp eq i64 %indvars.iv.next94, 4
  br i1 %exitcond95, label %for_end12, label %for_body11, !prof !29

for_end12:                                        ; preds = %for_body11
  %389 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %390 = tail call i32 %389(i32 1, i32 %22, i8* nonnull %37)
  %391 = add nsw i32 %35, 1
  %392 = icmp slt i32 %391, %30
  br i1 %392, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !607 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !609, metadata !DIExpression()), !dbg !612
  call void @llvm.dbg.value(metadata i8* %1, metadata !610, metadata !DIExpression()), !dbg !612
  call void @llvm.dbg.value(metadata i32 %2, metadata !611, metadata !DIExpression()), !dbg !612
  %3 = bitcast i8* %0 to %1**, !dbg !612
  %4 = load %1*, %1** %3, align 8, !dbg !612
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !612
  %6 = bitcast i8* %5 to %1**, !dbg !612
  %7 = load %1*, %1** %6, align 8, !dbg !612
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !612
  %9 = bitcast i8* %8 to %1**, !dbg !612
  %10 = load %1*, %1** %9, align 8, !dbg !612
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !612
  %12 = bitcast i8* %11 to %1**, !dbg !612
  %13 = load %1*, %1** %12, align 8, !dbg !612
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !612
  %15 = load i8*, i8** %14, align 8, !dbg !612
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !612
  %17 = load i32, i32* %16, align 4, !dbg !612
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !612
  %19 = load i8*, i8** %18, align 8, !dbg !612
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !612
  %21 = load i8*, i8** %20, align 8, !dbg !612
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !612
  %23 = load i8*, i8** %22, align 8, !dbg !612
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !612
  ret i32 %24, !dbg !612
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %6 = tail call i8* %5(i32 1, i32 %4, i64 460800, i32 2, i32 32)
  %7 = alloca %37, align 8
  %8 = getelementptr inbounds %37, %37* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %37, %37* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %37* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.33, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !19

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %38, align 8
  %15 = getelementptr inbounds %38, %38* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %38, %38* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %38, %38* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %38, %38* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %38, %38* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %38* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.34, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !19

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.33(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 29
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 30
  %15 = select i1 %14, i32 %13, i32 30
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 30
  %18 = select i1 %17, i32 %16, i32 30
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end3
  %20 = phi i32 [ %536, %for_end3 ], [ %18, %for_body.preheader ]
  %21 = mul nsw i32 %20, 3840
  %.off = add i32 %20, -1
  %22 = icmp ult i32 %.off, 28
  %23 = mul nsw i32 %20, 3584
  br i1 %22, label %for_body2.us.preheader, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_body
  br label %for_body2

for_body2.us.preheader:                           ; preds = %for_body
  br label %for_body2.us

for_body2.us:                                     ; preds = %for_body2.us.preheader, %for_end6.us
  %indvars.iv24 = phi i64 [ %indvars.iv.next25, %for_end6.us ], [ 0, %for_body2.us.preheader ]
  %24 = shl nsw i64 %indvars.iv24, 7
  %25 = trunc i64 %indvars.iv24 to i32
  %26 = add i32 %25, -1
  %27 = icmp ult i32 %26, 28
  %28 = trunc i64 %24 to i32
  %29 = add i32 %21, %28
  br i1 %27, label %vector.body, label %vector.body37

for_end6.us:                                      ; preds = %vector.body37, %vector.body
  %indvars.iv.next25 = add nuw nsw i64 %indvars.iv24, 1
  %exitcond27 = icmp eq i64 %indvars.iv.next25, 30
  br i1 %exitcond27, label %for_end3, label %for_body2.us, !prof !29

vector.body:                                      ; preds = %for_body2.us
  %30 = trunc i64 %24 to i32
  %31 = add i32 %30, -3712
  %32 = add i32 %31, %23
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds float, float* %7, i64 %33
  %35 = bitcast float* %34 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %35, align 4, !tbaa !613
  %36 = getelementptr float, float* %34, i64 4
  %37 = bitcast float* %36 to <4 x i32>*
  %wide.load36 = load <4 x i32>, <4 x i32>* %37, align 4, !tbaa !613
  %38 = sext i32 %29 to i64
  %39 = getelementptr inbounds float, float* %4, i64 %38
  %40 = bitcast float* %39 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %40, align 4, !tbaa !616
  %41 = getelementptr float, float* %39, i64 4
  %42 = bitcast float* %41 to <4 x i32>*
  store <4 x i32> %wide.load36, <4 x i32>* %42, align 4, !tbaa !616
  %43 = or i64 %24, 8
  %44 = trunc i64 %43 to i32
  %45 = add i32 %21, %44
  %46 = trunc i64 %43 to i32
  %47 = add i32 %46, -3712
  %48 = add i32 %47, %23
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %51, align 4, !tbaa !613
  %52 = getelementptr float, float* %50, i64 4
  %53 = bitcast float* %52 to <4 x i32>*
  %wide.load36.1 = load <4 x i32>, <4 x i32>* %53, align 4, !tbaa !613
  %54 = sext i32 %45 to i64
  %55 = getelementptr inbounds float, float* %4, i64 %54
  %56 = bitcast float* %55 to <4 x i32>*
  store <4 x i32> %wide.load.1, <4 x i32>* %56, align 4, !tbaa !616
  %57 = getelementptr float, float* %55, i64 4
  %58 = bitcast float* %57 to <4 x i32>*
  store <4 x i32> %wide.load36.1, <4 x i32>* %58, align 4, !tbaa !616
  %59 = or i64 %24, 16
  %60 = trunc i64 %59 to i32
  %61 = add i32 %21, %60
  %62 = trunc i64 %59 to i32
  %63 = add i32 %62, -3712
  %64 = add i32 %63, %23
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %67, align 4, !tbaa !613
  %68 = getelementptr float, float* %66, i64 4
  %69 = bitcast float* %68 to <4 x i32>*
  %wide.load36.2 = load <4 x i32>, <4 x i32>* %69, align 4, !tbaa !613
  %70 = sext i32 %61 to i64
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = bitcast float* %71 to <4 x i32>*
  store <4 x i32> %wide.load.2, <4 x i32>* %72, align 4, !tbaa !616
  %73 = getelementptr float, float* %71, i64 4
  %74 = bitcast float* %73 to <4 x i32>*
  store <4 x i32> %wide.load36.2, <4 x i32>* %74, align 4, !tbaa !616
  %75 = or i64 %24, 24
  %76 = trunc i64 %75 to i32
  %77 = add i32 %21, %76
  %78 = trunc i64 %75 to i32
  %79 = add i32 %78, -3712
  %80 = add i32 %79, %23
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <4 x i32>*
  %wide.load.3 = load <4 x i32>, <4 x i32>* %83, align 4, !tbaa !613
  %84 = getelementptr float, float* %82, i64 4
  %85 = bitcast float* %84 to <4 x i32>*
  %wide.load36.3 = load <4 x i32>, <4 x i32>* %85, align 4, !tbaa !613
  %86 = sext i32 %77 to i64
  %87 = getelementptr inbounds float, float* %4, i64 %86
  %88 = bitcast float* %87 to <4 x i32>*
  store <4 x i32> %wide.load.3, <4 x i32>* %88, align 4, !tbaa !616
  %89 = getelementptr float, float* %87, i64 4
  %90 = bitcast float* %89 to <4 x i32>*
  store <4 x i32> %wide.load36.3, <4 x i32>* %90, align 4, !tbaa !616
  %91 = or i64 %24, 32
  %92 = trunc i64 %91 to i32
  %93 = add i32 %21, %92
  %94 = trunc i64 %91 to i32
  %95 = add i32 %94, -3712
  %96 = add i32 %95, %23
  %97 = sext i32 %96 to i64
  %98 = getelementptr inbounds float, float* %7, i64 %97
  %99 = bitcast float* %98 to <4 x i32>*
  %wide.load.4 = load <4 x i32>, <4 x i32>* %99, align 4, !tbaa !613
  %100 = getelementptr float, float* %98, i64 4
  %101 = bitcast float* %100 to <4 x i32>*
  %wide.load36.4 = load <4 x i32>, <4 x i32>* %101, align 4, !tbaa !613
  %102 = sext i32 %93 to i64
  %103 = getelementptr inbounds float, float* %4, i64 %102
  %104 = bitcast float* %103 to <4 x i32>*
  store <4 x i32> %wide.load.4, <4 x i32>* %104, align 4, !tbaa !616
  %105 = getelementptr float, float* %103, i64 4
  %106 = bitcast float* %105 to <4 x i32>*
  store <4 x i32> %wide.load36.4, <4 x i32>* %106, align 4, !tbaa !616
  %107 = or i64 %24, 40
  %108 = trunc i64 %107 to i32
  %109 = add i32 %21, %108
  %110 = trunc i64 %107 to i32
  %111 = add i32 %110, -3712
  %112 = add i32 %111, %23
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to <4 x i32>*
  %wide.load.5 = load <4 x i32>, <4 x i32>* %115, align 4, !tbaa !613
  %116 = getelementptr float, float* %114, i64 4
  %117 = bitcast float* %116 to <4 x i32>*
  %wide.load36.5 = load <4 x i32>, <4 x i32>* %117, align 4, !tbaa !613
  %118 = sext i32 %109 to i64
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = bitcast float* %119 to <4 x i32>*
  store <4 x i32> %wide.load.5, <4 x i32>* %120, align 4, !tbaa !616
  %121 = getelementptr float, float* %119, i64 4
  %122 = bitcast float* %121 to <4 x i32>*
  store <4 x i32> %wide.load36.5, <4 x i32>* %122, align 4, !tbaa !616
  %123 = or i64 %24, 48
  %124 = trunc i64 %123 to i32
  %125 = add i32 %21, %124
  %126 = trunc i64 %123 to i32
  %127 = add i32 %126, -3712
  %128 = add i32 %127, %23
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %7, i64 %129
  %131 = bitcast float* %130 to <4 x i32>*
  %wide.load.6 = load <4 x i32>, <4 x i32>* %131, align 4, !tbaa !613
  %132 = getelementptr float, float* %130, i64 4
  %133 = bitcast float* %132 to <4 x i32>*
  %wide.load36.6 = load <4 x i32>, <4 x i32>* %133, align 4, !tbaa !613
  %134 = sext i32 %125 to i64
  %135 = getelementptr inbounds float, float* %4, i64 %134
  %136 = bitcast float* %135 to <4 x i32>*
  store <4 x i32> %wide.load.6, <4 x i32>* %136, align 4, !tbaa !616
  %137 = getelementptr float, float* %135, i64 4
  %138 = bitcast float* %137 to <4 x i32>*
  store <4 x i32> %wide.load36.6, <4 x i32>* %138, align 4, !tbaa !616
  %139 = or i64 %24, 56
  %140 = trunc i64 %139 to i32
  %141 = add i32 %21, %140
  %142 = trunc i64 %139 to i32
  %143 = add i32 %142, -3712
  %144 = add i32 %143, %23
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds float, float* %7, i64 %145
  %147 = bitcast float* %146 to <4 x i32>*
  %wide.load.7 = load <4 x i32>, <4 x i32>* %147, align 4, !tbaa !613
  %148 = getelementptr float, float* %146, i64 4
  %149 = bitcast float* %148 to <4 x i32>*
  %wide.load36.7 = load <4 x i32>, <4 x i32>* %149, align 4, !tbaa !613
  %150 = sext i32 %141 to i64
  %151 = getelementptr inbounds float, float* %4, i64 %150
  %152 = bitcast float* %151 to <4 x i32>*
  store <4 x i32> %wide.load.7, <4 x i32>* %152, align 4, !tbaa !616
  %153 = getelementptr float, float* %151, i64 4
  %154 = bitcast float* %153 to <4 x i32>*
  store <4 x i32> %wide.load36.7, <4 x i32>* %154, align 4, !tbaa !616
  %155 = or i64 %24, 64
  %156 = trunc i64 %155 to i32
  %157 = add i32 %21, %156
  %158 = trunc i64 %155 to i32
  %159 = add i32 %158, -3712
  %160 = add i32 %159, %23
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds float, float* %7, i64 %161
  %163 = bitcast float* %162 to <4 x i32>*
  %wide.load.8 = load <4 x i32>, <4 x i32>* %163, align 4, !tbaa !613
  %164 = getelementptr float, float* %162, i64 4
  %165 = bitcast float* %164 to <4 x i32>*
  %wide.load36.8 = load <4 x i32>, <4 x i32>* %165, align 4, !tbaa !613
  %166 = sext i32 %157 to i64
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = bitcast float* %167 to <4 x i32>*
  store <4 x i32> %wide.load.8, <4 x i32>* %168, align 4, !tbaa !616
  %169 = getelementptr float, float* %167, i64 4
  %170 = bitcast float* %169 to <4 x i32>*
  store <4 x i32> %wide.load36.8, <4 x i32>* %170, align 4, !tbaa !616
  %171 = or i64 %24, 72
  %172 = trunc i64 %171 to i32
  %173 = add i32 %21, %172
  %174 = trunc i64 %171 to i32
  %175 = add i32 %174, -3712
  %176 = add i32 %175, %23
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <4 x i32>*
  %wide.load.9 = load <4 x i32>, <4 x i32>* %179, align 4, !tbaa !613
  %180 = getelementptr float, float* %178, i64 4
  %181 = bitcast float* %180 to <4 x i32>*
  %wide.load36.9 = load <4 x i32>, <4 x i32>* %181, align 4, !tbaa !613
  %182 = sext i32 %173 to i64
  %183 = getelementptr inbounds float, float* %4, i64 %182
  %184 = bitcast float* %183 to <4 x i32>*
  store <4 x i32> %wide.load.9, <4 x i32>* %184, align 4, !tbaa !616
  %185 = getelementptr float, float* %183, i64 4
  %186 = bitcast float* %185 to <4 x i32>*
  store <4 x i32> %wide.load36.9, <4 x i32>* %186, align 4, !tbaa !616
  %187 = or i64 %24, 80
  %188 = trunc i64 %187 to i32
  %189 = add i32 %21, %188
  %190 = trunc i64 %187 to i32
  %191 = add i32 %190, -3712
  %192 = add i32 %191, %23
  %193 = sext i32 %192 to i64
  %194 = getelementptr inbounds float, float* %7, i64 %193
  %195 = bitcast float* %194 to <4 x i32>*
  %wide.load.10 = load <4 x i32>, <4 x i32>* %195, align 4, !tbaa !613
  %196 = getelementptr float, float* %194, i64 4
  %197 = bitcast float* %196 to <4 x i32>*
  %wide.load36.10 = load <4 x i32>, <4 x i32>* %197, align 4, !tbaa !613
  %198 = sext i32 %189 to i64
  %199 = getelementptr inbounds float, float* %4, i64 %198
  %200 = bitcast float* %199 to <4 x i32>*
  store <4 x i32> %wide.load.10, <4 x i32>* %200, align 4, !tbaa !616
  %201 = getelementptr float, float* %199, i64 4
  %202 = bitcast float* %201 to <4 x i32>*
  store <4 x i32> %wide.load36.10, <4 x i32>* %202, align 4, !tbaa !616
  %203 = or i64 %24, 88
  %204 = trunc i64 %203 to i32
  %205 = add i32 %21, %204
  %206 = trunc i64 %203 to i32
  %207 = add i32 %206, -3712
  %208 = add i32 %207, %23
  %209 = sext i32 %208 to i64
  %210 = getelementptr inbounds float, float* %7, i64 %209
  %211 = bitcast float* %210 to <4 x i32>*
  %wide.load.11 = load <4 x i32>, <4 x i32>* %211, align 4, !tbaa !613
  %212 = getelementptr float, float* %210, i64 4
  %213 = bitcast float* %212 to <4 x i32>*
  %wide.load36.11 = load <4 x i32>, <4 x i32>* %213, align 4, !tbaa !613
  %214 = sext i32 %205 to i64
  %215 = getelementptr inbounds float, float* %4, i64 %214
  %216 = bitcast float* %215 to <4 x i32>*
  store <4 x i32> %wide.load.11, <4 x i32>* %216, align 4, !tbaa !616
  %217 = getelementptr float, float* %215, i64 4
  %218 = bitcast float* %217 to <4 x i32>*
  store <4 x i32> %wide.load36.11, <4 x i32>* %218, align 4, !tbaa !616
  %219 = or i64 %24, 96
  %220 = trunc i64 %219 to i32
  %221 = add i32 %21, %220
  %222 = trunc i64 %219 to i32
  %223 = add i32 %222, -3712
  %224 = add i32 %223, %23
  %225 = sext i32 %224 to i64
  %226 = getelementptr inbounds float, float* %7, i64 %225
  %227 = bitcast float* %226 to <4 x i32>*
  %wide.load.12 = load <4 x i32>, <4 x i32>* %227, align 4, !tbaa !613
  %228 = getelementptr float, float* %226, i64 4
  %229 = bitcast float* %228 to <4 x i32>*
  %wide.load36.12 = load <4 x i32>, <4 x i32>* %229, align 4, !tbaa !613
  %230 = sext i32 %221 to i64
  %231 = getelementptr inbounds float, float* %4, i64 %230
  %232 = bitcast float* %231 to <4 x i32>*
  store <4 x i32> %wide.load.12, <4 x i32>* %232, align 4, !tbaa !616
  %233 = getelementptr float, float* %231, i64 4
  %234 = bitcast float* %233 to <4 x i32>*
  store <4 x i32> %wide.load36.12, <4 x i32>* %234, align 4, !tbaa !616
  %235 = or i64 %24, 104
  %236 = trunc i64 %235 to i32
  %237 = add i32 %21, %236
  %238 = trunc i64 %235 to i32
  %239 = add i32 %238, -3712
  %240 = add i32 %239, %23
  %241 = sext i32 %240 to i64
  %242 = getelementptr inbounds float, float* %7, i64 %241
  %243 = bitcast float* %242 to <4 x i32>*
  %wide.load.13 = load <4 x i32>, <4 x i32>* %243, align 4, !tbaa !613
  %244 = getelementptr float, float* %242, i64 4
  %245 = bitcast float* %244 to <4 x i32>*
  %wide.load36.13 = load <4 x i32>, <4 x i32>* %245, align 4, !tbaa !613
  %246 = sext i32 %237 to i64
  %247 = getelementptr inbounds float, float* %4, i64 %246
  %248 = bitcast float* %247 to <4 x i32>*
  store <4 x i32> %wide.load.13, <4 x i32>* %248, align 4, !tbaa !616
  %249 = getelementptr float, float* %247, i64 4
  %250 = bitcast float* %249 to <4 x i32>*
  store <4 x i32> %wide.load36.13, <4 x i32>* %250, align 4, !tbaa !616
  %251 = or i64 %24, 112
  %252 = trunc i64 %251 to i32
  %253 = add i32 %21, %252
  %254 = trunc i64 %251 to i32
  %255 = add i32 %254, -3712
  %256 = add i32 %255, %23
  %257 = sext i32 %256 to i64
  %258 = getelementptr inbounds float, float* %7, i64 %257
  %259 = bitcast float* %258 to <4 x i32>*
  %wide.load.14 = load <4 x i32>, <4 x i32>* %259, align 4, !tbaa !613
  %260 = getelementptr float, float* %258, i64 4
  %261 = bitcast float* %260 to <4 x i32>*
  %wide.load36.14 = load <4 x i32>, <4 x i32>* %261, align 4, !tbaa !613
  %262 = sext i32 %253 to i64
  %263 = getelementptr inbounds float, float* %4, i64 %262
  %264 = bitcast float* %263 to <4 x i32>*
  store <4 x i32> %wide.load.14, <4 x i32>* %264, align 4, !tbaa !616
  %265 = getelementptr float, float* %263, i64 4
  %266 = bitcast float* %265 to <4 x i32>*
  store <4 x i32> %wide.load36.14, <4 x i32>* %266, align 4, !tbaa !616
  %267 = or i64 %24, 120
  %268 = trunc i64 %267 to i32
  %269 = add i32 %21, %268
  %270 = trunc i64 %267 to i32
  %271 = add i32 %270, -3712
  %272 = add i32 %271, %23
  %273 = sext i32 %272 to i64
  %274 = getelementptr inbounds float, float* %7, i64 %273
  %275 = bitcast float* %274 to <4 x i32>*
  %wide.load.15 = load <4 x i32>, <4 x i32>* %275, align 4, !tbaa !613
  %276 = getelementptr float, float* %274, i64 4
  %277 = bitcast float* %276 to <4 x i32>*
  %wide.load36.15 = load <4 x i32>, <4 x i32>* %277, align 4, !tbaa !613
  %278 = sext i32 %269 to i64
  %279 = getelementptr inbounds float, float* %4, i64 %278
  %280 = bitcast float* %279 to <4 x i32>*
  store <4 x i32> %wide.load.15, <4 x i32>* %280, align 4, !tbaa !616
  %281 = getelementptr float, float* %279, i64 4
  %282 = bitcast float* %281 to <4 x i32>*
  store <4 x i32> %wide.load36.15, <4 x i32>* %282, align 4, !tbaa !616
  br label %for_end6.us

vector.body37:                                    ; preds = %for_body2.us
  %283 = sext i32 %29 to i64
  %284 = getelementptr inbounds float, float* %4, i64 %283
  %285 = bitcast float* %284 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %285, align 4, !tbaa !616
  %286 = getelementptr float, float* %284, i64 4
  %287 = bitcast float* %286 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %287, align 4, !tbaa !616
  %288 = trunc i64 %24 to i32
  %289 = or i32 %288, 8
  %290 = add i32 %21, %289
  %291 = sext i32 %290 to i64
  %292 = getelementptr inbounds float, float* %4, i64 %291
  %293 = bitcast float* %292 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %293, align 4, !tbaa !616
  %294 = getelementptr float, float* %292, i64 4
  %295 = bitcast float* %294 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %295, align 4, !tbaa !616
  %296 = trunc i64 %24 to i32
  %297 = or i32 %296, 16
  %298 = add i32 %21, %297
  %299 = sext i32 %298 to i64
  %300 = getelementptr inbounds float, float* %4, i64 %299
  %301 = bitcast float* %300 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %301, align 4, !tbaa !616
  %302 = getelementptr float, float* %300, i64 4
  %303 = bitcast float* %302 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %303, align 4, !tbaa !616
  %304 = trunc i64 %24 to i32
  %305 = or i32 %304, 24
  %306 = add i32 %21, %305
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds float, float* %4, i64 %307
  %309 = bitcast float* %308 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %309, align 4, !tbaa !616
  %310 = getelementptr float, float* %308, i64 4
  %311 = bitcast float* %310 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %311, align 4, !tbaa !616
  %312 = trunc i64 %24 to i32
  %313 = or i32 %312, 32
  %314 = add i32 %21, %313
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds float, float* %4, i64 %315
  %317 = bitcast float* %316 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %317, align 4, !tbaa !616
  %318 = getelementptr float, float* %316, i64 4
  %319 = bitcast float* %318 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %319, align 4, !tbaa !616
  %320 = trunc i64 %24 to i32
  %321 = or i32 %320, 40
  %322 = add i32 %21, %321
  %323 = sext i32 %322 to i64
  %324 = getelementptr inbounds float, float* %4, i64 %323
  %325 = bitcast float* %324 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %325, align 4, !tbaa !616
  %326 = getelementptr float, float* %324, i64 4
  %327 = bitcast float* %326 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %327, align 4, !tbaa !616
  %328 = trunc i64 %24 to i32
  %329 = or i32 %328, 48
  %330 = add i32 %21, %329
  %331 = sext i32 %330 to i64
  %332 = getelementptr inbounds float, float* %4, i64 %331
  %333 = bitcast float* %332 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %333, align 4, !tbaa !616
  %334 = getelementptr float, float* %332, i64 4
  %335 = bitcast float* %334 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %335, align 4, !tbaa !616
  %336 = trunc i64 %24 to i32
  %337 = or i32 %336, 56
  %338 = add i32 %21, %337
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds float, float* %4, i64 %339
  %341 = bitcast float* %340 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %341, align 4, !tbaa !616
  %342 = getelementptr float, float* %340, i64 4
  %343 = bitcast float* %342 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %343, align 4, !tbaa !616
  %344 = trunc i64 %24 to i32
  %345 = or i32 %344, 64
  %346 = add i32 %21, %345
  %347 = sext i32 %346 to i64
  %348 = getelementptr inbounds float, float* %4, i64 %347
  %349 = bitcast float* %348 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %349, align 4, !tbaa !616
  %350 = getelementptr float, float* %348, i64 4
  %351 = bitcast float* %350 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %351, align 4, !tbaa !616
  %352 = trunc i64 %24 to i32
  %353 = or i32 %352, 72
  %354 = add i32 %21, %353
  %355 = sext i32 %354 to i64
  %356 = getelementptr inbounds float, float* %4, i64 %355
  %357 = bitcast float* %356 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %357, align 4, !tbaa !616
  %358 = getelementptr float, float* %356, i64 4
  %359 = bitcast float* %358 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %359, align 4, !tbaa !616
  %360 = trunc i64 %24 to i32
  %361 = or i32 %360, 80
  %362 = add i32 %21, %361
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds float, float* %4, i64 %363
  %365 = bitcast float* %364 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %365, align 4, !tbaa !616
  %366 = getelementptr float, float* %364, i64 4
  %367 = bitcast float* %366 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %367, align 4, !tbaa !616
  %368 = trunc i64 %24 to i32
  %369 = or i32 %368, 88
  %370 = add i32 %21, %369
  %371 = sext i32 %370 to i64
  %372 = getelementptr inbounds float, float* %4, i64 %371
  %373 = bitcast float* %372 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %373, align 4, !tbaa !616
  %374 = getelementptr float, float* %372, i64 4
  %375 = bitcast float* %374 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %375, align 4, !tbaa !616
  %376 = trunc i64 %24 to i32
  %377 = or i32 %376, 96
  %378 = add i32 %21, %377
  %379 = sext i32 %378 to i64
  %380 = getelementptr inbounds float, float* %4, i64 %379
  %381 = bitcast float* %380 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %381, align 4, !tbaa !616
  %382 = getelementptr float, float* %380, i64 4
  %383 = bitcast float* %382 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %383, align 4, !tbaa !616
  %384 = trunc i64 %24 to i32
  %385 = or i32 %384, 104
  %386 = add i32 %21, %385
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds float, float* %4, i64 %387
  %389 = bitcast float* %388 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %389, align 4, !tbaa !616
  %390 = getelementptr float, float* %388, i64 4
  %391 = bitcast float* %390 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %391, align 4, !tbaa !616
  %392 = trunc i64 %24 to i32
  %393 = or i32 %392, 112
  %394 = add i32 %21, %393
  %395 = sext i32 %394 to i64
  %396 = getelementptr inbounds float, float* %4, i64 %395
  %397 = bitcast float* %396 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %397, align 4, !tbaa !616
  %398 = getelementptr float, float* %396, i64 4
  %399 = bitcast float* %398 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %399, align 4, !tbaa !616
  %400 = trunc i64 %24 to i32
  %401 = or i32 %400, 120
  %402 = add i32 %21, %401
  %403 = sext i32 %402 to i64
  %404 = getelementptr inbounds float, float* %4, i64 %403
  %405 = bitcast float* %404 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %405, align 4, !tbaa !616
  %406 = getelementptr float, float* %404, i64 4
  %407 = bitcast float* %406 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %407, align 4, !tbaa !616
  br label %for_end6.us

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2.preheader, %for_body2
  %indvars.iv15 = phi i64 [ %indvars.iv.next16, %for_body2 ], [ 0, %for_body2.preheader ]
  %408 = shl nsw i64 %indvars.iv15, 7
  %409 = trunc i64 %408 to i32
  %410 = add i32 %21, %409
  %411 = sext i32 %410 to i64
  %412 = getelementptr inbounds float, float* %4, i64 %411
  %413 = bitcast float* %412 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %413, align 4, !tbaa !616
  %414 = getelementptr float, float* %412, i64 4
  %415 = bitcast float* %414 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %415, align 4, !tbaa !616
  %416 = trunc i64 %408 to i32
  %417 = or i32 %416, 8
  %418 = add i32 %21, %417
  %419 = sext i32 %418 to i64
  %420 = getelementptr inbounds float, float* %4, i64 %419
  %421 = bitcast float* %420 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %421, align 4, !tbaa !616
  %422 = getelementptr float, float* %420, i64 4
  %423 = bitcast float* %422 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %423, align 4, !tbaa !616
  %424 = trunc i64 %408 to i32
  %425 = or i32 %424, 16
  %426 = add i32 %21, %425
  %427 = sext i32 %426 to i64
  %428 = getelementptr inbounds float, float* %4, i64 %427
  %429 = bitcast float* %428 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %429, align 4, !tbaa !616
  %430 = getelementptr float, float* %428, i64 4
  %431 = bitcast float* %430 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %431, align 4, !tbaa !616
  %432 = trunc i64 %408 to i32
  %433 = or i32 %432, 24
  %434 = add i32 %21, %433
  %435 = sext i32 %434 to i64
  %436 = getelementptr inbounds float, float* %4, i64 %435
  %437 = bitcast float* %436 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %437, align 4, !tbaa !616
  %438 = getelementptr float, float* %436, i64 4
  %439 = bitcast float* %438 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %439, align 4, !tbaa !616
  %440 = trunc i64 %408 to i32
  %441 = or i32 %440, 32
  %442 = add i32 %21, %441
  %443 = sext i32 %442 to i64
  %444 = getelementptr inbounds float, float* %4, i64 %443
  %445 = bitcast float* %444 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %445, align 4, !tbaa !616
  %446 = getelementptr float, float* %444, i64 4
  %447 = bitcast float* %446 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %447, align 4, !tbaa !616
  %448 = trunc i64 %408 to i32
  %449 = or i32 %448, 40
  %450 = add i32 %21, %449
  %451 = sext i32 %450 to i64
  %452 = getelementptr inbounds float, float* %4, i64 %451
  %453 = bitcast float* %452 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %453, align 4, !tbaa !616
  %454 = getelementptr float, float* %452, i64 4
  %455 = bitcast float* %454 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %455, align 4, !tbaa !616
  %456 = trunc i64 %408 to i32
  %457 = or i32 %456, 48
  %458 = add i32 %21, %457
  %459 = sext i32 %458 to i64
  %460 = getelementptr inbounds float, float* %4, i64 %459
  %461 = bitcast float* %460 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %461, align 4, !tbaa !616
  %462 = getelementptr float, float* %460, i64 4
  %463 = bitcast float* %462 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %463, align 4, !tbaa !616
  %464 = trunc i64 %408 to i32
  %465 = or i32 %464, 56
  %466 = add i32 %21, %465
  %467 = sext i32 %466 to i64
  %468 = getelementptr inbounds float, float* %4, i64 %467
  %469 = bitcast float* %468 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %469, align 4, !tbaa !616
  %470 = getelementptr float, float* %468, i64 4
  %471 = bitcast float* %470 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %471, align 4, !tbaa !616
  %472 = trunc i64 %408 to i32
  %473 = or i32 %472, 64
  %474 = add i32 %21, %473
  %475 = sext i32 %474 to i64
  %476 = getelementptr inbounds float, float* %4, i64 %475
  %477 = bitcast float* %476 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %477, align 4, !tbaa !616
  %478 = getelementptr float, float* %476, i64 4
  %479 = bitcast float* %478 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %479, align 4, !tbaa !616
  %480 = trunc i64 %408 to i32
  %481 = or i32 %480, 72
  %482 = add i32 %21, %481
  %483 = sext i32 %482 to i64
  %484 = getelementptr inbounds float, float* %4, i64 %483
  %485 = bitcast float* %484 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %485, align 4, !tbaa !616
  %486 = getelementptr float, float* %484, i64 4
  %487 = bitcast float* %486 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %487, align 4, !tbaa !616
  %488 = trunc i64 %408 to i32
  %489 = or i32 %488, 80
  %490 = add i32 %21, %489
  %491 = sext i32 %490 to i64
  %492 = getelementptr inbounds float, float* %4, i64 %491
  %493 = bitcast float* %492 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %493, align 4, !tbaa !616
  %494 = getelementptr float, float* %492, i64 4
  %495 = bitcast float* %494 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %495, align 4, !tbaa !616
  %496 = trunc i64 %408 to i32
  %497 = or i32 %496, 88
  %498 = add i32 %21, %497
  %499 = sext i32 %498 to i64
  %500 = getelementptr inbounds float, float* %4, i64 %499
  %501 = bitcast float* %500 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %501, align 4, !tbaa !616
  %502 = getelementptr float, float* %500, i64 4
  %503 = bitcast float* %502 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %503, align 4, !tbaa !616
  %504 = trunc i64 %408 to i32
  %505 = or i32 %504, 96
  %506 = add i32 %21, %505
  %507 = sext i32 %506 to i64
  %508 = getelementptr inbounds float, float* %4, i64 %507
  %509 = bitcast float* %508 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %509, align 4, !tbaa !616
  %510 = getelementptr float, float* %508, i64 4
  %511 = bitcast float* %510 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %511, align 4, !tbaa !616
  %512 = trunc i64 %408 to i32
  %513 = or i32 %512, 104
  %514 = add i32 %21, %513
  %515 = sext i32 %514 to i64
  %516 = getelementptr inbounds float, float* %4, i64 %515
  %517 = bitcast float* %516 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %517, align 4, !tbaa !616
  %518 = getelementptr float, float* %516, i64 4
  %519 = bitcast float* %518 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %519, align 4, !tbaa !616
  %520 = trunc i64 %408 to i32
  %521 = or i32 %520, 112
  %522 = add i32 %21, %521
  %523 = sext i32 %522 to i64
  %524 = getelementptr inbounds float, float* %4, i64 %523
  %525 = bitcast float* %524 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %525, align 4, !tbaa !616
  %526 = getelementptr float, float* %524, i64 4
  %527 = bitcast float* %526 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %527, align 4, !tbaa !616
  %528 = trunc i64 %408 to i32
  %529 = or i32 %528, 120
  %530 = add i32 %21, %529
  %531 = sext i32 %530 to i64
  %532 = getelementptr inbounds float, float* %4, i64 %531
  %533 = bitcast float* %532 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %533, align 4, !tbaa !616
  %534 = getelementptr float, float* %532, i64 4
  %535 = bitcast float* %534 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %535, align 4, !tbaa !616
  %indvars.iv.next16 = add nuw nsw i64 %indvars.iv15, 1
  %exitcond17 = icmp eq i64 %indvars.iv.next16, 30
  br i1 %exitcond17, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2, %for_end6.us
  %536 = add nsw i32 %20, 1
  %537 = icmp slt i32 %536, %15
  br i1 %537, label %for_body, label %for_end, !prof !19
}

define private i32 @__tvm_parallel_lambda.34(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = add nsw i32 %20, 111
  %22 = sdiv i32 %21, %20
  %23 = add nsw i32 %0, 1
  %24 = mul nsw i32 %22, %23
  %25 = icmp slt i32 %24, 112
  %26 = select i1 %25, i32 %24, i32 112
  %27 = mul nsw i32 %22, %0
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = icmp slt i32 %29, %26
  br i1 %30, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %31 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %32 = bitcast float* %31 to <32 x float>*
  %33 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %34 = bitcast float* %33 to <32 x float>*
  %35 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %36 = bitcast float* %35 to <32 x float>*
  %37 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %38 = bitcast float* %37 to <32 x float>*
  %39 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %40 = bitcast float* %39 to <32 x float>*
  %41 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %42 = bitcast float* %41 to <32 x float>*
  %43 = add i32 %29, 1
  %44 = sext i32 %43 to i64
  %45 = add nsw i64 %44, -1
  %46 = sext i32 %26 to i64
  %47 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv64 = phi i64 [ %45, %for_body.lr.ph ], [ %indvars.iv.next65, %for_end3 ]
  %48 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %49 = tail call i8* %48(i32 1, i32 %18, i64 3584, i32 2, i32 32)
  %50 = trunc i64 %indvars.iv64 to i32
  %51 = srem i32 %50, 28
  %52 = sdiv i32 %50, 28
  %53 = mul nsw i32 %52, 36864
  %54 = sext i32 %53 to i64
  %55 = mul nsw i32 %51, 3840
  %56 = sext i32 %55 to i64
  %57 = mul nsw i32 %51, 3840
  %58 = add nsw i32 %57, 3840
  %59 = sext i32 %58 to i64
  %60 = add nsw i64 %54, 12288
  %61 = mul nsw i32 %51, 3840
  %62 = add nsw i32 %61, 7680
  %63 = sext i32 %62 to i64
  %64 = add nsw i64 %54, 24576
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %65 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %49, i64 %65
  %66 = add nsw i64 %65, %56
  call void @llvm.memset.p0i8.i64(i8* nonnull %47, i8 0, i64 896, i32 128, i1 false)
  br label %for_body8

for_end3:                                         ; preds = %for_end9.2
  %67 = mul nsw i64 %indvars.iv64, 896
  %68 = shl nsw i32 %52, 5
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %15, i64 %69
  %71 = bitcast float* %70 to <32 x float>*
  %72 = load <32 x float>, <32 x float>* %71, align 64, !tbaa !619
  %73 = bitcast i8* %49 to <32 x float>*
  %74 = load <32 x float>, <32 x float>* %73, align 64, !tbaa !622
  %75 = fadd <32 x float> %72, %74
  %76 = fcmp ogt <32 x float> %75, zeroinitializer
  %77 = select <32 x i1> %76, <32 x float> %75, <32 x float> zeroinitializer
  %78 = getelementptr inbounds float, float* %12, i64 %67
  %79 = bitcast float* %78 to <32 x float>*
  store <32 x float> %77, <32 x float>* %79, align 64, !tbaa !625
  %80 = getelementptr inbounds i8, i8* %49, i64 128
  %81 = bitcast i8* %80 to <32 x float>*
  %82 = load <32 x float>, <32 x float>* %81, align 64, !tbaa !622
  %83 = fadd <32 x float> %72, %82
  %84 = fcmp ogt <32 x float> %83, zeroinitializer
  %85 = select <32 x i1> %84, <32 x float> %83, <32 x float> zeroinitializer
  %86 = mul i64 %indvars.iv64, 3848290697216
  %sext = ashr exact i64 %86, 32
  %87 = or i64 %sext, 32
  %88 = getelementptr inbounds float, float* %12, i64 %87
  %89 = bitcast float* %88 to <32 x float>*
  store <32 x float> %85, <32 x float>* %89, align 64, !tbaa !625
  %90 = getelementptr inbounds i8, i8* %49, i64 256
  %91 = bitcast i8* %90 to <32 x float>*
  %92 = load <32 x float>, <32 x float>* %91, align 64, !tbaa !622
  %93 = fadd <32 x float> %72, %92
  %94 = fcmp ogt <32 x float> %93, zeroinitializer
  %95 = select <32 x i1> %94, <32 x float> %93, <32 x float> zeroinitializer
  %96 = mul i64 %indvars.iv64, 3848290697216
  %sext66 = ashr exact i64 %96, 32
  %97 = or i64 %sext66, 64
  %98 = getelementptr inbounds float, float* %12, i64 %97
  %99 = bitcast float* %98 to <32 x float>*
  store <32 x float> %95, <32 x float>* %99, align 64, !tbaa !625
  %100 = getelementptr inbounds i8, i8* %49, i64 384
  %101 = bitcast i8* %100 to <32 x float>*
  %102 = load <32 x float>, <32 x float>* %101, align 64, !tbaa !622
  %103 = fadd <32 x float> %72, %102
  %104 = fcmp ogt <32 x float> %103, zeroinitializer
  %105 = select <32 x i1> %104, <32 x float> %103, <32 x float> zeroinitializer
  %106 = mul i64 %indvars.iv64, 3848290697216
  %sext67 = ashr exact i64 %106, 32
  %107 = or i64 %sext67, 96
  %108 = getelementptr inbounds float, float* %12, i64 %107
  %109 = bitcast float* %108 to <32 x float>*
  store <32 x float> %105, <32 x float>* %109, align 64, !tbaa !625
  %110 = getelementptr inbounds i8, i8* %49, i64 512
  %111 = bitcast i8* %110 to <32 x float>*
  %112 = load <32 x float>, <32 x float>* %111, align 64, !tbaa !622
  %113 = fadd <32 x float> %72, %112
  %114 = fcmp ogt <32 x float> %113, zeroinitializer
  %115 = select <32 x i1> %114, <32 x float> %113, <32 x float> zeroinitializer
  %116 = mul i64 %indvars.iv64, 3848290697216
  %sext68 = add i64 %116, 549755813888
  %117 = ashr exact i64 %sext68, 32
  %118 = getelementptr inbounds float, float* %12, i64 %117
  %119 = bitcast float* %118 to <32 x float>*
  store <32 x float> %115, <32 x float>* %119, align 64, !tbaa !625
  %120 = getelementptr inbounds i8, i8* %49, i64 640
  %121 = bitcast i8* %120 to <32 x float>*
  %122 = load <32 x float>, <32 x float>* %121, align 64, !tbaa !622
  %123 = fadd <32 x float> %72, %122
  %124 = fcmp ogt <32 x float> %123, zeroinitializer
  %125 = select <32 x i1> %124, <32 x float> %123, <32 x float> zeroinitializer
  %126 = mul i64 %indvars.iv64, 3848290697216
  %sext69 = add i64 %126, 687194767360
  %127 = ashr exact i64 %sext69, 32
  %128 = getelementptr inbounds float, float* %12, i64 %127
  %129 = bitcast float* %128 to <32 x float>*
  store <32 x float> %125, <32 x float>* %129, align 64, !tbaa !625
  %130 = getelementptr inbounds i8, i8* %49, i64 768
  %131 = bitcast i8* %130 to <32 x float>*
  %132 = load <32 x float>, <32 x float>* %131, align 64, !tbaa !622
  %133 = fadd <32 x float> %72, %132
  %134 = fcmp ogt <32 x float> %133, zeroinitializer
  %135 = select <32 x i1> %134, <32 x float> %133, <32 x float> zeroinitializer
  %136 = mul i64 %indvars.iv64, 3848290697216
  %sext70 = add i64 %136, 824633720832
  %137 = ashr exact i64 %sext70, 32
  %138 = getelementptr inbounds float, float* %12, i64 %137
  %139 = bitcast float* %138 to <32 x float>*
  store <32 x float> %135, <32 x float>* %139, align 64, !tbaa !625
  %140 = getelementptr inbounds i8, i8* %49, i64 896
  %141 = bitcast i8* %140 to <32 x float>*
  %142 = load <32 x float>, <32 x float>* %141, align 64, !tbaa !622
  %143 = fadd <32 x float> %72, %142
  %144 = fcmp ogt <32 x float> %143, zeroinitializer
  %145 = select <32 x i1> %144, <32 x float> %143, <32 x float> zeroinitializer
  %146 = mul i64 %indvars.iv64, 3848290697216
  %sext71 = add i64 %146, 962072674304
  %147 = ashr exact i64 %sext71, 32
  %148 = getelementptr inbounds float, float* %12, i64 %147
  %149 = bitcast float* %148 to <32 x float>*
  store <32 x float> %145, <32 x float>* %149, align 64, !tbaa !625
  %150 = getelementptr inbounds i8, i8* %49, i64 1024
  %151 = bitcast i8* %150 to <32 x float>*
  %152 = load <32 x float>, <32 x float>* %151, align 64, !tbaa !622
  %153 = fadd <32 x float> %72, %152
  %154 = fcmp ogt <32 x float> %153, zeroinitializer
  %155 = select <32 x i1> %154, <32 x float> %153, <32 x float> zeroinitializer
  %156 = mul i64 %indvars.iv64, 3848290697216
  %sext72 = add i64 %156, 1099511627776
  %157 = ashr exact i64 %sext72, 32
  %158 = getelementptr inbounds float, float* %12, i64 %157
  %159 = bitcast float* %158 to <32 x float>*
  store <32 x float> %155, <32 x float>* %159, align 64, !tbaa !625
  %160 = getelementptr inbounds i8, i8* %49, i64 1152
  %161 = bitcast i8* %160 to <32 x float>*
  %162 = load <32 x float>, <32 x float>* %161, align 64, !tbaa !622
  %163 = fadd <32 x float> %72, %162
  %164 = fcmp ogt <32 x float> %163, zeroinitializer
  %165 = select <32 x i1> %164, <32 x float> %163, <32 x float> zeroinitializer
  %166 = mul i64 %indvars.iv64, 3848290697216
  %sext73 = add i64 %166, 1236950581248
  %167 = ashr exact i64 %sext73, 32
  %168 = getelementptr inbounds float, float* %12, i64 %167
  %169 = bitcast float* %168 to <32 x float>*
  store <32 x float> %165, <32 x float>* %169, align 64, !tbaa !625
  %170 = getelementptr inbounds i8, i8* %49, i64 1280
  %171 = bitcast i8* %170 to <32 x float>*
  %172 = load <32 x float>, <32 x float>* %171, align 64, !tbaa !622
  %173 = fadd <32 x float> %72, %172
  %174 = fcmp ogt <32 x float> %173, zeroinitializer
  %175 = select <32 x i1> %174, <32 x float> %173, <32 x float> zeroinitializer
  %176 = mul i64 %indvars.iv64, 3848290697216
  %sext74 = add i64 %176, 1374389534720
  %177 = ashr exact i64 %sext74, 32
  %178 = getelementptr inbounds float, float* %12, i64 %177
  %179 = bitcast float* %178 to <32 x float>*
  store <32 x float> %175, <32 x float>* %179, align 64, !tbaa !625
  %180 = getelementptr inbounds i8, i8* %49, i64 1408
  %181 = bitcast i8* %180 to <32 x float>*
  %182 = load <32 x float>, <32 x float>* %181, align 64, !tbaa !622
  %183 = fadd <32 x float> %72, %182
  %184 = fcmp ogt <32 x float> %183, zeroinitializer
  %185 = select <32 x i1> %184, <32 x float> %183, <32 x float> zeroinitializer
  %186 = mul i64 %indvars.iv64, 3848290697216
  %sext75 = add i64 %186, 1511828488192
  %187 = ashr exact i64 %sext75, 32
  %188 = getelementptr inbounds float, float* %12, i64 %187
  %189 = bitcast float* %188 to <32 x float>*
  store <32 x float> %185, <32 x float>* %189, align 64, !tbaa !625
  %190 = getelementptr inbounds i8, i8* %49, i64 1536
  %191 = bitcast i8* %190 to <32 x float>*
  %192 = load <32 x float>, <32 x float>* %191, align 64, !tbaa !622
  %193 = fadd <32 x float> %72, %192
  %194 = fcmp ogt <32 x float> %193, zeroinitializer
  %195 = select <32 x i1> %194, <32 x float> %193, <32 x float> zeroinitializer
  %196 = mul i64 %indvars.iv64, 3848290697216
  %sext76 = add i64 %196, 1649267441664
  %197 = ashr exact i64 %sext76, 32
  %198 = getelementptr inbounds float, float* %12, i64 %197
  %199 = bitcast float* %198 to <32 x float>*
  store <32 x float> %195, <32 x float>* %199, align 64, !tbaa !625
  %200 = getelementptr inbounds i8, i8* %49, i64 1664
  %201 = bitcast i8* %200 to <32 x float>*
  %202 = load <32 x float>, <32 x float>* %201, align 64, !tbaa !622
  %203 = fadd <32 x float> %72, %202
  %204 = fcmp ogt <32 x float> %203, zeroinitializer
  %205 = select <32 x i1> %204, <32 x float> %203, <32 x float> zeroinitializer
  %206 = mul i64 %indvars.iv64, 3848290697216
  %sext77 = add i64 %206, 1786706395136
  %207 = ashr exact i64 %sext77, 32
  %208 = getelementptr inbounds float, float* %12, i64 %207
  %209 = bitcast float* %208 to <32 x float>*
  store <32 x float> %205, <32 x float>* %209, align 64, !tbaa !625
  %210 = getelementptr inbounds i8, i8* %49, i64 1792
  %211 = bitcast i8* %210 to <32 x float>*
  %212 = load <32 x float>, <32 x float>* %211, align 64, !tbaa !622
  %213 = fadd <32 x float> %72, %212
  %214 = fcmp ogt <32 x float> %213, zeroinitializer
  %215 = select <32 x i1> %214, <32 x float> %213, <32 x float> zeroinitializer
  %216 = mul i64 %indvars.iv64, 3848290697216
  %sext78 = add i64 %216, 1924145348608
  %217 = ashr exact i64 %sext78, 32
  %218 = getelementptr inbounds float, float* %12, i64 %217
  %219 = bitcast float* %218 to <32 x float>*
  store <32 x float> %215, <32 x float>* %219, align 64, !tbaa !625
  %220 = getelementptr inbounds i8, i8* %49, i64 1920
  %221 = bitcast i8* %220 to <32 x float>*
  %222 = load <32 x float>, <32 x float>* %221, align 64, !tbaa !622
  %223 = fadd <32 x float> %72, %222
  %224 = fcmp ogt <32 x float> %223, zeroinitializer
  %225 = select <32 x i1> %224, <32 x float> %223, <32 x float> zeroinitializer
  %226 = mul i64 %indvars.iv64, 3848290697216
  %sext79 = add i64 %226, 2061584302080
  %227 = ashr exact i64 %sext79, 32
  %228 = getelementptr inbounds float, float* %12, i64 %227
  %229 = bitcast float* %228 to <32 x float>*
  store <32 x float> %225, <32 x float>* %229, align 64, !tbaa !625
  %230 = getelementptr inbounds i8, i8* %49, i64 2048
  %231 = bitcast i8* %230 to <32 x float>*
  %232 = load <32 x float>, <32 x float>* %231, align 64, !tbaa !622
  %233 = fadd <32 x float> %72, %232
  %234 = fcmp ogt <32 x float> %233, zeroinitializer
  %235 = select <32 x i1> %234, <32 x float> %233, <32 x float> zeroinitializer
  %236 = mul i64 %indvars.iv64, 3848290697216
  %sext80 = add i64 %236, 2199023255552
  %237 = ashr exact i64 %sext80, 32
  %238 = getelementptr inbounds float, float* %12, i64 %237
  %239 = bitcast float* %238 to <32 x float>*
  store <32 x float> %235, <32 x float>* %239, align 64, !tbaa !625
  %240 = getelementptr inbounds i8, i8* %49, i64 2176
  %241 = bitcast i8* %240 to <32 x float>*
  %242 = load <32 x float>, <32 x float>* %241, align 64, !tbaa !622
  %243 = fadd <32 x float> %72, %242
  %244 = fcmp ogt <32 x float> %243, zeroinitializer
  %245 = select <32 x i1> %244, <32 x float> %243, <32 x float> zeroinitializer
  %246 = mul i64 %indvars.iv64, 3848290697216
  %sext81 = add i64 %246, 2336462209024
  %247 = ashr exact i64 %sext81, 32
  %248 = getelementptr inbounds float, float* %12, i64 %247
  %249 = bitcast float* %248 to <32 x float>*
  store <32 x float> %245, <32 x float>* %249, align 64, !tbaa !625
  %250 = getelementptr inbounds i8, i8* %49, i64 2304
  %251 = bitcast i8* %250 to <32 x float>*
  %252 = load <32 x float>, <32 x float>* %251, align 64, !tbaa !622
  %253 = fadd <32 x float> %72, %252
  %254 = fcmp ogt <32 x float> %253, zeroinitializer
  %255 = select <32 x i1> %254, <32 x float> %253, <32 x float> zeroinitializer
  %256 = mul i64 %indvars.iv64, 3848290697216
  %sext82 = add i64 %256, 2473901162496
  %257 = ashr exact i64 %sext82, 32
  %258 = getelementptr inbounds float, float* %12, i64 %257
  %259 = bitcast float* %258 to <32 x float>*
  store <32 x float> %255, <32 x float>* %259, align 64, !tbaa !625
  %260 = getelementptr inbounds i8, i8* %49, i64 2432
  %261 = bitcast i8* %260 to <32 x float>*
  %262 = load <32 x float>, <32 x float>* %261, align 64, !tbaa !622
  %263 = fadd <32 x float> %72, %262
  %264 = fcmp ogt <32 x float> %263, zeroinitializer
  %265 = select <32 x i1> %264, <32 x float> %263, <32 x float> zeroinitializer
  %266 = mul i64 %indvars.iv64, 3848290697216
  %sext83 = add i64 %266, 2611340115968
  %267 = ashr exact i64 %sext83, 32
  %268 = getelementptr inbounds float, float* %12, i64 %267
  %269 = bitcast float* %268 to <32 x float>*
  store <32 x float> %265, <32 x float>* %269, align 64, !tbaa !625
  %270 = getelementptr inbounds i8, i8* %49, i64 2560
  %271 = bitcast i8* %270 to <32 x float>*
  %272 = load <32 x float>, <32 x float>* %271, align 64, !tbaa !622
  %273 = fadd <32 x float> %72, %272
  %274 = fcmp ogt <32 x float> %273, zeroinitializer
  %275 = select <32 x i1> %274, <32 x float> %273, <32 x float> zeroinitializer
  %276 = mul i64 %indvars.iv64, 3848290697216
  %sext84 = add i64 %276, 2748779069440
  %277 = ashr exact i64 %sext84, 32
  %278 = getelementptr inbounds float, float* %12, i64 %277
  %279 = bitcast float* %278 to <32 x float>*
  store <32 x float> %275, <32 x float>* %279, align 64, !tbaa !625
  %280 = getelementptr inbounds i8, i8* %49, i64 2688
  %281 = bitcast i8* %280 to <32 x float>*
  %282 = load <32 x float>, <32 x float>* %281, align 64, !tbaa !622
  %283 = fadd <32 x float> %72, %282
  %284 = fcmp ogt <32 x float> %283, zeroinitializer
  %285 = select <32 x i1> %284, <32 x float> %283, <32 x float> zeroinitializer
  %286 = mul i64 %indvars.iv64, 3848290697216
  %sext85 = add i64 %286, 2886218022912
  %287 = ashr exact i64 %sext85, 32
  %288 = getelementptr inbounds float, float* %12, i64 %287
  %289 = bitcast float* %288 to <32 x float>*
  store <32 x float> %285, <32 x float>* %289, align 64, !tbaa !625
  %290 = getelementptr inbounds i8, i8* %49, i64 2816
  %291 = bitcast i8* %290 to <32 x float>*
  %292 = load <32 x float>, <32 x float>* %291, align 64, !tbaa !622
  %293 = fadd <32 x float> %72, %292
  %294 = fcmp ogt <32 x float> %293, zeroinitializer
  %295 = select <32 x i1> %294, <32 x float> %293, <32 x float> zeroinitializer
  %296 = mul i64 %indvars.iv64, 3848290697216
  %sext86 = add i64 %296, 3023656976384
  %297 = ashr exact i64 %sext86, 32
  %298 = getelementptr inbounds float, float* %12, i64 %297
  %299 = bitcast float* %298 to <32 x float>*
  store <32 x float> %295, <32 x float>* %299, align 64, !tbaa !625
  %300 = getelementptr inbounds i8, i8* %49, i64 2944
  %301 = bitcast i8* %300 to <32 x float>*
  %302 = load <32 x float>, <32 x float>* %301, align 64, !tbaa !622
  %303 = fadd <32 x float> %72, %302
  %304 = fcmp ogt <32 x float> %303, zeroinitializer
  %305 = select <32 x i1> %304, <32 x float> %303, <32 x float> zeroinitializer
  %306 = mul i64 %indvars.iv64, 3848290697216
  %sext87 = add i64 %306, 3161095929856
  %307 = ashr exact i64 %sext87, 32
  %308 = getelementptr inbounds float, float* %12, i64 %307
  %309 = bitcast float* %308 to <32 x float>*
  store <32 x float> %305, <32 x float>* %309, align 64, !tbaa !625
  %310 = getelementptr inbounds i8, i8* %49, i64 3072
  %311 = bitcast i8* %310 to <32 x float>*
  %312 = load <32 x float>, <32 x float>* %311, align 64, !tbaa !622
  %313 = fadd <32 x float> %72, %312
  %314 = fcmp ogt <32 x float> %313, zeroinitializer
  %315 = select <32 x i1> %314, <32 x float> %313, <32 x float> zeroinitializer
  %316 = mul i64 %indvars.iv64, 3848290697216
  %sext88 = add i64 %316, 3298534883328
  %317 = ashr exact i64 %sext88, 32
  %318 = getelementptr inbounds float, float* %12, i64 %317
  %319 = bitcast float* %318 to <32 x float>*
  store <32 x float> %315, <32 x float>* %319, align 64, !tbaa !625
  %320 = getelementptr inbounds i8, i8* %49, i64 3200
  %321 = bitcast i8* %320 to <32 x float>*
  %322 = load <32 x float>, <32 x float>* %321, align 64, !tbaa !622
  %323 = fadd <32 x float> %72, %322
  %324 = fcmp ogt <32 x float> %323, zeroinitializer
  %325 = select <32 x i1> %324, <32 x float> %323, <32 x float> zeroinitializer
  %326 = mul i64 %indvars.iv64, 3848290697216
  %sext89 = add i64 %326, 3435973836800
  %327 = ashr exact i64 %sext89, 32
  %328 = getelementptr inbounds float, float* %12, i64 %327
  %329 = bitcast float* %328 to <32 x float>*
  store <32 x float> %325, <32 x float>* %329, align 64, !tbaa !625
  %330 = getelementptr inbounds i8, i8* %49, i64 3328
  %331 = bitcast i8* %330 to <32 x float>*
  %332 = load <32 x float>, <32 x float>* %331, align 64, !tbaa !622
  %333 = fadd <32 x float> %72, %332
  %334 = fcmp ogt <32 x float> %333, zeroinitializer
  %335 = select <32 x i1> %334, <32 x float> %333, <32 x float> zeroinitializer
  %336 = mul i64 %indvars.iv64, 3848290697216
  %sext90 = add i64 %336, 3573412790272
  %337 = ashr exact i64 %sext90, 32
  %338 = getelementptr inbounds float, float* %12, i64 %337
  %339 = bitcast float* %338 to <32 x float>*
  store <32 x float> %335, <32 x float>* %339, align 64, !tbaa !625
  %340 = getelementptr inbounds i8, i8* %49, i64 3456
  %341 = bitcast i8* %340 to <32 x float>*
  %342 = load <32 x float>, <32 x float>* %341, align 64, !tbaa !622
  %343 = fadd <32 x float> %72, %342
  %344 = fcmp ogt <32 x float> %343, zeroinitializer
  %345 = select <32 x i1> %344, <32 x float> %343, <32 x float> zeroinitializer
  %346 = mul i64 %indvars.iv64, 3848290697216
  %sext91 = add i64 %346, 3710851743744
  %347 = ashr exact i64 %sext91, 32
  %348 = getelementptr inbounds float, float* %12, i64 %347
  %349 = bitcast float* %348 to <32 x float>*
  store <32 x float> %345, <32 x float>* %349, align 64, !tbaa !625
  %350 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %351 = tail call i32 %350(i32 1, i32 %18, i8* nonnull %49)
  %indvars.iv.next65 = add nsw i64 %indvars.iv64, 1
  %352 = icmp slt i64 %indvars.iv.next65, %46
  br i1 %352, label %for_body, label %for_end, !prof !19

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %353 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %438, %for_body8 ]
  %354 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %432, %for_body8 ]
  %355 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %431, %for_body8 ]
  %356 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %430, %for_body8 ]
  %357 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %429, %for_body8 ]
  %358 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %428, %for_body8 ]
  %359 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %427, %for_body8 ]
  %360 = add nsw i64 %66, %indvars.iv
  %361 = getelementptr inbounds float, float* %6, i64 %360
  %362 = load float, float* %361, align 4, !tbaa !616
  %363 = insertelement <32 x float> undef, float %362, i32 0
  %364 = shufflevector <32 x float> %363, <32 x float> undef, <32 x i32> zeroinitializer
  %365 = shl nsw i64 %indvars.iv, 5
  %366 = add nsw i64 %365, %54
  %367 = getelementptr inbounds float, float* %9, i64 %366
  %368 = bitcast float* %367 to <32 x float>*
  %369 = load <32 x float>, <32 x float>* %368, align 64, !tbaa !628
  %370 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %364, <32 x float> %369, <32 x float> %359)
  %371 = add nsw i64 %360, 128
  %372 = getelementptr inbounds float, float* %6, i64 %371
  %373 = load float, float* %372, align 4, !tbaa !616
  %374 = insertelement <32 x float> undef, float %373, i32 0
  %375 = shufflevector <32 x float> %374, <32 x float> undef, <32 x i32> zeroinitializer
  %376 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %375, <32 x float> %369, <32 x float> %358)
  %377 = add nsw i64 %360, 256
  %378 = getelementptr inbounds float, float* %6, i64 %377
  %379 = load float, float* %378, align 4, !tbaa !616
  %380 = insertelement <32 x float> undef, float %379, i32 0
  %381 = shufflevector <32 x float> %380, <32 x float> undef, <32 x i32> zeroinitializer
  %382 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %369, <32 x float> %357)
  %383 = add nsw i64 %360, 384
  %384 = getelementptr inbounds float, float* %6, i64 %383
  %385 = load float, float* %384, align 4, !tbaa !616
  %386 = insertelement <32 x float> undef, float %385, i32 0
  %387 = shufflevector <32 x float> %386, <32 x float> undef, <32 x i32> zeroinitializer
  %388 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %369, <32 x float> %356)
  %389 = add nsw i64 %360, 512
  %390 = getelementptr inbounds float, float* %6, i64 %389
  %391 = load float, float* %390, align 4, !tbaa !616
  %392 = insertelement <32 x float> undef, float %391, i32 0
  %393 = shufflevector <32 x float> %392, <32 x float> undef, <32 x i32> zeroinitializer
  %394 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %369, <32 x float> %355)
  %395 = add nsw i64 %360, 640
  %396 = getelementptr inbounds float, float* %6, i64 %395
  %397 = load float, float* %396, align 4, !tbaa !616
  %398 = insertelement <32 x float> undef, float %397, i32 0
  %399 = shufflevector <32 x float> %398, <32 x float> undef, <32 x i32> zeroinitializer
  %400 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %369, <32 x float> %354)
  %401 = add nsw i64 %360, 768
  %402 = getelementptr inbounds float, float* %6, i64 %401
  %403 = load float, float* %402, align 4, !tbaa !616
  %404 = insertelement <32 x float> undef, float %403, i32 0
  %405 = shufflevector <32 x float> %404, <32 x float> undef, <32 x i32> zeroinitializer
  %406 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %369, <32 x float> %353)
  %407 = add nsw i64 %366, 4096
  %408 = getelementptr inbounds float, float* %9, i64 %407
  %409 = bitcast float* %408 to <32 x float>*
  %410 = load <32 x float>, <32 x float>* %409, align 64, !tbaa !628
  %411 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %375, <32 x float> %410, <32 x float> %370)
  %412 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %410, <32 x float> %376)
  %413 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %410, <32 x float> %382)
  %414 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %410, <32 x float> %388)
  %415 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %410, <32 x float> %394)
  %416 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %410, <32 x float> %400)
  %417 = add nsw i64 %360, 896
  %418 = getelementptr inbounds float, float* %6, i64 %417
  %419 = load float, float* %418, align 4, !tbaa !616
  %420 = insertelement <32 x float> undef, float %419, i32 0
  %421 = shufflevector <32 x float> %420, <32 x float> undef, <32 x i32> zeroinitializer
  %422 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %410, <32 x float> %406)
  %423 = add nsw i64 %366, 8192
  %424 = getelementptr inbounds float, float* %9, i64 %423
  %425 = bitcast float* %424 to <32 x float>*
  %426 = load <32 x float>, <32 x float>* %425, align 64, !tbaa !628
  %427 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %381, <32 x float> %426, <32 x float> %411)
  %428 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %387, <32 x float> %426, <32 x float> %412)
  %429 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %393, <32 x float> %426, <32 x float> %413)
  %430 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %399, <32 x float> %426, <32 x float> %414)
  %431 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %426, <32 x float> %415)
  %432 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %421, <32 x float> %426, <32 x float> %416)
  %433 = add nsw i64 %360, 1024
  %434 = getelementptr inbounds float, float* %6, i64 %433
  %435 = load float, float* %434, align 4, !tbaa !616
  %436 = insertelement <32 x float> undef, float %435, i32 0
  %437 = shufflevector <32 x float> %436, <32 x float> undef, <32 x i32> zeroinitializer
  %438 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %437, <32 x float> %426, <32 x float> %422)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %439 = add nsw i64 %65, %59
  br label %for_body8.1

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %440 = phi <32 x float> [ %438, %for_end9 ], [ %525, %for_body8.1 ]
  %441 = phi <32 x float> [ %432, %for_end9 ], [ %519, %for_body8.1 ]
  %442 = phi <32 x float> [ %431, %for_end9 ], [ %518, %for_body8.1 ]
  %443 = phi <32 x float> [ %430, %for_end9 ], [ %517, %for_body8.1 ]
  %444 = phi <32 x float> [ %429, %for_end9 ], [ %516, %for_body8.1 ]
  %445 = phi <32 x float> [ %428, %for_end9 ], [ %515, %for_body8.1 ]
  %446 = phi <32 x float> [ %427, %for_end9 ], [ %514, %for_body8.1 ]
  %447 = add nsw i64 %439, %indvars.iv.1
  %448 = getelementptr inbounds float, float* %6, i64 %447
  %449 = load float, float* %448, align 4, !tbaa !616
  %450 = insertelement <32 x float> undef, float %449, i32 0
  %451 = shufflevector <32 x float> %450, <32 x float> undef, <32 x i32> zeroinitializer
  %452 = shl nsw i64 %indvars.iv.1, 5
  %453 = add nsw i64 %60, %452
  %454 = getelementptr inbounds float, float* %9, i64 %453
  %455 = bitcast float* %454 to <32 x float>*
  %456 = load <32 x float>, <32 x float>* %455, align 64, !tbaa !628
  %457 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %451, <32 x float> %456, <32 x float> %446)
  %458 = add nsw i64 %447, 128
  %459 = getelementptr inbounds float, float* %6, i64 %458
  %460 = load float, float* %459, align 4, !tbaa !616
  %461 = insertelement <32 x float> undef, float %460, i32 0
  %462 = shufflevector <32 x float> %461, <32 x float> undef, <32 x i32> zeroinitializer
  %463 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %462, <32 x float> %456, <32 x float> %445)
  %464 = add nsw i64 %447, 256
  %465 = getelementptr inbounds float, float* %6, i64 %464
  %466 = load float, float* %465, align 4, !tbaa !616
  %467 = insertelement <32 x float> undef, float %466, i32 0
  %468 = shufflevector <32 x float> %467, <32 x float> undef, <32 x i32> zeroinitializer
  %469 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %456, <32 x float> %444)
  %470 = add nsw i64 %447, 384
  %471 = getelementptr inbounds float, float* %6, i64 %470
  %472 = load float, float* %471, align 4, !tbaa !616
  %473 = insertelement <32 x float> undef, float %472, i32 0
  %474 = shufflevector <32 x float> %473, <32 x float> undef, <32 x i32> zeroinitializer
  %475 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %456, <32 x float> %443)
  %476 = add nsw i64 %447, 512
  %477 = getelementptr inbounds float, float* %6, i64 %476
  %478 = load float, float* %477, align 4, !tbaa !616
  %479 = insertelement <32 x float> undef, float %478, i32 0
  %480 = shufflevector <32 x float> %479, <32 x float> undef, <32 x i32> zeroinitializer
  %481 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %456, <32 x float> %442)
  %482 = add nsw i64 %447, 640
  %483 = getelementptr inbounds float, float* %6, i64 %482
  %484 = load float, float* %483, align 4, !tbaa !616
  %485 = insertelement <32 x float> undef, float %484, i32 0
  %486 = shufflevector <32 x float> %485, <32 x float> undef, <32 x i32> zeroinitializer
  %487 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %456, <32 x float> %441)
  %488 = add nsw i64 %447, 768
  %489 = getelementptr inbounds float, float* %6, i64 %488
  %490 = load float, float* %489, align 4, !tbaa !616
  %491 = insertelement <32 x float> undef, float %490, i32 0
  %492 = shufflevector <32 x float> %491, <32 x float> undef, <32 x i32> zeroinitializer
  %493 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %456, <32 x float> %440)
  %494 = add nsw i64 %453, 4096
  %495 = getelementptr inbounds float, float* %9, i64 %494
  %496 = bitcast float* %495 to <32 x float>*
  %497 = load <32 x float>, <32 x float>* %496, align 64, !tbaa !628
  %498 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %462, <32 x float> %497, <32 x float> %457)
  %499 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %497, <32 x float> %463)
  %500 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %497, <32 x float> %469)
  %501 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %497, <32 x float> %475)
  %502 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %497, <32 x float> %481)
  %503 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %497, <32 x float> %487)
  %504 = add nsw i64 %447, 896
  %505 = getelementptr inbounds float, float* %6, i64 %504
  %506 = load float, float* %505, align 4, !tbaa !616
  %507 = insertelement <32 x float> undef, float %506, i32 0
  %508 = shufflevector <32 x float> %507, <32 x float> undef, <32 x i32> zeroinitializer
  %509 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %497, <32 x float> %493)
  %510 = add nsw i64 %453, 8192
  %511 = getelementptr inbounds float, float* %9, i64 %510
  %512 = bitcast float* %511 to <32 x float>*
  %513 = load <32 x float>, <32 x float>* %512, align 64, !tbaa !628
  %514 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %513, <32 x float> %498)
  %515 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %474, <32 x float> %513, <32 x float> %499)
  %516 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %480, <32 x float> %513, <32 x float> %500)
  %517 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %513, <32 x float> %501)
  %518 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %492, <32 x float> %513, <32 x float> %502)
  %519 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %508, <32 x float> %513, <32 x float> %503)
  %520 = add nsw i64 %447, 1024
  %521 = getelementptr inbounds float, float* %6, i64 %520
  %522 = load float, float* %521, align 4, !tbaa !616
  %523 = insertelement <32 x float> undef, float %522, i32 0
  %524 = shufflevector <32 x float> %523, <32 x float> undef, <32 x i32> zeroinitializer
  %525 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %524, <32 x float> %513, <32 x float> %509)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 128
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !29

for_end9.1:                                       ; preds = %for_body8.1
  %526 = add nsw i64 %65, %63
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %527 = phi <32 x float> [ %525, %for_end9.1 ], [ %612, %for_body8.2 ]
  %528 = phi <32 x float> [ %519, %for_end9.1 ], [ %606, %for_body8.2 ]
  %529 = phi <32 x float> [ %518, %for_end9.1 ], [ %605, %for_body8.2 ]
  %530 = phi <32 x float> [ %517, %for_end9.1 ], [ %604, %for_body8.2 ]
  %531 = phi <32 x float> [ %516, %for_end9.1 ], [ %603, %for_body8.2 ]
  %532 = phi <32 x float> [ %515, %for_end9.1 ], [ %602, %for_body8.2 ]
  %533 = phi <32 x float> [ %514, %for_end9.1 ], [ %601, %for_body8.2 ]
  %534 = add nsw i64 %526, %indvars.iv.2
  %535 = getelementptr inbounds float, float* %6, i64 %534
  %536 = load float, float* %535, align 4, !tbaa !616
  %537 = insertelement <32 x float> undef, float %536, i32 0
  %538 = shufflevector <32 x float> %537, <32 x float> undef, <32 x i32> zeroinitializer
  %539 = shl nsw i64 %indvars.iv.2, 5
  %540 = add nsw i64 %64, %539
  %541 = getelementptr inbounds float, float* %9, i64 %540
  %542 = bitcast float* %541 to <32 x float>*
  %543 = load <32 x float>, <32 x float>* %542, align 64, !tbaa !628
  %544 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %538, <32 x float> %543, <32 x float> %533)
  %545 = add nsw i64 %534, 128
  %546 = getelementptr inbounds float, float* %6, i64 %545
  %547 = load float, float* %546, align 4, !tbaa !616
  %548 = insertelement <32 x float> undef, float %547, i32 0
  %549 = shufflevector <32 x float> %548, <32 x float> undef, <32 x i32> zeroinitializer
  %550 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %549, <32 x float> %543, <32 x float> %532)
  %551 = add nsw i64 %534, 256
  %552 = getelementptr inbounds float, float* %6, i64 %551
  %553 = load float, float* %552, align 4, !tbaa !616
  %554 = insertelement <32 x float> undef, float %553, i32 0
  %555 = shufflevector <32 x float> %554, <32 x float> undef, <32 x i32> zeroinitializer
  %556 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %555, <32 x float> %543, <32 x float> %531)
  %557 = add nsw i64 %534, 384
  %558 = getelementptr inbounds float, float* %6, i64 %557
  %559 = load float, float* %558, align 4, !tbaa !616
  %560 = insertelement <32 x float> undef, float %559, i32 0
  %561 = shufflevector <32 x float> %560, <32 x float> undef, <32 x i32> zeroinitializer
  %562 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %561, <32 x float> %543, <32 x float> %530)
  %563 = add nsw i64 %534, 512
  %564 = getelementptr inbounds float, float* %6, i64 %563
  %565 = load float, float* %564, align 4, !tbaa !616
  %566 = insertelement <32 x float> undef, float %565, i32 0
  %567 = shufflevector <32 x float> %566, <32 x float> undef, <32 x i32> zeroinitializer
  %568 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %543, <32 x float> %529)
  %569 = add nsw i64 %534, 640
  %570 = getelementptr inbounds float, float* %6, i64 %569
  %571 = load float, float* %570, align 4, !tbaa !616
  %572 = insertelement <32 x float> undef, float %571, i32 0
  %573 = shufflevector <32 x float> %572, <32 x float> undef, <32 x i32> zeroinitializer
  %574 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %573, <32 x float> %543, <32 x float> %528)
  %575 = add nsw i64 %534, 768
  %576 = getelementptr inbounds float, float* %6, i64 %575
  %577 = load float, float* %576, align 4, !tbaa !616
  %578 = insertelement <32 x float> undef, float %577, i32 0
  %579 = shufflevector <32 x float> %578, <32 x float> undef, <32 x i32> zeroinitializer
  %580 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %579, <32 x float> %543, <32 x float> %527)
  %581 = add nsw i64 %540, 4096
  %582 = getelementptr inbounds float, float* %9, i64 %581
  %583 = bitcast float* %582 to <32 x float>*
  %584 = load <32 x float>, <32 x float>* %583, align 64, !tbaa !628
  %585 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %549, <32 x float> %584, <32 x float> %544)
  %586 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %555, <32 x float> %584, <32 x float> %550)
  %587 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %561, <32 x float> %584, <32 x float> %556)
  %588 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %584, <32 x float> %562)
  %589 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %573, <32 x float> %584, <32 x float> %568)
  %590 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %579, <32 x float> %584, <32 x float> %574)
  %591 = add nsw i64 %534, 896
  %592 = getelementptr inbounds float, float* %6, i64 %591
  %593 = load float, float* %592, align 4, !tbaa !616
  %594 = insertelement <32 x float> undef, float %593, i32 0
  %595 = shufflevector <32 x float> %594, <32 x float> undef, <32 x i32> zeroinitializer
  %596 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %584, <32 x float> %580)
  %597 = add nsw i64 %540, 8192
  %598 = getelementptr inbounds float, float* %9, i64 %597
  %599 = bitcast float* %598 to <32 x float>*
  %600 = load <32 x float>, <32 x float>* %599, align 64, !tbaa !628
  %601 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %555, <32 x float> %600, <32 x float> %585)
  %602 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %561, <32 x float> %600, <32 x float> %586)
  %603 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %600, <32 x float> %587)
  %604 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %573, <32 x float> %600, <32 x float> %588)
  %605 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %579, <32 x float> %600, <32 x float> %589)
  %606 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %595, <32 x float> %600, <32 x float> %590)
  %607 = add nsw i64 %534, 1024
  %608 = getelementptr inbounds float, float* %6, i64 %607
  %609 = load float, float* %608, align 4, !tbaa !616
  %610 = insertelement <32 x float> undef, float %609, i32 0
  %611 = shufflevector <32 x float> %610, <32 x float> undef, <32 x i32> zeroinitializer
  %612 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %611, <32 x float> %600, <32 x float> %596)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 128
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !29

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %601, <32 x float>* %.sub, align 128, !tbaa !631
  store <32 x float> %602, <32 x float>* %32, align 128, !tbaa !631
  store <32 x float> %603, <32 x float>* %34, align 128, !tbaa !631
  store <32 x float> %604, <32 x float>* %36, align 128, !tbaa !631
  store <32 x float> %605, <32 x float>* %38, align 128, !tbaa !631
  store <32 x float> %606, <32 x float>* %40, align 128, !tbaa !631
  store <32 x float> %612, <32 x float>* %42, align 128, !tbaa !631
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %scevgep, i8* nonnull %4, i64 896, i32 64, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond57 = icmp eq i64 %indvar.next, 4
  br i1 %exitcond57, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !640 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !642, metadata !DIExpression()), !dbg !645
  call void @llvm.dbg.value(metadata i8* %1, metadata !643, metadata !DIExpression()), !dbg !645
  call void @llvm.dbg.value(metadata i32 %2, metadata !644, metadata !DIExpression()), !dbg !645
  %3 = bitcast i8* %0 to %1**, !dbg !645
  %4 = load %1*, %1** %3, align 8, !dbg !645
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !645
  %6 = bitcast i8* %5 to %1**, !dbg !645
  %7 = load %1*, %1** %6, align 8, !dbg !645
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !645
  %9 = bitcast i8* %8 to %1**, !dbg !645
  %10 = load %1*, %1** %9, align 8, !dbg !645
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !645
  %12 = bitcast i8* %11 to %1**, !dbg !645
  %13 = load %1*, %1** %12, align 8, !dbg !645
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !645
  %15 = load i8*, i8** %14, align 8, !dbg !645
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !645
  %17 = load i32, i32* %16, align 4, !dbg !645
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !645
  %19 = load i8*, i8** %18, align 8, !dbg !645
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !645
  %21 = load i8*, i8** %20, align 8, !dbg !645
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !645
  %23 = load i8*, i8** %22, align 8, !dbg !645
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !645
  ret i32 %24, !dbg !645
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = alloca %39, align 8
  %6 = getelementptr inbounds %39, %39* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %39, %39* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %39, %39* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %39, %39* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %39, %39* %5, i64 0, i32 4
  store i32 %4, i32* %10, align 8
  %11 = bitcast %39* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.35, i8* nonnull %11, i32 0)
  ret i32 %13
}

define private i32 @__tvm_parallel_lambda.35(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to i32*
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 447
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 448
  %24 = select i1 %23, i32 %22, i32 448
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 448
  %27 = select i1 %26, i32 %25, i32 448
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv58 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next59, %for_end3 ]
  %33 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %34 = tail call i8* %33(i32 1, i32 %16, i64 7168, i32 2, i32 32)
  %35 = bitcast i8* %34 to float*
  %36 = trunc i64 %indvars.iv58 to i32
  %37 = srem i32 %36, 56
  %38 = mul nsw i32 %37, 224
  %39 = sdiv i32 %36, 56
  %40 = shl i32 %39, 11
  %41 = sext i32 %40 to i64
  %42 = sext i32 %38 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv49 = phi i64 [ 0, %for_body ], [ %indvars.iv.next50, %for_end6 ]
  %43 = mul nuw nsw i64 %indvars.iv49, 224
  %44 = getelementptr inbounds float, float* %35, i64 %43
  %45 = bitcast float* %44 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %45, align 64, !tbaa !646
  %46 = add nuw nsw i64 %43, 32
  %47 = getelementptr inbounds float, float* %35, i64 %46
  %48 = bitcast float* %47 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %48, align 64, !tbaa !646
  %49 = add nuw nsw i64 %43, 64
  %50 = getelementptr inbounds float, float* %35, i64 %49
  %51 = bitcast float* %50 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %51, align 64, !tbaa !646
  %52 = add nuw nsw i64 %43, 96
  %53 = getelementptr inbounds float, float* %35, i64 %52
  %54 = bitcast float* %53 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %54, align 64, !tbaa !646
  %55 = add nuw nsw i64 %43, 128
  %56 = getelementptr inbounds float, float* %35, i64 %55
  %57 = bitcast float* %56 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %57, align 64, !tbaa !646
  %58 = add nuw nsw i64 %43, 160
  %59 = getelementptr inbounds float, float* %35, i64 %58
  %60 = bitcast float* %59 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %60, align 64, !tbaa !646
  %61 = add nuw nsw i64 %43, 192
  %62 = getelementptr inbounds float, float* %35, i64 %61
  %63 = bitcast float* %62 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %63, align 64, !tbaa !646
  %64 = mul nuw nsw i64 %indvars.iv49, 28
  %65 = add nsw i64 %64, %42
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %66 = mul nsw i64 %indvars.iv58, 1792
  %67 = shl nsw i32 %39, 5
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %13, i64 %68
  %70 = bitcast float* %69 to <32 x float>*
  %71 = load <32 x float>, <32 x float>* %70, align 64, !tbaa !649
  %72 = bitcast i8* %34 to <32 x float>*
  %73 = load <32 x float>, <32 x float>* %72, align 64, !tbaa !646
  %74 = fadd <32 x float> %71, %73
  %75 = getelementptr inbounds float, float* %10, i64 %66
  %76 = bitcast float* %75 to <32 x float>*
  store <32 x float> %74, <32 x float>* %76, align 64, !tbaa !652
  %77 = getelementptr inbounds i8, i8* %34, i64 128
  %78 = bitcast i8* %77 to <32 x float>*
  %79 = load <32 x float>, <32 x float>* %78, align 64, !tbaa !646
  %80 = fadd <32 x float> %71, %79
  %81 = mul i64 %indvars.iv58, 7696581394432
  %sext = ashr exact i64 %81, 32
  %82 = or i64 %sext, 32
  %83 = getelementptr inbounds float, float* %10, i64 %82
  %84 = bitcast float* %83 to <32 x float>*
  store <32 x float> %80, <32 x float>* %84, align 64, !tbaa !652
  %85 = getelementptr inbounds i8, i8* %34, i64 256
  %86 = bitcast i8* %85 to <32 x float>*
  %87 = load <32 x float>, <32 x float>* %86, align 64, !tbaa !646
  %88 = fadd <32 x float> %71, %87
  %89 = mul i64 %indvars.iv58, 7696581394432
  %sext60 = ashr exact i64 %89, 32
  %90 = or i64 %sext60, 64
  %91 = getelementptr inbounds float, float* %10, i64 %90
  %92 = bitcast float* %91 to <32 x float>*
  store <32 x float> %88, <32 x float>* %92, align 64, !tbaa !652
  %93 = getelementptr inbounds i8, i8* %34, i64 384
  %94 = bitcast i8* %93 to <32 x float>*
  %95 = load <32 x float>, <32 x float>* %94, align 64, !tbaa !646
  %96 = fadd <32 x float> %71, %95
  %97 = mul i64 %indvars.iv58, 7696581394432
  %sext61 = ashr exact i64 %97, 32
  %98 = or i64 %sext61, 96
  %99 = getelementptr inbounds float, float* %10, i64 %98
  %100 = bitcast float* %99 to <32 x float>*
  store <32 x float> %96, <32 x float>* %100, align 64, !tbaa !652
  %101 = getelementptr inbounds i8, i8* %34, i64 512
  %102 = bitcast i8* %101 to <32 x float>*
  %103 = load <32 x float>, <32 x float>* %102, align 64, !tbaa !646
  %104 = fadd <32 x float> %71, %103
  %105 = mul i64 %indvars.iv58, 7696581394432
  %sext62 = ashr exact i64 %105, 32
  %106 = or i64 %sext62, 128
  %107 = getelementptr inbounds float, float* %10, i64 %106
  %108 = bitcast float* %107 to <32 x float>*
  store <32 x float> %104, <32 x float>* %108, align 64, !tbaa !652
  %109 = getelementptr inbounds i8, i8* %34, i64 640
  %110 = bitcast i8* %109 to <32 x float>*
  %111 = load <32 x float>, <32 x float>* %110, align 64, !tbaa !646
  %112 = fadd <32 x float> %71, %111
  %113 = mul i64 %indvars.iv58, 7696581394432
  %sext63 = ashr exact i64 %113, 32
  %114 = or i64 %sext63, 160
  %115 = getelementptr inbounds float, float* %10, i64 %114
  %116 = bitcast float* %115 to <32 x float>*
  store <32 x float> %112, <32 x float>* %116, align 64, !tbaa !652
  %117 = getelementptr inbounds i8, i8* %34, i64 768
  %118 = bitcast i8* %117 to <32 x float>*
  %119 = load <32 x float>, <32 x float>* %118, align 64, !tbaa !646
  %120 = fadd <32 x float> %71, %119
  %121 = mul i64 %indvars.iv58, 7696581394432
  %sext64 = ashr exact i64 %121, 32
  %122 = or i64 %sext64, 192
  %123 = getelementptr inbounds float, float* %10, i64 %122
  %124 = bitcast float* %123 to <32 x float>*
  store <32 x float> %120, <32 x float>* %124, align 64, !tbaa !652
  %125 = getelementptr inbounds i8, i8* %34, i64 896
  %126 = bitcast i8* %125 to <32 x float>*
  %127 = load <32 x float>, <32 x float>* %126, align 64, !tbaa !646
  %128 = fadd <32 x float> %71, %127
  %129 = mul i64 %indvars.iv58, 7696581394432
  %sext65 = ashr exact i64 %129, 32
  %130 = or i64 %sext65, 224
  %131 = getelementptr inbounds float, float* %10, i64 %130
  %132 = bitcast float* %131 to <32 x float>*
  store <32 x float> %128, <32 x float>* %132, align 64, !tbaa !652
  %133 = getelementptr inbounds i8, i8* %34, i64 1024
  %134 = bitcast i8* %133 to <32 x float>*
  %135 = load <32 x float>, <32 x float>* %134, align 64, !tbaa !646
  %136 = fadd <32 x float> %71, %135
  %137 = mul i64 %indvars.iv58, 7696581394432
  %sext66 = add i64 %137, 1099511627776
  %138 = ashr exact i64 %sext66, 32
  %139 = getelementptr inbounds float, float* %10, i64 %138
  %140 = bitcast float* %139 to <32 x float>*
  store <32 x float> %136, <32 x float>* %140, align 64, !tbaa !652
  %141 = getelementptr inbounds i8, i8* %34, i64 1152
  %142 = bitcast i8* %141 to <32 x float>*
  %143 = load <32 x float>, <32 x float>* %142, align 64, !tbaa !646
  %144 = fadd <32 x float> %71, %143
  %145 = mul i64 %indvars.iv58, 7696581394432
  %sext67 = add i64 %145, 1236950581248
  %146 = ashr exact i64 %sext67, 32
  %147 = getelementptr inbounds float, float* %10, i64 %146
  %148 = bitcast float* %147 to <32 x float>*
  store <32 x float> %144, <32 x float>* %148, align 64, !tbaa !652
  %149 = getelementptr inbounds i8, i8* %34, i64 1280
  %150 = bitcast i8* %149 to <32 x float>*
  %151 = load <32 x float>, <32 x float>* %150, align 64, !tbaa !646
  %152 = fadd <32 x float> %71, %151
  %153 = mul i64 %indvars.iv58, 7696581394432
  %sext68 = add i64 %153, 1374389534720
  %154 = ashr exact i64 %sext68, 32
  %155 = getelementptr inbounds float, float* %10, i64 %154
  %156 = bitcast float* %155 to <32 x float>*
  store <32 x float> %152, <32 x float>* %156, align 64, !tbaa !652
  %157 = getelementptr inbounds i8, i8* %34, i64 1408
  %158 = bitcast i8* %157 to <32 x float>*
  %159 = load <32 x float>, <32 x float>* %158, align 64, !tbaa !646
  %160 = fadd <32 x float> %71, %159
  %161 = mul i64 %indvars.iv58, 7696581394432
  %sext69 = add i64 %161, 1511828488192
  %162 = ashr exact i64 %sext69, 32
  %163 = getelementptr inbounds float, float* %10, i64 %162
  %164 = bitcast float* %163 to <32 x float>*
  store <32 x float> %160, <32 x float>* %164, align 64, !tbaa !652
  %165 = getelementptr inbounds i8, i8* %34, i64 1536
  %166 = bitcast i8* %165 to <32 x float>*
  %167 = load <32 x float>, <32 x float>* %166, align 64, !tbaa !646
  %168 = fadd <32 x float> %71, %167
  %169 = mul i64 %indvars.iv58, 7696581394432
  %sext70 = add i64 %169, 1649267441664
  %170 = ashr exact i64 %sext70, 32
  %171 = getelementptr inbounds float, float* %10, i64 %170
  %172 = bitcast float* %171 to <32 x float>*
  store <32 x float> %168, <32 x float>* %172, align 64, !tbaa !652
  %173 = getelementptr inbounds i8, i8* %34, i64 1664
  %174 = bitcast i8* %173 to <32 x float>*
  %175 = load <32 x float>, <32 x float>* %174, align 64, !tbaa !646
  %176 = fadd <32 x float> %71, %175
  %177 = mul i64 %indvars.iv58, 7696581394432
  %sext71 = add i64 %177, 1786706395136
  %178 = ashr exact i64 %sext71, 32
  %179 = getelementptr inbounds float, float* %10, i64 %178
  %180 = bitcast float* %179 to <32 x float>*
  store <32 x float> %176, <32 x float>* %180, align 64, !tbaa !652
  %181 = getelementptr inbounds i8, i8* %34, i64 1792
  %182 = bitcast i8* %181 to <32 x float>*
  %183 = load <32 x float>, <32 x float>* %182, align 64, !tbaa !646
  %184 = fadd <32 x float> %71, %183
  %185 = mul i64 %indvars.iv58, 7696581394432
  %sext72 = add i64 %185, 1924145348608
  %186 = ashr exact i64 %sext72, 32
  %187 = getelementptr inbounds float, float* %10, i64 %186
  %188 = bitcast float* %187 to <32 x float>*
  store <32 x float> %184, <32 x float>* %188, align 64, !tbaa !652
  %189 = getelementptr inbounds i8, i8* %34, i64 1920
  %190 = bitcast i8* %189 to <32 x float>*
  %191 = load <32 x float>, <32 x float>* %190, align 64, !tbaa !646
  %192 = fadd <32 x float> %71, %191
  %193 = mul i64 %indvars.iv58, 7696581394432
  %sext73 = add i64 %193, 2061584302080
  %194 = ashr exact i64 %sext73, 32
  %195 = getelementptr inbounds float, float* %10, i64 %194
  %196 = bitcast float* %195 to <32 x float>*
  store <32 x float> %192, <32 x float>* %196, align 64, !tbaa !652
  %197 = getelementptr inbounds i8, i8* %34, i64 2048
  %198 = bitcast i8* %197 to <32 x float>*
  %199 = load <32 x float>, <32 x float>* %198, align 64, !tbaa !646
  %200 = fadd <32 x float> %71, %199
  %201 = mul i64 %indvars.iv58, 7696581394432
  %sext74 = add i64 %201, 2199023255552
  %202 = ashr exact i64 %sext74, 32
  %203 = getelementptr inbounds float, float* %10, i64 %202
  %204 = bitcast float* %203 to <32 x float>*
  store <32 x float> %200, <32 x float>* %204, align 64, !tbaa !652
  %205 = getelementptr inbounds i8, i8* %34, i64 2176
  %206 = bitcast i8* %205 to <32 x float>*
  %207 = load <32 x float>, <32 x float>* %206, align 64, !tbaa !646
  %208 = fadd <32 x float> %71, %207
  %209 = mul i64 %indvars.iv58, 7696581394432
  %sext75 = add i64 %209, 2336462209024
  %210 = ashr exact i64 %sext75, 32
  %211 = getelementptr inbounds float, float* %10, i64 %210
  %212 = bitcast float* %211 to <32 x float>*
  store <32 x float> %208, <32 x float>* %212, align 64, !tbaa !652
  %213 = getelementptr inbounds i8, i8* %34, i64 2304
  %214 = bitcast i8* %213 to <32 x float>*
  %215 = load <32 x float>, <32 x float>* %214, align 64, !tbaa !646
  %216 = fadd <32 x float> %71, %215
  %217 = mul i64 %indvars.iv58, 7696581394432
  %sext76 = add i64 %217, 2473901162496
  %218 = ashr exact i64 %sext76, 32
  %219 = getelementptr inbounds float, float* %10, i64 %218
  %220 = bitcast float* %219 to <32 x float>*
  store <32 x float> %216, <32 x float>* %220, align 64, !tbaa !652
  %221 = getelementptr inbounds i8, i8* %34, i64 2432
  %222 = bitcast i8* %221 to <32 x float>*
  %223 = load <32 x float>, <32 x float>* %222, align 64, !tbaa !646
  %224 = fadd <32 x float> %71, %223
  %225 = mul i64 %indvars.iv58, 7696581394432
  %sext77 = add i64 %225, 2611340115968
  %226 = ashr exact i64 %sext77, 32
  %227 = getelementptr inbounds float, float* %10, i64 %226
  %228 = bitcast float* %227 to <32 x float>*
  store <32 x float> %224, <32 x float>* %228, align 64, !tbaa !652
  %229 = getelementptr inbounds i8, i8* %34, i64 2560
  %230 = bitcast i8* %229 to <32 x float>*
  %231 = load <32 x float>, <32 x float>* %230, align 64, !tbaa !646
  %232 = fadd <32 x float> %71, %231
  %233 = mul i64 %indvars.iv58, 7696581394432
  %sext78 = add i64 %233, 2748779069440
  %234 = ashr exact i64 %sext78, 32
  %235 = getelementptr inbounds float, float* %10, i64 %234
  %236 = bitcast float* %235 to <32 x float>*
  store <32 x float> %232, <32 x float>* %236, align 64, !tbaa !652
  %237 = getelementptr inbounds i8, i8* %34, i64 2688
  %238 = bitcast i8* %237 to <32 x float>*
  %239 = load <32 x float>, <32 x float>* %238, align 64, !tbaa !646
  %240 = fadd <32 x float> %71, %239
  %241 = mul i64 %indvars.iv58, 7696581394432
  %sext79 = add i64 %241, 2886218022912
  %242 = ashr exact i64 %sext79, 32
  %243 = getelementptr inbounds float, float* %10, i64 %242
  %244 = bitcast float* %243 to <32 x float>*
  store <32 x float> %240, <32 x float>* %244, align 64, !tbaa !652
  %245 = getelementptr inbounds i8, i8* %34, i64 2816
  %246 = bitcast i8* %245 to <32 x float>*
  %247 = load <32 x float>, <32 x float>* %246, align 64, !tbaa !646
  %248 = fadd <32 x float> %71, %247
  %249 = mul i64 %indvars.iv58, 7696581394432
  %sext80 = add i64 %249, 3023656976384
  %250 = ashr exact i64 %sext80, 32
  %251 = getelementptr inbounds float, float* %10, i64 %250
  %252 = bitcast float* %251 to <32 x float>*
  store <32 x float> %248, <32 x float>* %252, align 64, !tbaa !652
  %253 = getelementptr inbounds i8, i8* %34, i64 2944
  %254 = bitcast i8* %253 to <32 x float>*
  %255 = load <32 x float>, <32 x float>* %254, align 64, !tbaa !646
  %256 = fadd <32 x float> %71, %255
  %257 = mul i64 %indvars.iv58, 7696581394432
  %sext81 = add i64 %257, 3161095929856
  %258 = ashr exact i64 %sext81, 32
  %259 = getelementptr inbounds float, float* %10, i64 %258
  %260 = bitcast float* %259 to <32 x float>*
  store <32 x float> %256, <32 x float>* %260, align 64, !tbaa !652
  %261 = getelementptr inbounds i8, i8* %34, i64 3072
  %262 = bitcast i8* %261 to <32 x float>*
  %263 = load <32 x float>, <32 x float>* %262, align 64, !tbaa !646
  %264 = fadd <32 x float> %71, %263
  %265 = mul i64 %indvars.iv58, 7696581394432
  %sext82 = add i64 %265, 3298534883328
  %266 = ashr exact i64 %sext82, 32
  %267 = getelementptr inbounds float, float* %10, i64 %266
  %268 = bitcast float* %267 to <32 x float>*
  store <32 x float> %264, <32 x float>* %268, align 64, !tbaa !652
  %269 = getelementptr inbounds i8, i8* %34, i64 3200
  %270 = bitcast i8* %269 to <32 x float>*
  %271 = load <32 x float>, <32 x float>* %270, align 64, !tbaa !646
  %272 = fadd <32 x float> %71, %271
  %273 = mul i64 %indvars.iv58, 7696581394432
  %sext83 = add i64 %273, 3435973836800
  %274 = ashr exact i64 %sext83, 32
  %275 = getelementptr inbounds float, float* %10, i64 %274
  %276 = bitcast float* %275 to <32 x float>*
  store <32 x float> %272, <32 x float>* %276, align 64, !tbaa !652
  %277 = getelementptr inbounds i8, i8* %34, i64 3328
  %278 = bitcast i8* %277 to <32 x float>*
  %279 = load <32 x float>, <32 x float>* %278, align 64, !tbaa !646
  %280 = fadd <32 x float> %71, %279
  %281 = mul i64 %indvars.iv58, 7696581394432
  %sext84 = add i64 %281, 3573412790272
  %282 = ashr exact i64 %sext84, 32
  %283 = getelementptr inbounds float, float* %10, i64 %282
  %284 = bitcast float* %283 to <32 x float>*
  store <32 x float> %280, <32 x float>* %284, align 64, !tbaa !652
  %285 = getelementptr inbounds i8, i8* %34, i64 3456
  %286 = bitcast i8* %285 to <32 x float>*
  %287 = load <32 x float>, <32 x float>* %286, align 64, !tbaa !646
  %288 = fadd <32 x float> %71, %287
  %289 = mul i64 %indvars.iv58, 7696581394432
  %sext85 = add i64 %289, 3710851743744
  %290 = ashr exact i64 %sext85, 32
  %291 = getelementptr inbounds float, float* %10, i64 %290
  %292 = bitcast float* %291 to <32 x float>*
  store <32 x float> %288, <32 x float>* %292, align 64, !tbaa !652
  %293 = getelementptr inbounds i8, i8* %34, i64 3584
  %294 = bitcast i8* %293 to <32 x float>*
  %295 = load <32 x float>, <32 x float>* %294, align 64, !tbaa !646
  %296 = fadd <32 x float> %71, %295
  %297 = mul i64 %indvars.iv58, 7696581394432
  %sext86 = add i64 %297, 3848290697216
  %298 = ashr exact i64 %sext86, 32
  %299 = getelementptr inbounds float, float* %10, i64 %298
  %300 = bitcast float* %299 to <32 x float>*
  store <32 x float> %296, <32 x float>* %300, align 64, !tbaa !652
  %301 = getelementptr inbounds i8, i8* %34, i64 3712
  %302 = bitcast i8* %301 to <32 x float>*
  %303 = load <32 x float>, <32 x float>* %302, align 64, !tbaa !646
  %304 = fadd <32 x float> %71, %303
  %305 = mul i64 %indvars.iv58, 7696581394432
  %sext87 = add i64 %305, 3985729650688
  %306 = ashr exact i64 %sext87, 32
  %307 = getelementptr inbounds float, float* %10, i64 %306
  %308 = bitcast float* %307 to <32 x float>*
  store <32 x float> %304, <32 x float>* %308, align 64, !tbaa !652
  %309 = getelementptr inbounds i8, i8* %34, i64 3840
  %310 = bitcast i8* %309 to <32 x float>*
  %311 = load <32 x float>, <32 x float>* %310, align 64, !tbaa !646
  %312 = fadd <32 x float> %71, %311
  %313 = mul i64 %indvars.iv58, 7696581394432
  %sext88 = add i64 %313, 4123168604160
  %314 = ashr exact i64 %sext88, 32
  %315 = getelementptr inbounds float, float* %10, i64 %314
  %316 = bitcast float* %315 to <32 x float>*
  store <32 x float> %312, <32 x float>* %316, align 64, !tbaa !652
  %317 = getelementptr inbounds i8, i8* %34, i64 3968
  %318 = bitcast i8* %317 to <32 x float>*
  %319 = load <32 x float>, <32 x float>* %318, align 64, !tbaa !646
  %320 = fadd <32 x float> %71, %319
  %321 = mul i64 %indvars.iv58, 7696581394432
  %sext89 = add i64 %321, 4260607557632
  %322 = ashr exact i64 %sext89, 32
  %323 = getelementptr inbounds float, float* %10, i64 %322
  %324 = bitcast float* %323 to <32 x float>*
  store <32 x float> %320, <32 x float>* %324, align 64, !tbaa !652
  %325 = getelementptr inbounds i8, i8* %34, i64 4096
  %326 = bitcast i8* %325 to <32 x float>*
  %327 = load <32 x float>, <32 x float>* %326, align 64, !tbaa !646
  %328 = fadd <32 x float> %71, %327
  %329 = mul i64 %indvars.iv58, 7696581394432
  %sext90 = add i64 %329, 4398046511104
  %330 = ashr exact i64 %sext90, 32
  %331 = getelementptr inbounds float, float* %10, i64 %330
  %332 = bitcast float* %331 to <32 x float>*
  store <32 x float> %328, <32 x float>* %332, align 64, !tbaa !652
  %333 = getelementptr inbounds i8, i8* %34, i64 4224
  %334 = bitcast i8* %333 to <32 x float>*
  %335 = load <32 x float>, <32 x float>* %334, align 64, !tbaa !646
  %336 = fadd <32 x float> %71, %335
  %337 = mul i64 %indvars.iv58, 7696581394432
  %sext91 = add i64 %337, 4535485464576
  %338 = ashr exact i64 %sext91, 32
  %339 = getelementptr inbounds float, float* %10, i64 %338
  %340 = bitcast float* %339 to <32 x float>*
  store <32 x float> %336, <32 x float>* %340, align 64, !tbaa !652
  %341 = getelementptr inbounds i8, i8* %34, i64 4352
  %342 = bitcast i8* %341 to <32 x float>*
  %343 = load <32 x float>, <32 x float>* %342, align 64, !tbaa !646
  %344 = fadd <32 x float> %71, %343
  %345 = mul i64 %indvars.iv58, 7696581394432
  %sext92 = add i64 %345, 4672924418048
  %346 = ashr exact i64 %sext92, 32
  %347 = getelementptr inbounds float, float* %10, i64 %346
  %348 = bitcast float* %347 to <32 x float>*
  store <32 x float> %344, <32 x float>* %348, align 64, !tbaa !652
  %349 = getelementptr inbounds i8, i8* %34, i64 4480
  %350 = bitcast i8* %349 to <32 x float>*
  %351 = load <32 x float>, <32 x float>* %350, align 64, !tbaa !646
  %352 = fadd <32 x float> %71, %351
  %353 = mul i64 %indvars.iv58, 7696581394432
  %sext93 = add i64 %353, 4810363371520
  %354 = ashr exact i64 %sext93, 32
  %355 = getelementptr inbounds float, float* %10, i64 %354
  %356 = bitcast float* %355 to <32 x float>*
  store <32 x float> %352, <32 x float>* %356, align 64, !tbaa !652
  %357 = getelementptr inbounds i8, i8* %34, i64 4608
  %358 = bitcast i8* %357 to <32 x float>*
  %359 = load <32 x float>, <32 x float>* %358, align 64, !tbaa !646
  %360 = fadd <32 x float> %71, %359
  %361 = mul i64 %indvars.iv58, 7696581394432
  %sext94 = add i64 %361, 4947802324992
  %362 = ashr exact i64 %sext94, 32
  %363 = getelementptr inbounds float, float* %10, i64 %362
  %364 = bitcast float* %363 to <32 x float>*
  store <32 x float> %360, <32 x float>* %364, align 64, !tbaa !652
  %365 = getelementptr inbounds i8, i8* %34, i64 4736
  %366 = bitcast i8* %365 to <32 x float>*
  %367 = load <32 x float>, <32 x float>* %366, align 64, !tbaa !646
  %368 = fadd <32 x float> %71, %367
  %369 = mul i64 %indvars.iv58, 7696581394432
  %sext95 = add i64 %369, 5085241278464
  %370 = ashr exact i64 %sext95, 32
  %371 = getelementptr inbounds float, float* %10, i64 %370
  %372 = bitcast float* %371 to <32 x float>*
  store <32 x float> %368, <32 x float>* %372, align 64, !tbaa !652
  %373 = getelementptr inbounds i8, i8* %34, i64 4864
  %374 = bitcast i8* %373 to <32 x float>*
  %375 = load <32 x float>, <32 x float>* %374, align 64, !tbaa !646
  %376 = fadd <32 x float> %71, %375
  %377 = mul i64 %indvars.iv58, 7696581394432
  %sext96 = add i64 %377, 5222680231936
  %378 = ashr exact i64 %sext96, 32
  %379 = getelementptr inbounds float, float* %10, i64 %378
  %380 = bitcast float* %379 to <32 x float>*
  store <32 x float> %376, <32 x float>* %380, align 64, !tbaa !652
  %381 = getelementptr inbounds i8, i8* %34, i64 4992
  %382 = bitcast i8* %381 to <32 x float>*
  %383 = load <32 x float>, <32 x float>* %382, align 64, !tbaa !646
  %384 = fadd <32 x float> %71, %383
  %385 = mul i64 %indvars.iv58, 7696581394432
  %sext97 = add i64 %385, 5360119185408
  %386 = ashr exact i64 %sext97, 32
  %387 = getelementptr inbounds float, float* %10, i64 %386
  %388 = bitcast float* %387 to <32 x float>*
  store <32 x float> %384, <32 x float>* %388, align 64, !tbaa !652
  %389 = getelementptr inbounds i8, i8* %34, i64 5120
  %390 = bitcast i8* %389 to <32 x float>*
  %391 = load <32 x float>, <32 x float>* %390, align 64, !tbaa !646
  %392 = fadd <32 x float> %71, %391
  %393 = mul i64 %indvars.iv58, 7696581394432
  %sext98 = add i64 %393, 5497558138880
  %394 = ashr exact i64 %sext98, 32
  %395 = getelementptr inbounds float, float* %10, i64 %394
  %396 = bitcast float* %395 to <32 x float>*
  store <32 x float> %392, <32 x float>* %396, align 64, !tbaa !652
  %397 = getelementptr inbounds i8, i8* %34, i64 5248
  %398 = bitcast i8* %397 to <32 x float>*
  %399 = load <32 x float>, <32 x float>* %398, align 64, !tbaa !646
  %400 = fadd <32 x float> %71, %399
  %401 = mul i64 %indvars.iv58, 7696581394432
  %sext99 = add i64 %401, 5634997092352
  %402 = ashr exact i64 %sext99, 32
  %403 = getelementptr inbounds float, float* %10, i64 %402
  %404 = bitcast float* %403 to <32 x float>*
  store <32 x float> %400, <32 x float>* %404, align 64, !tbaa !652
  %405 = getelementptr inbounds i8, i8* %34, i64 5376
  %406 = bitcast i8* %405 to <32 x float>*
  %407 = load <32 x float>, <32 x float>* %406, align 64, !tbaa !646
  %408 = fadd <32 x float> %71, %407
  %409 = mul i64 %indvars.iv58, 7696581394432
  %sext100 = add i64 %409, 5772436045824
  %410 = ashr exact i64 %sext100, 32
  %411 = getelementptr inbounds float, float* %10, i64 %410
  %412 = bitcast float* %411 to <32 x float>*
  store <32 x float> %408, <32 x float>* %412, align 64, !tbaa !652
  %413 = getelementptr inbounds i8, i8* %34, i64 5504
  %414 = bitcast i8* %413 to <32 x float>*
  %415 = load <32 x float>, <32 x float>* %414, align 64, !tbaa !646
  %416 = fadd <32 x float> %71, %415
  %417 = mul i64 %indvars.iv58, 7696581394432
  %sext101 = add i64 %417, 5909874999296
  %418 = ashr exact i64 %sext101, 32
  %419 = getelementptr inbounds float, float* %10, i64 %418
  %420 = bitcast float* %419 to <32 x float>*
  store <32 x float> %416, <32 x float>* %420, align 64, !tbaa !652
  %421 = getelementptr inbounds i8, i8* %34, i64 5632
  %422 = bitcast i8* %421 to <32 x float>*
  %423 = load <32 x float>, <32 x float>* %422, align 64, !tbaa !646
  %424 = fadd <32 x float> %71, %423
  %425 = mul i64 %indvars.iv58, 7696581394432
  %sext102 = add i64 %425, 6047313952768
  %426 = ashr exact i64 %sext102, 32
  %427 = getelementptr inbounds float, float* %10, i64 %426
  %428 = bitcast float* %427 to <32 x float>*
  store <32 x float> %424, <32 x float>* %428, align 64, !tbaa !652
  %429 = getelementptr inbounds i8, i8* %34, i64 5760
  %430 = bitcast i8* %429 to <32 x float>*
  %431 = load <32 x float>, <32 x float>* %430, align 64, !tbaa !646
  %432 = fadd <32 x float> %71, %431
  %433 = mul i64 %indvars.iv58, 7696581394432
  %sext103 = add i64 %433, 6184752906240
  %434 = ashr exact i64 %sext103, 32
  %435 = getelementptr inbounds float, float* %10, i64 %434
  %436 = bitcast float* %435 to <32 x float>*
  store <32 x float> %432, <32 x float>* %436, align 64, !tbaa !652
  %437 = getelementptr inbounds i8, i8* %34, i64 5888
  %438 = bitcast i8* %437 to <32 x float>*
  %439 = load <32 x float>, <32 x float>* %438, align 64, !tbaa !646
  %440 = fadd <32 x float> %71, %439
  %441 = mul i64 %indvars.iv58, 7696581394432
  %sext104 = add i64 %441, 6322191859712
  %442 = ashr exact i64 %sext104, 32
  %443 = getelementptr inbounds float, float* %10, i64 %442
  %444 = bitcast float* %443 to <32 x float>*
  store <32 x float> %440, <32 x float>* %444, align 64, !tbaa !652
  %445 = getelementptr inbounds i8, i8* %34, i64 6016
  %446 = bitcast i8* %445 to <32 x float>*
  %447 = load <32 x float>, <32 x float>* %446, align 64, !tbaa !646
  %448 = fadd <32 x float> %71, %447
  %449 = mul i64 %indvars.iv58, 7696581394432
  %sext105 = add i64 %449, 6459630813184
  %450 = ashr exact i64 %sext105, 32
  %451 = getelementptr inbounds float, float* %10, i64 %450
  %452 = bitcast float* %451 to <32 x float>*
  store <32 x float> %448, <32 x float>* %452, align 64, !tbaa !652
  %453 = getelementptr inbounds i8, i8* %34, i64 6144
  %454 = bitcast i8* %453 to <32 x float>*
  %455 = load <32 x float>, <32 x float>* %454, align 64, !tbaa !646
  %456 = fadd <32 x float> %71, %455
  %457 = mul i64 %indvars.iv58, 7696581394432
  %sext106 = add i64 %457, 6597069766656
  %458 = ashr exact i64 %sext106, 32
  %459 = getelementptr inbounds float, float* %10, i64 %458
  %460 = bitcast float* %459 to <32 x float>*
  store <32 x float> %456, <32 x float>* %460, align 64, !tbaa !652
  %461 = getelementptr inbounds i8, i8* %34, i64 6272
  %462 = bitcast i8* %461 to <32 x float>*
  %463 = load <32 x float>, <32 x float>* %462, align 64, !tbaa !646
  %464 = fadd <32 x float> %71, %463
  %465 = mul i64 %indvars.iv58, 7696581394432
  %sext107 = add i64 %465, 6734508720128
  %466 = ashr exact i64 %sext107, 32
  %467 = getelementptr inbounds float, float* %10, i64 %466
  %468 = bitcast float* %467 to <32 x float>*
  store <32 x float> %464, <32 x float>* %468, align 64, !tbaa !652
  %469 = getelementptr inbounds i8, i8* %34, i64 6400
  %470 = bitcast i8* %469 to <32 x float>*
  %471 = load <32 x float>, <32 x float>* %470, align 64, !tbaa !646
  %472 = fadd <32 x float> %71, %471
  %473 = mul i64 %indvars.iv58, 7696581394432
  %sext108 = add i64 %473, 6871947673600
  %474 = ashr exact i64 %sext108, 32
  %475 = getelementptr inbounds float, float* %10, i64 %474
  %476 = bitcast float* %475 to <32 x float>*
  store <32 x float> %472, <32 x float>* %476, align 64, !tbaa !652
  %477 = getelementptr inbounds i8, i8* %34, i64 6528
  %478 = bitcast i8* %477 to <32 x float>*
  %479 = load <32 x float>, <32 x float>* %478, align 64, !tbaa !646
  %480 = fadd <32 x float> %71, %479
  %481 = mul i64 %indvars.iv58, 7696581394432
  %sext109 = add i64 %481, 7009386627072
  %482 = ashr exact i64 %sext109, 32
  %483 = getelementptr inbounds float, float* %10, i64 %482
  %484 = bitcast float* %483 to <32 x float>*
  store <32 x float> %480, <32 x float>* %484, align 64, !tbaa !652
  %485 = getelementptr inbounds i8, i8* %34, i64 6656
  %486 = bitcast i8* %485 to <32 x float>*
  %487 = load <32 x float>, <32 x float>* %486, align 64, !tbaa !646
  %488 = fadd <32 x float> %71, %487
  %489 = mul i64 %indvars.iv58, 7696581394432
  %sext110 = add i64 %489, 7146825580544
  %490 = ashr exact i64 %sext110, 32
  %491 = getelementptr inbounds float, float* %10, i64 %490
  %492 = bitcast float* %491 to <32 x float>*
  store <32 x float> %488, <32 x float>* %492, align 64, !tbaa !652
  %493 = getelementptr inbounds i8, i8* %34, i64 6784
  %494 = bitcast i8* %493 to <32 x float>*
  %495 = load <32 x float>, <32 x float>* %494, align 64, !tbaa !646
  %496 = fadd <32 x float> %71, %495
  %497 = mul i64 %indvars.iv58, 7696581394432
  %sext111 = add i64 %497, 7284264534016
  %498 = ashr exact i64 %sext111, 32
  %499 = getelementptr inbounds float, float* %10, i64 %498
  %500 = bitcast float* %499 to <32 x float>*
  store <32 x float> %496, <32 x float>* %500, align 64, !tbaa !652
  %501 = getelementptr inbounds i8, i8* %34, i64 6912
  %502 = bitcast i8* %501 to <32 x float>*
  %503 = load <32 x float>, <32 x float>* %502, align 64, !tbaa !646
  %504 = fadd <32 x float> %71, %503
  %505 = mul i64 %indvars.iv58, 7696581394432
  %sext112 = add i64 %505, 7421703487488
  %506 = ashr exact i64 %sext112, 32
  %507 = getelementptr inbounds float, float* %10, i64 %506
  %508 = bitcast float* %507 to <32 x float>*
  store <32 x float> %504, <32 x float>* %508, align 64, !tbaa !652
  %509 = getelementptr inbounds i8, i8* %34, i64 7040
  %510 = bitcast i8* %509 to <32 x float>*
  %511 = load <32 x float>, <32 x float>* %510, align 64, !tbaa !646
  %512 = fadd <32 x float> %71, %511
  %513 = mul i64 %indvars.iv58, 7696581394432
  %sext113 = add i64 %513, 7559142440960
  %514 = ashr exact i64 %sext113, 32
  %515 = getelementptr inbounds float, float* %10, i64 %514
  %516 = bitcast float* %515 to <32 x float>*
  store <32 x float> %512, <32 x float>* %516, align 64, !tbaa !652
  %517 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %518 = tail call i32 %517(i32 1, i32 %16, i8* nonnull %34)
  %indvars.iv.next59 = add nsw i64 %indvars.iv58, 1
  %519 = icmp slt i64 %indvars.iv.next59, %32
  br i1 %519, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %.lcssa2942 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %705, %for_body5 ]
  %.lcssa2740 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %699, %for_body5 ]
  %.lcssa2538 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %693, %for_body5 ]
  %.lcssa2336 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %687, %for_body5 ]
  %.lcssa2134 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %681, %for_body5 ]
  %.lcssa1932 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %675, %for_body5 ]
  %.lcssa31 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %669, %for_body5 ]
  %520 = mul nuw nsw i64 %indvars.iv, 12544
  %521 = add nsw i64 %65, %520
  %522 = shl i64 %indvars.iv, 7
  %523 = add nuw nsw i64 %522, %41
  %524 = getelementptr inbounds float, float* %4, i64 %521
  %525 = load float, float* %524, align 4, !tbaa !655
  %526 = insertelement <32 x float> undef, float %525, i32 0
  %527 = shufflevector <32 x float> %526, <32 x float> undef, <32 x i32> zeroinitializer
  %528 = getelementptr inbounds float, float* %7, i64 %523
  %529 = bitcast float* %528 to <32 x float>*
  %530 = load <32 x float>, <32 x float>* %529, align 64, !tbaa !658
  %531 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %527, <32 x float> %530, <32 x float> %.lcssa31)
  %532 = add nsw i64 %521, 4
  %533 = getelementptr inbounds float, float* %4, i64 %532
  %534 = load float, float* %533, align 4, !tbaa !655
  %535 = insertelement <32 x float> undef, float %534, i32 0
  %536 = shufflevector <32 x float> %535, <32 x float> undef, <32 x i32> zeroinitializer
  %537 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %536, <32 x float> %530, <32 x float> %.lcssa1932)
  %538 = add nsw i64 %521, 8
  %539 = getelementptr inbounds float, float* %4, i64 %538
  %540 = load float, float* %539, align 4, !tbaa !655
  %541 = insertelement <32 x float> undef, float %540, i32 0
  %542 = shufflevector <32 x float> %541, <32 x float> undef, <32 x i32> zeroinitializer
  %543 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %542, <32 x float> %530, <32 x float> %.lcssa2134)
  %544 = add nsw i64 %521, 12
  %545 = getelementptr inbounds float, float* %4, i64 %544
  %546 = load float, float* %545, align 4, !tbaa !655
  %547 = insertelement <32 x float> undef, float %546, i32 0
  %548 = shufflevector <32 x float> %547, <32 x float> undef, <32 x i32> zeroinitializer
  %549 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %548, <32 x float> %530, <32 x float> %.lcssa2336)
  %550 = add nsw i64 %521, 16
  %551 = getelementptr inbounds float, float* %4, i64 %550
  %552 = load float, float* %551, align 4, !tbaa !655
  %553 = insertelement <32 x float> undef, float %552, i32 0
  %554 = shufflevector <32 x float> %553, <32 x float> undef, <32 x i32> zeroinitializer
  %555 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %554, <32 x float> %530, <32 x float> %.lcssa2538)
  %556 = add nsw i64 %521, 20
  %557 = getelementptr inbounds float, float* %4, i64 %556
  %558 = load float, float* %557, align 4, !tbaa !655
  %559 = insertelement <32 x float> undef, float %558, i32 0
  %560 = shufflevector <32 x float> %559, <32 x float> undef, <32 x i32> zeroinitializer
  %561 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %560, <32 x float> %530, <32 x float> %.lcssa2740)
  %562 = add nsw i64 %521, 24
  %563 = getelementptr inbounds float, float* %4, i64 %562
  %564 = load float, float* %563, align 4, !tbaa !655
  %565 = insertelement <32 x float> undef, float %564, i32 0
  %566 = shufflevector <32 x float> %565, <32 x float> undef, <32 x i32> zeroinitializer
  %567 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %566, <32 x float> %530, <32 x float> %.lcssa2942)
  %568 = or i64 %521, 1
  %569 = getelementptr inbounds float, float* %4, i64 %568
  %570 = load float, float* %569, align 4, !tbaa !655
  %571 = insertelement <32 x float> undef, float %570, i32 0
  %572 = shufflevector <32 x float> %571, <32 x float> undef, <32 x i32> zeroinitializer
  %573 = or i64 %523, 32
  %574 = getelementptr inbounds float, float* %7, i64 %573
  %575 = bitcast float* %574 to <32 x float>*
  %576 = load <32 x float>, <32 x float>* %575, align 64, !tbaa !658
  %577 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %572, <32 x float> %576, <32 x float> %531)
  %578 = add nsw i64 %568, 4
  %579 = getelementptr inbounds float, float* %4, i64 %578
  %580 = load float, float* %579, align 4, !tbaa !655
  %581 = insertelement <32 x float> undef, float %580, i32 0
  %582 = shufflevector <32 x float> %581, <32 x float> undef, <32 x i32> zeroinitializer
  %583 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %582, <32 x float> %576, <32 x float> %537)
  %584 = add nsw i64 %568, 8
  %585 = getelementptr inbounds float, float* %4, i64 %584
  %586 = load float, float* %585, align 4, !tbaa !655
  %587 = insertelement <32 x float> undef, float %586, i32 0
  %588 = shufflevector <32 x float> %587, <32 x float> undef, <32 x i32> zeroinitializer
  %589 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %588, <32 x float> %576, <32 x float> %543)
  %590 = add nsw i64 %568, 12
  %591 = getelementptr inbounds float, float* %4, i64 %590
  %592 = load float, float* %591, align 4, !tbaa !655
  %593 = insertelement <32 x float> undef, float %592, i32 0
  %594 = shufflevector <32 x float> %593, <32 x float> undef, <32 x i32> zeroinitializer
  %595 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %594, <32 x float> %576, <32 x float> %549)
  %596 = add nsw i64 %568, 16
  %597 = getelementptr inbounds float, float* %4, i64 %596
  %598 = load float, float* %597, align 4, !tbaa !655
  %599 = insertelement <32 x float> undef, float %598, i32 0
  %600 = shufflevector <32 x float> %599, <32 x float> undef, <32 x i32> zeroinitializer
  %601 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %600, <32 x float> %576, <32 x float> %555)
  %602 = add nsw i64 %568, 20
  %603 = getelementptr inbounds float, float* %4, i64 %602
  %604 = load float, float* %603, align 4, !tbaa !655
  %605 = insertelement <32 x float> undef, float %604, i32 0
  %606 = shufflevector <32 x float> %605, <32 x float> undef, <32 x i32> zeroinitializer
  %607 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %606, <32 x float> %576, <32 x float> %561)
  %608 = add nsw i64 %568, 24
  %609 = getelementptr inbounds float, float* %4, i64 %608
  %610 = load float, float* %609, align 4, !tbaa !655
  %611 = insertelement <32 x float> undef, float %610, i32 0
  %612 = shufflevector <32 x float> %611, <32 x float> undef, <32 x i32> zeroinitializer
  %613 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %612, <32 x float> %576, <32 x float> %567)
  %614 = or i64 %521, 2
  %615 = getelementptr inbounds float, float* %4, i64 %614
  %616 = load float, float* %615, align 4, !tbaa !655
  %617 = insertelement <32 x float> undef, float %616, i32 0
  %618 = shufflevector <32 x float> %617, <32 x float> undef, <32 x i32> zeroinitializer
  %619 = or i64 %523, 64
  %620 = getelementptr inbounds float, float* %7, i64 %619
  %621 = bitcast float* %620 to <32 x float>*
  %622 = load <32 x float>, <32 x float>* %621, align 64, !tbaa !658
  %623 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %618, <32 x float> %622, <32 x float> %577)
  %624 = add nsw i64 %614, 4
  %625 = getelementptr inbounds float, float* %4, i64 %624
  %626 = load float, float* %625, align 4, !tbaa !655
  %627 = insertelement <32 x float> undef, float %626, i32 0
  %628 = shufflevector <32 x float> %627, <32 x float> undef, <32 x i32> zeroinitializer
  %629 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %628, <32 x float> %622, <32 x float> %583)
  %630 = add nsw i64 %614, 8
  %631 = getelementptr inbounds float, float* %4, i64 %630
  %632 = load float, float* %631, align 4, !tbaa !655
  %633 = insertelement <32 x float> undef, float %632, i32 0
  %634 = shufflevector <32 x float> %633, <32 x float> undef, <32 x i32> zeroinitializer
  %635 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %634, <32 x float> %622, <32 x float> %589)
  %636 = add nsw i64 %614, 12
  %637 = getelementptr inbounds float, float* %4, i64 %636
  %638 = load float, float* %637, align 4, !tbaa !655
  %639 = insertelement <32 x float> undef, float %638, i32 0
  %640 = shufflevector <32 x float> %639, <32 x float> undef, <32 x i32> zeroinitializer
  %641 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %640, <32 x float> %622, <32 x float> %595)
  %642 = add nsw i64 %614, 16
  %643 = getelementptr inbounds float, float* %4, i64 %642
  %644 = load float, float* %643, align 4, !tbaa !655
  %645 = insertelement <32 x float> undef, float %644, i32 0
  %646 = shufflevector <32 x float> %645, <32 x float> undef, <32 x i32> zeroinitializer
  %647 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %646, <32 x float> %622, <32 x float> %601)
  %648 = add nsw i64 %614, 20
  %649 = getelementptr inbounds float, float* %4, i64 %648
  %650 = load float, float* %649, align 4, !tbaa !655
  %651 = insertelement <32 x float> undef, float %650, i32 0
  %652 = shufflevector <32 x float> %651, <32 x float> undef, <32 x i32> zeroinitializer
  %653 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %652, <32 x float> %622, <32 x float> %607)
  %654 = add nsw i64 %614, 24
  %655 = getelementptr inbounds float, float* %4, i64 %654
  %656 = load float, float* %655, align 4, !tbaa !655
  %657 = insertelement <32 x float> undef, float %656, i32 0
  %658 = shufflevector <32 x float> %657, <32 x float> undef, <32 x i32> zeroinitializer
  %659 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %658, <32 x float> %622, <32 x float> %613)
  %660 = or i64 %521, 3
  %661 = getelementptr inbounds float, float* %4, i64 %660
  %662 = load float, float* %661, align 4, !tbaa !655
  %663 = insertelement <32 x float> undef, float %662, i32 0
  %664 = shufflevector <32 x float> %663, <32 x float> undef, <32 x i32> zeroinitializer
  %665 = or i64 %523, 96
  %666 = getelementptr inbounds float, float* %7, i64 %665
  %667 = bitcast float* %666 to <32 x float>*
  %668 = load <32 x float>, <32 x float>* %667, align 64, !tbaa !658
  %669 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %664, <32 x float> %668, <32 x float> %623)
  %670 = add nsw i64 %660, 4
  %671 = getelementptr inbounds float, float* %4, i64 %670
  %672 = load float, float* %671, align 4, !tbaa !655
  %673 = insertelement <32 x float> undef, float %672, i32 0
  %674 = shufflevector <32 x float> %673, <32 x float> undef, <32 x i32> zeroinitializer
  %675 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %674, <32 x float> %668, <32 x float> %629)
  %676 = add nsw i64 %660, 8
  %677 = getelementptr inbounds float, float* %4, i64 %676
  %678 = load float, float* %677, align 4, !tbaa !655
  %679 = insertelement <32 x float> undef, float %678, i32 0
  %680 = shufflevector <32 x float> %679, <32 x float> undef, <32 x i32> zeroinitializer
  %681 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %680, <32 x float> %668, <32 x float> %635)
  %682 = add nsw i64 %660, 12
  %683 = getelementptr inbounds float, float* %4, i64 %682
  %684 = load float, float* %683, align 4, !tbaa !655
  %685 = insertelement <32 x float> undef, float %684, i32 0
  %686 = shufflevector <32 x float> %685, <32 x float> undef, <32 x i32> zeroinitializer
  %687 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %686, <32 x float> %668, <32 x float> %641)
  %688 = add nsw i64 %660, 16
  %689 = getelementptr inbounds float, float* %4, i64 %688
  %690 = load float, float* %689, align 4, !tbaa !655
  %691 = insertelement <32 x float> undef, float %690, i32 0
  %692 = shufflevector <32 x float> %691, <32 x float> undef, <32 x i32> zeroinitializer
  %693 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %692, <32 x float> %668, <32 x float> %647)
  %694 = add nsw i64 %660, 20
  %695 = getelementptr inbounds float, float* %4, i64 %694
  %696 = load float, float* %695, align 4, !tbaa !655
  %697 = insertelement <32 x float> undef, float %696, i32 0
  %698 = shufflevector <32 x float> %697, <32 x float> undef, <32 x i32> zeroinitializer
  %699 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %698, <32 x float> %668, <32 x float> %653)
  %700 = add nsw i64 %660, 24
  %701 = getelementptr inbounds float, float* %4, i64 %700
  %702 = load float, float* %701, align 4, !tbaa !655
  %703 = insertelement <32 x float> undef, float %702, i32 0
  %704 = shufflevector <32 x float> %703, <32 x float> undef, <32 x i32> zeroinitializer
  %705 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %704, <32 x float> %668, <32 x float> %659)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <32 x float> %669, <32 x float>* %45, align 64, !tbaa !646
  store <32 x float> %675, <32 x float>* %48, align 64, !tbaa !646
  store <32 x float> %681, <32 x float>* %51, align 64, !tbaa !646
  store <32 x float> %687, <32 x float>* %54, align 64, !tbaa !646
  store <32 x float> %693, <32 x float>* %57, align 64, !tbaa !646
  store <32 x float> %699, <32 x float>* %60, align 64, !tbaa !646
  store <32 x float> %705, <32 x float>* %63, align 64, !tbaa !646
  %indvars.iv.next50 = add nuw nsw i64 %indvars.iv49, 1
  %exitcond51 = icmp eq i64 %indvars.iv.next50, 8
  br i1 %exitcond51, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_layout_transform_34(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !661 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !663, metadata !DIExpression()), !dbg !666
  call void @llvm.dbg.value(metadata i8* %1, metadata !664, metadata !DIExpression()), !dbg !666
  call void @llvm.dbg.value(metadata i32 %2, metadata !665, metadata !DIExpression()), !dbg !666
  %3 = bitcast i8* %0 to %1**, !dbg !666
  %4 = load %1*, %1** %3, align 8, !dbg !666
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !666
  %6 = bitcast i8* %5 to %1**, !dbg !666
  %7 = load %1*, %1** %6, align 8, !dbg !666
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !666
  %9 = load i8*, i8** %8, align 8, !dbg !666
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !666
  %11 = load i8*, i8** %10, align 8, !dbg !666
  %12 = tail call fastcc i32 @fused_layout_transform_34_compute_(i8* %11, i8* %9), !dbg !666
  ret i32 %12, !dbg !666
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_34_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %40, align 8
  %3 = getelementptr inbounds %40, %40* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %40, %40* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %40* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.36, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.36(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 7168
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 14
  %27 = mul nsw i32 %26, 896
  %28 = sdiv i32 %25, 14
  %29 = mul nsw i32 %28, 100352
  %30 = add i32 %27, %29
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %31 = add nsw i64 %24, %indvars.iv
  %32 = trunc i64 %indvars.iv to i32
  %33 = and i32 %32, 63
  %34 = lshr i32 %32, 6
  %35 = mul nsw i32 %34, 12544
  %36 = add i32 %30, %35
  %37 = or i32 %36, %33
  %38 = sext i32 %37 to i64
  %39 = getelementptr inbounds float, float* %7, i64 %38
  %40 = bitcast float* %39 to i32*
  %41 = load i32, i32* %40, align 4, !tbaa !667
  %42 = getelementptr inbounds float, float* %4, i64 %31
  %43 = bitcast float* %42 to i32*
  store i32 %41, i32* %43, align 4, !tbaa !670
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %44 = or i64 %24, 512
  %45 = or i32 %30, 64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %46 = add nsw i64 %44, %indvars.iv.1
  %47 = trunc i64 %indvars.iv.1 to i32
  %48 = and i32 %47, 63
  %49 = lshr i32 %47, 6
  %50 = mul nsw i32 %49, 12544
  %51 = add i32 %45, %50
  %52 = or i32 %51, %48
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to i32*
  %56 = load i32, i32* %55, align 4, !tbaa !667
  %57 = getelementptr inbounds float, float* %4, i64 %46
  %58 = bitcast float* %57 to i32*
  store i32 %56, i32* %58, align 4, !tbaa !670
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %59 = add nsw i64 %24, 1024
  %60 = add i32 %30, 128
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %61 = add nsw i64 %59, %indvars.iv.2
  %62 = trunc i64 %indvars.iv.2 to i32
  %63 = and i32 %62, 63
  %64 = lshr i32 %62, 6
  %65 = mul nsw i32 %64, 12544
  %66 = add i32 %60, %65
  %67 = or i32 %66, %63
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds float, float* %7, i64 %68
  %70 = bitcast float* %69 to i32*
  %71 = load i32, i32* %70, align 4, !tbaa !667
  %72 = getelementptr inbounds float, float* %4, i64 %61
  %73 = bitcast float* %72 to i32*
  store i32 %71, i32* %73, align 4, !tbaa !670
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  %74 = add nsw i64 %24, 1536
  %75 = add i32 %30, 192
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %76 = add nsw i64 %74, %indvars.iv.3
  %77 = trunc i64 %indvars.iv.3 to i32
  %78 = and i32 %77, 63
  %79 = lshr i32 %77, 6
  %80 = mul nsw i32 %79, 12544
  %81 = add i32 %75, %80
  %82 = or i32 %81, %78
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds float, float* %7, i64 %83
  %85 = bitcast float* %84 to i32*
  %86 = load i32, i32* %85, align 4, !tbaa !667
  %87 = getelementptr inbounds float, float* %4, i64 %76
  %88 = bitcast float* %87 to i32*
  store i32 %86, i32* %88, align 4, !tbaa !670
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  %89 = add nsw i64 %24, 2048
  %90 = add i32 %30, 256
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %91 = add nsw i64 %89, %indvars.iv.4
  %92 = trunc i64 %indvars.iv.4 to i32
  %93 = and i32 %92, 63
  %94 = lshr i32 %92, 6
  %95 = mul nsw i32 %94, 12544
  %96 = add i32 %90, %95
  %97 = or i32 %96, %93
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %7, i64 %98
  %100 = bitcast float* %99 to i32*
  %101 = load i32, i32* %100, align 4, !tbaa !667
  %102 = getelementptr inbounds float, float* %4, i64 %91
  %103 = bitcast float* %102 to i32*
  store i32 %101, i32* %103, align 4, !tbaa !670
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  %104 = add nsw i64 %24, 2560
  %105 = add i32 %30, 320
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %106 = add nsw i64 %104, %indvars.iv.5
  %107 = trunc i64 %indvars.iv.5 to i32
  %108 = and i32 %107, 63
  %109 = lshr i32 %107, 6
  %110 = mul nsw i32 %109, 12544
  %111 = add i32 %105, %110
  %112 = or i32 %111, %108
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds float, float* %7, i64 %113
  %115 = bitcast float* %114 to i32*
  %116 = load i32, i32* %115, align 4, !tbaa !667
  %117 = getelementptr inbounds float, float* %4, i64 %106
  %118 = bitcast float* %117 to i32*
  store i32 %116, i32* %118, align 4, !tbaa !670
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  %119 = add nsw i64 %24, 3072
  %120 = add i32 %30, 384
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %121 = add nsw i64 %119, %indvars.iv.6
  %122 = trunc i64 %indvars.iv.6 to i32
  %123 = and i32 %122, 63
  %124 = lshr i32 %122, 6
  %125 = mul nsw i32 %124, 12544
  %126 = add i32 %120, %125
  %127 = or i32 %126, %123
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds float, float* %7, i64 %128
  %130 = bitcast float* %129 to i32*
  %131 = load i32, i32* %130, align 4, !tbaa !667
  %132 = getelementptr inbounds float, float* %4, i64 %121
  %133 = bitcast float* %132 to i32*
  store i32 %131, i32* %133, align 4, !tbaa !670
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  %134 = add nsw i64 %24, 3584
  %135 = add i32 %30, 448
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %136 = add nsw i64 %134, %indvars.iv.7
  %137 = trunc i64 %indvars.iv.7 to i32
  %138 = and i32 %137, 63
  %139 = lshr i32 %137, 6
  %140 = mul nsw i32 %139, 12544
  %141 = add i32 %135, %140
  %142 = or i32 %141, %138
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to i32*
  %146 = load i32, i32* %145, align 4, !tbaa !667
  %147 = getelementptr inbounds float, float* %4, i64 %136
  %148 = bitcast float* %147 to i32*
  store i32 %146, i32* %148, align 4, !tbaa !670
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 512
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !29

for_end6.7:                                       ; preds = %for_body5.7
  %149 = add nsw i64 %24, 4096
  %150 = add i32 %30, 512
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %151 = add nsw i64 %149, %indvars.iv.8
  %152 = trunc i64 %indvars.iv.8 to i32
  %153 = and i32 %152, 63
  %154 = lshr i32 %152, 6
  %155 = mul nsw i32 %154, 12544
  %156 = add i32 %150, %155
  %157 = or i32 %156, %153
  %158 = sext i32 %157 to i64
  %159 = getelementptr inbounds float, float* %7, i64 %158
  %160 = bitcast float* %159 to i32*
  %161 = load i32, i32* %160, align 4, !tbaa !667
  %162 = getelementptr inbounds float, float* %4, i64 %151
  %163 = bitcast float* %162 to i32*
  store i32 %161, i32* %163, align 4, !tbaa !670
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 512
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !29

for_end6.8:                                       ; preds = %for_body5.8
  %164 = add nsw i64 %24, 4608
  %165 = add i32 %30, 576
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %166 = add nsw i64 %164, %indvars.iv.9
  %167 = trunc i64 %indvars.iv.9 to i32
  %168 = and i32 %167, 63
  %169 = lshr i32 %167, 6
  %170 = mul nsw i32 %169, 12544
  %171 = add i32 %165, %170
  %172 = or i32 %171, %168
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds float, float* %7, i64 %173
  %175 = bitcast float* %174 to i32*
  %176 = load i32, i32* %175, align 4, !tbaa !667
  %177 = getelementptr inbounds float, float* %4, i64 %166
  %178 = bitcast float* %177 to i32*
  store i32 %176, i32* %178, align 4, !tbaa !670
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 512
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !29

for_end6.9:                                       ; preds = %for_body5.9
  %179 = add nsw i64 %24, 5120
  %180 = add i32 %30, 640
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %181 = add nsw i64 %179, %indvars.iv.10
  %182 = trunc i64 %indvars.iv.10 to i32
  %183 = and i32 %182, 63
  %184 = lshr i32 %182, 6
  %185 = mul nsw i32 %184, 12544
  %186 = add i32 %180, %185
  %187 = or i32 %186, %183
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4, !tbaa !667
  %192 = getelementptr inbounds float, float* %4, i64 %181
  %193 = bitcast float* %192 to i32*
  store i32 %191, i32* %193, align 4, !tbaa !670
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 512
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !29

for_end6.10:                                      ; preds = %for_body5.10
  %194 = add nsw i64 %24, 5632
  %195 = add i32 %30, 704
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %196 = add nsw i64 %194, %indvars.iv.11
  %197 = trunc i64 %indvars.iv.11 to i32
  %198 = and i32 %197, 63
  %199 = lshr i32 %197, 6
  %200 = mul nsw i32 %199, 12544
  %201 = add i32 %195, %200
  %202 = or i32 %201, %198
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds float, float* %7, i64 %203
  %205 = bitcast float* %204 to i32*
  %206 = load i32, i32* %205, align 4, !tbaa !667
  %207 = getelementptr inbounds float, float* %4, i64 %196
  %208 = bitcast float* %207 to i32*
  store i32 %206, i32* %208, align 4, !tbaa !670
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 512
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !29

for_end6.11:                                      ; preds = %for_body5.11
  %209 = add nsw i64 %24, 6144
  %210 = add i32 %30, 768
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %211 = add nsw i64 %209, %indvars.iv.12
  %212 = trunc i64 %indvars.iv.12 to i32
  %213 = and i32 %212, 63
  %214 = lshr i32 %212, 6
  %215 = mul nsw i32 %214, 12544
  %216 = add i32 %210, %215
  %217 = or i32 %216, %213
  %218 = sext i32 %217 to i64
  %219 = getelementptr inbounds float, float* %7, i64 %218
  %220 = bitcast float* %219 to i32*
  %221 = load i32, i32* %220, align 4, !tbaa !667
  %222 = getelementptr inbounds float, float* %4, i64 %211
  %223 = bitcast float* %222 to i32*
  store i32 %221, i32* %223, align 4, !tbaa !670
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 512
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !29

for_end6.12:                                      ; preds = %for_body5.12
  %224 = add nsw i64 %24, 6656
  %225 = add i32 %30, 832
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %226 = add nsw i64 %224, %indvars.iv.13
  %227 = trunc i64 %indvars.iv.13 to i32
  %228 = and i32 %227, 63
  %229 = lshr i32 %227, 6
  %230 = mul nsw i32 %229, 12544
  %231 = add i32 %225, %230
  %232 = or i32 %231, %228
  %233 = sext i32 %232 to i64
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to i32*
  %236 = load i32, i32* %235, align 4, !tbaa !667
  %237 = getelementptr inbounds float, float* %4, i64 %226
  %238 = bitcast float* %237 to i32*
  store i32 %236, i32* %238, align 4, !tbaa !670
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 512
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !29

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %239 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %239, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !673 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !675, metadata !DIExpression()), !dbg !678
  call void @llvm.dbg.value(metadata i8* %1, metadata !676, metadata !DIExpression()), !dbg !678
  call void @llvm.dbg.value(metadata i32 %2, metadata !677, metadata !DIExpression()), !dbg !678
  %3 = bitcast i8* %0 to %1**, !dbg !678
  %4 = load %1*, %1** %3, align 8, !dbg !678
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !678
  %6 = bitcast i8* %5 to %1**, !dbg !678
  %7 = load %1*, %1** %6, align 8, !dbg !678
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !678
  %9 = bitcast i8* %8 to %1**, !dbg !678
  %10 = load %1*, %1** %9, align 8, !dbg !678
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !678
  %12 = bitcast i8* %11 to %1**, !dbg !678
  %13 = load %1*, %1** %12, align 8, !dbg !678
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !678
  %15 = bitcast i8* %14 to %1**, !dbg !678
  %16 = load %1*, %1** %15, align 8, !dbg !678
  %17 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !678
  %18 = load i8*, i8** %17, align 8, !dbg !678
  %19 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !678
  %20 = load i32, i32* %19, align 4, !dbg !678
  %21 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !678
  %22 = load i8*, i8** %21, align 8, !dbg !678
  %23 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !678
  %24 = load i8*, i8** %23, align 8, !dbg !678
  %25 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !678
  %26 = load i8*, i8** %25, align 8, !dbg !678
  %27 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !678
  %28 = load i8*, i8** %27, align 8, !dbg !678
  %29 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4_compute_(i8* %18, i8* %22, i8* %28, i8* %24, i8* %26, i32 %20), !dbg !678
  ret i32 %29, !dbg !678
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %6 = alloca %41, align 8
  %7 = getelementptr inbounds %41, %41* %6, i64 0, i32 0
  store i8* %0, i8** %7, align 8
  %8 = getelementptr inbounds %41, %41* %6, i64 0, i32 1
  store i8* %1, i8** %8, align 8
  %9 = getelementptr inbounds %41, %41* %6, i64 0, i32 2
  store i8* %2, i8** %9, align 8
  %10 = getelementptr inbounds %41, %41* %6, i64 0, i32 3
  store i8* %3, i8** %10, align 8
  %11 = getelementptr inbounds %41, %41* %6, i64 0, i32 4
  store i8* %4, i8** %11, align 8
  %12 = getelementptr inbounds %41, %41* %6, i64 0, i32 5
  store i32 %5, i32* %12, align 8
  %13 = bitcast %41* %6 to i8*
  %14 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %15 = call i32 %14(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.37, i8* nonnull %13, i32 0)
  ret i32 %15
}

define private i32 @__tvm_parallel_lambda.37(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, 55
  %23 = sdiv i32 %22, %21
  %24 = add nsw i32 %0, 1
  %25 = mul nsw i32 %23, %24
  %26 = icmp slt i32 %25, 56
  %27 = select i1 %26, i32 %25, i32 56
  %28 = mul nsw i32 %23, %0
  %29 = icmp slt i32 %28, 56
  %30 = select i1 %29, i32 %28, i32 56
  %31 = icmp slt i32 %30, %27
  br i1 %31, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %32 = add i32 %30, 1
  %33 = sext i32 %32 to i64
  %34 = add nsw i64 %33, -1
  %35 = sext i32 %27 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.6
  %indvars.iv33 = phi i64 [ %34, %for_body.lr.ph ], [ %indvars.iv.next34, %for_end6.6 ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %37 = tail call i8* %36(i32 1, i32 %19, i64 7168, i32 2, i32 32)
  %38 = trunc i64 %indvars.iv33 to i32
  %39 = srem i32 %38, 28
  %40 = mul nsw i32 %39, 14336
  %41 = sdiv i32 %38, 28
  %42 = shl i32 %41, 15
  %43 = sext i32 %42 to i64
  %44 = sext i32 %40 to i64
  %45 = bitcast i8* %37 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %45, align 64, !tbaa !679
  %46 = getelementptr inbounds i8, i8* %37, i64 256
  %47 = bitcast i8* %46 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %47, align 64, !tbaa !679
  %48 = getelementptr inbounds i8, i8* %37, i64 512
  %49 = bitcast i8* %48 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %49, align 64, !tbaa !679
  %50 = getelementptr inbounds i8, i8* %37, i64 768
  %51 = bitcast i8* %50 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %51, align 64, !tbaa !679
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %52 = phi <64 x float> [ zeroinitializer, %for_body ], [ %84, %for_body5 ]
  %53 = phi <64 x float> [ zeroinitializer, %for_body ], [ %78, %for_body5 ]
  %54 = phi <64 x float> [ zeroinitializer, %for_body ], [ %72, %for_body5 ]
  %55 = phi <64 x float> [ zeroinitializer, %for_body ], [ %66, %for_body5 ]
  %56 = add nsw i64 %indvars.iv, %44
  %57 = getelementptr inbounds float, float* %4, i64 %56
  %58 = load float, float* %57, align 4, !tbaa !682
  %59 = insertelement <64 x float> undef, float %58, i32 0
  %60 = shufflevector <64 x float> %59, <64 x float> undef, <64 x i32> zeroinitializer
  %61 = shl i64 %indvars.iv, 6
  %62 = add nuw nsw i64 %61, %43
  %63 = getelementptr inbounds float, float* %7, i64 %62
  %64 = bitcast float* %63 to <64 x float>*
  %65 = load <64 x float>, <64 x float>* %64, align 64, !tbaa !685
  %66 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %60, <64 x float> %65, <64 x float> %55)
  %67 = add nsw i64 %56, 512
  %68 = getelementptr inbounds float, float* %4, i64 %67
  %69 = load float, float* %68, align 4, !tbaa !682
  %70 = insertelement <64 x float> undef, float %69, i32 0
  %71 = shufflevector <64 x float> %70, <64 x float> undef, <64 x i32> zeroinitializer
  %72 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %71, <64 x float> %65, <64 x float> %54)
  %73 = add nsw i64 %56, 1024
  %74 = getelementptr inbounds float, float* %4, i64 %73
  %75 = load float, float* %74, align 4, !tbaa !682
  %76 = insertelement <64 x float> undef, float %75, i32 0
  %77 = shufflevector <64 x float> %76, <64 x float> undef, <64 x i32> zeroinitializer
  %78 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %77, <64 x float> %65, <64 x float> %53)
  %79 = add nsw i64 %56, 1536
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !682
  %82 = insertelement <64 x float> undef, float %81, i32 0
  %83 = shufflevector <64 x float> %82, <64 x float> undef, <64 x i32> zeroinitializer
  %84 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %83, <64 x float> %65, <64 x float> %52)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <64 x float> %66, <64 x float>* %45, align 64, !tbaa !679
  store <64 x float> %72, <64 x float>* %47, align 64, !tbaa !679
  store <64 x float> %78, <64 x float>* %49, align 64, !tbaa !679
  store <64 x float> %84, <64 x float>* %51, align 64, !tbaa !679
  %85 = getelementptr inbounds i8, i8* %37, i64 1024
  %86 = bitcast i8* %85 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %86, align 64, !tbaa !679
  %87 = getelementptr inbounds i8, i8* %37, i64 1280
  %88 = bitcast i8* %87 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %88, align 64, !tbaa !679
  %89 = getelementptr inbounds i8, i8* %37, i64 1536
  %90 = bitcast i8* %89 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %90, align 64, !tbaa !679
  %91 = getelementptr inbounds i8, i8* %37, i64 1792
  %92 = bitcast i8* %91 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %92, align 64, !tbaa !679
  %93 = add nsw i64 %44, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %94 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %126, %for_body5.1 ]
  %95 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %120, %for_body5.1 ]
  %96 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %114, %for_body5.1 ]
  %97 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %108, %for_body5.1 ]
  %98 = add nsw i64 %93, %indvars.iv.1
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !682
  %101 = insertelement <64 x float> undef, float %100, i32 0
  %102 = shufflevector <64 x float> %101, <64 x float> undef, <64 x i32> zeroinitializer
  %103 = shl i64 %indvars.iv.1, 6
  %104 = add nuw nsw i64 %103, %43
  %105 = getelementptr inbounds float, float* %7, i64 %104
  %106 = bitcast float* %105 to <64 x float>*
  %107 = load <64 x float>, <64 x float>* %106, align 64, !tbaa !685
  %108 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %102, <64 x float> %107, <64 x float> %97)
  %109 = add nsw i64 %98, 512
  %110 = getelementptr inbounds float, float* %4, i64 %109
  %111 = load float, float* %110, align 4, !tbaa !682
  %112 = insertelement <64 x float> undef, float %111, i32 0
  %113 = shufflevector <64 x float> %112, <64 x float> undef, <64 x i32> zeroinitializer
  %114 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %113, <64 x float> %107, <64 x float> %96)
  %115 = add nsw i64 %98, 1024
  %116 = getelementptr inbounds float, float* %4, i64 %115
  %117 = load float, float* %116, align 4, !tbaa !682
  %118 = insertelement <64 x float> undef, float %117, i32 0
  %119 = shufflevector <64 x float> %118, <64 x float> undef, <64 x i32> zeroinitializer
  %120 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %119, <64 x float> %107, <64 x float> %95)
  %121 = add nsw i64 %98, 1536
  %122 = getelementptr inbounds float, float* %4, i64 %121
  %123 = load float, float* %122, align 4, !tbaa !682
  %124 = insertelement <64 x float> undef, float %123, i32 0
  %125 = shufflevector <64 x float> %124, <64 x float> undef, <64 x i32> zeroinitializer
  %126 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %125, <64 x float> %107, <64 x float> %94)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %108, <64 x float>* %86, align 64, !tbaa !679
  store <64 x float> %114, <64 x float>* %88, align 64, !tbaa !679
  store <64 x float> %120, <64 x float>* %90, align 64, !tbaa !679
  store <64 x float> %126, <64 x float>* %92, align 64, !tbaa !679
  %127 = getelementptr inbounds i8, i8* %37, i64 2048
  %128 = bitcast i8* %127 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %128, align 64, !tbaa !679
  %129 = getelementptr inbounds i8, i8* %37, i64 2304
  %130 = bitcast i8* %129 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %130, align 64, !tbaa !679
  %131 = getelementptr inbounds i8, i8* %37, i64 2560
  %132 = bitcast i8* %131 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %132, align 64, !tbaa !679
  %133 = getelementptr inbounds i8, i8* %37, i64 2816
  %134 = bitcast i8* %133 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %134, align 64, !tbaa !679
  %135 = add nsw i64 %44, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %136 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %168, %for_body5.2 ]
  %137 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %162, %for_body5.2 ]
  %138 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %156, %for_body5.2 ]
  %139 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %150, %for_body5.2 ]
  %140 = add nsw i64 %135, %indvars.iv.2
  %141 = getelementptr inbounds float, float* %4, i64 %140
  %142 = load float, float* %141, align 4, !tbaa !682
  %143 = insertelement <64 x float> undef, float %142, i32 0
  %144 = shufflevector <64 x float> %143, <64 x float> undef, <64 x i32> zeroinitializer
  %145 = shl i64 %indvars.iv.2, 6
  %146 = add nuw nsw i64 %145, %43
  %147 = getelementptr inbounds float, float* %7, i64 %146
  %148 = bitcast float* %147 to <64 x float>*
  %149 = load <64 x float>, <64 x float>* %148, align 64, !tbaa !685
  %150 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %144, <64 x float> %149, <64 x float> %139)
  %151 = add nsw i64 %140, 512
  %152 = getelementptr inbounds float, float* %4, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !682
  %154 = insertelement <64 x float> undef, float %153, i32 0
  %155 = shufflevector <64 x float> %154, <64 x float> undef, <64 x i32> zeroinitializer
  %156 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %155, <64 x float> %149, <64 x float> %138)
  %157 = add nsw i64 %140, 1024
  %158 = getelementptr inbounds float, float* %4, i64 %157
  %159 = load float, float* %158, align 4, !tbaa !682
  %160 = insertelement <64 x float> undef, float %159, i32 0
  %161 = shufflevector <64 x float> %160, <64 x float> undef, <64 x i32> zeroinitializer
  %162 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %161, <64 x float> %149, <64 x float> %137)
  %163 = add nsw i64 %140, 1536
  %164 = getelementptr inbounds float, float* %4, i64 %163
  %165 = load float, float* %164, align 4, !tbaa !682
  %166 = insertelement <64 x float> undef, float %165, i32 0
  %167 = shufflevector <64 x float> %166, <64 x float> undef, <64 x i32> zeroinitializer
  %168 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %167, <64 x float> %149, <64 x float> %136)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %150, <64 x float>* %128, align 64, !tbaa !679
  store <64 x float> %156, <64 x float>* %130, align 64, !tbaa !679
  store <64 x float> %162, <64 x float>* %132, align 64, !tbaa !679
  store <64 x float> %168, <64 x float>* %134, align 64, !tbaa !679
  %169 = getelementptr inbounds i8, i8* %37, i64 3072
  %170 = bitcast i8* %169 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %170, align 64, !tbaa !679
  %171 = getelementptr inbounds i8, i8* %37, i64 3328
  %172 = bitcast i8* %171 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %172, align 64, !tbaa !679
  %173 = getelementptr inbounds i8, i8* %37, i64 3584
  %174 = bitcast i8* %173 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %174, align 64, !tbaa !679
  %175 = getelementptr inbounds i8, i8* %37, i64 3840
  %176 = bitcast i8* %175 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %176, align 64, !tbaa !679
  %177 = add nsw i64 %44, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %178 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %210, %for_body5.3 ]
  %179 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %204, %for_body5.3 ]
  %180 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %198, %for_body5.3 ]
  %181 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %192, %for_body5.3 ]
  %182 = add nsw i64 %177, %indvars.iv.3
  %183 = getelementptr inbounds float, float* %4, i64 %182
  %184 = load float, float* %183, align 4, !tbaa !682
  %185 = insertelement <64 x float> undef, float %184, i32 0
  %186 = shufflevector <64 x float> %185, <64 x float> undef, <64 x i32> zeroinitializer
  %187 = shl i64 %indvars.iv.3, 6
  %188 = add nuw nsw i64 %187, %43
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to <64 x float>*
  %191 = load <64 x float>, <64 x float>* %190, align 64, !tbaa !685
  %192 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %186, <64 x float> %191, <64 x float> %181)
  %193 = add nsw i64 %182, 512
  %194 = getelementptr inbounds float, float* %4, i64 %193
  %195 = load float, float* %194, align 4, !tbaa !682
  %196 = insertelement <64 x float> undef, float %195, i32 0
  %197 = shufflevector <64 x float> %196, <64 x float> undef, <64 x i32> zeroinitializer
  %198 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %197, <64 x float> %191, <64 x float> %180)
  %199 = add nsw i64 %182, 1024
  %200 = getelementptr inbounds float, float* %4, i64 %199
  %201 = load float, float* %200, align 4, !tbaa !682
  %202 = insertelement <64 x float> undef, float %201, i32 0
  %203 = shufflevector <64 x float> %202, <64 x float> undef, <64 x i32> zeroinitializer
  %204 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %203, <64 x float> %191, <64 x float> %179)
  %205 = add nsw i64 %182, 1536
  %206 = getelementptr inbounds float, float* %4, i64 %205
  %207 = load float, float* %206, align 4, !tbaa !682
  %208 = insertelement <64 x float> undef, float %207, i32 0
  %209 = shufflevector <64 x float> %208, <64 x float> undef, <64 x i32> zeroinitializer
  %210 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %209, <64 x float> %191, <64 x float> %178)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %192, <64 x float>* %170, align 64, !tbaa !679
  store <64 x float> %198, <64 x float>* %172, align 64, !tbaa !679
  store <64 x float> %204, <64 x float>* %174, align 64, !tbaa !679
  store <64 x float> %210, <64 x float>* %176, align 64, !tbaa !679
  %211 = getelementptr inbounds i8, i8* %37, i64 4096
  %212 = bitcast i8* %211 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %212, align 64, !tbaa !679
  %213 = getelementptr inbounds i8, i8* %37, i64 4352
  %214 = bitcast i8* %213 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %214, align 64, !tbaa !679
  %215 = getelementptr inbounds i8, i8* %37, i64 4608
  %216 = bitcast i8* %215 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %216, align 64, !tbaa !679
  %217 = getelementptr inbounds i8, i8* %37, i64 4864
  %218 = bitcast i8* %217 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %218, align 64, !tbaa !679
  %219 = add nsw i64 %44, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %220 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %252, %for_body5.4 ]
  %221 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %246, %for_body5.4 ]
  %222 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %240, %for_body5.4 ]
  %223 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %234, %for_body5.4 ]
  %224 = add nsw i64 %219, %indvars.iv.4
  %225 = getelementptr inbounds float, float* %4, i64 %224
  %226 = load float, float* %225, align 4, !tbaa !682
  %227 = insertelement <64 x float> undef, float %226, i32 0
  %228 = shufflevector <64 x float> %227, <64 x float> undef, <64 x i32> zeroinitializer
  %229 = shl i64 %indvars.iv.4, 6
  %230 = add nuw nsw i64 %229, %43
  %231 = getelementptr inbounds float, float* %7, i64 %230
  %232 = bitcast float* %231 to <64 x float>*
  %233 = load <64 x float>, <64 x float>* %232, align 64, !tbaa !685
  %234 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %228, <64 x float> %233, <64 x float> %223)
  %235 = add nsw i64 %224, 512
  %236 = getelementptr inbounds float, float* %4, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !682
  %238 = insertelement <64 x float> undef, float %237, i32 0
  %239 = shufflevector <64 x float> %238, <64 x float> undef, <64 x i32> zeroinitializer
  %240 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %239, <64 x float> %233, <64 x float> %222)
  %241 = add nsw i64 %224, 1024
  %242 = getelementptr inbounds float, float* %4, i64 %241
  %243 = load float, float* %242, align 4, !tbaa !682
  %244 = insertelement <64 x float> undef, float %243, i32 0
  %245 = shufflevector <64 x float> %244, <64 x float> undef, <64 x i32> zeroinitializer
  %246 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %245, <64 x float> %233, <64 x float> %221)
  %247 = add nsw i64 %224, 1536
  %248 = getelementptr inbounds float, float* %4, i64 %247
  %249 = load float, float* %248, align 4, !tbaa !682
  %250 = insertelement <64 x float> undef, float %249, i32 0
  %251 = shufflevector <64 x float> %250, <64 x float> undef, <64 x i32> zeroinitializer
  %252 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %251, <64 x float> %233, <64 x float> %220)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %234, <64 x float>* %212, align 64, !tbaa !679
  store <64 x float> %240, <64 x float>* %214, align 64, !tbaa !679
  store <64 x float> %246, <64 x float>* %216, align 64, !tbaa !679
  store <64 x float> %252, <64 x float>* %218, align 64, !tbaa !679
  %253 = getelementptr inbounds i8, i8* %37, i64 5120
  %254 = bitcast i8* %253 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %254, align 64, !tbaa !679
  %255 = getelementptr inbounds i8, i8* %37, i64 5376
  %256 = bitcast i8* %255 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %256, align 64, !tbaa !679
  %257 = getelementptr inbounds i8, i8* %37, i64 5632
  %258 = bitcast i8* %257 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %258, align 64, !tbaa !679
  %259 = getelementptr inbounds i8, i8* %37, i64 5888
  %260 = bitcast i8* %259 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %260, align 64, !tbaa !679
  %261 = add nsw i64 %44, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %262 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %294, %for_body5.5 ]
  %263 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %288, %for_body5.5 ]
  %264 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %282, %for_body5.5 ]
  %265 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %276, %for_body5.5 ]
  %266 = add nsw i64 %261, %indvars.iv.5
  %267 = getelementptr inbounds float, float* %4, i64 %266
  %268 = load float, float* %267, align 4, !tbaa !682
  %269 = insertelement <64 x float> undef, float %268, i32 0
  %270 = shufflevector <64 x float> %269, <64 x float> undef, <64 x i32> zeroinitializer
  %271 = shl i64 %indvars.iv.5, 6
  %272 = add nuw nsw i64 %271, %43
  %273 = getelementptr inbounds float, float* %7, i64 %272
  %274 = bitcast float* %273 to <64 x float>*
  %275 = load <64 x float>, <64 x float>* %274, align 64, !tbaa !685
  %276 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %270, <64 x float> %275, <64 x float> %265)
  %277 = add nsw i64 %266, 512
  %278 = getelementptr inbounds float, float* %4, i64 %277
  %279 = load float, float* %278, align 4, !tbaa !682
  %280 = insertelement <64 x float> undef, float %279, i32 0
  %281 = shufflevector <64 x float> %280, <64 x float> undef, <64 x i32> zeroinitializer
  %282 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %281, <64 x float> %275, <64 x float> %264)
  %283 = add nsw i64 %266, 1024
  %284 = getelementptr inbounds float, float* %4, i64 %283
  %285 = load float, float* %284, align 4, !tbaa !682
  %286 = insertelement <64 x float> undef, float %285, i32 0
  %287 = shufflevector <64 x float> %286, <64 x float> undef, <64 x i32> zeroinitializer
  %288 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %287, <64 x float> %275, <64 x float> %263)
  %289 = add nsw i64 %266, 1536
  %290 = getelementptr inbounds float, float* %4, i64 %289
  %291 = load float, float* %290, align 4, !tbaa !682
  %292 = insertelement <64 x float> undef, float %291, i32 0
  %293 = shufflevector <64 x float> %292, <64 x float> undef, <64 x i32> zeroinitializer
  %294 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %293, <64 x float> %275, <64 x float> %262)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %276, <64 x float>* %254, align 64, !tbaa !679
  store <64 x float> %282, <64 x float>* %256, align 64, !tbaa !679
  store <64 x float> %288, <64 x float>* %258, align 64, !tbaa !679
  store <64 x float> %294, <64 x float>* %260, align 64, !tbaa !679
  %295 = getelementptr inbounds i8, i8* %37, i64 6144
  %296 = bitcast i8* %295 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %296, align 64, !tbaa !679
  %297 = getelementptr inbounds i8, i8* %37, i64 6400
  %298 = bitcast i8* %297 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %298, align 64, !tbaa !679
  %299 = getelementptr inbounds i8, i8* %37, i64 6656
  %300 = bitcast i8* %299 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %300, align 64, !tbaa !679
  %301 = getelementptr inbounds i8, i8* %37, i64 6912
  %302 = bitcast i8* %301 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %302, align 64, !tbaa !679
  %303 = add nsw i64 %44, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %304 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %336, %for_body5.6 ]
  %305 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %330, %for_body5.6 ]
  %306 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %324, %for_body5.6 ]
  %307 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %318, %for_body5.6 ]
  %308 = add nsw i64 %303, %indvars.iv.6
  %309 = getelementptr inbounds float, float* %4, i64 %308
  %310 = load float, float* %309, align 4, !tbaa !682
  %311 = insertelement <64 x float> undef, float %310, i32 0
  %312 = shufflevector <64 x float> %311, <64 x float> undef, <64 x i32> zeroinitializer
  %313 = shl i64 %indvars.iv.6, 6
  %314 = add nuw nsw i64 %313, %43
  %315 = getelementptr inbounds float, float* %7, i64 %314
  %316 = bitcast float* %315 to <64 x float>*
  %317 = load <64 x float>, <64 x float>* %316, align 64, !tbaa !685
  %318 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %312, <64 x float> %317, <64 x float> %307)
  %319 = add nsw i64 %308, 512
  %320 = getelementptr inbounds float, float* %4, i64 %319
  %321 = load float, float* %320, align 4, !tbaa !682
  %322 = insertelement <64 x float> undef, float %321, i32 0
  %323 = shufflevector <64 x float> %322, <64 x float> undef, <64 x i32> zeroinitializer
  %324 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %323, <64 x float> %317, <64 x float> %306)
  %325 = add nsw i64 %308, 1024
  %326 = getelementptr inbounds float, float* %4, i64 %325
  %327 = load float, float* %326, align 4, !tbaa !682
  %328 = insertelement <64 x float> undef, float %327, i32 0
  %329 = shufflevector <64 x float> %328, <64 x float> undef, <64 x i32> zeroinitializer
  %330 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %329, <64 x float> %317, <64 x float> %305)
  %331 = add nsw i64 %308, 1536
  %332 = getelementptr inbounds float, float* %4, i64 %331
  %333 = load float, float* %332, align 4, !tbaa !682
  %334 = insertelement <64 x float> undef, float %333, i32 0
  %335 = shufflevector <64 x float> %334, <64 x float> undef, <64 x i32> zeroinitializer
  %336 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %335, <64 x float> %317, <64 x float> %304)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %318, <64 x float>* %296, align 64, !tbaa !679
  store <64 x float> %324, <64 x float>* %298, align 64, !tbaa !679
  store <64 x float> %330, <64 x float>* %300, align 64, !tbaa !679
  store <64 x float> %336, <64 x float>* %302, align 64, !tbaa !679
  %337 = mul nsw i64 %indvars.iv33, 1792
  %338 = shl nsw i32 %41, 6
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds float, float* %16, i64 %339
  %341 = bitcast float* %340 to <64 x float>*
  %342 = load <64 x float>, <64 x float>* %341, align 64, !tbaa !688
  %343 = getelementptr inbounds float, float* %13, i64 %339
  %344 = bitcast float* %343 to <64 x float>*
  %345 = load <64 x float>, <64 x float>* %344, align 64, !tbaa !691
  %346 = bitcast i8* %37 to <64 x float>*
  %347 = load <64 x float>, <64 x float>* %346, align 64, !tbaa !679
  %348 = fadd <64 x float> %345, %347
  %349 = fadd <64 x float> %342, %348
  %350 = fcmp ogt <64 x float> %349, zeroinitializer
  %351 = select <64 x i1> %350, <64 x float> %349, <64 x float> zeroinitializer
  %352 = getelementptr inbounds float, float* %10, i64 %337
  %353 = bitcast float* %352 to <64 x float>*
  store <64 x float> %351, <64 x float>* %353, align 64, !tbaa !694
  %354 = getelementptr inbounds i8, i8* %37, i64 256
  %355 = bitcast i8* %354 to <64 x float>*
  %356 = load <64 x float>, <64 x float>* %355, align 64, !tbaa !679
  %357 = fadd <64 x float> %345, %356
  %358 = fadd <64 x float> %342, %357
  %359 = fcmp ogt <64 x float> %358, zeroinitializer
  %360 = select <64 x i1> %359, <64 x float> %358, <64 x float> zeroinitializer
  %361 = mul i64 %indvars.iv33, 7696581394432
  %sext = ashr exact i64 %361, 32
  %362 = or i64 %sext, 64
  %363 = getelementptr inbounds float, float* %10, i64 %362
  %364 = bitcast float* %363 to <64 x float>*
  store <64 x float> %360, <64 x float>* %364, align 64, !tbaa !694
  %365 = getelementptr inbounds i8, i8* %37, i64 512
  %366 = bitcast i8* %365 to <64 x float>*
  %367 = load <64 x float>, <64 x float>* %366, align 64, !tbaa !679
  %368 = fadd <64 x float> %345, %367
  %369 = fadd <64 x float> %342, %368
  %370 = fcmp ogt <64 x float> %369, zeroinitializer
  %371 = select <64 x i1> %370, <64 x float> %369, <64 x float> zeroinitializer
  %372 = mul i64 %indvars.iv33, 7696581394432
  %sext35 = ashr exact i64 %372, 32
  %373 = or i64 %sext35, 128
  %374 = getelementptr inbounds float, float* %10, i64 %373
  %375 = bitcast float* %374 to <64 x float>*
  store <64 x float> %371, <64 x float>* %375, align 64, !tbaa !694
  %376 = getelementptr inbounds i8, i8* %37, i64 768
  %377 = bitcast i8* %376 to <64 x float>*
  %378 = load <64 x float>, <64 x float>* %377, align 64, !tbaa !679
  %379 = fadd <64 x float> %345, %378
  %380 = fadd <64 x float> %342, %379
  %381 = fcmp ogt <64 x float> %380, zeroinitializer
  %382 = select <64 x i1> %381, <64 x float> %380, <64 x float> zeroinitializer
  %383 = mul i64 %indvars.iv33, 7696581394432
  %sext36 = ashr exact i64 %383, 32
  %384 = or i64 %sext36, 192
  %385 = getelementptr inbounds float, float* %10, i64 %384
  %386 = bitcast float* %385 to <64 x float>*
  store <64 x float> %382, <64 x float>* %386, align 64, !tbaa !694
  %387 = getelementptr inbounds i8, i8* %37, i64 1024
  %388 = bitcast i8* %387 to <64 x float>*
  %389 = load <64 x float>, <64 x float>* %388, align 64, !tbaa !679
  %390 = fadd <64 x float> %345, %389
  %391 = fadd <64 x float> %342, %390
  %392 = fcmp ogt <64 x float> %391, zeroinitializer
  %393 = select <64 x i1> %392, <64 x float> %391, <64 x float> zeroinitializer
  %394 = mul i64 %indvars.iv33, 7696581394432
  %sext37 = add i64 %394, 1099511627776
  %395 = ashr exact i64 %sext37, 32
  %396 = getelementptr inbounds float, float* %10, i64 %395
  %397 = bitcast float* %396 to <64 x float>*
  store <64 x float> %393, <64 x float>* %397, align 64, !tbaa !694
  %398 = getelementptr inbounds i8, i8* %37, i64 1280
  %399 = bitcast i8* %398 to <64 x float>*
  %400 = load <64 x float>, <64 x float>* %399, align 64, !tbaa !679
  %401 = fadd <64 x float> %345, %400
  %402 = fadd <64 x float> %342, %401
  %403 = fcmp ogt <64 x float> %402, zeroinitializer
  %404 = select <64 x i1> %403, <64 x float> %402, <64 x float> zeroinitializer
  %405 = mul i64 %indvars.iv33, 7696581394432
  %sext38 = add i64 %405, 1374389534720
  %406 = ashr exact i64 %sext38, 32
  %407 = getelementptr inbounds float, float* %10, i64 %406
  %408 = bitcast float* %407 to <64 x float>*
  store <64 x float> %404, <64 x float>* %408, align 64, !tbaa !694
  %409 = getelementptr inbounds i8, i8* %37, i64 1536
  %410 = bitcast i8* %409 to <64 x float>*
  %411 = load <64 x float>, <64 x float>* %410, align 64, !tbaa !679
  %412 = fadd <64 x float> %345, %411
  %413 = fadd <64 x float> %342, %412
  %414 = fcmp ogt <64 x float> %413, zeroinitializer
  %415 = select <64 x i1> %414, <64 x float> %413, <64 x float> zeroinitializer
  %416 = mul i64 %indvars.iv33, 7696581394432
  %sext39 = add i64 %416, 1649267441664
  %417 = ashr exact i64 %sext39, 32
  %418 = getelementptr inbounds float, float* %10, i64 %417
  %419 = bitcast float* %418 to <64 x float>*
  store <64 x float> %415, <64 x float>* %419, align 64, !tbaa !694
  %420 = getelementptr inbounds i8, i8* %37, i64 1792
  %421 = bitcast i8* %420 to <64 x float>*
  %422 = load <64 x float>, <64 x float>* %421, align 64, !tbaa !679
  %423 = fadd <64 x float> %345, %422
  %424 = fadd <64 x float> %342, %423
  %425 = fcmp ogt <64 x float> %424, zeroinitializer
  %426 = select <64 x i1> %425, <64 x float> %424, <64 x float> zeroinitializer
  %427 = mul i64 %indvars.iv33, 7696581394432
  %sext40 = add i64 %427, 1924145348608
  %428 = ashr exact i64 %sext40, 32
  %429 = getelementptr inbounds float, float* %10, i64 %428
  %430 = bitcast float* %429 to <64 x float>*
  store <64 x float> %426, <64 x float>* %430, align 64, !tbaa !694
  %431 = getelementptr inbounds i8, i8* %37, i64 2048
  %432 = bitcast i8* %431 to <64 x float>*
  %433 = load <64 x float>, <64 x float>* %432, align 64, !tbaa !679
  %434 = fadd <64 x float> %345, %433
  %435 = fadd <64 x float> %342, %434
  %436 = fcmp ogt <64 x float> %435, zeroinitializer
  %437 = select <64 x i1> %436, <64 x float> %435, <64 x float> zeroinitializer
  %438 = mul i64 %indvars.iv33, 7696581394432
  %sext41 = add i64 %438, 2199023255552
  %439 = ashr exact i64 %sext41, 32
  %440 = getelementptr inbounds float, float* %10, i64 %439
  %441 = bitcast float* %440 to <64 x float>*
  store <64 x float> %437, <64 x float>* %441, align 64, !tbaa !694
  %442 = getelementptr inbounds i8, i8* %37, i64 2304
  %443 = bitcast i8* %442 to <64 x float>*
  %444 = load <64 x float>, <64 x float>* %443, align 64, !tbaa !679
  %445 = fadd <64 x float> %345, %444
  %446 = fadd <64 x float> %342, %445
  %447 = fcmp ogt <64 x float> %446, zeroinitializer
  %448 = select <64 x i1> %447, <64 x float> %446, <64 x float> zeroinitializer
  %449 = mul i64 %indvars.iv33, 7696581394432
  %sext42 = add i64 %449, 2473901162496
  %450 = ashr exact i64 %sext42, 32
  %451 = getelementptr inbounds float, float* %10, i64 %450
  %452 = bitcast float* %451 to <64 x float>*
  store <64 x float> %448, <64 x float>* %452, align 64, !tbaa !694
  %453 = getelementptr inbounds i8, i8* %37, i64 2560
  %454 = bitcast i8* %453 to <64 x float>*
  %455 = load <64 x float>, <64 x float>* %454, align 64, !tbaa !679
  %456 = fadd <64 x float> %345, %455
  %457 = fadd <64 x float> %342, %456
  %458 = fcmp ogt <64 x float> %457, zeroinitializer
  %459 = select <64 x i1> %458, <64 x float> %457, <64 x float> zeroinitializer
  %460 = mul i64 %indvars.iv33, 7696581394432
  %sext43 = add i64 %460, 2748779069440
  %461 = ashr exact i64 %sext43, 32
  %462 = getelementptr inbounds float, float* %10, i64 %461
  %463 = bitcast float* %462 to <64 x float>*
  store <64 x float> %459, <64 x float>* %463, align 64, !tbaa !694
  %464 = getelementptr inbounds i8, i8* %37, i64 2816
  %465 = bitcast i8* %464 to <64 x float>*
  %466 = load <64 x float>, <64 x float>* %465, align 64, !tbaa !679
  %467 = fadd <64 x float> %345, %466
  %468 = fadd <64 x float> %342, %467
  %469 = fcmp ogt <64 x float> %468, zeroinitializer
  %470 = select <64 x i1> %469, <64 x float> %468, <64 x float> zeroinitializer
  %471 = mul i64 %indvars.iv33, 7696581394432
  %sext44 = add i64 %471, 3023656976384
  %472 = ashr exact i64 %sext44, 32
  %473 = getelementptr inbounds float, float* %10, i64 %472
  %474 = bitcast float* %473 to <64 x float>*
  store <64 x float> %470, <64 x float>* %474, align 64, !tbaa !694
  %475 = getelementptr inbounds i8, i8* %37, i64 3072
  %476 = bitcast i8* %475 to <64 x float>*
  %477 = load <64 x float>, <64 x float>* %476, align 64, !tbaa !679
  %478 = fadd <64 x float> %345, %477
  %479 = fadd <64 x float> %342, %478
  %480 = fcmp ogt <64 x float> %479, zeroinitializer
  %481 = select <64 x i1> %480, <64 x float> %479, <64 x float> zeroinitializer
  %482 = mul i64 %indvars.iv33, 7696581394432
  %sext45 = add i64 %482, 3298534883328
  %483 = ashr exact i64 %sext45, 32
  %484 = getelementptr inbounds float, float* %10, i64 %483
  %485 = bitcast float* %484 to <64 x float>*
  store <64 x float> %481, <64 x float>* %485, align 64, !tbaa !694
  %486 = getelementptr inbounds i8, i8* %37, i64 3328
  %487 = bitcast i8* %486 to <64 x float>*
  %488 = load <64 x float>, <64 x float>* %487, align 64, !tbaa !679
  %489 = fadd <64 x float> %345, %488
  %490 = fadd <64 x float> %342, %489
  %491 = fcmp ogt <64 x float> %490, zeroinitializer
  %492 = select <64 x i1> %491, <64 x float> %490, <64 x float> zeroinitializer
  %493 = mul i64 %indvars.iv33, 7696581394432
  %sext46 = add i64 %493, 3573412790272
  %494 = ashr exact i64 %sext46, 32
  %495 = getelementptr inbounds float, float* %10, i64 %494
  %496 = bitcast float* %495 to <64 x float>*
  store <64 x float> %492, <64 x float>* %496, align 64, !tbaa !694
  %497 = getelementptr inbounds i8, i8* %37, i64 3584
  %498 = bitcast i8* %497 to <64 x float>*
  %499 = load <64 x float>, <64 x float>* %498, align 64, !tbaa !679
  %500 = fadd <64 x float> %345, %499
  %501 = fadd <64 x float> %342, %500
  %502 = fcmp ogt <64 x float> %501, zeroinitializer
  %503 = select <64 x i1> %502, <64 x float> %501, <64 x float> zeroinitializer
  %504 = mul i64 %indvars.iv33, 7696581394432
  %sext47 = add i64 %504, 3848290697216
  %505 = ashr exact i64 %sext47, 32
  %506 = getelementptr inbounds float, float* %10, i64 %505
  %507 = bitcast float* %506 to <64 x float>*
  store <64 x float> %503, <64 x float>* %507, align 64, !tbaa !694
  %508 = getelementptr inbounds i8, i8* %37, i64 3840
  %509 = bitcast i8* %508 to <64 x float>*
  %510 = load <64 x float>, <64 x float>* %509, align 64, !tbaa !679
  %511 = fadd <64 x float> %345, %510
  %512 = fadd <64 x float> %342, %511
  %513 = fcmp ogt <64 x float> %512, zeroinitializer
  %514 = select <64 x i1> %513, <64 x float> %512, <64 x float> zeroinitializer
  %515 = mul i64 %indvars.iv33, 7696581394432
  %sext48 = add i64 %515, 4123168604160
  %516 = ashr exact i64 %sext48, 32
  %517 = getelementptr inbounds float, float* %10, i64 %516
  %518 = bitcast float* %517 to <64 x float>*
  store <64 x float> %514, <64 x float>* %518, align 64, !tbaa !694
  %519 = getelementptr inbounds i8, i8* %37, i64 4096
  %520 = bitcast i8* %519 to <64 x float>*
  %521 = load <64 x float>, <64 x float>* %520, align 64, !tbaa !679
  %522 = fadd <64 x float> %345, %521
  %523 = fadd <64 x float> %342, %522
  %524 = fcmp ogt <64 x float> %523, zeroinitializer
  %525 = select <64 x i1> %524, <64 x float> %523, <64 x float> zeroinitializer
  %526 = mul i64 %indvars.iv33, 7696581394432
  %sext49 = add i64 %526, 4398046511104
  %527 = ashr exact i64 %sext49, 32
  %528 = getelementptr inbounds float, float* %10, i64 %527
  %529 = bitcast float* %528 to <64 x float>*
  store <64 x float> %525, <64 x float>* %529, align 64, !tbaa !694
  %530 = getelementptr inbounds i8, i8* %37, i64 4352
  %531 = bitcast i8* %530 to <64 x float>*
  %532 = load <64 x float>, <64 x float>* %531, align 64, !tbaa !679
  %533 = fadd <64 x float> %345, %532
  %534 = fadd <64 x float> %342, %533
  %535 = fcmp ogt <64 x float> %534, zeroinitializer
  %536 = select <64 x i1> %535, <64 x float> %534, <64 x float> zeroinitializer
  %537 = mul i64 %indvars.iv33, 7696581394432
  %sext50 = add i64 %537, 4672924418048
  %538 = ashr exact i64 %sext50, 32
  %539 = getelementptr inbounds float, float* %10, i64 %538
  %540 = bitcast float* %539 to <64 x float>*
  store <64 x float> %536, <64 x float>* %540, align 64, !tbaa !694
  %541 = getelementptr inbounds i8, i8* %37, i64 4608
  %542 = bitcast i8* %541 to <64 x float>*
  %543 = load <64 x float>, <64 x float>* %542, align 64, !tbaa !679
  %544 = fadd <64 x float> %345, %543
  %545 = fadd <64 x float> %342, %544
  %546 = fcmp ogt <64 x float> %545, zeroinitializer
  %547 = select <64 x i1> %546, <64 x float> %545, <64 x float> zeroinitializer
  %548 = mul i64 %indvars.iv33, 7696581394432
  %sext51 = add i64 %548, 4947802324992
  %549 = ashr exact i64 %sext51, 32
  %550 = getelementptr inbounds float, float* %10, i64 %549
  %551 = bitcast float* %550 to <64 x float>*
  store <64 x float> %547, <64 x float>* %551, align 64, !tbaa !694
  %552 = getelementptr inbounds i8, i8* %37, i64 4864
  %553 = bitcast i8* %552 to <64 x float>*
  %554 = load <64 x float>, <64 x float>* %553, align 64, !tbaa !679
  %555 = fadd <64 x float> %345, %554
  %556 = fadd <64 x float> %342, %555
  %557 = fcmp ogt <64 x float> %556, zeroinitializer
  %558 = select <64 x i1> %557, <64 x float> %556, <64 x float> zeroinitializer
  %559 = mul i64 %indvars.iv33, 7696581394432
  %sext52 = add i64 %559, 5222680231936
  %560 = ashr exact i64 %sext52, 32
  %561 = getelementptr inbounds float, float* %10, i64 %560
  %562 = bitcast float* %561 to <64 x float>*
  store <64 x float> %558, <64 x float>* %562, align 64, !tbaa !694
  %563 = getelementptr inbounds i8, i8* %37, i64 5120
  %564 = bitcast i8* %563 to <64 x float>*
  %565 = load <64 x float>, <64 x float>* %564, align 64, !tbaa !679
  %566 = fadd <64 x float> %345, %565
  %567 = fadd <64 x float> %342, %566
  %568 = fcmp ogt <64 x float> %567, zeroinitializer
  %569 = select <64 x i1> %568, <64 x float> %567, <64 x float> zeroinitializer
  %570 = mul i64 %indvars.iv33, 7696581394432
  %sext53 = add i64 %570, 5497558138880
  %571 = ashr exact i64 %sext53, 32
  %572 = getelementptr inbounds float, float* %10, i64 %571
  %573 = bitcast float* %572 to <64 x float>*
  store <64 x float> %569, <64 x float>* %573, align 64, !tbaa !694
  %574 = getelementptr inbounds i8, i8* %37, i64 5376
  %575 = bitcast i8* %574 to <64 x float>*
  %576 = load <64 x float>, <64 x float>* %575, align 64, !tbaa !679
  %577 = fadd <64 x float> %345, %576
  %578 = fadd <64 x float> %342, %577
  %579 = fcmp ogt <64 x float> %578, zeroinitializer
  %580 = select <64 x i1> %579, <64 x float> %578, <64 x float> zeroinitializer
  %581 = mul i64 %indvars.iv33, 7696581394432
  %sext54 = add i64 %581, 5772436045824
  %582 = ashr exact i64 %sext54, 32
  %583 = getelementptr inbounds float, float* %10, i64 %582
  %584 = bitcast float* %583 to <64 x float>*
  store <64 x float> %580, <64 x float>* %584, align 64, !tbaa !694
  %585 = getelementptr inbounds i8, i8* %37, i64 5632
  %586 = bitcast i8* %585 to <64 x float>*
  %587 = load <64 x float>, <64 x float>* %586, align 64, !tbaa !679
  %588 = fadd <64 x float> %345, %587
  %589 = fadd <64 x float> %342, %588
  %590 = fcmp ogt <64 x float> %589, zeroinitializer
  %591 = select <64 x i1> %590, <64 x float> %589, <64 x float> zeroinitializer
  %592 = mul i64 %indvars.iv33, 7696581394432
  %sext55 = add i64 %592, 6047313952768
  %593 = ashr exact i64 %sext55, 32
  %594 = getelementptr inbounds float, float* %10, i64 %593
  %595 = bitcast float* %594 to <64 x float>*
  store <64 x float> %591, <64 x float>* %595, align 64, !tbaa !694
  %596 = getelementptr inbounds i8, i8* %37, i64 5888
  %597 = bitcast i8* %596 to <64 x float>*
  %598 = load <64 x float>, <64 x float>* %597, align 64, !tbaa !679
  %599 = fadd <64 x float> %345, %598
  %600 = fadd <64 x float> %342, %599
  %601 = fcmp ogt <64 x float> %600, zeroinitializer
  %602 = select <64 x i1> %601, <64 x float> %600, <64 x float> zeroinitializer
  %603 = mul i64 %indvars.iv33, 7696581394432
  %sext56 = add i64 %603, 6322191859712
  %604 = ashr exact i64 %sext56, 32
  %605 = getelementptr inbounds float, float* %10, i64 %604
  %606 = bitcast float* %605 to <64 x float>*
  store <64 x float> %602, <64 x float>* %606, align 64, !tbaa !694
  %607 = getelementptr inbounds i8, i8* %37, i64 6144
  %608 = bitcast i8* %607 to <64 x float>*
  %609 = load <64 x float>, <64 x float>* %608, align 64, !tbaa !679
  %610 = fadd <64 x float> %345, %609
  %611 = fadd <64 x float> %342, %610
  %612 = fcmp ogt <64 x float> %611, zeroinitializer
  %613 = select <64 x i1> %612, <64 x float> %611, <64 x float> zeroinitializer
  %614 = mul i64 %indvars.iv33, 7696581394432
  %sext57 = add i64 %614, 6597069766656
  %615 = ashr exact i64 %sext57, 32
  %616 = getelementptr inbounds float, float* %10, i64 %615
  %617 = bitcast float* %616 to <64 x float>*
  store <64 x float> %613, <64 x float>* %617, align 64, !tbaa !694
  %618 = getelementptr inbounds i8, i8* %37, i64 6400
  %619 = bitcast i8* %618 to <64 x float>*
  %620 = load <64 x float>, <64 x float>* %619, align 64, !tbaa !679
  %621 = fadd <64 x float> %345, %620
  %622 = fadd <64 x float> %342, %621
  %623 = fcmp ogt <64 x float> %622, zeroinitializer
  %624 = select <64 x i1> %623, <64 x float> %622, <64 x float> zeroinitializer
  %625 = mul i64 %indvars.iv33, 7696581394432
  %sext58 = add i64 %625, 6871947673600
  %626 = ashr exact i64 %sext58, 32
  %627 = getelementptr inbounds float, float* %10, i64 %626
  %628 = bitcast float* %627 to <64 x float>*
  store <64 x float> %624, <64 x float>* %628, align 64, !tbaa !694
  %629 = getelementptr inbounds i8, i8* %37, i64 6656
  %630 = bitcast i8* %629 to <64 x float>*
  %631 = load <64 x float>, <64 x float>* %630, align 64, !tbaa !679
  %632 = fadd <64 x float> %345, %631
  %633 = fadd <64 x float> %342, %632
  %634 = fcmp ogt <64 x float> %633, zeroinitializer
  %635 = select <64 x i1> %634, <64 x float> %633, <64 x float> zeroinitializer
  %636 = mul i64 %indvars.iv33, 7696581394432
  %sext59 = add i64 %636, 7146825580544
  %637 = ashr exact i64 %sext59, 32
  %638 = getelementptr inbounds float, float* %10, i64 %637
  %639 = bitcast float* %638 to <64 x float>*
  store <64 x float> %635, <64 x float>* %639, align 64, !tbaa !694
  %640 = getelementptr inbounds i8, i8* %37, i64 6912
  %641 = bitcast i8* %640 to <64 x float>*
  %642 = load <64 x float>, <64 x float>* %641, align 64, !tbaa !679
  %643 = fadd <64 x float> %345, %642
  %644 = fadd <64 x float> %342, %643
  %645 = fcmp ogt <64 x float> %644, zeroinitializer
  %646 = select <64 x i1> %645, <64 x float> %644, <64 x float> zeroinitializer
  %647 = mul i64 %indvars.iv33, 7696581394432
  %sext60 = add i64 %647, 7421703487488
  %648 = ashr exact i64 %sext60, 32
  %649 = getelementptr inbounds float, float* %10, i64 %648
  %650 = bitcast float* %649 to <64 x float>*
  store <64 x float> %646, <64 x float>* %650, align 64, !tbaa !694
  %651 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %652 = tail call i32 %651(i32 1, i32 %19, i8* nonnull %37)
  %indvars.iv.next34 = add nsw i64 %indvars.iv33, 1
  %653 = icmp slt i64 %indvars.iv.next34, %35
  br i1 %653, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_37(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !697 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !699, metadata !DIExpression()), !dbg !702
  call void @llvm.dbg.value(metadata i8* %1, metadata !700, metadata !DIExpression()), !dbg !702
  call void @llvm.dbg.value(metadata i32 %2, metadata !701, metadata !DIExpression()), !dbg !702
  %3 = bitcast i8* %0 to %1**, !dbg !702
  %4 = load %1*, %1** %3, align 8, !dbg !702
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !702
  %6 = bitcast i8* %5 to %1**, !dbg !702
  %7 = load %1*, %1** %6, align 8, !dbg !702
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !702
  %9 = load i8*, i8** %8, align 8, !dbg !702
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !702
  %11 = load i8*, i8** %10, align 8, !dbg !702
  %12 = tail call fastcc i32 @fused_layout_transform_37_compute_(i8* %11, i8* %9), !dbg !702
  ret i32 %12, !dbg !702
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_37_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %42, align 8
  %3 = getelementptr inbounds %42, %42* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %42, %42* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %42* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.38, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.38(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 223
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 224
  %15 = select i1 %14, i32 %13, i32 224
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 224
  %18 = select i1 %17, i32 %16, i32 224
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 1792
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = srem i32 %25, 28
  %27 = mul nsw i32 %26, 896
  %28 = sdiv i32 %25, 28
  %29 = mul nsw i32 %28, 50176
  %30 = add i32 %27, %29
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %31 = shl i64 %indvars.iv7, 6
  %32 = add nsw i64 %31, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %33 = shl i32 %indvars.iv7.tr, 5
  %34 = add i32 %30, %33
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %35 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %35, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %36 = add nsw i64 %32, %indvars.iv
  %37 = trunc i64 %indvars.iv to i32
  %38 = and i32 %37, 31
  %39 = lshr i32 %37, 5
  %40 = mul nsw i32 %39, 25088
  %41 = add i32 %34, %40
  %42 = or i32 %41, %38
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds float, float* %7, i64 %43
  %45 = bitcast float* %44 to i32*
  %46 = load i32, i32* %45, align 4, !tbaa !703
  %47 = getelementptr inbounds float, float* %4, i64 %36
  %48 = bitcast float* %47 to i32*
  store i32 %46, i32* %48, align 4, !tbaa !706
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !709 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !711, metadata !DIExpression()), !dbg !714
  call void @llvm.dbg.value(metadata i8* %1, metadata !712, metadata !DIExpression()), !dbg !714
  call void @llvm.dbg.value(metadata i32 %2, metadata !713, metadata !DIExpression()), !dbg !714
  %3 = bitcast i8* %0 to %1**, !dbg !714
  %4 = load %1*, %1** %3, align 8, !dbg !714
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !714
  %6 = bitcast i8* %5 to %1**, !dbg !714
  %7 = load %1*, %1** %6, align 8, !dbg !714
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !714
  %9 = bitcast i8* %8 to %1**, !dbg !714
  %10 = load %1*, %1** %9, align 8, !dbg !714
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !714
  %12 = bitcast i8* %11 to %1**, !dbg !714
  %13 = load %1*, %1** %12, align 8, !dbg !714
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !714
  %15 = bitcast i8* %14 to %1**, !dbg !714
  %16 = load %1*, %1** %15, align 8, !dbg !714
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !714
  %18 = bitcast i8* %17 to %1**, !dbg !714
  %19 = load %1*, %1** %18, align 8, !dbg !714
  %20 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !714
  %21 = load i8*, i8** %20, align 8, !dbg !714
  %22 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !714
  %23 = load i32, i32* %22, align 4, !dbg !714
  %24 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !714
  %25 = load i8*, i8** %24, align 8, !dbg !714
  %26 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !714
  %27 = load i8*, i8** %26, align 8, !dbg !714
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !714
  %29 = load i8*, i8** %28, align 8, !dbg !714
  %30 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !714
  %31 = load i8*, i8** %30, align 8, !dbg !714
  %32 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !714
  %33 = load i8*, i8** %32, align 8, !dbg !714
  %34 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3_compute_(i8* %21, i8* %25, i8* %33, i8* %27, i8* %29, i8* %31, i32 %23), !dbg !714
  ret i32 %34, !dbg !714
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %43, align 8
  %8 = getelementptr inbounds %43, %43* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %43, %43* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %43, %43* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %43, %43* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %43, %43* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %43, %43* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %43, %43* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %43* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.39, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.39(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 111
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 112
  %30 = select i1 %29, i32 %28, i32 112
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 112
  %33 = select i1 %32, i32 %31, i32 112
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end9
  %35 = phi i32 [ %227, %for_end9 ], [ %33, %for_body.preheader ]
  %36 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %37 = tail call i8* %36(i32 1, i32 %22, i64 7168, i32 2, i32 32)
  %38 = bitcast i8* %37 to float*
  %39 = srem i32 %35, 56
  %40 = mul nsw i32 %39, 14336
  %41 = sdiv i32 %35, 56
  %42 = shl i32 %41, 13
  %43 = sext i32 %42 to i64
  %44 = sext i32 %40 to i64
  br label %for_body2

for_end:                                          ; preds = %for_end9, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv33 = phi i64 [ 0, %for_body ], [ %indvars.iv.next34, %for_end6 ]
  %45 = mul nuw nsw i64 %indvars.iv33, 224
  %46 = getelementptr inbounds float, float* %38, i64 %45
  %47 = bitcast float* %46 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %47, align 64, !tbaa !715
  %48 = add nuw nsw i64 %45, 32
  %49 = getelementptr inbounds float, float* %38, i64 %48
  %50 = bitcast float* %49 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %50, align 64, !tbaa !715
  %51 = add nuw nsw i64 %45, 64
  %52 = getelementptr inbounds float, float* %38, i64 %51
  %53 = bitcast float* %52 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %53, align 64, !tbaa !715
  %54 = add nuw nsw i64 %45, 96
  %55 = getelementptr inbounds float, float* %38, i64 %54
  %56 = bitcast float* %55 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %56, align 64, !tbaa !715
  %57 = add nuw nsw i64 %45, 128
  %58 = getelementptr inbounds float, float* %38, i64 %57
  %59 = bitcast float* %58 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %59, align 64, !tbaa !715
  %60 = add nuw nsw i64 %45, 160
  %61 = getelementptr inbounds float, float* %38, i64 %60
  %62 = bitcast float* %61 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %62, align 64, !tbaa !715
  %63 = add nuw nsw i64 %45, 192
  %64 = getelementptr inbounds float, float* %38, i64 %63
  %65 = bitcast float* %64 to <32 x float>*
  store <32 x float> zeroinitializer, <32 x float>* %65, align 64, !tbaa !715
  %66 = mul nuw nsw i64 %indvars.iv33, 1792
  %67 = add nsw i64 %66, %44
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %68 = mul nsw i32 %35, 1792
  %69 = shl nsw i32 %41, 5
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds float, float* %13, i64 %70
  %72 = bitcast float* %71 to <32 x float>*
  %73 = load <32 x float>, <32 x float>* %72, align 64, !tbaa !718
  %74 = getelementptr inbounds float, float* %16, i64 %70
  %75 = bitcast float* %74 to <32 x float>*
  %76 = load <32 x float>, <32 x float>* %75, align 64, !tbaa !721
  %77 = getelementptr inbounds float, float* %19, i64 %70
  %78 = bitcast float* %77 to <32 x float>*
  %79 = load <32 x float>, <32 x float>* %78, align 64, !tbaa !724
  br label %for_body8

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %80 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %133, %for_body5 ]
  %81 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %127, %for_body5 ]
  %82 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %121, %for_body5 ]
  %83 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %115, %for_body5 ]
  %84 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %109, %for_body5 ]
  %85 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %103, %for_body5 ]
  %86 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %97, %for_body5 ]
  %87 = add nsw i64 %67, %indvars.iv
  %88 = getelementptr inbounds float, float* %4, i64 %87
  %89 = load float, float* %88, align 4, !tbaa !727
  %90 = insertelement <32 x float> undef, float %89, i32 0
  %91 = shufflevector <32 x float> %90, <32 x float> undef, <32 x i32> zeroinitializer
  %92 = shl i64 %indvars.iv, 5
  %93 = add nuw nsw i64 %92, %43
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <32 x float>*
  %96 = load <32 x float>, <32 x float>* %95, align 64, !tbaa !730
  %97 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %91, <32 x float> %96, <32 x float> %86)
  %98 = add nsw i64 %87, 256
  %99 = getelementptr inbounds float, float* %4, i64 %98
  %100 = load float, float* %99, align 4, !tbaa !727
  %101 = insertelement <32 x float> undef, float %100, i32 0
  %102 = shufflevector <32 x float> %101, <32 x float> undef, <32 x i32> zeroinitializer
  %103 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %102, <32 x float> %96, <32 x float> %85)
  %104 = add nsw i64 %87, 512
  %105 = getelementptr inbounds float, float* %4, i64 %104
  %106 = load float, float* %105, align 4, !tbaa !727
  %107 = insertelement <32 x float> undef, float %106, i32 0
  %108 = shufflevector <32 x float> %107, <32 x float> undef, <32 x i32> zeroinitializer
  %109 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %108, <32 x float> %96, <32 x float> %84)
  %110 = add nsw i64 %87, 768
  %111 = getelementptr inbounds float, float* %4, i64 %110
  %112 = load float, float* %111, align 4, !tbaa !727
  %113 = insertelement <32 x float> undef, float %112, i32 0
  %114 = shufflevector <32 x float> %113, <32 x float> undef, <32 x i32> zeroinitializer
  %115 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %114, <32 x float> %96, <32 x float> %83)
  %116 = add nsw i64 %87, 1024
  %117 = getelementptr inbounds float, float* %4, i64 %116
  %118 = load float, float* %117, align 4, !tbaa !727
  %119 = insertelement <32 x float> undef, float %118, i32 0
  %120 = shufflevector <32 x float> %119, <32 x float> undef, <32 x i32> zeroinitializer
  %121 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %120, <32 x float> %96, <32 x float> %82)
  %122 = add nsw i64 %87, 1280
  %123 = getelementptr inbounds float, float* %4, i64 %122
  %124 = load float, float* %123, align 4, !tbaa !727
  %125 = insertelement <32 x float> undef, float %124, i32 0
  %126 = shufflevector <32 x float> %125, <32 x float> undef, <32 x i32> zeroinitializer
  %127 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %126, <32 x float> %96, <32 x float> %81)
  %128 = add nsw i64 %87, 1536
  %129 = getelementptr inbounds float, float* %4, i64 %128
  %130 = load float, float* %129, align 4, !tbaa !727
  %131 = insertelement <32 x float> undef, float %130, i32 0
  %132 = shufflevector <32 x float> %131, <32 x float> undef, <32 x i32> zeroinitializer
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %132, <32 x float> %96, <32 x float> %80)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <32 x float> %97, <32 x float>* %47, align 64, !tbaa !715
  store <32 x float> %103, <32 x float>* %50, align 64, !tbaa !715
  store <32 x float> %109, <32 x float>* %53, align 64, !tbaa !715
  store <32 x float> %115, <32 x float>* %56, align 64, !tbaa !715
  store <32 x float> %121, <32 x float>* %59, align 64, !tbaa !715
  store <32 x float> %127, <32 x float>* %62, align 64, !tbaa !715
  store <32 x float> %133, <32 x float>* %65, align 64, !tbaa !715
  %indvars.iv.next34 = add nuw nsw i64 %indvars.iv33, 1
  %exitcond35 = icmp eq i64 %indvars.iv.next34, 8
  br i1 %exitcond35, label %for_end3, label %for_body2, !prof !29

for_body8:                                        ; preds = %for_body8, %for_end3
  %indvars.iv39 = phi i64 [ 0, %for_end3 ], [ %indvars.iv.next40, %for_body8 ]
  %134 = mul nuw nsw i64 %indvars.iv39, 224
  %135 = trunc i64 %134 to i32
  %136 = add i32 %68, %135
  %137 = getelementptr inbounds float, float* %38, i64 %134
  %138 = bitcast float* %137 to <32 x float>*
  %139 = load <32 x float>, <32 x float>* %138, align 64, !tbaa !715
  %140 = fadd <32 x float> %73, %139
  %141 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %140, <32 x float> %76, <32 x float> %79)
  %142 = fcmp ogt <32 x float> %141, zeroinitializer
  %143 = select <32 x i1> %142, <32 x float> %141, <32 x float> zeroinitializer
  %144 = sext i32 %136 to i64
  %145 = getelementptr inbounds float, float* %10, i64 %144
  %146 = bitcast float* %145 to <32 x float>*
  store <32 x float> %143, <32 x float>* %146, align 64, !tbaa !733
  %147 = add nuw nsw i64 %134, 32
  %148 = trunc i64 %147 to i32
  %149 = add i32 %68, %148
  %150 = getelementptr inbounds float, float* %38, i64 %147
  %151 = bitcast float* %150 to <32 x float>*
  %152 = load <32 x float>, <32 x float>* %151, align 64, !tbaa !715
  %153 = fadd <32 x float> %73, %152
  %154 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %153, <32 x float> %76, <32 x float> %79)
  %155 = fcmp ogt <32 x float> %154, zeroinitializer
  %156 = select <32 x i1> %155, <32 x float> %154, <32 x float> zeroinitializer
  %157 = sext i32 %149 to i64
  %158 = getelementptr inbounds float, float* %10, i64 %157
  %159 = bitcast float* %158 to <32 x float>*
  store <32 x float> %156, <32 x float>* %159, align 64, !tbaa !733
  %160 = add nuw nsw i64 %134, 64
  %161 = trunc i64 %160 to i32
  %162 = add i32 %68, %161
  %163 = getelementptr inbounds float, float* %38, i64 %160
  %164 = bitcast float* %163 to <32 x float>*
  %165 = load <32 x float>, <32 x float>* %164, align 64, !tbaa !715
  %166 = fadd <32 x float> %73, %165
  %167 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %166, <32 x float> %76, <32 x float> %79)
  %168 = fcmp ogt <32 x float> %167, zeroinitializer
  %169 = select <32 x i1> %168, <32 x float> %167, <32 x float> zeroinitializer
  %170 = sext i32 %162 to i64
  %171 = getelementptr inbounds float, float* %10, i64 %170
  %172 = bitcast float* %171 to <32 x float>*
  store <32 x float> %169, <32 x float>* %172, align 64, !tbaa !733
  %173 = add nuw nsw i64 %134, 96
  %174 = trunc i64 %173 to i32
  %175 = add i32 %68, %174
  %176 = getelementptr inbounds float, float* %38, i64 %173
  %177 = bitcast float* %176 to <32 x float>*
  %178 = load <32 x float>, <32 x float>* %177, align 64, !tbaa !715
  %179 = fadd <32 x float> %73, %178
  %180 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %179, <32 x float> %76, <32 x float> %79)
  %181 = fcmp ogt <32 x float> %180, zeroinitializer
  %182 = select <32 x i1> %181, <32 x float> %180, <32 x float> zeroinitializer
  %183 = sext i32 %175 to i64
  %184 = getelementptr inbounds float, float* %10, i64 %183
  %185 = bitcast float* %184 to <32 x float>*
  store <32 x float> %182, <32 x float>* %185, align 64, !tbaa !733
  %186 = add nuw nsw i64 %134, 128
  %187 = trunc i64 %186 to i32
  %188 = add i32 %68, %187
  %189 = getelementptr inbounds float, float* %38, i64 %186
  %190 = bitcast float* %189 to <32 x float>*
  %191 = load <32 x float>, <32 x float>* %190, align 64, !tbaa !715
  %192 = fadd <32 x float> %73, %191
  %193 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %192, <32 x float> %76, <32 x float> %79)
  %194 = fcmp ogt <32 x float> %193, zeroinitializer
  %195 = select <32 x i1> %194, <32 x float> %193, <32 x float> zeroinitializer
  %196 = sext i32 %188 to i64
  %197 = getelementptr inbounds float, float* %10, i64 %196
  %198 = bitcast float* %197 to <32 x float>*
  store <32 x float> %195, <32 x float>* %198, align 64, !tbaa !733
  %199 = add nuw nsw i64 %134, 160
  %200 = trunc i64 %199 to i32
  %201 = add i32 %68, %200
  %202 = getelementptr inbounds float, float* %38, i64 %199
  %203 = bitcast float* %202 to <32 x float>*
  %204 = load <32 x float>, <32 x float>* %203, align 64, !tbaa !715
  %205 = fadd <32 x float> %73, %204
  %206 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %205, <32 x float> %76, <32 x float> %79)
  %207 = fcmp ogt <32 x float> %206, zeroinitializer
  %208 = select <32 x i1> %207, <32 x float> %206, <32 x float> zeroinitializer
  %209 = sext i32 %201 to i64
  %210 = getelementptr inbounds float, float* %10, i64 %209
  %211 = bitcast float* %210 to <32 x float>*
  store <32 x float> %208, <32 x float>* %211, align 64, !tbaa !733
  %212 = add nuw nsw i64 %134, 192
  %213 = trunc i64 %212 to i32
  %214 = add i32 %68, %213
  %215 = getelementptr inbounds float, float* %38, i64 %212
  %216 = bitcast float* %215 to <32 x float>*
  %217 = load <32 x float>, <32 x float>* %216, align 64, !tbaa !715
  %218 = fadd <32 x float> %73, %217
  %219 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %218, <32 x float> %76, <32 x float> %79)
  %220 = fcmp ogt <32 x float> %219, zeroinitializer
  %221 = select <32 x i1> %220, <32 x float> %219, <32 x float> zeroinitializer
  %222 = sext i32 %214 to i64
  %223 = getelementptr inbounds float, float* %10, i64 %222
  %224 = bitcast float* %223 to <32 x float>*
  store <32 x float> %221, <32 x float>* %224, align 64, !tbaa !733
  %indvars.iv.next40 = add nuw nsw i64 %indvars.iv39, 1
  %exitcond41 = icmp eq i64 %indvars.iv.next40, 8
  br i1 %exitcond41, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %225 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %226 = tail call i32 %225(i32 1, i32 %22, i8* nonnull %37)
  %227 = add nsw i32 %35, 1
  %228 = icmp slt i32 %227, %30
  br i1 %228, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !736 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !738, metadata !DIExpression()), !dbg !741
  call void @llvm.dbg.value(metadata i8* %1, metadata !739, metadata !DIExpression()), !dbg !741
  call void @llvm.dbg.value(metadata i32 %2, metadata !740, metadata !DIExpression()), !dbg !741
  %3 = bitcast i8* %0 to %1**, !dbg !741
  %4 = load %1*, %1** %3, align 8, !dbg !741
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !741
  %6 = bitcast i8* %5 to %1**, !dbg !741
  %7 = load %1*, %1** %6, align 8, !dbg !741
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !741
  %9 = bitcast i8* %8 to %1**, !dbg !741
  %10 = load %1*, %1** %9, align 8, !dbg !741
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !741
  %12 = bitcast i8* %11 to %1**, !dbg !741
  %13 = load %1*, %1** %12, align 8, !dbg !741
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !741
  %15 = bitcast i8* %14 to %1**, !dbg !741
  %16 = load %1*, %1** %15, align 8, !dbg !741
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !741
  %18 = bitcast i8* %17 to %1**, !dbg !741
  %19 = load %1*, %1** %18, align 8, !dbg !741
  %20 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !741
  %21 = load i8*, i8** %20, align 8, !dbg !741
  %22 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !741
  %23 = load i32, i32* %22, align 4, !dbg !741
  %24 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !741
  %25 = load i8*, i8** %24, align 8, !dbg !741
  %26 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !741
  %27 = load i8*, i8** %26, align 8, !dbg !741
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !741
  %29 = load i8*, i8** %28, align 8, !dbg !741
  %30 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !741
  %31 = load i8*, i8** %30, align 8, !dbg !741
  %32 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !741
  %33 = load i8*, i8** %32, align 8, !dbg !741
  %34 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1_compute_(i8* %21, i8* %25, i8* %33, i8* %27, i8* %29, i8* %31, i32 %23), !dbg !741
  ret i32 %34, !dbg !741
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %44, align 8
  %8 = getelementptr inbounds %44, %44* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %44, %44* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %44, %44* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %44, %44* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %44, %44* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %44, %44* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %44, %44* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %44* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.40, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.40(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 55
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 56
  %30 = select i1 %29, i32 %28, i32 56
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 56
  %33 = select i1 %32, i32 %31, i32 56
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.6
  %indvars.iv33 = phi i64 [ %37, %for_body.lr.ph ], [ %indvars.iv.next34, %for_end6.6 ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %40 = tail call i8* %39(i32 1, i32 %22, i64 7168, i32 2, i32 32)
  %41 = trunc i64 %indvars.iv33 to i32
  %42 = srem i32 %41, 28
  %43 = mul nsw i32 %42, 14336
  %44 = sdiv i32 %41, 28
  %45 = shl i32 %44, 15
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  %48 = bitcast i8* %40 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %48, align 64, !tbaa !742
  %49 = getelementptr inbounds i8, i8* %40, i64 256
  %50 = bitcast i8* %49 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %50, align 64, !tbaa !742
  %51 = getelementptr inbounds i8, i8* %40, i64 512
  %52 = bitcast i8* %51 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %52, align 64, !tbaa !742
  %53 = getelementptr inbounds i8, i8* %40, i64 768
  %54 = bitcast i8* %53 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %54, align 64, !tbaa !742
  br label %for_body5

for_end:                                          ; preds = %for_end6.6, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %55 = phi <64 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %56 = phi <64 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %57 = phi <64 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %58 = phi <64 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %59 = add nsw i64 %indvars.iv, %47
  %60 = getelementptr inbounds float, float* %4, i64 %59
  %61 = load float, float* %60, align 4, !tbaa !745
  %62 = insertelement <64 x float> undef, float %61, i32 0
  %63 = shufflevector <64 x float> %62, <64 x float> undef, <64 x i32> zeroinitializer
  %64 = shl i64 %indvars.iv, 6
  %65 = add nuw nsw i64 %64, %46
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to <64 x float>*
  %68 = load <64 x float>, <64 x float>* %67, align 64, !tbaa !748
  %69 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %63, <64 x float> %68, <64 x float> %58)
  %70 = add nsw i64 %59, 512
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !745
  %73 = insertelement <64 x float> undef, float %72, i32 0
  %74 = shufflevector <64 x float> %73, <64 x float> undef, <64 x i32> zeroinitializer
  %75 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %74, <64 x float> %68, <64 x float> %57)
  %76 = add nsw i64 %59, 1024
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !745
  %79 = insertelement <64 x float> undef, float %78, i32 0
  %80 = shufflevector <64 x float> %79, <64 x float> undef, <64 x i32> zeroinitializer
  %81 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %80, <64 x float> %68, <64 x float> %56)
  %82 = add nsw i64 %59, 1536
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !745
  %85 = insertelement <64 x float> undef, float %84, i32 0
  %86 = shufflevector <64 x float> %85, <64 x float> undef, <64 x i32> zeroinitializer
  %87 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %86, <64 x float> %68, <64 x float> %55)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <64 x float> %69, <64 x float>* %48, align 64, !tbaa !742
  store <64 x float> %75, <64 x float>* %50, align 64, !tbaa !742
  store <64 x float> %81, <64 x float>* %52, align 64, !tbaa !742
  store <64 x float> %87, <64 x float>* %54, align 64, !tbaa !742
  %88 = getelementptr inbounds i8, i8* %40, i64 1024
  %89 = bitcast i8* %88 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %89, align 64, !tbaa !742
  %90 = getelementptr inbounds i8, i8* %40, i64 1280
  %91 = bitcast i8* %90 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %91, align 64, !tbaa !742
  %92 = getelementptr inbounds i8, i8* %40, i64 1536
  %93 = bitcast i8* %92 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %93, align 64, !tbaa !742
  %94 = getelementptr inbounds i8, i8* %40, i64 1792
  %95 = bitcast i8* %94 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %95, align 64, !tbaa !742
  %96 = add nsw i64 %47, 2048
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %97 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %129, %for_body5.1 ]
  %98 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %123, %for_body5.1 ]
  %99 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %117, %for_body5.1 ]
  %100 = phi <64 x float> [ zeroinitializer, %for_end6 ], [ %111, %for_body5.1 ]
  %101 = add nsw i64 %96, %indvars.iv.1
  %102 = getelementptr inbounds float, float* %4, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !745
  %104 = insertelement <64 x float> undef, float %103, i32 0
  %105 = shufflevector <64 x float> %104, <64 x float> undef, <64 x i32> zeroinitializer
  %106 = shl i64 %indvars.iv.1, 6
  %107 = add nuw nsw i64 %106, %46
  %108 = getelementptr inbounds float, float* %7, i64 %107
  %109 = bitcast float* %108 to <64 x float>*
  %110 = load <64 x float>, <64 x float>* %109, align 64, !tbaa !748
  %111 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %105, <64 x float> %110, <64 x float> %100)
  %112 = add nsw i64 %101, 512
  %113 = getelementptr inbounds float, float* %4, i64 %112
  %114 = load float, float* %113, align 4, !tbaa !745
  %115 = insertelement <64 x float> undef, float %114, i32 0
  %116 = shufflevector <64 x float> %115, <64 x float> undef, <64 x i32> zeroinitializer
  %117 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %116, <64 x float> %110, <64 x float> %99)
  %118 = add nsw i64 %101, 1024
  %119 = getelementptr inbounds float, float* %4, i64 %118
  %120 = load float, float* %119, align 4, !tbaa !745
  %121 = insertelement <64 x float> undef, float %120, i32 0
  %122 = shufflevector <64 x float> %121, <64 x float> undef, <64 x i32> zeroinitializer
  %123 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %122, <64 x float> %110, <64 x float> %98)
  %124 = add nsw i64 %101, 1536
  %125 = getelementptr inbounds float, float* %4, i64 %124
  %126 = load float, float* %125, align 4, !tbaa !745
  %127 = insertelement <64 x float> undef, float %126, i32 0
  %128 = shufflevector <64 x float> %127, <64 x float> undef, <64 x i32> zeroinitializer
  %129 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %128, <64 x float> %110, <64 x float> %97)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  store <64 x float> %111, <64 x float>* %89, align 64, !tbaa !742
  store <64 x float> %117, <64 x float>* %91, align 64, !tbaa !742
  store <64 x float> %123, <64 x float>* %93, align 64, !tbaa !742
  store <64 x float> %129, <64 x float>* %95, align 64, !tbaa !742
  %130 = getelementptr inbounds i8, i8* %40, i64 2048
  %131 = bitcast i8* %130 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %131, align 64, !tbaa !742
  %132 = getelementptr inbounds i8, i8* %40, i64 2304
  %133 = bitcast i8* %132 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %133, align 64, !tbaa !742
  %134 = getelementptr inbounds i8, i8* %40, i64 2560
  %135 = bitcast i8* %134 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %135, align 64, !tbaa !742
  %136 = getelementptr inbounds i8, i8* %40, i64 2816
  %137 = bitcast i8* %136 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %137, align 64, !tbaa !742
  %138 = add nsw i64 %47, 4096
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %139 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %171, %for_body5.2 ]
  %140 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %165, %for_body5.2 ]
  %141 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %159, %for_body5.2 ]
  %142 = phi <64 x float> [ zeroinitializer, %for_end6.1 ], [ %153, %for_body5.2 ]
  %143 = add nsw i64 %138, %indvars.iv.2
  %144 = getelementptr inbounds float, float* %4, i64 %143
  %145 = load float, float* %144, align 4, !tbaa !745
  %146 = insertelement <64 x float> undef, float %145, i32 0
  %147 = shufflevector <64 x float> %146, <64 x float> undef, <64 x i32> zeroinitializer
  %148 = shl i64 %indvars.iv.2, 6
  %149 = add nuw nsw i64 %148, %46
  %150 = getelementptr inbounds float, float* %7, i64 %149
  %151 = bitcast float* %150 to <64 x float>*
  %152 = load <64 x float>, <64 x float>* %151, align 64, !tbaa !748
  %153 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %147, <64 x float> %152, <64 x float> %142)
  %154 = add nsw i64 %143, 512
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !745
  %157 = insertelement <64 x float> undef, float %156, i32 0
  %158 = shufflevector <64 x float> %157, <64 x float> undef, <64 x i32> zeroinitializer
  %159 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %158, <64 x float> %152, <64 x float> %141)
  %160 = add nsw i64 %143, 1024
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !745
  %163 = insertelement <64 x float> undef, float %162, i32 0
  %164 = shufflevector <64 x float> %163, <64 x float> undef, <64 x i32> zeroinitializer
  %165 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %164, <64 x float> %152, <64 x float> %140)
  %166 = add nsw i64 %143, 1536
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !745
  %169 = insertelement <64 x float> undef, float %168, i32 0
  %170 = shufflevector <64 x float> %169, <64 x float> undef, <64 x i32> zeroinitializer
  %171 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %170, <64 x float> %152, <64 x float> %139)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 512
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  store <64 x float> %153, <64 x float>* %131, align 64, !tbaa !742
  store <64 x float> %159, <64 x float>* %133, align 64, !tbaa !742
  store <64 x float> %165, <64 x float>* %135, align 64, !tbaa !742
  store <64 x float> %171, <64 x float>* %137, align 64, !tbaa !742
  %172 = getelementptr inbounds i8, i8* %40, i64 3072
  %173 = bitcast i8* %172 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %173, align 64, !tbaa !742
  %174 = getelementptr inbounds i8, i8* %40, i64 3328
  %175 = bitcast i8* %174 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %175, align 64, !tbaa !742
  %176 = getelementptr inbounds i8, i8* %40, i64 3584
  %177 = bitcast i8* %176 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %177, align 64, !tbaa !742
  %178 = getelementptr inbounds i8, i8* %40, i64 3840
  %179 = bitcast i8* %178 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %179, align 64, !tbaa !742
  %180 = add nsw i64 %47, 6144
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %181 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %213, %for_body5.3 ]
  %182 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %207, %for_body5.3 ]
  %183 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %201, %for_body5.3 ]
  %184 = phi <64 x float> [ zeroinitializer, %for_end6.2 ], [ %195, %for_body5.3 ]
  %185 = add nsw i64 %180, %indvars.iv.3
  %186 = getelementptr inbounds float, float* %4, i64 %185
  %187 = load float, float* %186, align 4, !tbaa !745
  %188 = insertelement <64 x float> undef, float %187, i32 0
  %189 = shufflevector <64 x float> %188, <64 x float> undef, <64 x i32> zeroinitializer
  %190 = shl i64 %indvars.iv.3, 6
  %191 = add nuw nsw i64 %190, %46
  %192 = getelementptr inbounds float, float* %7, i64 %191
  %193 = bitcast float* %192 to <64 x float>*
  %194 = load <64 x float>, <64 x float>* %193, align 64, !tbaa !748
  %195 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %189, <64 x float> %194, <64 x float> %184)
  %196 = add nsw i64 %185, 512
  %197 = getelementptr inbounds float, float* %4, i64 %196
  %198 = load float, float* %197, align 4, !tbaa !745
  %199 = insertelement <64 x float> undef, float %198, i32 0
  %200 = shufflevector <64 x float> %199, <64 x float> undef, <64 x i32> zeroinitializer
  %201 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %200, <64 x float> %194, <64 x float> %183)
  %202 = add nsw i64 %185, 1024
  %203 = getelementptr inbounds float, float* %4, i64 %202
  %204 = load float, float* %203, align 4, !tbaa !745
  %205 = insertelement <64 x float> undef, float %204, i32 0
  %206 = shufflevector <64 x float> %205, <64 x float> undef, <64 x i32> zeroinitializer
  %207 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %206, <64 x float> %194, <64 x float> %182)
  %208 = add nsw i64 %185, 1536
  %209 = getelementptr inbounds float, float* %4, i64 %208
  %210 = load float, float* %209, align 4, !tbaa !745
  %211 = insertelement <64 x float> undef, float %210, i32 0
  %212 = shufflevector <64 x float> %211, <64 x float> undef, <64 x i32> zeroinitializer
  %213 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %212, <64 x float> %194, <64 x float> %181)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 512
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  store <64 x float> %195, <64 x float>* %173, align 64, !tbaa !742
  store <64 x float> %201, <64 x float>* %175, align 64, !tbaa !742
  store <64 x float> %207, <64 x float>* %177, align 64, !tbaa !742
  store <64 x float> %213, <64 x float>* %179, align 64, !tbaa !742
  %214 = getelementptr inbounds i8, i8* %40, i64 4096
  %215 = bitcast i8* %214 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %215, align 64, !tbaa !742
  %216 = getelementptr inbounds i8, i8* %40, i64 4352
  %217 = bitcast i8* %216 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %217, align 64, !tbaa !742
  %218 = getelementptr inbounds i8, i8* %40, i64 4608
  %219 = bitcast i8* %218 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %219, align 64, !tbaa !742
  %220 = getelementptr inbounds i8, i8* %40, i64 4864
  %221 = bitcast i8* %220 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %221, align 64, !tbaa !742
  %222 = add nsw i64 %47, 8192
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %223 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %255, %for_body5.4 ]
  %224 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %249, %for_body5.4 ]
  %225 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %243, %for_body5.4 ]
  %226 = phi <64 x float> [ zeroinitializer, %for_end6.3 ], [ %237, %for_body5.4 ]
  %227 = add nsw i64 %222, %indvars.iv.4
  %228 = getelementptr inbounds float, float* %4, i64 %227
  %229 = load float, float* %228, align 4, !tbaa !745
  %230 = insertelement <64 x float> undef, float %229, i32 0
  %231 = shufflevector <64 x float> %230, <64 x float> undef, <64 x i32> zeroinitializer
  %232 = shl i64 %indvars.iv.4, 6
  %233 = add nuw nsw i64 %232, %46
  %234 = getelementptr inbounds float, float* %7, i64 %233
  %235 = bitcast float* %234 to <64 x float>*
  %236 = load <64 x float>, <64 x float>* %235, align 64, !tbaa !748
  %237 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %231, <64 x float> %236, <64 x float> %226)
  %238 = add nsw i64 %227, 512
  %239 = getelementptr inbounds float, float* %4, i64 %238
  %240 = load float, float* %239, align 4, !tbaa !745
  %241 = insertelement <64 x float> undef, float %240, i32 0
  %242 = shufflevector <64 x float> %241, <64 x float> undef, <64 x i32> zeroinitializer
  %243 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %242, <64 x float> %236, <64 x float> %225)
  %244 = add nsw i64 %227, 1024
  %245 = getelementptr inbounds float, float* %4, i64 %244
  %246 = load float, float* %245, align 4, !tbaa !745
  %247 = insertelement <64 x float> undef, float %246, i32 0
  %248 = shufflevector <64 x float> %247, <64 x float> undef, <64 x i32> zeroinitializer
  %249 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %248, <64 x float> %236, <64 x float> %224)
  %250 = add nsw i64 %227, 1536
  %251 = getelementptr inbounds float, float* %4, i64 %250
  %252 = load float, float* %251, align 4, !tbaa !745
  %253 = insertelement <64 x float> undef, float %252, i32 0
  %254 = shufflevector <64 x float> %253, <64 x float> undef, <64 x i32> zeroinitializer
  %255 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %254, <64 x float> %236, <64 x float> %223)
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 512
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  store <64 x float> %237, <64 x float>* %215, align 64, !tbaa !742
  store <64 x float> %243, <64 x float>* %217, align 64, !tbaa !742
  store <64 x float> %249, <64 x float>* %219, align 64, !tbaa !742
  store <64 x float> %255, <64 x float>* %221, align 64, !tbaa !742
  %256 = getelementptr inbounds i8, i8* %40, i64 5120
  %257 = bitcast i8* %256 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %257, align 64, !tbaa !742
  %258 = getelementptr inbounds i8, i8* %40, i64 5376
  %259 = bitcast i8* %258 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %259, align 64, !tbaa !742
  %260 = getelementptr inbounds i8, i8* %40, i64 5632
  %261 = bitcast i8* %260 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %261, align 64, !tbaa !742
  %262 = getelementptr inbounds i8, i8* %40, i64 5888
  %263 = bitcast i8* %262 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %263, align 64, !tbaa !742
  %264 = add nsw i64 %47, 10240
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %265 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %297, %for_body5.5 ]
  %266 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %291, %for_body5.5 ]
  %267 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %285, %for_body5.5 ]
  %268 = phi <64 x float> [ zeroinitializer, %for_end6.4 ], [ %279, %for_body5.5 ]
  %269 = add nsw i64 %264, %indvars.iv.5
  %270 = getelementptr inbounds float, float* %4, i64 %269
  %271 = load float, float* %270, align 4, !tbaa !745
  %272 = insertelement <64 x float> undef, float %271, i32 0
  %273 = shufflevector <64 x float> %272, <64 x float> undef, <64 x i32> zeroinitializer
  %274 = shl i64 %indvars.iv.5, 6
  %275 = add nuw nsw i64 %274, %46
  %276 = getelementptr inbounds float, float* %7, i64 %275
  %277 = bitcast float* %276 to <64 x float>*
  %278 = load <64 x float>, <64 x float>* %277, align 64, !tbaa !748
  %279 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %273, <64 x float> %278, <64 x float> %268)
  %280 = add nsw i64 %269, 512
  %281 = getelementptr inbounds float, float* %4, i64 %280
  %282 = load float, float* %281, align 4, !tbaa !745
  %283 = insertelement <64 x float> undef, float %282, i32 0
  %284 = shufflevector <64 x float> %283, <64 x float> undef, <64 x i32> zeroinitializer
  %285 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %284, <64 x float> %278, <64 x float> %267)
  %286 = add nsw i64 %269, 1024
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !745
  %289 = insertelement <64 x float> undef, float %288, i32 0
  %290 = shufflevector <64 x float> %289, <64 x float> undef, <64 x i32> zeroinitializer
  %291 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %290, <64 x float> %278, <64 x float> %266)
  %292 = add nsw i64 %269, 1536
  %293 = getelementptr inbounds float, float* %4, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !745
  %295 = insertelement <64 x float> undef, float %294, i32 0
  %296 = shufflevector <64 x float> %295, <64 x float> undef, <64 x i32> zeroinitializer
  %297 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %296, <64 x float> %278, <64 x float> %265)
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 512
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  store <64 x float> %279, <64 x float>* %257, align 64, !tbaa !742
  store <64 x float> %285, <64 x float>* %259, align 64, !tbaa !742
  store <64 x float> %291, <64 x float>* %261, align 64, !tbaa !742
  store <64 x float> %297, <64 x float>* %263, align 64, !tbaa !742
  %298 = getelementptr inbounds i8, i8* %40, i64 6144
  %299 = bitcast i8* %298 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %299, align 64, !tbaa !742
  %300 = getelementptr inbounds i8, i8* %40, i64 6400
  %301 = bitcast i8* %300 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %301, align 64, !tbaa !742
  %302 = getelementptr inbounds i8, i8* %40, i64 6656
  %303 = bitcast i8* %302 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %303, align 64, !tbaa !742
  %304 = getelementptr inbounds i8, i8* %40, i64 6912
  %305 = bitcast i8* %304 to <64 x float>*
  store <64 x float> zeroinitializer, <64 x float>* %305, align 64, !tbaa !742
  %306 = add nsw i64 %47, 12288
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %307 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %339, %for_body5.6 ]
  %308 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %333, %for_body5.6 ]
  %309 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %327, %for_body5.6 ]
  %310 = phi <64 x float> [ zeroinitializer, %for_end6.5 ], [ %321, %for_body5.6 ]
  %311 = add nsw i64 %306, %indvars.iv.6
  %312 = getelementptr inbounds float, float* %4, i64 %311
  %313 = load float, float* %312, align 4, !tbaa !745
  %314 = insertelement <64 x float> undef, float %313, i32 0
  %315 = shufflevector <64 x float> %314, <64 x float> undef, <64 x i32> zeroinitializer
  %316 = shl i64 %indvars.iv.6, 6
  %317 = add nuw nsw i64 %316, %46
  %318 = getelementptr inbounds float, float* %7, i64 %317
  %319 = bitcast float* %318 to <64 x float>*
  %320 = load <64 x float>, <64 x float>* %319, align 64, !tbaa !748
  %321 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %315, <64 x float> %320, <64 x float> %310)
  %322 = add nsw i64 %311, 512
  %323 = getelementptr inbounds float, float* %4, i64 %322
  %324 = load float, float* %323, align 4, !tbaa !745
  %325 = insertelement <64 x float> undef, float %324, i32 0
  %326 = shufflevector <64 x float> %325, <64 x float> undef, <64 x i32> zeroinitializer
  %327 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %326, <64 x float> %320, <64 x float> %309)
  %328 = add nsw i64 %311, 1024
  %329 = getelementptr inbounds float, float* %4, i64 %328
  %330 = load float, float* %329, align 4, !tbaa !745
  %331 = insertelement <64 x float> undef, float %330, i32 0
  %332 = shufflevector <64 x float> %331, <64 x float> undef, <64 x i32> zeroinitializer
  %333 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %332, <64 x float> %320, <64 x float> %308)
  %334 = add nsw i64 %311, 1536
  %335 = getelementptr inbounds float, float* %4, i64 %334
  %336 = load float, float* %335, align 4, !tbaa !745
  %337 = insertelement <64 x float> undef, float %336, i32 0
  %338 = shufflevector <64 x float> %337, <64 x float> undef, <64 x i32> zeroinitializer
  %339 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %338, <64 x float> %320, <64 x float> %307)
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 512
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  store <64 x float> %321, <64 x float>* %299, align 64, !tbaa !742
  store <64 x float> %327, <64 x float>* %301, align 64, !tbaa !742
  store <64 x float> %333, <64 x float>* %303, align 64, !tbaa !742
  store <64 x float> %339, <64 x float>* %305, align 64, !tbaa !742
  %340 = mul nsw i64 %indvars.iv33, 1792
  %341 = shl nsw i32 %44, 6
  %342 = sext i32 %341 to i64
  %343 = getelementptr inbounds float, float* %13, i64 %342
  %344 = bitcast float* %343 to <64 x float>*
  %345 = load <64 x float>, <64 x float>* %344, align 64, !tbaa !751
  %346 = getelementptr inbounds float, float* %16, i64 %342
  %347 = bitcast float* %346 to <64 x float>*
  %348 = load <64 x float>, <64 x float>* %347, align 64, !tbaa !754
  %349 = getelementptr inbounds float, float* %19, i64 %342
  %350 = bitcast float* %349 to <64 x float>*
  %351 = load <64 x float>, <64 x float>* %350, align 64, !tbaa !757
  %352 = bitcast i8* %40 to <64 x float>*
  %353 = load <64 x float>, <64 x float>* %352, align 64, !tbaa !742
  %354 = fadd <64 x float> %345, %353
  %355 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %354, <64 x float> %348, <64 x float> %351)
  %356 = fcmp ogt <64 x float> %355, zeroinitializer
  %357 = select <64 x i1> %356, <64 x float> %355, <64 x float> zeroinitializer
  %358 = getelementptr inbounds float, float* %10, i64 %340
  %359 = bitcast float* %358 to <64 x float>*
  store <64 x float> %357, <64 x float>* %359, align 64, !tbaa !760
  %360 = getelementptr inbounds i8, i8* %40, i64 256
  %361 = bitcast i8* %360 to <64 x float>*
  %362 = load <64 x float>, <64 x float>* %361, align 64, !tbaa !742
  %363 = fadd <64 x float> %345, %362
  %364 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %363, <64 x float> %348, <64 x float> %351)
  %365 = fcmp ogt <64 x float> %364, zeroinitializer
  %366 = select <64 x i1> %365, <64 x float> %364, <64 x float> zeroinitializer
  %367 = mul i64 %indvars.iv33, 7696581394432
  %sext = ashr exact i64 %367, 32
  %368 = or i64 %sext, 64
  %369 = getelementptr inbounds float, float* %10, i64 %368
  %370 = bitcast float* %369 to <64 x float>*
  store <64 x float> %366, <64 x float>* %370, align 64, !tbaa !760
  %371 = getelementptr inbounds i8, i8* %40, i64 512
  %372 = bitcast i8* %371 to <64 x float>*
  %373 = load <64 x float>, <64 x float>* %372, align 64, !tbaa !742
  %374 = fadd <64 x float> %345, %373
  %375 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %374, <64 x float> %348, <64 x float> %351)
  %376 = fcmp ogt <64 x float> %375, zeroinitializer
  %377 = select <64 x i1> %376, <64 x float> %375, <64 x float> zeroinitializer
  %378 = mul i64 %indvars.iv33, 7696581394432
  %sext35 = ashr exact i64 %378, 32
  %379 = or i64 %sext35, 128
  %380 = getelementptr inbounds float, float* %10, i64 %379
  %381 = bitcast float* %380 to <64 x float>*
  store <64 x float> %377, <64 x float>* %381, align 64, !tbaa !760
  %382 = getelementptr inbounds i8, i8* %40, i64 768
  %383 = bitcast i8* %382 to <64 x float>*
  %384 = load <64 x float>, <64 x float>* %383, align 64, !tbaa !742
  %385 = fadd <64 x float> %345, %384
  %386 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %385, <64 x float> %348, <64 x float> %351)
  %387 = fcmp ogt <64 x float> %386, zeroinitializer
  %388 = select <64 x i1> %387, <64 x float> %386, <64 x float> zeroinitializer
  %389 = mul i64 %indvars.iv33, 7696581394432
  %sext36 = ashr exact i64 %389, 32
  %390 = or i64 %sext36, 192
  %391 = getelementptr inbounds float, float* %10, i64 %390
  %392 = bitcast float* %391 to <64 x float>*
  store <64 x float> %388, <64 x float>* %392, align 64, !tbaa !760
  %393 = getelementptr inbounds i8, i8* %40, i64 1024
  %394 = bitcast i8* %393 to <64 x float>*
  %395 = load <64 x float>, <64 x float>* %394, align 64, !tbaa !742
  %396 = fadd <64 x float> %345, %395
  %397 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %396, <64 x float> %348, <64 x float> %351)
  %398 = fcmp ogt <64 x float> %397, zeroinitializer
  %399 = select <64 x i1> %398, <64 x float> %397, <64 x float> zeroinitializer
  %400 = mul i64 %indvars.iv33, 7696581394432
  %sext37 = add i64 %400, 1099511627776
  %401 = ashr exact i64 %sext37, 32
  %402 = getelementptr inbounds float, float* %10, i64 %401
  %403 = bitcast float* %402 to <64 x float>*
  store <64 x float> %399, <64 x float>* %403, align 64, !tbaa !760
  %404 = getelementptr inbounds i8, i8* %40, i64 1280
  %405 = bitcast i8* %404 to <64 x float>*
  %406 = load <64 x float>, <64 x float>* %405, align 64, !tbaa !742
  %407 = fadd <64 x float> %345, %406
  %408 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %407, <64 x float> %348, <64 x float> %351)
  %409 = fcmp ogt <64 x float> %408, zeroinitializer
  %410 = select <64 x i1> %409, <64 x float> %408, <64 x float> zeroinitializer
  %411 = mul i64 %indvars.iv33, 7696581394432
  %sext38 = add i64 %411, 1374389534720
  %412 = ashr exact i64 %sext38, 32
  %413 = getelementptr inbounds float, float* %10, i64 %412
  %414 = bitcast float* %413 to <64 x float>*
  store <64 x float> %410, <64 x float>* %414, align 64, !tbaa !760
  %415 = getelementptr inbounds i8, i8* %40, i64 1536
  %416 = bitcast i8* %415 to <64 x float>*
  %417 = load <64 x float>, <64 x float>* %416, align 64, !tbaa !742
  %418 = fadd <64 x float> %345, %417
  %419 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %418, <64 x float> %348, <64 x float> %351)
  %420 = fcmp ogt <64 x float> %419, zeroinitializer
  %421 = select <64 x i1> %420, <64 x float> %419, <64 x float> zeroinitializer
  %422 = mul i64 %indvars.iv33, 7696581394432
  %sext39 = add i64 %422, 1649267441664
  %423 = ashr exact i64 %sext39, 32
  %424 = getelementptr inbounds float, float* %10, i64 %423
  %425 = bitcast float* %424 to <64 x float>*
  store <64 x float> %421, <64 x float>* %425, align 64, !tbaa !760
  %426 = getelementptr inbounds i8, i8* %40, i64 1792
  %427 = bitcast i8* %426 to <64 x float>*
  %428 = load <64 x float>, <64 x float>* %427, align 64, !tbaa !742
  %429 = fadd <64 x float> %345, %428
  %430 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %429, <64 x float> %348, <64 x float> %351)
  %431 = fcmp ogt <64 x float> %430, zeroinitializer
  %432 = select <64 x i1> %431, <64 x float> %430, <64 x float> zeroinitializer
  %433 = mul i64 %indvars.iv33, 7696581394432
  %sext40 = add i64 %433, 1924145348608
  %434 = ashr exact i64 %sext40, 32
  %435 = getelementptr inbounds float, float* %10, i64 %434
  %436 = bitcast float* %435 to <64 x float>*
  store <64 x float> %432, <64 x float>* %436, align 64, !tbaa !760
  %437 = getelementptr inbounds i8, i8* %40, i64 2048
  %438 = bitcast i8* %437 to <64 x float>*
  %439 = load <64 x float>, <64 x float>* %438, align 64, !tbaa !742
  %440 = fadd <64 x float> %345, %439
  %441 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %440, <64 x float> %348, <64 x float> %351)
  %442 = fcmp ogt <64 x float> %441, zeroinitializer
  %443 = select <64 x i1> %442, <64 x float> %441, <64 x float> zeroinitializer
  %444 = mul i64 %indvars.iv33, 7696581394432
  %sext41 = add i64 %444, 2199023255552
  %445 = ashr exact i64 %sext41, 32
  %446 = getelementptr inbounds float, float* %10, i64 %445
  %447 = bitcast float* %446 to <64 x float>*
  store <64 x float> %443, <64 x float>* %447, align 64, !tbaa !760
  %448 = getelementptr inbounds i8, i8* %40, i64 2304
  %449 = bitcast i8* %448 to <64 x float>*
  %450 = load <64 x float>, <64 x float>* %449, align 64, !tbaa !742
  %451 = fadd <64 x float> %345, %450
  %452 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %451, <64 x float> %348, <64 x float> %351)
  %453 = fcmp ogt <64 x float> %452, zeroinitializer
  %454 = select <64 x i1> %453, <64 x float> %452, <64 x float> zeroinitializer
  %455 = mul i64 %indvars.iv33, 7696581394432
  %sext42 = add i64 %455, 2473901162496
  %456 = ashr exact i64 %sext42, 32
  %457 = getelementptr inbounds float, float* %10, i64 %456
  %458 = bitcast float* %457 to <64 x float>*
  store <64 x float> %454, <64 x float>* %458, align 64, !tbaa !760
  %459 = getelementptr inbounds i8, i8* %40, i64 2560
  %460 = bitcast i8* %459 to <64 x float>*
  %461 = load <64 x float>, <64 x float>* %460, align 64, !tbaa !742
  %462 = fadd <64 x float> %345, %461
  %463 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %462, <64 x float> %348, <64 x float> %351)
  %464 = fcmp ogt <64 x float> %463, zeroinitializer
  %465 = select <64 x i1> %464, <64 x float> %463, <64 x float> zeroinitializer
  %466 = mul i64 %indvars.iv33, 7696581394432
  %sext43 = add i64 %466, 2748779069440
  %467 = ashr exact i64 %sext43, 32
  %468 = getelementptr inbounds float, float* %10, i64 %467
  %469 = bitcast float* %468 to <64 x float>*
  store <64 x float> %465, <64 x float>* %469, align 64, !tbaa !760
  %470 = getelementptr inbounds i8, i8* %40, i64 2816
  %471 = bitcast i8* %470 to <64 x float>*
  %472 = load <64 x float>, <64 x float>* %471, align 64, !tbaa !742
  %473 = fadd <64 x float> %345, %472
  %474 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %473, <64 x float> %348, <64 x float> %351)
  %475 = fcmp ogt <64 x float> %474, zeroinitializer
  %476 = select <64 x i1> %475, <64 x float> %474, <64 x float> zeroinitializer
  %477 = mul i64 %indvars.iv33, 7696581394432
  %sext44 = add i64 %477, 3023656976384
  %478 = ashr exact i64 %sext44, 32
  %479 = getelementptr inbounds float, float* %10, i64 %478
  %480 = bitcast float* %479 to <64 x float>*
  store <64 x float> %476, <64 x float>* %480, align 64, !tbaa !760
  %481 = getelementptr inbounds i8, i8* %40, i64 3072
  %482 = bitcast i8* %481 to <64 x float>*
  %483 = load <64 x float>, <64 x float>* %482, align 64, !tbaa !742
  %484 = fadd <64 x float> %345, %483
  %485 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %484, <64 x float> %348, <64 x float> %351)
  %486 = fcmp ogt <64 x float> %485, zeroinitializer
  %487 = select <64 x i1> %486, <64 x float> %485, <64 x float> zeroinitializer
  %488 = mul i64 %indvars.iv33, 7696581394432
  %sext45 = add i64 %488, 3298534883328
  %489 = ashr exact i64 %sext45, 32
  %490 = getelementptr inbounds float, float* %10, i64 %489
  %491 = bitcast float* %490 to <64 x float>*
  store <64 x float> %487, <64 x float>* %491, align 64, !tbaa !760
  %492 = getelementptr inbounds i8, i8* %40, i64 3328
  %493 = bitcast i8* %492 to <64 x float>*
  %494 = load <64 x float>, <64 x float>* %493, align 64, !tbaa !742
  %495 = fadd <64 x float> %345, %494
  %496 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %495, <64 x float> %348, <64 x float> %351)
  %497 = fcmp ogt <64 x float> %496, zeroinitializer
  %498 = select <64 x i1> %497, <64 x float> %496, <64 x float> zeroinitializer
  %499 = mul i64 %indvars.iv33, 7696581394432
  %sext46 = add i64 %499, 3573412790272
  %500 = ashr exact i64 %sext46, 32
  %501 = getelementptr inbounds float, float* %10, i64 %500
  %502 = bitcast float* %501 to <64 x float>*
  store <64 x float> %498, <64 x float>* %502, align 64, !tbaa !760
  %503 = getelementptr inbounds i8, i8* %40, i64 3584
  %504 = bitcast i8* %503 to <64 x float>*
  %505 = load <64 x float>, <64 x float>* %504, align 64, !tbaa !742
  %506 = fadd <64 x float> %345, %505
  %507 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %506, <64 x float> %348, <64 x float> %351)
  %508 = fcmp ogt <64 x float> %507, zeroinitializer
  %509 = select <64 x i1> %508, <64 x float> %507, <64 x float> zeroinitializer
  %510 = mul i64 %indvars.iv33, 7696581394432
  %sext47 = add i64 %510, 3848290697216
  %511 = ashr exact i64 %sext47, 32
  %512 = getelementptr inbounds float, float* %10, i64 %511
  %513 = bitcast float* %512 to <64 x float>*
  store <64 x float> %509, <64 x float>* %513, align 64, !tbaa !760
  %514 = getelementptr inbounds i8, i8* %40, i64 3840
  %515 = bitcast i8* %514 to <64 x float>*
  %516 = load <64 x float>, <64 x float>* %515, align 64, !tbaa !742
  %517 = fadd <64 x float> %345, %516
  %518 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %517, <64 x float> %348, <64 x float> %351)
  %519 = fcmp ogt <64 x float> %518, zeroinitializer
  %520 = select <64 x i1> %519, <64 x float> %518, <64 x float> zeroinitializer
  %521 = mul i64 %indvars.iv33, 7696581394432
  %sext48 = add i64 %521, 4123168604160
  %522 = ashr exact i64 %sext48, 32
  %523 = getelementptr inbounds float, float* %10, i64 %522
  %524 = bitcast float* %523 to <64 x float>*
  store <64 x float> %520, <64 x float>* %524, align 64, !tbaa !760
  %525 = getelementptr inbounds i8, i8* %40, i64 4096
  %526 = bitcast i8* %525 to <64 x float>*
  %527 = load <64 x float>, <64 x float>* %526, align 64, !tbaa !742
  %528 = fadd <64 x float> %345, %527
  %529 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %528, <64 x float> %348, <64 x float> %351)
  %530 = fcmp ogt <64 x float> %529, zeroinitializer
  %531 = select <64 x i1> %530, <64 x float> %529, <64 x float> zeroinitializer
  %532 = mul i64 %indvars.iv33, 7696581394432
  %sext49 = add i64 %532, 4398046511104
  %533 = ashr exact i64 %sext49, 32
  %534 = getelementptr inbounds float, float* %10, i64 %533
  %535 = bitcast float* %534 to <64 x float>*
  store <64 x float> %531, <64 x float>* %535, align 64, !tbaa !760
  %536 = getelementptr inbounds i8, i8* %40, i64 4352
  %537 = bitcast i8* %536 to <64 x float>*
  %538 = load <64 x float>, <64 x float>* %537, align 64, !tbaa !742
  %539 = fadd <64 x float> %345, %538
  %540 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %539, <64 x float> %348, <64 x float> %351)
  %541 = fcmp ogt <64 x float> %540, zeroinitializer
  %542 = select <64 x i1> %541, <64 x float> %540, <64 x float> zeroinitializer
  %543 = mul i64 %indvars.iv33, 7696581394432
  %sext50 = add i64 %543, 4672924418048
  %544 = ashr exact i64 %sext50, 32
  %545 = getelementptr inbounds float, float* %10, i64 %544
  %546 = bitcast float* %545 to <64 x float>*
  store <64 x float> %542, <64 x float>* %546, align 64, !tbaa !760
  %547 = getelementptr inbounds i8, i8* %40, i64 4608
  %548 = bitcast i8* %547 to <64 x float>*
  %549 = load <64 x float>, <64 x float>* %548, align 64, !tbaa !742
  %550 = fadd <64 x float> %345, %549
  %551 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %550, <64 x float> %348, <64 x float> %351)
  %552 = fcmp ogt <64 x float> %551, zeroinitializer
  %553 = select <64 x i1> %552, <64 x float> %551, <64 x float> zeroinitializer
  %554 = mul i64 %indvars.iv33, 7696581394432
  %sext51 = add i64 %554, 4947802324992
  %555 = ashr exact i64 %sext51, 32
  %556 = getelementptr inbounds float, float* %10, i64 %555
  %557 = bitcast float* %556 to <64 x float>*
  store <64 x float> %553, <64 x float>* %557, align 64, !tbaa !760
  %558 = getelementptr inbounds i8, i8* %40, i64 4864
  %559 = bitcast i8* %558 to <64 x float>*
  %560 = load <64 x float>, <64 x float>* %559, align 64, !tbaa !742
  %561 = fadd <64 x float> %345, %560
  %562 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %561, <64 x float> %348, <64 x float> %351)
  %563 = fcmp ogt <64 x float> %562, zeroinitializer
  %564 = select <64 x i1> %563, <64 x float> %562, <64 x float> zeroinitializer
  %565 = mul i64 %indvars.iv33, 7696581394432
  %sext52 = add i64 %565, 5222680231936
  %566 = ashr exact i64 %sext52, 32
  %567 = getelementptr inbounds float, float* %10, i64 %566
  %568 = bitcast float* %567 to <64 x float>*
  store <64 x float> %564, <64 x float>* %568, align 64, !tbaa !760
  %569 = getelementptr inbounds i8, i8* %40, i64 5120
  %570 = bitcast i8* %569 to <64 x float>*
  %571 = load <64 x float>, <64 x float>* %570, align 64, !tbaa !742
  %572 = fadd <64 x float> %345, %571
  %573 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %572, <64 x float> %348, <64 x float> %351)
  %574 = fcmp ogt <64 x float> %573, zeroinitializer
  %575 = select <64 x i1> %574, <64 x float> %573, <64 x float> zeroinitializer
  %576 = mul i64 %indvars.iv33, 7696581394432
  %sext53 = add i64 %576, 5497558138880
  %577 = ashr exact i64 %sext53, 32
  %578 = getelementptr inbounds float, float* %10, i64 %577
  %579 = bitcast float* %578 to <64 x float>*
  store <64 x float> %575, <64 x float>* %579, align 64, !tbaa !760
  %580 = getelementptr inbounds i8, i8* %40, i64 5376
  %581 = bitcast i8* %580 to <64 x float>*
  %582 = load <64 x float>, <64 x float>* %581, align 64, !tbaa !742
  %583 = fadd <64 x float> %345, %582
  %584 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %583, <64 x float> %348, <64 x float> %351)
  %585 = fcmp ogt <64 x float> %584, zeroinitializer
  %586 = select <64 x i1> %585, <64 x float> %584, <64 x float> zeroinitializer
  %587 = mul i64 %indvars.iv33, 7696581394432
  %sext54 = add i64 %587, 5772436045824
  %588 = ashr exact i64 %sext54, 32
  %589 = getelementptr inbounds float, float* %10, i64 %588
  %590 = bitcast float* %589 to <64 x float>*
  store <64 x float> %586, <64 x float>* %590, align 64, !tbaa !760
  %591 = getelementptr inbounds i8, i8* %40, i64 5632
  %592 = bitcast i8* %591 to <64 x float>*
  %593 = load <64 x float>, <64 x float>* %592, align 64, !tbaa !742
  %594 = fadd <64 x float> %345, %593
  %595 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %594, <64 x float> %348, <64 x float> %351)
  %596 = fcmp ogt <64 x float> %595, zeroinitializer
  %597 = select <64 x i1> %596, <64 x float> %595, <64 x float> zeroinitializer
  %598 = mul i64 %indvars.iv33, 7696581394432
  %sext55 = add i64 %598, 6047313952768
  %599 = ashr exact i64 %sext55, 32
  %600 = getelementptr inbounds float, float* %10, i64 %599
  %601 = bitcast float* %600 to <64 x float>*
  store <64 x float> %597, <64 x float>* %601, align 64, !tbaa !760
  %602 = getelementptr inbounds i8, i8* %40, i64 5888
  %603 = bitcast i8* %602 to <64 x float>*
  %604 = load <64 x float>, <64 x float>* %603, align 64, !tbaa !742
  %605 = fadd <64 x float> %345, %604
  %606 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %605, <64 x float> %348, <64 x float> %351)
  %607 = fcmp ogt <64 x float> %606, zeroinitializer
  %608 = select <64 x i1> %607, <64 x float> %606, <64 x float> zeroinitializer
  %609 = mul i64 %indvars.iv33, 7696581394432
  %sext56 = add i64 %609, 6322191859712
  %610 = ashr exact i64 %sext56, 32
  %611 = getelementptr inbounds float, float* %10, i64 %610
  %612 = bitcast float* %611 to <64 x float>*
  store <64 x float> %608, <64 x float>* %612, align 64, !tbaa !760
  %613 = getelementptr inbounds i8, i8* %40, i64 6144
  %614 = bitcast i8* %613 to <64 x float>*
  %615 = load <64 x float>, <64 x float>* %614, align 64, !tbaa !742
  %616 = fadd <64 x float> %345, %615
  %617 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %616, <64 x float> %348, <64 x float> %351)
  %618 = fcmp ogt <64 x float> %617, zeroinitializer
  %619 = select <64 x i1> %618, <64 x float> %617, <64 x float> zeroinitializer
  %620 = mul i64 %indvars.iv33, 7696581394432
  %sext57 = add i64 %620, 6597069766656
  %621 = ashr exact i64 %sext57, 32
  %622 = getelementptr inbounds float, float* %10, i64 %621
  %623 = bitcast float* %622 to <64 x float>*
  store <64 x float> %619, <64 x float>* %623, align 64, !tbaa !760
  %624 = getelementptr inbounds i8, i8* %40, i64 6400
  %625 = bitcast i8* %624 to <64 x float>*
  %626 = load <64 x float>, <64 x float>* %625, align 64, !tbaa !742
  %627 = fadd <64 x float> %345, %626
  %628 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %627, <64 x float> %348, <64 x float> %351)
  %629 = fcmp ogt <64 x float> %628, zeroinitializer
  %630 = select <64 x i1> %629, <64 x float> %628, <64 x float> zeroinitializer
  %631 = mul i64 %indvars.iv33, 7696581394432
  %sext58 = add i64 %631, 6871947673600
  %632 = ashr exact i64 %sext58, 32
  %633 = getelementptr inbounds float, float* %10, i64 %632
  %634 = bitcast float* %633 to <64 x float>*
  store <64 x float> %630, <64 x float>* %634, align 64, !tbaa !760
  %635 = getelementptr inbounds i8, i8* %40, i64 6656
  %636 = bitcast i8* %635 to <64 x float>*
  %637 = load <64 x float>, <64 x float>* %636, align 64, !tbaa !742
  %638 = fadd <64 x float> %345, %637
  %639 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %638, <64 x float> %348, <64 x float> %351)
  %640 = fcmp ogt <64 x float> %639, zeroinitializer
  %641 = select <64 x i1> %640, <64 x float> %639, <64 x float> zeroinitializer
  %642 = mul i64 %indvars.iv33, 7696581394432
  %sext59 = add i64 %642, 7146825580544
  %643 = ashr exact i64 %sext59, 32
  %644 = getelementptr inbounds float, float* %10, i64 %643
  %645 = bitcast float* %644 to <64 x float>*
  store <64 x float> %641, <64 x float>* %645, align 64, !tbaa !760
  %646 = getelementptr inbounds i8, i8* %40, i64 6912
  %647 = bitcast i8* %646 to <64 x float>*
  %648 = load <64 x float>, <64 x float>* %647, align 64, !tbaa !742
  %649 = fadd <64 x float> %345, %648
  %650 = tail call <64 x float> @llvm.fmuladd.v64f32(<64 x float> %649, <64 x float> %348, <64 x float> %351)
  %651 = fcmp ogt <64 x float> %650, zeroinitializer
  %652 = select <64 x i1> %651, <64 x float> %650, <64 x float> zeroinitializer
  %653 = mul i64 %indvars.iv33, 7696581394432
  %sext60 = add i64 %653, 7421703487488
  %654 = ashr exact i64 %sext60, 32
  %655 = getelementptr inbounds float, float* %10, i64 %654
  %656 = bitcast float* %655 to <64 x float>*
  store <64 x float> %652, <64 x float>* %656, align 64, !tbaa !760
  %657 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %658 = tail call i32 %657(i32 1, i32 %22, i8* nonnull %40)
  %indvars.iv.next34 = add nsw i64 %indvars.iv33, 1
  %659 = icmp slt i64 %indvars.iv.next34, %38
  br i1 %659, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_49(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !763 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !765, metadata !DIExpression()), !dbg !768
  call void @llvm.dbg.value(metadata i8* %1, metadata !766, metadata !DIExpression()), !dbg !768
  call void @llvm.dbg.value(metadata i32 %2, metadata !767, metadata !DIExpression()), !dbg !768
  %3 = bitcast i8* %0 to %1**, !dbg !768
  %4 = load %1*, %1** %3, align 8, !dbg !768
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !768
  %6 = bitcast i8* %5 to %1**, !dbg !768
  %7 = load %1*, %1** %6, align 8, !dbg !768
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !768
  %9 = load i8*, i8** %8, align 8, !dbg !768
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !768
  %11 = load i8*, i8** %10, align 8, !dbg !768
  %12 = tail call fastcc i32 @fused_layout_transform_49_compute_(i8* %11, i8* %9), !dbg !768
  ret i32 %12, !dbg !768
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_49_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %45, align 8
  %3 = getelementptr inbounds %45, %45* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %45, %45* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %45* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.41, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.41(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 13
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 14
  %15 = select i1 %14, i32 %13, i32 14
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 14
  %18 = select i1 %17, i32 %16, i32 14
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.13
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end6.13 ]
  %24 = mul nsw i64 %indvars.iv10, 14336
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_body5

for_end:                                          ; preds = %for_end6.13, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %27 = add nsw i64 %24, %indvars.iv
  %28 = trunc i64 %indvars.iv to i32
  %29 = and i32 %28, 63
  %30 = lshr i32 %28, 6
  %31 = mul nsw i32 %30, 12544
  %32 = add i32 %26, %31
  %33 = or i32 %32, %29
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds float, float* %7, i64 %34
  %36 = bitcast float* %35 to i32*
  %37 = load i32, i32* %36, align 4, !tbaa !769
  %38 = getelementptr inbounds float, float* %4, i64 %27
  %39 = bitcast float* %38 to i32*
  store i32 %37, i32* %39, align 4, !tbaa !772
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %40 = or i64 %24, 1024
  %41 = or i32 %26, 64
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %42 = add nsw i64 %40, %indvars.iv.1
  %43 = trunc i64 %indvars.iv.1 to i32
  %44 = and i32 %43, 63
  %45 = lshr i32 %43, 6
  %46 = mul nsw i32 %45, 12544
  %47 = add i32 %41, %46
  %48 = or i32 %47, %44
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %7, i64 %49
  %51 = bitcast float* %50 to i32*
  %52 = load i32, i32* %51, align 4, !tbaa !769
  %53 = getelementptr inbounds float, float* %4, i64 %42
  %54 = bitcast float* %53 to i32*
  store i32 %52, i32* %54, align 4, !tbaa !772
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 1024
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %55 = add nsw i64 %24, 2048
  %56 = add i32 %26, 128
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %57 = add nsw i64 %55, %indvars.iv.2
  %58 = trunc i64 %indvars.iv.2 to i32
  %59 = and i32 %58, 63
  %60 = lshr i32 %58, 6
  %61 = mul nsw i32 %60, 12544
  %62 = add i32 %56, %61
  %63 = or i32 %62, %59
  %64 = sext i32 %63 to i64
  %65 = getelementptr inbounds float, float* %7, i64 %64
  %66 = bitcast float* %65 to i32*
  %67 = load i32, i32* %66, align 4, !tbaa !769
  %68 = getelementptr inbounds float, float* %4, i64 %57
  %69 = bitcast float* %68 to i32*
  store i32 %67, i32* %69, align 4, !tbaa !772
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 1024
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  %70 = add nsw i64 %24, 3072
  %71 = add i32 %26, 192
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %72 = add nsw i64 %70, %indvars.iv.3
  %73 = trunc i64 %indvars.iv.3 to i32
  %74 = and i32 %73, 63
  %75 = lshr i32 %73, 6
  %76 = mul nsw i32 %75, 12544
  %77 = add i32 %71, %76
  %78 = or i32 %77, %74
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds float, float* %7, i64 %79
  %81 = bitcast float* %80 to i32*
  %82 = load i32, i32* %81, align 4, !tbaa !769
  %83 = getelementptr inbounds float, float* %4, i64 %72
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4, !tbaa !772
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 1024
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  %85 = add nsw i64 %24, 4096
  %86 = add i32 %26, 256
  br label %for_body5.4

for_body5.4:                                      ; preds = %for_body5.4, %for_end6.3
  %indvars.iv.4 = phi i64 [ 0, %for_end6.3 ], [ %indvars.iv.next.4, %for_body5.4 ]
  %87 = add nsw i64 %85, %indvars.iv.4
  %88 = trunc i64 %indvars.iv.4 to i32
  %89 = and i32 %88, 63
  %90 = lshr i32 %88, 6
  %91 = mul nsw i32 %90, 12544
  %92 = add i32 %86, %91
  %93 = or i32 %92, %89
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !769
  %98 = getelementptr inbounds float, float* %4, i64 %87
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !772
  %indvars.iv.next.4 = add nuw nsw i64 %indvars.iv.4, 1
  %exitcond.4 = icmp eq i64 %indvars.iv.next.4, 1024
  br i1 %exitcond.4, label %for_end6.4, label %for_body5.4, !prof !29

for_end6.4:                                       ; preds = %for_body5.4
  %100 = add nsw i64 %24, 5120
  %101 = add i32 %26, 320
  br label %for_body5.5

for_body5.5:                                      ; preds = %for_body5.5, %for_end6.4
  %indvars.iv.5 = phi i64 [ 0, %for_end6.4 ], [ %indvars.iv.next.5, %for_body5.5 ]
  %102 = add nsw i64 %100, %indvars.iv.5
  %103 = trunc i64 %indvars.iv.5 to i32
  %104 = and i32 %103, 63
  %105 = lshr i32 %103, 6
  %106 = mul nsw i32 %105, 12544
  %107 = add i32 %101, %106
  %108 = or i32 %107, %104
  %109 = sext i32 %108 to i64
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to i32*
  %112 = load i32, i32* %111, align 4, !tbaa !769
  %113 = getelementptr inbounds float, float* %4, i64 %102
  %114 = bitcast float* %113 to i32*
  store i32 %112, i32* %114, align 4, !tbaa !772
  %indvars.iv.next.5 = add nuw nsw i64 %indvars.iv.5, 1
  %exitcond.5 = icmp eq i64 %indvars.iv.next.5, 1024
  br i1 %exitcond.5, label %for_end6.5, label %for_body5.5, !prof !29

for_end6.5:                                       ; preds = %for_body5.5
  %115 = add nsw i64 %24, 6144
  %116 = add i32 %26, 384
  br label %for_body5.6

for_body5.6:                                      ; preds = %for_body5.6, %for_end6.5
  %indvars.iv.6 = phi i64 [ 0, %for_end6.5 ], [ %indvars.iv.next.6, %for_body5.6 ]
  %117 = add nsw i64 %115, %indvars.iv.6
  %118 = trunc i64 %indvars.iv.6 to i32
  %119 = and i32 %118, 63
  %120 = lshr i32 %118, 6
  %121 = mul nsw i32 %120, 12544
  %122 = add i32 %116, %121
  %123 = or i32 %122, %119
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds float, float* %7, i64 %124
  %126 = bitcast float* %125 to i32*
  %127 = load i32, i32* %126, align 4, !tbaa !769
  %128 = getelementptr inbounds float, float* %4, i64 %117
  %129 = bitcast float* %128 to i32*
  store i32 %127, i32* %129, align 4, !tbaa !772
  %indvars.iv.next.6 = add nuw nsw i64 %indvars.iv.6, 1
  %exitcond.6 = icmp eq i64 %indvars.iv.next.6, 1024
  br i1 %exitcond.6, label %for_end6.6, label %for_body5.6, !prof !29

for_end6.6:                                       ; preds = %for_body5.6
  %130 = add nsw i64 %24, 7168
  %131 = add i32 %26, 448
  br label %for_body5.7

for_body5.7:                                      ; preds = %for_body5.7, %for_end6.6
  %indvars.iv.7 = phi i64 [ 0, %for_end6.6 ], [ %indvars.iv.next.7, %for_body5.7 ]
  %132 = add nsw i64 %130, %indvars.iv.7
  %133 = trunc i64 %indvars.iv.7 to i32
  %134 = and i32 %133, 63
  %135 = lshr i32 %133, 6
  %136 = mul nsw i32 %135, 12544
  %137 = add i32 %131, %136
  %138 = or i32 %137, %134
  %139 = sext i32 %138 to i64
  %140 = getelementptr inbounds float, float* %7, i64 %139
  %141 = bitcast float* %140 to i32*
  %142 = load i32, i32* %141, align 4, !tbaa !769
  %143 = getelementptr inbounds float, float* %4, i64 %132
  %144 = bitcast float* %143 to i32*
  store i32 %142, i32* %144, align 4, !tbaa !772
  %indvars.iv.next.7 = add nuw nsw i64 %indvars.iv.7, 1
  %exitcond.7 = icmp eq i64 %indvars.iv.next.7, 1024
  br i1 %exitcond.7, label %for_end6.7, label %for_body5.7, !prof !29

for_end6.7:                                       ; preds = %for_body5.7
  %145 = add nsw i64 %24, 8192
  %146 = add i32 %26, 512
  br label %for_body5.8

for_body5.8:                                      ; preds = %for_body5.8, %for_end6.7
  %indvars.iv.8 = phi i64 [ 0, %for_end6.7 ], [ %indvars.iv.next.8, %for_body5.8 ]
  %147 = add nsw i64 %145, %indvars.iv.8
  %148 = trunc i64 %indvars.iv.8 to i32
  %149 = and i32 %148, 63
  %150 = lshr i32 %148, 6
  %151 = mul nsw i32 %150, 12544
  %152 = add i32 %146, %151
  %153 = or i32 %152, %149
  %154 = sext i32 %153 to i64
  %155 = getelementptr inbounds float, float* %7, i64 %154
  %156 = bitcast float* %155 to i32*
  %157 = load i32, i32* %156, align 4, !tbaa !769
  %158 = getelementptr inbounds float, float* %4, i64 %147
  %159 = bitcast float* %158 to i32*
  store i32 %157, i32* %159, align 4, !tbaa !772
  %indvars.iv.next.8 = add nuw nsw i64 %indvars.iv.8, 1
  %exitcond.8 = icmp eq i64 %indvars.iv.next.8, 1024
  br i1 %exitcond.8, label %for_end6.8, label %for_body5.8, !prof !29

for_end6.8:                                       ; preds = %for_body5.8
  %160 = add nsw i64 %24, 9216
  %161 = add i32 %26, 576
  br label %for_body5.9

for_body5.9:                                      ; preds = %for_body5.9, %for_end6.8
  %indvars.iv.9 = phi i64 [ 0, %for_end6.8 ], [ %indvars.iv.next.9, %for_body5.9 ]
  %162 = add nsw i64 %160, %indvars.iv.9
  %163 = trunc i64 %indvars.iv.9 to i32
  %164 = and i32 %163, 63
  %165 = lshr i32 %163, 6
  %166 = mul nsw i32 %165, 12544
  %167 = add i32 %161, %166
  %168 = or i32 %167, %164
  %169 = sext i32 %168 to i64
  %170 = getelementptr inbounds float, float* %7, i64 %169
  %171 = bitcast float* %170 to i32*
  %172 = load i32, i32* %171, align 4, !tbaa !769
  %173 = getelementptr inbounds float, float* %4, i64 %162
  %174 = bitcast float* %173 to i32*
  store i32 %172, i32* %174, align 4, !tbaa !772
  %indvars.iv.next.9 = add nuw nsw i64 %indvars.iv.9, 1
  %exitcond.9 = icmp eq i64 %indvars.iv.next.9, 1024
  br i1 %exitcond.9, label %for_end6.9, label %for_body5.9, !prof !29

for_end6.9:                                       ; preds = %for_body5.9
  %175 = add nsw i64 %24, 10240
  %176 = add i32 %26, 640
  br label %for_body5.10

for_body5.10:                                     ; preds = %for_body5.10, %for_end6.9
  %indvars.iv.10 = phi i64 [ 0, %for_end6.9 ], [ %indvars.iv.next.10, %for_body5.10 ]
  %177 = add nsw i64 %175, %indvars.iv.10
  %178 = trunc i64 %indvars.iv.10 to i32
  %179 = and i32 %178, 63
  %180 = lshr i32 %178, 6
  %181 = mul nsw i32 %180, 12544
  %182 = add i32 %176, %181
  %183 = or i32 %182, %179
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds float, float* %7, i64 %184
  %186 = bitcast float* %185 to i32*
  %187 = load i32, i32* %186, align 4, !tbaa !769
  %188 = getelementptr inbounds float, float* %4, i64 %177
  %189 = bitcast float* %188 to i32*
  store i32 %187, i32* %189, align 4, !tbaa !772
  %indvars.iv.next.10 = add nuw nsw i64 %indvars.iv.10, 1
  %exitcond.10 = icmp eq i64 %indvars.iv.next.10, 1024
  br i1 %exitcond.10, label %for_end6.10, label %for_body5.10, !prof !29

for_end6.10:                                      ; preds = %for_body5.10
  %190 = add nsw i64 %24, 11264
  %191 = add i32 %26, 704
  br label %for_body5.11

for_body5.11:                                     ; preds = %for_body5.11, %for_end6.10
  %indvars.iv.11 = phi i64 [ 0, %for_end6.10 ], [ %indvars.iv.next.11, %for_body5.11 ]
  %192 = add nsw i64 %190, %indvars.iv.11
  %193 = trunc i64 %indvars.iv.11 to i32
  %194 = and i32 %193, 63
  %195 = lshr i32 %193, 6
  %196 = mul nsw i32 %195, 12544
  %197 = add i32 %191, %196
  %198 = or i32 %197, %194
  %199 = sext i32 %198 to i64
  %200 = getelementptr inbounds float, float* %7, i64 %199
  %201 = bitcast float* %200 to i32*
  %202 = load i32, i32* %201, align 4, !tbaa !769
  %203 = getelementptr inbounds float, float* %4, i64 %192
  %204 = bitcast float* %203 to i32*
  store i32 %202, i32* %204, align 4, !tbaa !772
  %indvars.iv.next.11 = add nuw nsw i64 %indvars.iv.11, 1
  %exitcond.11 = icmp eq i64 %indvars.iv.next.11, 1024
  br i1 %exitcond.11, label %for_end6.11, label %for_body5.11, !prof !29

for_end6.11:                                      ; preds = %for_body5.11
  %205 = add nsw i64 %24, 12288
  %206 = add i32 %26, 768
  br label %for_body5.12

for_body5.12:                                     ; preds = %for_body5.12, %for_end6.11
  %indvars.iv.12 = phi i64 [ 0, %for_end6.11 ], [ %indvars.iv.next.12, %for_body5.12 ]
  %207 = add nsw i64 %205, %indvars.iv.12
  %208 = trunc i64 %indvars.iv.12 to i32
  %209 = and i32 %208, 63
  %210 = lshr i32 %208, 6
  %211 = mul nsw i32 %210, 12544
  %212 = add i32 %206, %211
  %213 = or i32 %212, %209
  %214 = sext i32 %213 to i64
  %215 = getelementptr inbounds float, float* %7, i64 %214
  %216 = bitcast float* %215 to i32*
  %217 = load i32, i32* %216, align 4, !tbaa !769
  %218 = getelementptr inbounds float, float* %4, i64 %207
  %219 = bitcast float* %218 to i32*
  store i32 %217, i32* %219, align 4, !tbaa !772
  %indvars.iv.next.12 = add nuw nsw i64 %indvars.iv.12, 1
  %exitcond.12 = icmp eq i64 %indvars.iv.next.12, 1024
  br i1 %exitcond.12, label %for_end6.12, label %for_body5.12, !prof !29

for_end6.12:                                      ; preds = %for_body5.12
  %220 = add nsw i64 %24, 13312
  %221 = add i32 %26, 832
  br label %for_body5.13

for_body5.13:                                     ; preds = %for_body5.13, %for_end6.12
  %indvars.iv.13 = phi i64 [ 0, %for_end6.12 ], [ %indvars.iv.next.13, %for_body5.13 ]
  %222 = add nsw i64 %220, %indvars.iv.13
  %223 = trunc i64 %indvars.iv.13 to i32
  %224 = and i32 %223, 63
  %225 = lshr i32 %223, 6
  %226 = mul nsw i32 %225, 12544
  %227 = add i32 %221, %226
  %228 = or i32 %227, %224
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds float, float* %7, i64 %229
  %231 = bitcast float* %230 to i32*
  %232 = load i32, i32* %231, align 4, !tbaa !769
  %233 = getelementptr inbounds float, float* %4, i64 %222
  %234 = bitcast float* %233 to i32*
  store i32 %232, i32* %234, align 4, !tbaa !772
  %indvars.iv.next.13 = add nuw nsw i64 %indvars.iv.13, 1
  %exitcond.13 = icmp eq i64 %indvars.iv.next.13, 1024
  br i1 %exitcond.13, label %for_end6.13, label %for_body5.13, !prof !29

for_end6.13:                                      ; preds = %for_body5.13
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %235 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %235, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_layout_transform_45(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !775 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !777, metadata !DIExpression()), !dbg !780
  call void @llvm.dbg.value(metadata i8* %1, metadata !778, metadata !DIExpression()), !dbg !780
  call void @llvm.dbg.value(metadata i32 %2, metadata !779, metadata !DIExpression()), !dbg !780
  %3 = bitcast i8* %0 to %1**, !dbg !780
  %4 = load %1*, %1** %3, align 8, !dbg !780
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !780
  %6 = bitcast i8* %5 to %1**, !dbg !780
  %7 = load %1*, %1** %6, align 8, !dbg !780
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !780
  %9 = load i8*, i8** %8, align 8, !dbg !780
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !780
  %11 = load i8*, i8** %10, align 8, !dbg !780
  %12 = tail call fastcc i32 @fused_layout_transform_45_compute_(i8* %11, i8* %9), !dbg !780
  ret i32 %12, !dbg !780
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_45_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %46, align 8
  %3 = getelementptr inbounds %46, %46* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %46, %46* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %46* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.42, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.42(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 55
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 56
  %15 = select i1 %14, i32 %13, i32 56
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 56
  %18 = select i1 %17, i32 %16, i32 56
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 6
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 4
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 15
  %35 = lshr i32 %33, 4
  %36 = mul nsw i32 %35, 50176
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !781
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !784
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 56
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_layout_transform_41(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !787 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !789, metadata !DIExpression()), !dbg !792
  call void @llvm.dbg.value(metadata i8* %1, metadata !790, metadata !DIExpression()), !dbg !792
  call void @llvm.dbg.value(metadata i32 %2, metadata !791, metadata !DIExpression()), !dbg !792
  %3 = bitcast i8* %0 to %1**, !dbg !792
  %4 = load %1*, %1** %3, align 8, !dbg !792
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !792
  %6 = bitcast i8* %5 to %1**, !dbg !792
  %7 = load %1*, %1** %6, align 8, !dbg !792
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !792
  %9 = load i8*, i8** %8, align 8, !dbg !792
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !792
  %11 = load i8*, i8** %10, align 8, !dbg !792
  %12 = tail call fastcc i32 @fused_layout_transform_41_compute_(i8* %11, i8* %9), !dbg !792
  ret i32 %12, !dbg !792
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_41_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %47, align 8
  %3 = getelementptr inbounds %47, %47* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %47, %47* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %47* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.43, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.43(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 27
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 28
  %15 = select i1 %14, i32 %13, i32 28
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 28
  %18 = select i1 %17, i32 %16, i32 28
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv10 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next11, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv10, 3584
  %25 = trunc i64 %indvars.iv10 to i32
  %26 = mul i32 %25, 896
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end6, %for_body
  %indvars.iv7 = phi i64 [ 0, %for_body ], [ %indvars.iv.next8, %for_end6 ]
  %27 = shl i64 %indvars.iv7, 7
  %28 = add nsw i64 %27, %24
  %indvars.iv7.tr = trunc i64 %indvars.iv7 to i32
  %29 = shl i32 %indvars.iv7.tr, 5
  %30 = add i32 %29, %26
  br label %for_body5

for_end3:                                         ; preds = %for_end6
  %indvars.iv.next11 = add nsw i64 %indvars.iv10, 1
  %31 = icmp slt i64 %indvars.iv.next11, %23
  br i1 %31, label %for_body, label %for_end, !prof !19

for_body5:                                        ; preds = %for_body5, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body5 ]
  %32 = add nsw i64 %28, %indvars.iv
  %33 = trunc i64 %indvars.iv to i32
  %34 = and i32 %33, 31
  %35 = lshr i32 %33, 5
  %36 = mul nsw i32 %35, 25088
  %37 = add i32 %30, %36
  %38 = or i32 %37, %34
  %39 = sext i32 %38 to i64
  %40 = getelementptr inbounds float, float* %7, i64 %39
  %41 = bitcast float* %40 to i32*
  %42 = load i32, i32* %41, align 4, !tbaa !793
  %43 = getelementptr inbounds float, float* %4, i64 %32
  %44 = bitcast float* %43 to i32*
  store i32 %42, i32* %44, align 4, !tbaa !796
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 128
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %indvars.iv.next8 = add nuw nsw i64 %indvars.iv7, 1
  %exitcond9 = icmp eq i64 %indvars.iv.next8, 28
  br i1 %exitcond9, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !799 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !801, metadata !DIExpression()), !dbg !804
  call void @llvm.dbg.value(metadata i8* %1, metadata !802, metadata !DIExpression()), !dbg !804
  call void @llvm.dbg.value(metadata i32 %2, metadata !803, metadata !DIExpression()), !dbg !804
  %3 = bitcast i8* %0 to %1**, !dbg !804
  %4 = load %1*, %1** %3, align 8, !dbg !804
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !804
  %6 = bitcast i8* %5 to %1**, !dbg !804
  %7 = load %1*, %1** %6, align 8, !dbg !804
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !804
  %9 = bitcast i8* %8 to %1**, !dbg !804
  %10 = load %1*, %1** %9, align 8, !dbg !804
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !804
  %12 = bitcast i8* %11 to %1**, !dbg !804
  %13 = load %1*, %1** %12, align 8, !dbg !804
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !804
  %15 = bitcast i8* %14 to %1**, !dbg !804
  %16 = load %1*, %1** %15, align 8, !dbg !804
  %17 = getelementptr inbounds i8, i8* %0, i64 40, !dbg !804
  %18 = bitcast i8* %17 to %1**, !dbg !804
  %19 = load %1*, %1** %18, align 8, !dbg !804
  %20 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !804
  %21 = load i8*, i8** %20, align 8, !dbg !804
  %22 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !804
  %23 = load i32, i32* %22, align 4, !dbg !804
  %24 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !804
  %25 = load i8*, i8** %24, align 8, !dbg !804
  %26 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !804
  %27 = load i8*, i8** %26, align 8, !dbg !804
  %28 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !804
  %29 = load i8*, i8** %28, align 8, !dbg !804
  %30 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !804
  %31 = load i8*, i8** %30, align 8, !dbg !804
  %32 = getelementptr inbounds %1, %1* %19, i64 0, i32 0, !dbg !804
  %33 = load i8*, i8** %32, align 8, !dbg !804
  %34 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2_compute_(i8* %21, i8* %25, i8* %33, i8* %27, i8* %29, i8* %31, i32 %23), !dbg !804
  ret i32 %34, !dbg !804
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %7 = alloca %48, align 8
  %8 = getelementptr inbounds %48, %48* %7, i64 0, i32 0
  store i8* %0, i8** %8, align 8
  %9 = getelementptr inbounds %48, %48* %7, i64 0, i32 1
  store i8* %1, i8** %9, align 8
  %10 = getelementptr inbounds %48, %48* %7, i64 0, i32 2
  store i8* %2, i8** %10, align 8
  %11 = getelementptr inbounds %48, %48* %7, i64 0, i32 3
  store i8* %3, i8** %11, align 8
  %12 = getelementptr inbounds %48, %48* %7, i64 0, i32 4
  store i8* %4, i8** %12, align 8
  %13 = getelementptr inbounds %48, %48* %7, i64 0, i32 5
  store i8* %5, i8** %13, align 8
  %14 = getelementptr inbounds %48, %48* %7, i64 0, i32 6
  store i32 %6, i32* %14, align 8
  %15 = bitcast %48* %7 to i8*
  %16 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %17 = call i32 %16(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.44, i8* nonnull %15, i32 0)
  ret i32 %17
}

define private i32 @__tvm_parallel_lambda.44(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds i8, i8* %2, i64 40
  %18 = bitcast i8* %17 to float**
  %19 = load float*, float** %18, align 8
  %20 = getelementptr inbounds i8, i8* %2, i64 48
  %21 = bitcast i8* %20 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %24, 111
  %26 = sdiv i32 %25, %24
  %27 = add nsw i32 %0, 1
  %28 = mul nsw i32 %26, %27
  %29 = icmp slt i32 %28, 112
  %30 = select i1 %29, i32 %28, i32 112
  %31 = mul nsw i32 %26, %0
  %32 = icmp slt i32 %31, 112
  %33 = select i1 %32, i32 %31, i32 112
  %34 = icmp slt i32 %33, %30
  br i1 %34, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %35 = add i32 %33, 1
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, -1
  %38 = sext i32 %30 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.3
  %indvars.iv42 = phi i64 [ %37, %for_body.lr.ph ], [ %indvars.iv.next43, %for_end6.3 ]
  %39 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %40 = tail call i8* %39(i32 1, i32 %22, i64 3584, i32 2, i32 32)
  %41 = trunc i64 %indvars.iv42 to i32
  %42 = srem i32 %41, 28
  %43 = mul nsw i32 %42, 28672
  %44 = sdiv i32 %41, 28
  %45 = shl i32 %44, 13
  %46 = sext i32 %45 to i64
  %47 = sext i32 %43 to i64
  %48 = bitcast i8* %40 to <32 x float>*
  %49 = getelementptr inbounds i8, i8* %40, i64 128
  %50 = bitcast i8* %49 to <32 x float>*
  %51 = getelementptr inbounds i8, i8* %40, i64 256
  %52 = bitcast i8* %51 to <32 x float>*
  %53 = getelementptr inbounds i8, i8* %40, i64 384
  %54 = bitcast i8* %53 to <32 x float>*
  %55 = getelementptr inbounds i8, i8* %40, i64 512
  %56 = bitcast i8* %55 to <32 x float>*
  %57 = getelementptr inbounds i8, i8* %40, i64 640
  %58 = bitcast i8* %57 to <32 x float>*
  %59 = getelementptr inbounds i8, i8* %40, i64 768
  %60 = bitcast i8* %59 to <32 x float>*
  call void @llvm.memset.p0i8.i64(i8* %40, i8 0, i64 896, i32 64, i1 false)
  br label %for_body5

for_end:                                          ; preds = %for_end6.3, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %61 = phi <32 x float> [ zeroinitializer, %for_body ], [ %114, %for_body5 ]
  %62 = phi <32 x float> [ zeroinitializer, %for_body ], [ %108, %for_body5 ]
  %63 = phi <32 x float> [ zeroinitializer, %for_body ], [ %102, %for_body5 ]
  %64 = phi <32 x float> [ zeroinitializer, %for_body ], [ %96, %for_body5 ]
  %65 = phi <32 x float> [ zeroinitializer, %for_body ], [ %90, %for_body5 ]
  %66 = phi <32 x float> [ zeroinitializer, %for_body ], [ %84, %for_body5 ]
  %67 = phi <32 x float> [ zeroinitializer, %for_body ], [ %78, %for_body5 ]
  %68 = add nsw i64 %indvars.iv, %47
  %69 = getelementptr inbounds float, float* %4, i64 %68
  %70 = load float, float* %69, align 4, !tbaa !805
  %71 = insertelement <32 x float> undef, float %70, i32 0
  %72 = shufflevector <32 x float> %71, <32 x float> undef, <32 x i32> zeroinitializer
  %73 = shl i64 %indvars.iv, 5
  %74 = add nuw nsw i64 %73, %46
  %75 = getelementptr inbounds float, float* %7, i64 %74
  %76 = bitcast float* %75 to <32 x float>*
  %77 = load <32 x float>, <32 x float>* %76, align 64, !tbaa !808
  %78 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %72, <32 x float> %77, <32 x float> %67)
  %79 = add nsw i64 %68, 512
  %80 = getelementptr inbounds float, float* %4, i64 %79
  %81 = load float, float* %80, align 4, !tbaa !805
  %82 = insertelement <32 x float> undef, float %81, i32 0
  %83 = shufflevector <32 x float> %82, <32 x float> undef, <32 x i32> zeroinitializer
  %84 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %83, <32 x float> %77, <32 x float> %66)
  %85 = add nsw i64 %68, 1024
  %86 = getelementptr inbounds float, float* %4, i64 %85
  %87 = load float, float* %86, align 4, !tbaa !805
  %88 = insertelement <32 x float> undef, float %87, i32 0
  %89 = shufflevector <32 x float> %88, <32 x float> undef, <32 x i32> zeroinitializer
  %90 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %89, <32 x float> %77, <32 x float> %65)
  %91 = add nsw i64 %68, 1536
  %92 = getelementptr inbounds float, float* %4, i64 %91
  %93 = load float, float* %92, align 4, !tbaa !805
  %94 = insertelement <32 x float> undef, float %93, i32 0
  %95 = shufflevector <32 x float> %94, <32 x float> undef, <32 x i32> zeroinitializer
  %96 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %95, <32 x float> %77, <32 x float> %64)
  %97 = add nsw i64 %68, 2048
  %98 = getelementptr inbounds float, float* %4, i64 %97
  %99 = load float, float* %98, align 4, !tbaa !805
  %100 = insertelement <32 x float> undef, float %99, i32 0
  %101 = shufflevector <32 x float> %100, <32 x float> undef, <32 x i32> zeroinitializer
  %102 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %101, <32 x float> %77, <32 x float> %63)
  %103 = add nsw i64 %68, 2560
  %104 = getelementptr inbounds float, float* %4, i64 %103
  %105 = load float, float* %104, align 4, !tbaa !805
  %106 = insertelement <32 x float> undef, float %105, i32 0
  %107 = shufflevector <32 x float> %106, <32 x float> undef, <32 x i32> zeroinitializer
  %108 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %107, <32 x float> %77, <32 x float> %62)
  %109 = add nsw i64 %68, 3072
  %110 = getelementptr inbounds float, float* %4, i64 %109
  %111 = load float, float* %110, align 4, !tbaa !805
  %112 = insertelement <32 x float> undef, float %111, i32 0
  %113 = shufflevector <32 x float> %112, <32 x float> undef, <32 x i32> zeroinitializer
  %114 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %113, <32 x float> %77, <32 x float> %61)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  store <32 x float> %78, <32 x float>* %48, align 64, !tbaa !811
  store <32 x float> %84, <32 x float>* %50, align 64, !tbaa !811
  store <32 x float> %90, <32 x float>* %52, align 64, !tbaa !811
  store <32 x float> %96, <32 x float>* %54, align 64, !tbaa !811
  store <32 x float> %102, <32 x float>* %56, align 64, !tbaa !811
  store <32 x float> %108, <32 x float>* %58, align 64, !tbaa !811
  store <32 x float> %114, <32 x float>* %60, align 64, !tbaa !811
  %115 = getelementptr inbounds i8, i8* %40, i64 896
  %116 = bitcast i8* %115 to <32 x float>*
  %117 = getelementptr inbounds i8, i8* %40, i64 1024
  %118 = bitcast i8* %117 to <32 x float>*
  %119 = getelementptr inbounds i8, i8* %40, i64 1152
  %120 = bitcast i8* %119 to <32 x float>*
  %121 = getelementptr inbounds i8, i8* %40, i64 1280
  %122 = bitcast i8* %121 to <32 x float>*
  %123 = getelementptr inbounds i8, i8* %40, i64 1408
  %124 = bitcast i8* %123 to <32 x float>*
  %125 = getelementptr inbounds i8, i8* %40, i64 1536
  %126 = bitcast i8* %125 to <32 x float>*
  %127 = getelementptr inbounds i8, i8* %40, i64 1664
  %128 = bitcast i8* %127 to <32 x float>*
  %129 = or i64 %47, 3584
  call void @llvm.memset.p0i8.i64(i8* nonnull %115, i8 0, i64 896, i32 64, i1 false)
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %130 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %183, %for_body5.1 ]
  %131 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %177, %for_body5.1 ]
  %132 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %171, %for_body5.1 ]
  %133 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %165, %for_body5.1 ]
  %134 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %159, %for_body5.1 ]
  %135 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %153, %for_body5.1 ]
  %136 = phi <32 x float> [ zeroinitializer, %for_end6 ], [ %147, %for_body5.1 ]
  %137 = add nsw i64 %129, %indvars.iv.1
  %138 = getelementptr inbounds float, float* %4, i64 %137
  %139 = load float, float* %138, align 4, !tbaa !805
  %140 = insertelement <32 x float> undef, float %139, i32 0
  %141 = shufflevector <32 x float> %140, <32 x float> undef, <32 x i32> zeroinitializer
  %142 = shl i64 %indvars.iv.1, 5
  %143 = add nuw nsw i64 %142, %46
  %144 = getelementptr inbounds float, float* %7, i64 %143
  %145 = bitcast float* %144 to <32 x float>*
  %146 = load <32 x float>, <32 x float>* %145, align 64, !tbaa !808
  %147 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %141, <32 x float> %146, <32 x float> %136)
  %148 = add nsw i64 %137, 512
  %149 = getelementptr inbounds float, float* %4, i64 %148
  %150 = load float, float* %149, align 4, !tbaa !805
  %151 = insertelement <32 x float> undef, float %150, i32 0
  %152 = shufflevector <32 x float> %151, <32 x float> undef, <32 x i32> zeroinitializer
  %153 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %152, <32 x float> %146, <32 x float> %135)
  %154 = add nsw i64 %137, 1024
  %155 = getelementptr inbounds float, float* %4, i64 %154
  %156 = load float, float* %155, align 4, !tbaa !805
  %157 = insertelement <32 x float> undef, float %156, i32 0
  %158 = shufflevector <32 x float> %157, <32 x float> undef, <32 x i32> zeroinitializer
  %159 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %158, <32 x float> %146, <32 x float> %134)
  %160 = add nsw i64 %137, 1536
  %161 = getelementptr inbounds float, float* %4, i64 %160
  %162 = load float, float* %161, align 4, !tbaa !805
  %163 = insertelement <32 x float> undef, float %162, i32 0
  %164 = shufflevector <32 x float> %163, <32 x float> undef, <32 x i32> zeroinitializer
  %165 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %164, <32 x float> %146, <32 x float> %133)
  %166 = add nsw i64 %137, 2048
  %167 = getelementptr inbounds float, float* %4, i64 %166
  %168 = load float, float* %167, align 4, !tbaa !805
  %169 = insertelement <32 x float> undef, float %168, i32 0
  %170 = shufflevector <32 x float> %169, <32 x float> undef, <32 x i32> zeroinitializer
  %171 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %170, <32 x float> %146, <32 x float> %132)
  %172 = add nsw i64 %137, 2560
  %173 = getelementptr inbounds float, float* %4, i64 %172
  %174 = load float, float* %173, align 4, !tbaa !805
  %175 = insertelement <32 x float> undef, float %174, i32 0
  %176 = shufflevector <32 x float> %175, <32 x float> undef, <32 x i32> zeroinitializer
  %177 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %176, <32 x float> %146, <32 x float> %131)
  %178 = add nsw i64 %137, 3072
  %179 = getelementptr inbounds float, float* %4, i64 %178
  %180 = load float, float* %179, align 4, !tbaa !805
  %181 = insertelement <32 x float> undef, float %180, i32 0
  %182 = shufflevector <32 x float> %181, <32 x float> undef, <32 x i32> zeroinitializer
  %183 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %182, <32 x float> %146, <32 x float> %130)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 256
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  store <32 x float> %147, <32 x float>* %116, align 64, !tbaa !811
  store <32 x float> %153, <32 x float>* %118, align 64, !tbaa !811
  store <32 x float> %159, <32 x float>* %120, align 64, !tbaa !811
  store <32 x float> %165, <32 x float>* %122, align 64, !tbaa !811
  store <32 x float> %171, <32 x float>* %124, align 64, !tbaa !811
  store <32 x float> %177, <32 x float>* %126, align 64, !tbaa !811
  store <32 x float> %183, <32 x float>* %128, align 64, !tbaa !811
  %184 = getelementptr inbounds i8, i8* %40, i64 1792
  %185 = bitcast i8* %184 to <32 x float>*
  %186 = getelementptr inbounds i8, i8* %40, i64 1920
  %187 = bitcast i8* %186 to <32 x float>*
  %188 = getelementptr inbounds i8, i8* %40, i64 2048
  %189 = bitcast i8* %188 to <32 x float>*
  %190 = getelementptr inbounds i8, i8* %40, i64 2176
  %191 = bitcast i8* %190 to <32 x float>*
  %192 = getelementptr inbounds i8, i8* %40, i64 2304
  %193 = bitcast i8* %192 to <32 x float>*
  %194 = getelementptr inbounds i8, i8* %40, i64 2432
  %195 = bitcast i8* %194 to <32 x float>*
  %196 = getelementptr inbounds i8, i8* %40, i64 2560
  %197 = bitcast i8* %196 to <32 x float>*
  %198 = add nsw i64 %47, 7168
  call void @llvm.memset.p0i8.i64(i8* nonnull %184, i8 0, i64 896, i32 64, i1 false)
  br label %for_body5.2

for_body5.2:                                      ; preds = %for_body5.2, %for_end6.1
  %indvars.iv.2 = phi i64 [ 0, %for_end6.1 ], [ %indvars.iv.next.2, %for_body5.2 ]
  %199 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %252, %for_body5.2 ]
  %200 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %246, %for_body5.2 ]
  %201 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %240, %for_body5.2 ]
  %202 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %234, %for_body5.2 ]
  %203 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %228, %for_body5.2 ]
  %204 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %222, %for_body5.2 ]
  %205 = phi <32 x float> [ zeroinitializer, %for_end6.1 ], [ %216, %for_body5.2 ]
  %206 = add nsw i64 %198, %indvars.iv.2
  %207 = getelementptr inbounds float, float* %4, i64 %206
  %208 = load float, float* %207, align 4, !tbaa !805
  %209 = insertelement <32 x float> undef, float %208, i32 0
  %210 = shufflevector <32 x float> %209, <32 x float> undef, <32 x i32> zeroinitializer
  %211 = shl i64 %indvars.iv.2, 5
  %212 = add nuw nsw i64 %211, %46
  %213 = getelementptr inbounds float, float* %7, i64 %212
  %214 = bitcast float* %213 to <32 x float>*
  %215 = load <32 x float>, <32 x float>* %214, align 64, !tbaa !808
  %216 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %210, <32 x float> %215, <32 x float> %205)
  %217 = add nsw i64 %206, 512
  %218 = getelementptr inbounds float, float* %4, i64 %217
  %219 = load float, float* %218, align 4, !tbaa !805
  %220 = insertelement <32 x float> undef, float %219, i32 0
  %221 = shufflevector <32 x float> %220, <32 x float> undef, <32 x i32> zeroinitializer
  %222 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %221, <32 x float> %215, <32 x float> %204)
  %223 = add nsw i64 %206, 1024
  %224 = getelementptr inbounds float, float* %4, i64 %223
  %225 = load float, float* %224, align 4, !tbaa !805
  %226 = insertelement <32 x float> undef, float %225, i32 0
  %227 = shufflevector <32 x float> %226, <32 x float> undef, <32 x i32> zeroinitializer
  %228 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %227, <32 x float> %215, <32 x float> %203)
  %229 = add nsw i64 %206, 1536
  %230 = getelementptr inbounds float, float* %4, i64 %229
  %231 = load float, float* %230, align 4, !tbaa !805
  %232 = insertelement <32 x float> undef, float %231, i32 0
  %233 = shufflevector <32 x float> %232, <32 x float> undef, <32 x i32> zeroinitializer
  %234 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %233, <32 x float> %215, <32 x float> %202)
  %235 = add nsw i64 %206, 2048
  %236 = getelementptr inbounds float, float* %4, i64 %235
  %237 = load float, float* %236, align 4, !tbaa !805
  %238 = insertelement <32 x float> undef, float %237, i32 0
  %239 = shufflevector <32 x float> %238, <32 x float> undef, <32 x i32> zeroinitializer
  %240 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %239, <32 x float> %215, <32 x float> %201)
  %241 = add nsw i64 %206, 2560
  %242 = getelementptr inbounds float, float* %4, i64 %241
  %243 = load float, float* %242, align 4, !tbaa !805
  %244 = insertelement <32 x float> undef, float %243, i32 0
  %245 = shufflevector <32 x float> %244, <32 x float> undef, <32 x i32> zeroinitializer
  %246 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %245, <32 x float> %215, <32 x float> %200)
  %247 = add nsw i64 %206, 3072
  %248 = getelementptr inbounds float, float* %4, i64 %247
  %249 = load float, float* %248, align 4, !tbaa !805
  %250 = insertelement <32 x float> undef, float %249, i32 0
  %251 = shufflevector <32 x float> %250, <32 x float> undef, <32 x i32> zeroinitializer
  %252 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %251, <32 x float> %215, <32 x float> %199)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 256
  br i1 %exitcond.2, label %for_end6.2, label %for_body5.2, !prof !29

for_end6.2:                                       ; preds = %for_body5.2
  store <32 x float> %216, <32 x float>* %185, align 64, !tbaa !811
  store <32 x float> %222, <32 x float>* %187, align 64, !tbaa !811
  store <32 x float> %228, <32 x float>* %189, align 64, !tbaa !811
  store <32 x float> %234, <32 x float>* %191, align 64, !tbaa !811
  store <32 x float> %240, <32 x float>* %193, align 64, !tbaa !811
  store <32 x float> %246, <32 x float>* %195, align 64, !tbaa !811
  store <32 x float> %252, <32 x float>* %197, align 64, !tbaa !811
  %253 = getelementptr inbounds i8, i8* %40, i64 2688
  %254 = bitcast i8* %253 to <32 x float>*
  %255 = getelementptr inbounds i8, i8* %40, i64 2816
  %256 = bitcast i8* %255 to <32 x float>*
  %257 = getelementptr inbounds i8, i8* %40, i64 2944
  %258 = bitcast i8* %257 to <32 x float>*
  %259 = getelementptr inbounds i8, i8* %40, i64 3072
  %260 = bitcast i8* %259 to <32 x float>*
  %261 = getelementptr inbounds i8, i8* %40, i64 3200
  %262 = bitcast i8* %261 to <32 x float>*
  %263 = getelementptr inbounds i8, i8* %40, i64 3328
  %264 = bitcast i8* %263 to <32 x float>*
  %265 = getelementptr inbounds i8, i8* %40, i64 3456
  %266 = bitcast i8* %265 to <32 x float>*
  %267 = add nsw i64 %47, 10752
  call void @llvm.memset.p0i8.i64(i8* nonnull %253, i8 0, i64 896, i32 64, i1 false)
  br label %for_body5.3

for_body5.3:                                      ; preds = %for_body5.3, %for_end6.2
  %indvars.iv.3 = phi i64 [ 0, %for_end6.2 ], [ %indvars.iv.next.3, %for_body5.3 ]
  %268 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %321, %for_body5.3 ]
  %269 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %315, %for_body5.3 ]
  %270 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %309, %for_body5.3 ]
  %271 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %303, %for_body5.3 ]
  %272 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %297, %for_body5.3 ]
  %273 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %291, %for_body5.3 ]
  %274 = phi <32 x float> [ zeroinitializer, %for_end6.2 ], [ %285, %for_body5.3 ]
  %275 = add nsw i64 %267, %indvars.iv.3
  %276 = getelementptr inbounds float, float* %4, i64 %275
  %277 = load float, float* %276, align 4, !tbaa !805
  %278 = insertelement <32 x float> undef, float %277, i32 0
  %279 = shufflevector <32 x float> %278, <32 x float> undef, <32 x i32> zeroinitializer
  %280 = shl i64 %indvars.iv.3, 5
  %281 = add nuw nsw i64 %280, %46
  %282 = getelementptr inbounds float, float* %7, i64 %281
  %283 = bitcast float* %282 to <32 x float>*
  %284 = load <32 x float>, <32 x float>* %283, align 64, !tbaa !808
  %285 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %279, <32 x float> %284, <32 x float> %274)
  %286 = add nsw i64 %275, 512
  %287 = getelementptr inbounds float, float* %4, i64 %286
  %288 = load float, float* %287, align 4, !tbaa !805
  %289 = insertelement <32 x float> undef, float %288, i32 0
  %290 = shufflevector <32 x float> %289, <32 x float> undef, <32 x i32> zeroinitializer
  %291 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %290, <32 x float> %284, <32 x float> %273)
  %292 = add nsw i64 %275, 1024
  %293 = getelementptr inbounds float, float* %4, i64 %292
  %294 = load float, float* %293, align 4, !tbaa !805
  %295 = insertelement <32 x float> undef, float %294, i32 0
  %296 = shufflevector <32 x float> %295, <32 x float> undef, <32 x i32> zeroinitializer
  %297 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %296, <32 x float> %284, <32 x float> %272)
  %298 = add nsw i64 %275, 1536
  %299 = getelementptr inbounds float, float* %4, i64 %298
  %300 = load float, float* %299, align 4, !tbaa !805
  %301 = insertelement <32 x float> undef, float %300, i32 0
  %302 = shufflevector <32 x float> %301, <32 x float> undef, <32 x i32> zeroinitializer
  %303 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %302, <32 x float> %284, <32 x float> %271)
  %304 = add nsw i64 %275, 2048
  %305 = getelementptr inbounds float, float* %4, i64 %304
  %306 = load float, float* %305, align 4, !tbaa !805
  %307 = insertelement <32 x float> undef, float %306, i32 0
  %308 = shufflevector <32 x float> %307, <32 x float> undef, <32 x i32> zeroinitializer
  %309 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %308, <32 x float> %284, <32 x float> %270)
  %310 = add nsw i64 %275, 2560
  %311 = getelementptr inbounds float, float* %4, i64 %310
  %312 = load float, float* %311, align 4, !tbaa !805
  %313 = insertelement <32 x float> undef, float %312, i32 0
  %314 = shufflevector <32 x float> %313, <32 x float> undef, <32 x i32> zeroinitializer
  %315 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %314, <32 x float> %284, <32 x float> %269)
  %316 = add nsw i64 %275, 3072
  %317 = getelementptr inbounds float, float* %4, i64 %316
  %318 = load float, float* %317, align 4, !tbaa !805
  %319 = insertelement <32 x float> undef, float %318, i32 0
  %320 = shufflevector <32 x float> %319, <32 x float> undef, <32 x i32> zeroinitializer
  %321 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %320, <32 x float> %284, <32 x float> %268)
  %indvars.iv.next.3 = add nuw nsw i64 %indvars.iv.3, 1
  %exitcond.3 = icmp eq i64 %indvars.iv.next.3, 256
  br i1 %exitcond.3, label %for_end6.3, label %for_body5.3, !prof !29

for_end6.3:                                       ; preds = %for_body5.3
  store <32 x float> %285, <32 x float>* %254, align 64, !tbaa !811
  store <32 x float> %291, <32 x float>* %256, align 64, !tbaa !811
  store <32 x float> %297, <32 x float>* %258, align 64, !tbaa !811
  store <32 x float> %303, <32 x float>* %260, align 64, !tbaa !811
  store <32 x float> %309, <32 x float>* %262, align 64, !tbaa !811
  store <32 x float> %315, <32 x float>* %264, align 64, !tbaa !811
  store <32 x float> %321, <32 x float>* %266, align 64, !tbaa !811
  %322 = mul nsw i64 %indvars.iv42, 896
  %323 = shl nsw i32 %44, 5
  %324 = sext i32 %323 to i64
  %325 = getelementptr inbounds float, float* %13, i64 %324
  %326 = bitcast float* %325 to <32 x float>*
  %327 = load <32 x float>, <32 x float>* %326, align 64, !tbaa !814
  %328 = getelementptr inbounds float, float* %16, i64 %324
  %329 = bitcast float* %328 to <32 x float>*
  %330 = load <32 x float>, <32 x float>* %329, align 64, !tbaa !817
  %331 = getelementptr inbounds float, float* %19, i64 %324
  %332 = bitcast float* %331 to <32 x float>*
  %333 = load <32 x float>, <32 x float>* %332, align 64, !tbaa !820
  %334 = fadd <32 x float> %327, %78
  %335 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %334, <32 x float> %330, <32 x float> %333)
  %336 = fcmp ogt <32 x float> %335, zeroinitializer
  %337 = select <32 x i1> %336, <32 x float> %335, <32 x float> zeroinitializer
  %338 = getelementptr inbounds float, float* %10, i64 %322
  %339 = bitcast float* %338 to <32 x float>*
  store <32 x float> %337, <32 x float>* %339, align 64, !tbaa !823
  %340 = fadd <32 x float> %327, %84
  %341 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %340, <32 x float> %330, <32 x float> %333)
  %342 = fcmp ogt <32 x float> %341, zeroinitializer
  %343 = select <32 x i1> %342, <32 x float> %341, <32 x float> zeroinitializer
  %344 = mul i64 %indvars.iv42, 3848290697216
  %sext = ashr exact i64 %344, 32
  %345 = or i64 %sext, 32
  %346 = getelementptr inbounds float, float* %10, i64 %345
  %347 = bitcast float* %346 to <32 x float>*
  store <32 x float> %343, <32 x float>* %347, align 64, !tbaa !823
  %348 = fadd <32 x float> %327, %90
  %349 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %348, <32 x float> %330, <32 x float> %333)
  %350 = fcmp ogt <32 x float> %349, zeroinitializer
  %351 = select <32 x i1> %350, <32 x float> %349, <32 x float> zeroinitializer
  %352 = mul i64 %indvars.iv42, 3848290697216
  %sext44 = ashr exact i64 %352, 32
  %353 = or i64 %sext44, 64
  %354 = getelementptr inbounds float, float* %10, i64 %353
  %355 = bitcast float* %354 to <32 x float>*
  store <32 x float> %351, <32 x float>* %355, align 64, !tbaa !823
  %356 = fadd <32 x float> %327, %96
  %357 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %356, <32 x float> %330, <32 x float> %333)
  %358 = fcmp ogt <32 x float> %357, zeroinitializer
  %359 = select <32 x i1> %358, <32 x float> %357, <32 x float> zeroinitializer
  %360 = mul i64 %indvars.iv42, 3848290697216
  %sext45 = ashr exact i64 %360, 32
  %361 = or i64 %sext45, 96
  %362 = getelementptr inbounds float, float* %10, i64 %361
  %363 = bitcast float* %362 to <32 x float>*
  store <32 x float> %359, <32 x float>* %363, align 64, !tbaa !823
  %364 = fadd <32 x float> %327, %102
  %365 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %364, <32 x float> %330, <32 x float> %333)
  %366 = fcmp ogt <32 x float> %365, zeroinitializer
  %367 = select <32 x i1> %366, <32 x float> %365, <32 x float> zeroinitializer
  %368 = mul i64 %indvars.iv42, 3848290697216
  %sext46 = add i64 %368, 549755813888
  %369 = ashr exact i64 %sext46, 32
  %370 = getelementptr inbounds float, float* %10, i64 %369
  %371 = bitcast float* %370 to <32 x float>*
  store <32 x float> %367, <32 x float>* %371, align 64, !tbaa !823
  %372 = fadd <32 x float> %327, %108
  %373 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %372, <32 x float> %330, <32 x float> %333)
  %374 = fcmp ogt <32 x float> %373, zeroinitializer
  %375 = select <32 x i1> %374, <32 x float> %373, <32 x float> zeroinitializer
  %376 = mul i64 %indvars.iv42, 3848290697216
  %sext47 = add i64 %376, 687194767360
  %377 = ashr exact i64 %sext47, 32
  %378 = getelementptr inbounds float, float* %10, i64 %377
  %379 = bitcast float* %378 to <32 x float>*
  store <32 x float> %375, <32 x float>* %379, align 64, !tbaa !823
  %380 = fadd <32 x float> %327, %114
  %381 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %380, <32 x float> %330, <32 x float> %333)
  %382 = fcmp ogt <32 x float> %381, zeroinitializer
  %383 = select <32 x i1> %382, <32 x float> %381, <32 x float> zeroinitializer
  %384 = mul i64 %indvars.iv42, 3848290697216
  %sext48 = add i64 %384, 824633720832
  %385 = ashr exact i64 %sext48, 32
  %386 = getelementptr inbounds float, float* %10, i64 %385
  %387 = bitcast float* %386 to <32 x float>*
  store <32 x float> %383, <32 x float>* %387, align 64, !tbaa !823
  %388 = fadd <32 x float> %327, %147
  %389 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %388, <32 x float> %330, <32 x float> %333)
  %390 = fcmp ogt <32 x float> %389, zeroinitializer
  %391 = select <32 x i1> %390, <32 x float> %389, <32 x float> zeroinitializer
  %392 = mul i64 %indvars.iv42, 3848290697216
  %sext49 = add i64 %392, 962072674304
  %393 = ashr exact i64 %sext49, 32
  %394 = getelementptr inbounds float, float* %10, i64 %393
  %395 = bitcast float* %394 to <32 x float>*
  store <32 x float> %391, <32 x float>* %395, align 64, !tbaa !823
  %396 = fadd <32 x float> %327, %153
  %397 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %396, <32 x float> %330, <32 x float> %333)
  %398 = fcmp ogt <32 x float> %397, zeroinitializer
  %399 = select <32 x i1> %398, <32 x float> %397, <32 x float> zeroinitializer
  %400 = mul i64 %indvars.iv42, 3848290697216
  %sext50 = add i64 %400, 1099511627776
  %401 = ashr exact i64 %sext50, 32
  %402 = getelementptr inbounds float, float* %10, i64 %401
  %403 = bitcast float* %402 to <32 x float>*
  store <32 x float> %399, <32 x float>* %403, align 64, !tbaa !823
  %404 = load <32 x float>, <32 x float>* %120, align 64, !tbaa !811
  %405 = fadd <32 x float> %327, %404
  %406 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %405, <32 x float> %330, <32 x float> %333)
  %407 = fcmp ogt <32 x float> %406, zeroinitializer
  %408 = select <32 x i1> %407, <32 x float> %406, <32 x float> zeroinitializer
  %409 = mul i64 %indvars.iv42, 3848290697216
  %sext51 = add i64 %409, 1236950581248
  %410 = ashr exact i64 %sext51, 32
  %411 = getelementptr inbounds float, float* %10, i64 %410
  %412 = bitcast float* %411 to <32 x float>*
  store <32 x float> %408, <32 x float>* %412, align 64, !tbaa !823
  %413 = load <32 x float>, <32 x float>* %122, align 64, !tbaa !811
  %414 = fadd <32 x float> %327, %413
  %415 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %414, <32 x float> %330, <32 x float> %333)
  %416 = fcmp ogt <32 x float> %415, zeroinitializer
  %417 = select <32 x i1> %416, <32 x float> %415, <32 x float> zeroinitializer
  %418 = mul i64 %indvars.iv42, 3848290697216
  %sext52 = add i64 %418, 1374389534720
  %419 = ashr exact i64 %sext52, 32
  %420 = getelementptr inbounds float, float* %10, i64 %419
  %421 = bitcast float* %420 to <32 x float>*
  store <32 x float> %417, <32 x float>* %421, align 64, !tbaa !823
  %422 = load <32 x float>, <32 x float>* %124, align 64, !tbaa !811
  %423 = fadd <32 x float> %327, %422
  %424 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %423, <32 x float> %330, <32 x float> %333)
  %425 = fcmp ogt <32 x float> %424, zeroinitializer
  %426 = select <32 x i1> %425, <32 x float> %424, <32 x float> zeroinitializer
  %427 = mul i64 %indvars.iv42, 3848290697216
  %sext53 = add i64 %427, 1511828488192
  %428 = ashr exact i64 %sext53, 32
  %429 = getelementptr inbounds float, float* %10, i64 %428
  %430 = bitcast float* %429 to <32 x float>*
  store <32 x float> %426, <32 x float>* %430, align 64, !tbaa !823
  %431 = load <32 x float>, <32 x float>* %126, align 64, !tbaa !811
  %432 = fadd <32 x float> %327, %431
  %433 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %432, <32 x float> %330, <32 x float> %333)
  %434 = fcmp ogt <32 x float> %433, zeroinitializer
  %435 = select <32 x i1> %434, <32 x float> %433, <32 x float> zeroinitializer
  %436 = mul i64 %indvars.iv42, 3848290697216
  %sext54 = add i64 %436, 1649267441664
  %437 = ashr exact i64 %sext54, 32
  %438 = getelementptr inbounds float, float* %10, i64 %437
  %439 = bitcast float* %438 to <32 x float>*
  store <32 x float> %435, <32 x float>* %439, align 64, !tbaa !823
  %440 = load <32 x float>, <32 x float>* %128, align 64, !tbaa !811
  %441 = fadd <32 x float> %327, %440
  %442 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %441, <32 x float> %330, <32 x float> %333)
  %443 = fcmp ogt <32 x float> %442, zeroinitializer
  %444 = select <32 x i1> %443, <32 x float> %442, <32 x float> zeroinitializer
  %445 = mul i64 %indvars.iv42, 3848290697216
  %sext55 = add i64 %445, 1786706395136
  %446 = ashr exact i64 %sext55, 32
  %447 = getelementptr inbounds float, float* %10, i64 %446
  %448 = bitcast float* %447 to <32 x float>*
  store <32 x float> %444, <32 x float>* %448, align 64, !tbaa !823
  %449 = load <32 x float>, <32 x float>* %185, align 64, !tbaa !811
  %450 = fadd <32 x float> %327, %449
  %451 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %450, <32 x float> %330, <32 x float> %333)
  %452 = fcmp ogt <32 x float> %451, zeroinitializer
  %453 = select <32 x i1> %452, <32 x float> %451, <32 x float> zeroinitializer
  %454 = mul i64 %indvars.iv42, 3848290697216
  %sext56 = add i64 %454, 1924145348608
  %455 = ashr exact i64 %sext56, 32
  %456 = getelementptr inbounds float, float* %10, i64 %455
  %457 = bitcast float* %456 to <32 x float>*
  store <32 x float> %453, <32 x float>* %457, align 64, !tbaa !823
  %458 = load <32 x float>, <32 x float>* %187, align 64, !tbaa !811
  %459 = fadd <32 x float> %327, %458
  %460 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %459, <32 x float> %330, <32 x float> %333)
  %461 = fcmp ogt <32 x float> %460, zeroinitializer
  %462 = select <32 x i1> %461, <32 x float> %460, <32 x float> zeroinitializer
  %463 = mul i64 %indvars.iv42, 3848290697216
  %sext57 = add i64 %463, 2061584302080
  %464 = ashr exact i64 %sext57, 32
  %465 = getelementptr inbounds float, float* %10, i64 %464
  %466 = bitcast float* %465 to <32 x float>*
  store <32 x float> %462, <32 x float>* %466, align 64, !tbaa !823
  %467 = load <32 x float>, <32 x float>* %189, align 64, !tbaa !811
  %468 = fadd <32 x float> %327, %467
  %469 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %468, <32 x float> %330, <32 x float> %333)
  %470 = fcmp ogt <32 x float> %469, zeroinitializer
  %471 = select <32 x i1> %470, <32 x float> %469, <32 x float> zeroinitializer
  %472 = mul i64 %indvars.iv42, 3848290697216
  %sext58 = add i64 %472, 2199023255552
  %473 = ashr exact i64 %sext58, 32
  %474 = getelementptr inbounds float, float* %10, i64 %473
  %475 = bitcast float* %474 to <32 x float>*
  store <32 x float> %471, <32 x float>* %475, align 64, !tbaa !823
  %476 = load <32 x float>, <32 x float>* %191, align 64, !tbaa !811
  %477 = fadd <32 x float> %327, %476
  %478 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %477, <32 x float> %330, <32 x float> %333)
  %479 = fcmp ogt <32 x float> %478, zeroinitializer
  %480 = select <32 x i1> %479, <32 x float> %478, <32 x float> zeroinitializer
  %481 = mul i64 %indvars.iv42, 3848290697216
  %sext59 = add i64 %481, 2336462209024
  %482 = ashr exact i64 %sext59, 32
  %483 = getelementptr inbounds float, float* %10, i64 %482
  %484 = bitcast float* %483 to <32 x float>*
  store <32 x float> %480, <32 x float>* %484, align 64, !tbaa !823
  %485 = load <32 x float>, <32 x float>* %193, align 64, !tbaa !811
  %486 = fadd <32 x float> %327, %485
  %487 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %486, <32 x float> %330, <32 x float> %333)
  %488 = fcmp ogt <32 x float> %487, zeroinitializer
  %489 = select <32 x i1> %488, <32 x float> %487, <32 x float> zeroinitializer
  %490 = mul i64 %indvars.iv42, 3848290697216
  %sext60 = add i64 %490, 2473901162496
  %491 = ashr exact i64 %sext60, 32
  %492 = getelementptr inbounds float, float* %10, i64 %491
  %493 = bitcast float* %492 to <32 x float>*
  store <32 x float> %489, <32 x float>* %493, align 64, !tbaa !823
  %494 = load <32 x float>, <32 x float>* %195, align 64, !tbaa !811
  %495 = fadd <32 x float> %327, %494
  %496 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %495, <32 x float> %330, <32 x float> %333)
  %497 = fcmp ogt <32 x float> %496, zeroinitializer
  %498 = select <32 x i1> %497, <32 x float> %496, <32 x float> zeroinitializer
  %499 = mul i64 %indvars.iv42, 3848290697216
  %sext61 = add i64 %499, 2611340115968
  %500 = ashr exact i64 %sext61, 32
  %501 = getelementptr inbounds float, float* %10, i64 %500
  %502 = bitcast float* %501 to <32 x float>*
  store <32 x float> %498, <32 x float>* %502, align 64, !tbaa !823
  %503 = load <32 x float>, <32 x float>* %197, align 64, !tbaa !811
  %504 = fadd <32 x float> %327, %503
  %505 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %504, <32 x float> %330, <32 x float> %333)
  %506 = fcmp ogt <32 x float> %505, zeroinitializer
  %507 = select <32 x i1> %506, <32 x float> %505, <32 x float> zeroinitializer
  %508 = mul i64 %indvars.iv42, 3848290697216
  %sext62 = add i64 %508, 2748779069440
  %509 = ashr exact i64 %sext62, 32
  %510 = getelementptr inbounds float, float* %10, i64 %509
  %511 = bitcast float* %510 to <32 x float>*
  store <32 x float> %507, <32 x float>* %511, align 64, !tbaa !823
  %512 = load <32 x float>, <32 x float>* %254, align 64, !tbaa !811
  %513 = fadd <32 x float> %327, %512
  %514 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %513, <32 x float> %330, <32 x float> %333)
  %515 = fcmp ogt <32 x float> %514, zeroinitializer
  %516 = select <32 x i1> %515, <32 x float> %514, <32 x float> zeroinitializer
  %517 = mul i64 %indvars.iv42, 3848290697216
  %sext63 = add i64 %517, 2886218022912
  %518 = ashr exact i64 %sext63, 32
  %519 = getelementptr inbounds float, float* %10, i64 %518
  %520 = bitcast float* %519 to <32 x float>*
  store <32 x float> %516, <32 x float>* %520, align 64, !tbaa !823
  %521 = load <32 x float>, <32 x float>* %256, align 64, !tbaa !811
  %522 = fadd <32 x float> %327, %521
  %523 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %522, <32 x float> %330, <32 x float> %333)
  %524 = fcmp ogt <32 x float> %523, zeroinitializer
  %525 = select <32 x i1> %524, <32 x float> %523, <32 x float> zeroinitializer
  %526 = mul i64 %indvars.iv42, 3848290697216
  %sext64 = add i64 %526, 3023656976384
  %527 = ashr exact i64 %sext64, 32
  %528 = getelementptr inbounds float, float* %10, i64 %527
  %529 = bitcast float* %528 to <32 x float>*
  store <32 x float> %525, <32 x float>* %529, align 64, !tbaa !823
  %530 = load <32 x float>, <32 x float>* %258, align 64, !tbaa !811
  %531 = fadd <32 x float> %327, %530
  %532 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %531, <32 x float> %330, <32 x float> %333)
  %533 = fcmp ogt <32 x float> %532, zeroinitializer
  %534 = select <32 x i1> %533, <32 x float> %532, <32 x float> zeroinitializer
  %535 = mul i64 %indvars.iv42, 3848290697216
  %sext65 = add i64 %535, 3161095929856
  %536 = ashr exact i64 %sext65, 32
  %537 = getelementptr inbounds float, float* %10, i64 %536
  %538 = bitcast float* %537 to <32 x float>*
  store <32 x float> %534, <32 x float>* %538, align 64, !tbaa !823
  %539 = load <32 x float>, <32 x float>* %260, align 64, !tbaa !811
  %540 = fadd <32 x float> %327, %539
  %541 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %540, <32 x float> %330, <32 x float> %333)
  %542 = fcmp ogt <32 x float> %541, zeroinitializer
  %543 = select <32 x i1> %542, <32 x float> %541, <32 x float> zeroinitializer
  %544 = mul i64 %indvars.iv42, 3848290697216
  %sext66 = add i64 %544, 3298534883328
  %545 = ashr exact i64 %sext66, 32
  %546 = getelementptr inbounds float, float* %10, i64 %545
  %547 = bitcast float* %546 to <32 x float>*
  store <32 x float> %543, <32 x float>* %547, align 64, !tbaa !823
  %548 = load <32 x float>, <32 x float>* %262, align 64, !tbaa !811
  %549 = fadd <32 x float> %327, %548
  %550 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %549, <32 x float> %330, <32 x float> %333)
  %551 = fcmp ogt <32 x float> %550, zeroinitializer
  %552 = select <32 x i1> %551, <32 x float> %550, <32 x float> zeroinitializer
  %553 = mul i64 %indvars.iv42, 3848290697216
  %sext67 = add i64 %553, 3435973836800
  %554 = ashr exact i64 %sext67, 32
  %555 = getelementptr inbounds float, float* %10, i64 %554
  %556 = bitcast float* %555 to <32 x float>*
  store <32 x float> %552, <32 x float>* %556, align 64, !tbaa !823
  %557 = load <32 x float>, <32 x float>* %264, align 64, !tbaa !811
  %558 = fadd <32 x float> %327, %557
  %559 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %558, <32 x float> %330, <32 x float> %333)
  %560 = fcmp ogt <32 x float> %559, zeroinitializer
  %561 = select <32 x i1> %560, <32 x float> %559, <32 x float> zeroinitializer
  %562 = mul i64 %indvars.iv42, 3848290697216
  %sext68 = add i64 %562, 3573412790272
  %563 = ashr exact i64 %sext68, 32
  %564 = getelementptr inbounds float, float* %10, i64 %563
  %565 = bitcast float* %564 to <32 x float>*
  store <32 x float> %561, <32 x float>* %565, align 64, !tbaa !823
  %566 = load <32 x float>, <32 x float>* %266, align 64, !tbaa !811
  %567 = fadd <32 x float> %327, %566
  %568 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %567, <32 x float> %330, <32 x float> %333)
  %569 = fcmp ogt <32 x float> %568, zeroinitializer
  %570 = select <32 x i1> %569, <32 x float> %568, <32 x float> zeroinitializer
  %571 = mul i64 %indvars.iv42, 3848290697216
  %sext69 = add i64 %571, 3710851743744
  %572 = ashr exact i64 %sext69, 32
  %573 = getelementptr inbounds float, float* %10, i64 %572
  %574 = bitcast float* %573 to <32 x float>*
  store <32 x float> %570, <32 x float>* %574, align 64, !tbaa !823
  %575 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %576 = tail call i32 %575(i32 1, i32 %22, i8* %40)
  %indvars.iv.next43 = add nsw i64 %indvars.iv42, 1
  %577 = icmp slt i64 %indvars.iv.next43, %38
  br i1 %577, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !826 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !828, metadata !DIExpression()), !dbg !831
  call void @llvm.dbg.value(metadata i8* %1, metadata !829, metadata !DIExpression()), !dbg !831
  call void @llvm.dbg.value(metadata i32 %2, metadata !830, metadata !DIExpression()), !dbg !831
  %3 = bitcast i8* %0 to %1**, !dbg !831
  %4 = load %1*, %1** %3, align 8, !dbg !831
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !831
  %6 = bitcast i8* %5 to %1**, !dbg !831
  %7 = load %1*, %1** %6, align 8, !dbg !831
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !831
  %9 = bitcast i8* %8 to %1**, !dbg !831
  %10 = load %1*, %1** %9, align 8, !dbg !831
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !831
  %12 = bitcast i8* %11 to %1**, !dbg !831
  %13 = load %1*, %1** %12, align 8, !dbg !831
  %14 = getelementptr inbounds i8, i8* %0, i64 32, !dbg !831
  %15 = bitcast i8* %14 to %1**, !dbg !831
  %16 = load %1*, %1** %15, align 8, !dbg !831
  %17 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !831
  %18 = load i8*, i8** %17, align 8, !dbg !831
  %19 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !831
  %20 = load i8*, i8** %19, align 8, !dbg !831
  %21 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !831
  %22 = load i8*, i8** %21, align 8, !dbg !831
  %23 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !831
  %24 = load i8*, i8** %23, align 8, !dbg !831
  %25 = getelementptr inbounds %1, %1* %16, i64 0, i32 0, !dbg !831
  %26 = load i8*, i8** %25, align 8, !dbg !831
  %27 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1_compute_(i8* %18, i8* %20, i8* %26, i8* %22, i8* %24), !dbg !831
  ret i32 %27, !dbg !831
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %5 = alloca %49, align 8
  %6 = getelementptr inbounds %49, %49* %5, i64 0, i32 0
  store i8* %0, i8** %6, align 8
  %7 = getelementptr inbounds %49, %49* %5, i64 0, i32 1
  store i8* %1, i8** %7, align 8
  %8 = getelementptr inbounds %49, %49* %5, i64 0, i32 2
  store i8* %2, i8** %8, align 8
  %9 = getelementptr inbounds %49, %49* %5, i64 0, i32 3
  store i8* %3, i8** %9, align 8
  %10 = getelementptr inbounds %49, %49* %5, i64 0, i32 4
  store i8* %4, i8** %10, align 8
  %11 = bitcast %49* %5 to i8*
  %12 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %13 = call i32 %12(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.45, i8* nonnull %11, i32 0)
  ret i32 %13
}

; Function Attrs: nounwind
define private i32 @__tvm_parallel_lambda.45(i32, %0* nocapture readonly, i8* nocapture readonly) #3 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds i8, i8* %2, i64 16
  %9 = bitcast i8* %8 to float**
  %10 = load float*, float** %9, align 8
  %11 = getelementptr inbounds i8, i8* %2, i64 24
  %12 = bitcast i8* %11 to float**
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds i8, i8* %2, i64 32
  %15 = bitcast i8* %14 to float**
  %16 = load float*, float** %15, align 8
  %17 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = add nsw i32 %18, 111
  %20 = sdiv i32 %19, %18
  %21 = add nsw i32 %0, 1
  %22 = mul nsw i32 %20, %21
  %23 = icmp slt i32 %22, 112
  %24 = select i1 %23, i32 %22, i32 112
  %25 = mul nsw i32 %20, %0
  %26 = icmp slt i32 %25, 112
  %27 = select i1 %26, i32 %25, i32 112
  %28 = icmp slt i32 %27, %24
  br i1 %28, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %29 = add i32 %27, 1
  %30 = sext i32 %29 to i64
  %31 = add nsw i64 %30, -1
  %32 = sext i32 %24 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end6.1
  %indvars.iv46 = phi i64 [ %31, %for_body.lr.ph ], [ %indvars.iv.next47, %for_end6.1 ]
  %33 = trunc i64 %indvars.iv46 to i32
  %34 = srem i32 %33, 7
  %35 = mul nsw i32 %34, 14336
  %36 = sdiv i32 %33, 7
  %37 = shl i32 %36, 15
  %38 = sext i32 %35 to i64
  %39 = sext i32 %37 to i64
  br label %for_body5

for_end:                                          ; preds = %for_end6.1, %entry
  ret i32 0

for_body5:                                        ; preds = %for_body5, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body5 ]
  %40 = phi <32 x float> [ zeroinitializer, %for_body ], [ %93, %for_body5 ]
  %41 = phi <32 x float> [ zeroinitializer, %for_body ], [ %87, %for_body5 ]
  %42 = phi <32 x float> [ zeroinitializer, %for_body ], [ %81, %for_body5 ]
  %43 = phi <32 x float> [ zeroinitializer, %for_body ], [ %75, %for_body5 ]
  %44 = phi <32 x float> [ zeroinitializer, %for_body ], [ %69, %for_body5 ]
  %45 = phi <32 x float> [ zeroinitializer, %for_body ], [ %63, %for_body5 ]
  %46 = phi <32 x float> [ zeroinitializer, %for_body ], [ %57, %for_body5 ]
  %47 = add nsw i64 %indvars.iv, %38
  %48 = getelementptr inbounds float, float* %4, i64 %47
  %49 = load float, float* %48, align 4, !tbaa !832
  %50 = insertelement <32 x float> undef, float %49, i32 0
  %51 = shufflevector <32 x float> %50, <32 x float> undef, <32 x i32> zeroinitializer
  %52 = shl i64 %indvars.iv, 5
  %53 = add nsw i64 %52, %39
  %54 = getelementptr inbounds float, float* %7, i64 %53
  %55 = bitcast float* %54 to <32 x float>*
  %56 = load <32 x float>, <32 x float>* %55, align 64, !tbaa !835
  %57 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %51, <32 x float> %56, <32 x float> %46)
  %58 = add nsw i64 %47, 1024
  %59 = getelementptr inbounds float, float* %4, i64 %58
  %60 = load float, float* %59, align 4, !tbaa !832
  %61 = insertelement <32 x float> undef, float %60, i32 0
  %62 = shufflevector <32 x float> %61, <32 x float> undef, <32 x i32> zeroinitializer
  %63 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %62, <32 x float> %56, <32 x float> %45)
  %64 = add nsw i64 %47, 2048
  %65 = getelementptr inbounds float, float* %4, i64 %64
  %66 = load float, float* %65, align 4, !tbaa !832
  %67 = insertelement <32 x float> undef, float %66, i32 0
  %68 = shufflevector <32 x float> %67, <32 x float> undef, <32 x i32> zeroinitializer
  %69 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %68, <32 x float> %56, <32 x float> %44)
  %70 = add nsw i64 %47, 3072
  %71 = getelementptr inbounds float, float* %4, i64 %70
  %72 = load float, float* %71, align 4, !tbaa !832
  %73 = insertelement <32 x float> undef, float %72, i32 0
  %74 = shufflevector <32 x float> %73, <32 x float> undef, <32 x i32> zeroinitializer
  %75 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %74, <32 x float> %56, <32 x float> %43)
  %76 = add nsw i64 %47, 4096
  %77 = getelementptr inbounds float, float* %4, i64 %76
  %78 = load float, float* %77, align 4, !tbaa !832
  %79 = insertelement <32 x float> undef, float %78, i32 0
  %80 = shufflevector <32 x float> %79, <32 x float> undef, <32 x i32> zeroinitializer
  %81 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %80, <32 x float> %56, <32 x float> %42)
  %82 = add nsw i64 %47, 5120
  %83 = getelementptr inbounds float, float* %4, i64 %82
  %84 = load float, float* %83, align 4, !tbaa !832
  %85 = insertelement <32 x float> undef, float %84, i32 0
  %86 = shufflevector <32 x float> %85, <32 x float> undef, <32 x i32> zeroinitializer
  %87 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %86, <32 x float> %56, <32 x float> %41)
  %88 = add nsw i64 %47, 6144
  %89 = getelementptr inbounds float, float* %4, i64 %88
  %90 = load float, float* %89, align 4, !tbaa !832
  %91 = insertelement <32 x float> undef, float %90, i32 0
  %92 = shufflevector <32 x float> %91, <32 x float> undef, <32 x i32> zeroinitializer
  %93 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %92, <32 x float> %56, <32 x float> %40)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 512
  br i1 %exitcond, label %for_end6, label %for_body5, !prof !29

for_end6:                                         ; preds = %for_body5
  %94 = add nsw i64 %38, 100352
  %95 = or i64 %39, 16384
  br label %for_body5.1

for_body5.1:                                      ; preds = %for_body5.1, %for_end6
  %indvars.iv.1 = phi i64 [ 0, %for_end6 ], [ %indvars.iv.next.1, %for_body5.1 ]
  %96 = phi <32 x float> [ %93, %for_end6 ], [ %149, %for_body5.1 ]
  %97 = phi <32 x float> [ %87, %for_end6 ], [ %143, %for_body5.1 ]
  %98 = phi <32 x float> [ %81, %for_end6 ], [ %137, %for_body5.1 ]
  %99 = phi <32 x float> [ %75, %for_end6 ], [ %131, %for_body5.1 ]
  %100 = phi <32 x float> [ %69, %for_end6 ], [ %125, %for_body5.1 ]
  %101 = phi <32 x float> [ %63, %for_end6 ], [ %119, %for_body5.1 ]
  %102 = phi <32 x float> [ %57, %for_end6 ], [ %113, %for_body5.1 ]
  %103 = add nsw i64 %94, %indvars.iv.1
  %104 = getelementptr inbounds float, float* %4, i64 %103
  %105 = load float, float* %104, align 4, !tbaa !832
  %106 = insertelement <32 x float> undef, float %105, i32 0
  %107 = shufflevector <32 x float> %106, <32 x float> undef, <32 x i32> zeroinitializer
  %108 = shl i64 %indvars.iv.1, 5
  %109 = add nsw i64 %95, %108
  %110 = getelementptr inbounds float, float* %7, i64 %109
  %111 = bitcast float* %110 to <32 x float>*
  %112 = load <32 x float>, <32 x float>* %111, align 64, !tbaa !835
  %113 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %107, <32 x float> %112, <32 x float> %102)
  %114 = add nsw i64 %103, 1024
  %115 = getelementptr inbounds float, float* %4, i64 %114
  %116 = load float, float* %115, align 4, !tbaa !832
  %117 = insertelement <32 x float> undef, float %116, i32 0
  %118 = shufflevector <32 x float> %117, <32 x float> undef, <32 x i32> zeroinitializer
  %119 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %118, <32 x float> %112, <32 x float> %101)
  %120 = add nsw i64 %103, 2048
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = load float, float* %121, align 4, !tbaa !832
  %123 = insertelement <32 x float> undef, float %122, i32 0
  %124 = shufflevector <32 x float> %123, <32 x float> undef, <32 x i32> zeroinitializer
  %125 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %124, <32 x float> %112, <32 x float> %100)
  %126 = add nsw i64 %103, 3072
  %127 = getelementptr inbounds float, float* %4, i64 %126
  %128 = load float, float* %127, align 4, !tbaa !832
  %129 = insertelement <32 x float> undef, float %128, i32 0
  %130 = shufflevector <32 x float> %129, <32 x float> undef, <32 x i32> zeroinitializer
  %131 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %130, <32 x float> %112, <32 x float> %99)
  %132 = add nsw i64 %103, 4096
  %133 = getelementptr inbounds float, float* %4, i64 %132
  %134 = load float, float* %133, align 4, !tbaa !832
  %135 = insertelement <32 x float> undef, float %134, i32 0
  %136 = shufflevector <32 x float> %135, <32 x float> undef, <32 x i32> zeroinitializer
  %137 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %136, <32 x float> %112, <32 x float> %98)
  %138 = add nsw i64 %103, 5120
  %139 = getelementptr inbounds float, float* %4, i64 %138
  %140 = load float, float* %139, align 4, !tbaa !832
  %141 = insertelement <32 x float> undef, float %140, i32 0
  %142 = shufflevector <32 x float> %141, <32 x float> undef, <32 x i32> zeroinitializer
  %143 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %142, <32 x float> %112, <32 x float> %97)
  %144 = add nsw i64 %103, 6144
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = load float, float* %145, align 4, !tbaa !832
  %147 = insertelement <32 x float> undef, float %146, i32 0
  %148 = shufflevector <32 x float> %147, <32 x float> undef, <32 x i32> zeroinitializer
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %148, <32 x float> %112, <32 x float> %96)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 512
  br i1 %exitcond.1, label %for_end6.1, label %for_body5.1, !prof !29

for_end6.1:                                       ; preds = %for_body5.1
  %150 = mul nsw i64 %indvars.iv46, 224
  %151 = shl nsw i32 %36, 5
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds float, float* %16, i64 %152
  %154 = bitcast float* %153 to <32 x float>*
  %155 = load <32 x float>, <32 x float>* %154, align 64, !tbaa !838
  %156 = getelementptr inbounds float, float* %13, i64 %152
  %157 = bitcast float* %156 to <32 x float>*
  %158 = load <32 x float>, <32 x float>* %157, align 64, !tbaa !841
  %159 = fadd <32 x float> %158, %113
  %160 = fadd <32 x float> %155, %159
  %161 = fcmp ogt <32 x float> %160, zeroinitializer
  %162 = select <32 x i1> %161, <32 x float> %160, <32 x float> zeroinitializer
  %163 = getelementptr inbounds float, float* %10, i64 %150
  %164 = bitcast float* %163 to <32 x float>*
  store <32 x float> %162, <32 x float>* %164, align 64, !tbaa !844
  %165 = add nsw i64 %150, 32
  %166 = fadd <32 x float> %158, %119
  %167 = fadd <32 x float> %155, %166
  %168 = fcmp ogt <32 x float> %167, zeroinitializer
  %169 = select <32 x i1> %168, <32 x float> %167, <32 x float> zeroinitializer
  %170 = getelementptr inbounds float, float* %10, i64 %165
  %171 = bitcast float* %170 to <32 x float>*
  store <32 x float> %169, <32 x float>* %171, align 64, !tbaa !844
  %172 = add nsw i64 %150, 64
  %173 = fadd <32 x float> %158, %125
  %174 = fadd <32 x float> %155, %173
  %175 = fcmp ogt <32 x float> %174, zeroinitializer
  %176 = select <32 x i1> %175, <32 x float> %174, <32 x float> zeroinitializer
  %177 = getelementptr inbounds float, float* %10, i64 %172
  %178 = bitcast float* %177 to <32 x float>*
  store <32 x float> %176, <32 x float>* %178, align 64, !tbaa !844
  %179 = add nsw i64 %150, 96
  %180 = fadd <32 x float> %158, %131
  %181 = fadd <32 x float> %155, %180
  %182 = fcmp ogt <32 x float> %181, zeroinitializer
  %183 = select <32 x i1> %182, <32 x float> %181, <32 x float> zeroinitializer
  %184 = getelementptr inbounds float, float* %10, i64 %179
  %185 = bitcast float* %184 to <32 x float>*
  store <32 x float> %183, <32 x float>* %185, align 64, !tbaa !844
  %186 = add nsw i64 %150, 128
  %187 = fadd <32 x float> %158, %137
  %188 = fadd <32 x float> %155, %187
  %189 = fcmp ogt <32 x float> %188, zeroinitializer
  %190 = select <32 x i1> %189, <32 x float> %188, <32 x float> zeroinitializer
  %191 = getelementptr inbounds float, float* %10, i64 %186
  %192 = bitcast float* %191 to <32 x float>*
  store <32 x float> %190, <32 x float>* %192, align 64, !tbaa !844
  %193 = add nsw i64 %150, 160
  %194 = fadd <32 x float> %158, %143
  %195 = fadd <32 x float> %155, %194
  %196 = fcmp ogt <32 x float> %195, zeroinitializer
  %197 = select <32 x i1> %196, <32 x float> %195, <32 x float> zeroinitializer
  %198 = getelementptr inbounds float, float* %10, i64 %193
  %199 = bitcast float* %198 to <32 x float>*
  store <32 x float> %197, <32 x float>* %199, align 64, !tbaa !844
  %200 = add nsw i64 %150, 192
  %201 = fadd <32 x float> %158, %149
  %202 = fadd <32 x float> %155, %201
  %203 = fcmp ogt <32 x float> %202, zeroinitializer
  %204 = select <32 x i1> %203, <32 x float> %202, <32 x float> zeroinitializer
  %205 = getelementptr inbounds float, float* %10, i64 %200
  %206 = bitcast float* %205 to <32 x float>*
  store <32 x float> %204, <32 x float>* %206, align 64, !tbaa !844
  %indvars.iv.next47 = add nsw i64 %indvars.iv46, 1
  %207 = icmp slt i64 %indvars.iv.next47, %32
  br i1 %207, label %for_body, label %for_end, !prof !19
}

define dllexport i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !847 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !849, metadata !DIExpression()), !dbg !852
  call void @llvm.dbg.value(metadata i8* %1, metadata !850, metadata !DIExpression()), !dbg !852
  call void @llvm.dbg.value(metadata i32 %2, metadata !851, metadata !DIExpression()), !dbg !852
  %3 = bitcast i8* %0 to %1**, !dbg !852
  %4 = load %1*, %1** %3, align 8, !dbg !852
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !852
  %6 = bitcast i8* %5 to %1**, !dbg !852
  %7 = load %1*, %1** %6, align 8, !dbg !852
  %8 = getelementptr inbounds i8, i8* %0, i64 16, !dbg !852
  %9 = bitcast i8* %8 to %1**, !dbg !852
  %10 = load %1*, %1** %9, align 8, !dbg !852
  %11 = getelementptr inbounds i8, i8* %0, i64 24, !dbg !852
  %12 = bitcast i8* %11 to %1**, !dbg !852
  %13 = load %1*, %1** %12, align 8, !dbg !852
  %14 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !852
  %15 = load i8*, i8** %14, align 8, !dbg !852
  %16 = getelementptr inbounds %1, %1* %4, i64 0, i32 1, i32 1, !dbg !852
  %17 = load i32, i32* %16, align 4, !dbg !852
  %18 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !852
  %19 = load i8*, i8** %18, align 8, !dbg !852
  %20 = getelementptr inbounds %1, %1* %10, i64 0, i32 0, !dbg !852
  %21 = load i8*, i8** %20, align 8, !dbg !852
  %22 = getelementptr inbounds %1, %1* %13, i64 0, i32 0, !dbg !852
  %23 = load i8*, i8** %22, align 8, !dbg !852
  %24 = tail call fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3_compute_(i8* %15, i8* %19, i8* %23, i8* %21, i32 %17), !dbg !852
  ret i32 %24, !dbg !852
}

; Function Attrs: noinline
define private fastcc i32 @fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3_compute_(i8* noalias, i8* noalias, i8* noalias, i8* noalias, i32) unnamed_addr #0 {
entry:
  %5 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %6 = tail call i8* %5(i32 1, i32 %4, i64 861184, i32 2, i32 32)
  %7 = alloca %50, align 8
  %8 = getelementptr inbounds %50, %50* %7, i64 0, i32 0
  store i8* %6, i8** %8, align 8
  %9 = getelementptr inbounds %50, %50* %7, i64 0, i32 1
  store i8* %0, i8** %9, align 8
  %10 = bitcast %50* %7 to i8*
  %11 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %12 = call i32 %11(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.46, i8* nonnull %10, i32 0)
  %13 = icmp eq i32 %12, 0
  br i1 %13, label %call_end, label %call_fail, !prof !19

call_fail:                                        ; preds = %call_end, %call_end2, %entry
  %merge = phi i32 [ %12, %entry ], [ 0, %call_end2 ], [ %22, %call_end ]
  ret i32 %merge

call_end:                                         ; preds = %entry
  %14 = alloca %51, align 8
  %15 = getelementptr inbounds %51, %51* %14, i64 0, i32 0
  store i8* %6, i8** %15, align 8
  %16 = getelementptr inbounds %51, %51* %14, i64 0, i32 1
  store i8* %1, i8** %16, align 8
  %17 = getelementptr inbounds %51, %51* %14, i64 0, i32 2
  store i8* %2, i8** %17, align 8
  %18 = getelementptr inbounds %51, %51* %14, i64 0, i32 3
  store i8* %3, i8** %18, align 8
  %19 = getelementptr inbounds %51, %51* %14, i64 0, i32 4
  store i32 %4, i32* %19, align 8
  %20 = bitcast %51* %14 to i8*
  %21 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %22 = call i32 %21(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.47, i8* nonnull %20, i32 0)
  %23 = icmp eq i32 %22, 0
  br i1 %23, label %call_end2, label %call_fail, !prof !19

call_end2:                                        ; preds = %call_end
  %24 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %25 = call i32 %24(i32 1, i32 %4, i8* %6)
  br label %call_fail
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.46(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 57
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 58
  %15 = select i1 %14, i32 %13, i32 58
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 58
  %18 = select i1 %17, i32 %16, i32 58
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.preheader, label %for_end, !prof !19

for_body.preheader:                               ; preds = %entry
  br label %for_body

for_body:                                         ; preds = %for_body.preheader, %for_end3
  %20 = phi i32 [ %408, %for_end3 ], [ %18, %for_body.preheader ]
  %21 = mul nsw i32 %20, 3712
  %.off = add i32 %20, -1
  %22 = icmp ult i32 %.off, 56
  %23 = mul nsw i32 %20, 3584
  br i1 %22, label %for_body2.us.preheader, label %for_body2.preheader

for_body2.preheader:                              ; preds = %for_body
  br label %for_body2

for_body2.us.preheader:                           ; preds = %for_body
  br label %for_body2.us

for_body2.us:                                     ; preds = %for_body2.us.preheader, %for_end6.us
  %indvars.iv24 = phi i64 [ %indvars.iv.next25, %for_end6.us ], [ 0, %for_body2.us.preheader ]
  %24 = shl nsw i64 %indvars.iv24, 6
  %25 = trunc i64 %indvars.iv24 to i32
  %26 = add i32 %25, -1
  %27 = icmp ult i32 %26, 56
  %28 = trunc i64 %24 to i32
  %29 = add i32 %21, %28
  br i1 %27, label %vector.body, label %vector.body35

for_end6.us:                                      ; preds = %vector.body35, %vector.body
  %indvars.iv.next25 = add nuw nsw i64 %indvars.iv24, 1
  %exitcond27 = icmp eq i64 %indvars.iv.next25, 58
  br i1 %exitcond27, label %for_end3, label %for_body2.us, !prof !29

vector.body:                                      ; preds = %for_body2.us
  %30 = trunc i64 %24 to i32
  %31 = add i32 %30, -3648
  %32 = add i32 %31, %23
  %33 = sext i32 %32 to i64
  %34 = getelementptr inbounds float, float* %7, i64 %33
  %35 = bitcast float* %34 to <4 x i32>*
  %wide.load = load <4 x i32>, <4 x i32>* %35, align 4, !tbaa !853
  %36 = sext i32 %29 to i64
  %37 = getelementptr inbounds float, float* %4, i64 %36
  %38 = bitcast float* %37 to <4 x i32>*
  store <4 x i32> %wide.load, <4 x i32>* %38, align 4, !tbaa !856
  %39 = or i64 %24, 4
  %40 = trunc i64 %39 to i32
  %41 = add i32 %21, %40
  %42 = trunc i64 %39 to i32
  %43 = add i32 %42, -3648
  %44 = add i32 %43, %23
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %7, i64 %45
  %47 = bitcast float* %46 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %47, align 4, !tbaa !853
  %48 = sext i32 %41 to i64
  %49 = getelementptr inbounds float, float* %4, i64 %48
  %50 = bitcast float* %49 to <4 x i32>*
  store <4 x i32> %wide.load.1, <4 x i32>* %50, align 4, !tbaa !856
  %51 = or i64 %24, 8
  %52 = trunc i64 %51 to i32
  %53 = add i32 %21, %52
  %54 = trunc i64 %51 to i32
  %55 = add i32 %54, -3648
  %56 = add i32 %55, %23
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds float, float* %7, i64 %57
  %59 = bitcast float* %58 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %59, align 4, !tbaa !853
  %60 = sext i32 %53 to i64
  %61 = getelementptr inbounds float, float* %4, i64 %60
  %62 = bitcast float* %61 to <4 x i32>*
  store <4 x i32> %wide.load.2, <4 x i32>* %62, align 4, !tbaa !856
  %63 = or i64 %24, 12
  %64 = trunc i64 %63 to i32
  %65 = add i32 %21, %64
  %66 = trunc i64 %63 to i32
  %67 = add i32 %66, -3648
  %68 = add i32 %67, %23
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds float, float* %7, i64 %69
  %71 = bitcast float* %70 to <4 x i32>*
  %wide.load.3 = load <4 x i32>, <4 x i32>* %71, align 4, !tbaa !853
  %72 = sext i32 %65 to i64
  %73 = getelementptr inbounds float, float* %4, i64 %72
  %74 = bitcast float* %73 to <4 x i32>*
  store <4 x i32> %wide.load.3, <4 x i32>* %74, align 4, !tbaa !856
  %75 = or i64 %24, 16
  %76 = trunc i64 %75 to i32
  %77 = add i32 %21, %76
  %78 = trunc i64 %75 to i32
  %79 = add i32 %78, -3648
  %80 = add i32 %79, %23
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to <4 x i32>*
  %wide.load.4 = load <4 x i32>, <4 x i32>* %83, align 4, !tbaa !853
  %84 = sext i32 %77 to i64
  %85 = getelementptr inbounds float, float* %4, i64 %84
  %86 = bitcast float* %85 to <4 x i32>*
  store <4 x i32> %wide.load.4, <4 x i32>* %86, align 4, !tbaa !856
  %87 = or i64 %24, 20
  %88 = trunc i64 %87 to i32
  %89 = add i32 %21, %88
  %90 = trunc i64 %87 to i32
  %91 = add i32 %90, -3648
  %92 = add i32 %91, %23
  %93 = sext i32 %92 to i64
  %94 = getelementptr inbounds float, float* %7, i64 %93
  %95 = bitcast float* %94 to <4 x i32>*
  %wide.load.5 = load <4 x i32>, <4 x i32>* %95, align 4, !tbaa !853
  %96 = sext i32 %89 to i64
  %97 = getelementptr inbounds float, float* %4, i64 %96
  %98 = bitcast float* %97 to <4 x i32>*
  store <4 x i32> %wide.load.5, <4 x i32>* %98, align 4, !tbaa !856
  %99 = or i64 %24, 24
  %100 = trunc i64 %99 to i32
  %101 = add i32 %21, %100
  %102 = trunc i64 %99 to i32
  %103 = add i32 %102, -3648
  %104 = add i32 %103, %23
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds float, float* %7, i64 %105
  %107 = bitcast float* %106 to <4 x i32>*
  %wide.load.6 = load <4 x i32>, <4 x i32>* %107, align 4, !tbaa !853
  %108 = sext i32 %101 to i64
  %109 = getelementptr inbounds float, float* %4, i64 %108
  %110 = bitcast float* %109 to <4 x i32>*
  store <4 x i32> %wide.load.6, <4 x i32>* %110, align 4, !tbaa !856
  %111 = or i64 %24, 28
  %112 = trunc i64 %111 to i32
  %113 = add i32 %21, %112
  %114 = trunc i64 %111 to i32
  %115 = add i32 %114, -3648
  %116 = add i32 %115, %23
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds float, float* %7, i64 %117
  %119 = bitcast float* %118 to <4 x i32>*
  %wide.load.7 = load <4 x i32>, <4 x i32>* %119, align 4, !tbaa !853
  %120 = sext i32 %113 to i64
  %121 = getelementptr inbounds float, float* %4, i64 %120
  %122 = bitcast float* %121 to <4 x i32>*
  store <4 x i32> %wide.load.7, <4 x i32>* %122, align 4, !tbaa !856
  %123 = or i64 %24, 32
  %124 = trunc i64 %123 to i32
  %125 = add i32 %21, %124
  %126 = trunc i64 %123 to i32
  %127 = add i32 %126, -3648
  %128 = add i32 %127, %23
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds float, float* %7, i64 %129
  %131 = bitcast float* %130 to <4 x i32>*
  %wide.load.8 = load <4 x i32>, <4 x i32>* %131, align 4, !tbaa !853
  %132 = sext i32 %125 to i64
  %133 = getelementptr inbounds float, float* %4, i64 %132
  %134 = bitcast float* %133 to <4 x i32>*
  store <4 x i32> %wide.load.8, <4 x i32>* %134, align 4, !tbaa !856
  %135 = or i64 %24, 36
  %136 = trunc i64 %135 to i32
  %137 = add i32 %21, %136
  %138 = trunc i64 %135 to i32
  %139 = add i32 %138, -3648
  %140 = add i32 %139, %23
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to <4 x i32>*
  %wide.load.9 = load <4 x i32>, <4 x i32>* %143, align 4, !tbaa !853
  %144 = sext i32 %137 to i64
  %145 = getelementptr inbounds float, float* %4, i64 %144
  %146 = bitcast float* %145 to <4 x i32>*
  store <4 x i32> %wide.load.9, <4 x i32>* %146, align 4, !tbaa !856
  %147 = or i64 %24, 40
  %148 = trunc i64 %147 to i32
  %149 = add i32 %21, %148
  %150 = trunc i64 %147 to i32
  %151 = add i32 %150, -3648
  %152 = add i32 %151, %23
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds float, float* %7, i64 %153
  %155 = bitcast float* %154 to <4 x i32>*
  %wide.load.10 = load <4 x i32>, <4 x i32>* %155, align 4, !tbaa !853
  %156 = sext i32 %149 to i64
  %157 = getelementptr inbounds float, float* %4, i64 %156
  %158 = bitcast float* %157 to <4 x i32>*
  store <4 x i32> %wide.load.10, <4 x i32>* %158, align 4, !tbaa !856
  %159 = or i64 %24, 44
  %160 = trunc i64 %159 to i32
  %161 = add i32 %21, %160
  %162 = trunc i64 %159 to i32
  %163 = add i32 %162, -3648
  %164 = add i32 %163, %23
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds float, float* %7, i64 %165
  %167 = bitcast float* %166 to <4 x i32>*
  %wide.load.11 = load <4 x i32>, <4 x i32>* %167, align 4, !tbaa !853
  %168 = sext i32 %161 to i64
  %169 = getelementptr inbounds float, float* %4, i64 %168
  %170 = bitcast float* %169 to <4 x i32>*
  store <4 x i32> %wide.load.11, <4 x i32>* %170, align 4, !tbaa !856
  %171 = or i64 %24, 48
  %172 = trunc i64 %171 to i32
  %173 = add i32 %21, %172
  %174 = trunc i64 %171 to i32
  %175 = add i32 %174, -3648
  %176 = add i32 %175, %23
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds float, float* %7, i64 %177
  %179 = bitcast float* %178 to <4 x i32>*
  %wide.load.12 = load <4 x i32>, <4 x i32>* %179, align 4, !tbaa !853
  %180 = sext i32 %173 to i64
  %181 = getelementptr inbounds float, float* %4, i64 %180
  %182 = bitcast float* %181 to <4 x i32>*
  store <4 x i32> %wide.load.12, <4 x i32>* %182, align 4, !tbaa !856
  %183 = or i64 %24, 52
  %184 = trunc i64 %183 to i32
  %185 = add i32 %21, %184
  %186 = trunc i64 %183 to i32
  %187 = add i32 %186, -3648
  %188 = add i32 %187, %23
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds float, float* %7, i64 %189
  %191 = bitcast float* %190 to <4 x i32>*
  %wide.load.13 = load <4 x i32>, <4 x i32>* %191, align 4, !tbaa !853
  %192 = sext i32 %185 to i64
  %193 = getelementptr inbounds float, float* %4, i64 %192
  %194 = bitcast float* %193 to <4 x i32>*
  store <4 x i32> %wide.load.13, <4 x i32>* %194, align 4, !tbaa !856
  %195 = or i64 %24, 56
  %196 = trunc i64 %195 to i32
  %197 = add i32 %21, %196
  %198 = trunc i64 %195 to i32
  %199 = add i32 %198, -3648
  %200 = add i32 %199, %23
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds float, float* %7, i64 %201
  %203 = bitcast float* %202 to <4 x i32>*
  %wide.load.14 = load <4 x i32>, <4 x i32>* %203, align 4, !tbaa !853
  %204 = sext i32 %197 to i64
  %205 = getelementptr inbounds float, float* %4, i64 %204
  %206 = bitcast float* %205 to <4 x i32>*
  store <4 x i32> %wide.load.14, <4 x i32>* %206, align 4, !tbaa !856
  %207 = or i64 %24, 60
  %208 = trunc i64 %207 to i32
  %209 = add i32 %21, %208
  %210 = trunc i64 %207 to i32
  %211 = add i32 %210, -3648
  %212 = add i32 %211, %23
  %213 = sext i32 %212 to i64
  %214 = getelementptr inbounds float, float* %7, i64 %213
  %215 = bitcast float* %214 to <4 x i32>*
  %wide.load.15 = load <4 x i32>, <4 x i32>* %215, align 4, !tbaa !853
  %216 = sext i32 %209 to i64
  %217 = getelementptr inbounds float, float* %4, i64 %216
  %218 = bitcast float* %217 to <4 x i32>*
  store <4 x i32> %wide.load.15, <4 x i32>* %218, align 4, !tbaa !856
  br label %for_end6.us

vector.body35:                                    ; preds = %for_body2.us
  %219 = sext i32 %29 to i64
  %220 = getelementptr inbounds float, float* %4, i64 %219
  %221 = bitcast float* %220 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %221, align 4, !tbaa !856
  %222 = trunc i64 %24 to i32
  %223 = or i32 %222, 4
  %224 = add i32 %21, %223
  %225 = sext i32 %224 to i64
  %226 = getelementptr inbounds float, float* %4, i64 %225
  %227 = bitcast float* %226 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %227, align 4, !tbaa !856
  %228 = trunc i64 %24 to i32
  %229 = or i32 %228, 8
  %230 = add i32 %21, %229
  %231 = sext i32 %230 to i64
  %232 = getelementptr inbounds float, float* %4, i64 %231
  %233 = bitcast float* %232 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %233, align 4, !tbaa !856
  %234 = trunc i64 %24 to i32
  %235 = or i32 %234, 12
  %236 = add i32 %21, %235
  %237 = sext i32 %236 to i64
  %238 = getelementptr inbounds float, float* %4, i64 %237
  %239 = bitcast float* %238 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %239, align 4, !tbaa !856
  %240 = trunc i64 %24 to i32
  %241 = or i32 %240, 16
  %242 = add i32 %21, %241
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds float, float* %4, i64 %243
  %245 = bitcast float* %244 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %245, align 4, !tbaa !856
  %246 = trunc i64 %24 to i32
  %247 = or i32 %246, 20
  %248 = add i32 %21, %247
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds float, float* %4, i64 %249
  %251 = bitcast float* %250 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %251, align 4, !tbaa !856
  %252 = trunc i64 %24 to i32
  %253 = or i32 %252, 24
  %254 = add i32 %21, %253
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds float, float* %4, i64 %255
  %257 = bitcast float* %256 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %257, align 4, !tbaa !856
  %258 = trunc i64 %24 to i32
  %259 = or i32 %258, 28
  %260 = add i32 %21, %259
  %261 = sext i32 %260 to i64
  %262 = getelementptr inbounds float, float* %4, i64 %261
  %263 = bitcast float* %262 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %263, align 4, !tbaa !856
  %264 = trunc i64 %24 to i32
  %265 = or i32 %264, 32
  %266 = add i32 %21, %265
  %267 = sext i32 %266 to i64
  %268 = getelementptr inbounds float, float* %4, i64 %267
  %269 = bitcast float* %268 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %269, align 4, !tbaa !856
  %270 = trunc i64 %24 to i32
  %271 = or i32 %270, 36
  %272 = add i32 %21, %271
  %273 = sext i32 %272 to i64
  %274 = getelementptr inbounds float, float* %4, i64 %273
  %275 = bitcast float* %274 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %275, align 4, !tbaa !856
  %276 = trunc i64 %24 to i32
  %277 = or i32 %276, 40
  %278 = add i32 %21, %277
  %279 = sext i32 %278 to i64
  %280 = getelementptr inbounds float, float* %4, i64 %279
  %281 = bitcast float* %280 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %281, align 4, !tbaa !856
  %282 = trunc i64 %24 to i32
  %283 = or i32 %282, 44
  %284 = add i32 %21, %283
  %285 = sext i32 %284 to i64
  %286 = getelementptr inbounds float, float* %4, i64 %285
  %287 = bitcast float* %286 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %287, align 4, !tbaa !856
  %288 = trunc i64 %24 to i32
  %289 = or i32 %288, 48
  %290 = add i32 %21, %289
  %291 = sext i32 %290 to i64
  %292 = getelementptr inbounds float, float* %4, i64 %291
  %293 = bitcast float* %292 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %293, align 4, !tbaa !856
  %294 = trunc i64 %24 to i32
  %295 = or i32 %294, 52
  %296 = add i32 %21, %295
  %297 = sext i32 %296 to i64
  %298 = getelementptr inbounds float, float* %4, i64 %297
  %299 = bitcast float* %298 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %299, align 4, !tbaa !856
  %300 = trunc i64 %24 to i32
  %301 = or i32 %300, 56
  %302 = add i32 %21, %301
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds float, float* %4, i64 %303
  %305 = bitcast float* %304 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %305, align 4, !tbaa !856
  %306 = trunc i64 %24 to i32
  %307 = or i32 %306, 60
  %308 = add i32 %21, %307
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds float, float* %4, i64 %309
  %311 = bitcast float* %310 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %311, align 4, !tbaa !856
  br label %for_end6.us

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2.preheader, %for_body2
  %indvars.iv15 = phi i64 [ %indvars.iv.next16, %for_body2 ], [ 0, %for_body2.preheader ]
  %312 = shl nsw i64 %indvars.iv15, 6
  %313 = trunc i64 %312 to i32
  %314 = add i32 %21, %313
  %315 = sext i32 %314 to i64
  %316 = getelementptr inbounds float, float* %4, i64 %315
  %317 = bitcast float* %316 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %317, align 4, !tbaa !856
  %318 = trunc i64 %312 to i32
  %319 = or i32 %318, 4
  %320 = add i32 %21, %319
  %321 = sext i32 %320 to i64
  %322 = getelementptr inbounds float, float* %4, i64 %321
  %323 = bitcast float* %322 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %323, align 4, !tbaa !856
  %324 = trunc i64 %312 to i32
  %325 = or i32 %324, 8
  %326 = add i32 %21, %325
  %327 = sext i32 %326 to i64
  %328 = getelementptr inbounds float, float* %4, i64 %327
  %329 = bitcast float* %328 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %329, align 4, !tbaa !856
  %330 = trunc i64 %312 to i32
  %331 = or i32 %330, 12
  %332 = add i32 %21, %331
  %333 = sext i32 %332 to i64
  %334 = getelementptr inbounds float, float* %4, i64 %333
  %335 = bitcast float* %334 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %335, align 4, !tbaa !856
  %336 = trunc i64 %312 to i32
  %337 = or i32 %336, 16
  %338 = add i32 %21, %337
  %339 = sext i32 %338 to i64
  %340 = getelementptr inbounds float, float* %4, i64 %339
  %341 = bitcast float* %340 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %341, align 4, !tbaa !856
  %342 = trunc i64 %312 to i32
  %343 = or i32 %342, 20
  %344 = add i32 %21, %343
  %345 = sext i32 %344 to i64
  %346 = getelementptr inbounds float, float* %4, i64 %345
  %347 = bitcast float* %346 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %347, align 4, !tbaa !856
  %348 = trunc i64 %312 to i32
  %349 = or i32 %348, 24
  %350 = add i32 %21, %349
  %351 = sext i32 %350 to i64
  %352 = getelementptr inbounds float, float* %4, i64 %351
  %353 = bitcast float* %352 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %353, align 4, !tbaa !856
  %354 = trunc i64 %312 to i32
  %355 = or i32 %354, 28
  %356 = add i32 %21, %355
  %357 = sext i32 %356 to i64
  %358 = getelementptr inbounds float, float* %4, i64 %357
  %359 = bitcast float* %358 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %359, align 4, !tbaa !856
  %360 = trunc i64 %312 to i32
  %361 = or i32 %360, 32
  %362 = add i32 %21, %361
  %363 = sext i32 %362 to i64
  %364 = getelementptr inbounds float, float* %4, i64 %363
  %365 = bitcast float* %364 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %365, align 4, !tbaa !856
  %366 = trunc i64 %312 to i32
  %367 = or i32 %366, 36
  %368 = add i32 %21, %367
  %369 = sext i32 %368 to i64
  %370 = getelementptr inbounds float, float* %4, i64 %369
  %371 = bitcast float* %370 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %371, align 4, !tbaa !856
  %372 = trunc i64 %312 to i32
  %373 = or i32 %372, 40
  %374 = add i32 %21, %373
  %375 = sext i32 %374 to i64
  %376 = getelementptr inbounds float, float* %4, i64 %375
  %377 = bitcast float* %376 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %377, align 4, !tbaa !856
  %378 = trunc i64 %312 to i32
  %379 = or i32 %378, 44
  %380 = add i32 %21, %379
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds float, float* %4, i64 %381
  %383 = bitcast float* %382 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %383, align 4, !tbaa !856
  %384 = trunc i64 %312 to i32
  %385 = or i32 %384, 48
  %386 = add i32 %21, %385
  %387 = sext i32 %386 to i64
  %388 = getelementptr inbounds float, float* %4, i64 %387
  %389 = bitcast float* %388 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %389, align 4, !tbaa !856
  %390 = trunc i64 %312 to i32
  %391 = or i32 %390, 52
  %392 = add i32 %21, %391
  %393 = sext i32 %392 to i64
  %394 = getelementptr inbounds float, float* %4, i64 %393
  %395 = bitcast float* %394 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %395, align 4, !tbaa !856
  %396 = trunc i64 %312 to i32
  %397 = or i32 %396, 56
  %398 = add i32 %21, %397
  %399 = sext i32 %398 to i64
  %400 = getelementptr inbounds float, float* %4, i64 %399
  %401 = bitcast float* %400 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %401, align 4, !tbaa !856
  %402 = trunc i64 %312 to i32
  %403 = or i32 %402, 60
  %404 = add i32 %21, %403
  %405 = sext i32 %404 to i64
  %406 = getelementptr inbounds float, float* %4, i64 %405
  %407 = bitcast float* %406 to <4 x float>*
  store <4 x float> zeroinitializer, <4 x float>* %407, align 4, !tbaa !856
  %indvars.iv.next16 = add nuw nsw i64 %indvars.iv15, 1
  %exitcond17 = icmp eq i64 %indvars.iv.next16, 58
  br i1 %exitcond17, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2, %for_end6.us
  %408 = add nsw i32 %20, 1
  %409 = icmp slt i32 %408, %15
  br i1 %409, label %for_body, label %for_end, !prof !19
}

define private i32 @__tvm_parallel_lambda.47(i32, %0* nocapture readonly, i8* nocapture readonly) {
entry:
  %3 = alloca [7 x <32 x float>], align 128
  %4 = bitcast [7 x <32 x float>]* %3 to i8*
  %.sub = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0
  %5 = bitcast i8* %2 to float**
  %6 = load float*, float** %5, align 8
  %7 = getelementptr inbounds i8, i8* %2, i64 8
  %8 = bitcast i8* %7 to float**
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds i8, i8* %2, i64 16
  %11 = bitcast i8* %10 to float**
  %12 = load float*, float** %11, align 8
  %13 = getelementptr inbounds i8, i8* %2, i64 24
  %14 = bitcast i8* %13 to float**
  %15 = load float*, float** %14, align 8
  %16 = getelementptr inbounds i8, i8* %2, i64 32
  %17 = bitcast i8* %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = add nsw i32 %20, 111
  %22 = sdiv i32 %21, %20
  %23 = add nsw i32 %0, 1
  %24 = mul nsw i32 %22, %23
  %25 = icmp slt i32 %24, 112
  %26 = select i1 %25, i32 %24, i32 112
  %27 = mul nsw i32 %22, %0
  %28 = icmp slt i32 %27, 112
  %29 = select i1 %28, i32 %27, i32 112
  %30 = icmp slt i32 %29, %26
  br i1 %30, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %31 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 32
  %32 = bitcast float* %31 to <32 x float>*
  %33 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 64
  %34 = bitcast float* %33 to <32 x float>*
  %35 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 96
  %36 = bitcast float* %35 to <32 x float>*
  %37 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 128
  %38 = bitcast float* %37 to <32 x float>*
  %39 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 160
  %40 = bitcast float* %39 to <32 x float>*
  %41 = getelementptr inbounds [7 x <32 x float>], [7 x <32 x float>]* %3, i64 0, i64 0, i64 192
  %42 = bitcast float* %41 to <32 x float>*
  %43 = bitcast [7 x <32 x float>]* %3 to i8*
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end15
  %44 = phi i32 [ %29, %for_body.lr.ph ], [ %244, %for_end15 ]
  %45 = load i8* (i32, i32, i64, i32, i32)*, i8* (i32, i32, i64, i32, i32)** @__TVMBackendAllocWorkspace, align 8, !tbaa !16
  %46 = tail call i8* %45(i32 1, i32 %18, i64 7168, i32 2, i32 32)
  %47 = srem i32 %44, 56
  %48 = sdiv i32 %44, 56
  %49 = mul nsw i32 %48, 18432
  %50 = bitcast i8* %46 to float*
  %51 = sext i32 %49 to i64
  %52 = mul nsw i32 %47, 3712
  %53 = sext i32 %52 to i64
  %54 = mul nsw i32 %47, 3712
  %55 = add nsw i32 %54, 3712
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %51, 6144
  %58 = mul nsw i32 %47, 3712
  %59 = add nsw i32 %58, 7424
  %60 = sext i32 %59 to i64
  %61 = add nsw i64 %51, 12288
  br label %for_body2

for_end:                                          ; preds = %for_end15, %entry
  ret i32 0

for_body2:                                        ; preds = %for_end9.2, %for_body
  %indvar = phi i64 [ 0, %for_body ], [ %indvar.next, %for_end9.2 ]
  %62 = mul nuw nsw i64 %indvar, 896
  %scevgep = getelementptr i8, i8* %46, i64 %62
  %63 = mul nuw nsw i64 %indvar, 448
  %64 = add nsw i64 %63, %53
  call void @llvm.memset.p0i8.i64(i8* nonnull %43, i8 0, i64 896, i32 128, i1 false)
  br label %for_body8

for_end3:                                         ; preds = %for_end9.2
  %65 = mul nsw i32 %44, 1792
  %66 = shl nsw i32 %48, 5
  %67 = sext i32 %66 to i64
  %68 = getelementptr inbounds float, float* %15, i64 %67
  %69 = bitcast float* %68 to <32 x float>*
  %70 = load <32 x float>, <32 x float>* %69, align 64, !tbaa !859
  br label %for_body14

for_body8:                                        ; preds = %for_body8, %for_body2
  %indvars.iv = phi i64 [ 0, %for_body2 ], [ %indvars.iv.next, %for_body8 ]
  %71 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %156, %for_body8 ]
  %72 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %150, %for_body8 ]
  %73 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %149, %for_body8 ]
  %74 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %148, %for_body8 ]
  %75 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %147, %for_body8 ]
  %76 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %146, %for_body8 ]
  %77 = phi <32 x float> [ zeroinitializer, %for_body2 ], [ %145, %for_body8 ]
  %78 = add nsw i64 %64, %indvars.iv
  %79 = getelementptr inbounds float, float* %6, i64 %78
  %80 = load float, float* %79, align 4, !tbaa !856
  %81 = insertelement <32 x float> undef, float %80, i32 0
  %82 = shufflevector <32 x float> %81, <32 x float> undef, <32 x i32> zeroinitializer
  %83 = shl nsw i64 %indvars.iv, 5
  %84 = add nsw i64 %83, %51
  %85 = getelementptr inbounds float, float* %9, i64 %84
  %86 = bitcast float* %85 to <32 x float>*
  %87 = load <32 x float>, <32 x float>* %86, align 64, !tbaa !862
  %88 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %82, <32 x float> %87, <32 x float> %77)
  %89 = add nsw i64 %78, 64
  %90 = getelementptr inbounds float, float* %6, i64 %89
  %91 = load float, float* %90, align 4, !tbaa !856
  %92 = insertelement <32 x float> undef, float %91, i32 0
  %93 = shufflevector <32 x float> %92, <32 x float> undef, <32 x i32> zeroinitializer
  %94 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %93, <32 x float> %87, <32 x float> %76)
  %95 = add nsw i64 %78, 128
  %96 = getelementptr inbounds float, float* %6, i64 %95
  %97 = load float, float* %96, align 4, !tbaa !856
  %98 = insertelement <32 x float> undef, float %97, i32 0
  %99 = shufflevector <32 x float> %98, <32 x float> undef, <32 x i32> zeroinitializer
  %100 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %87, <32 x float> %75)
  %101 = add nsw i64 %78, 192
  %102 = getelementptr inbounds float, float* %6, i64 %101
  %103 = load float, float* %102, align 4, !tbaa !856
  %104 = insertelement <32 x float> undef, float %103, i32 0
  %105 = shufflevector <32 x float> %104, <32 x float> undef, <32 x i32> zeroinitializer
  %106 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %87, <32 x float> %74)
  %107 = add nsw i64 %78, 256
  %108 = getelementptr inbounds float, float* %6, i64 %107
  %109 = load float, float* %108, align 4, !tbaa !856
  %110 = insertelement <32 x float> undef, float %109, i32 0
  %111 = shufflevector <32 x float> %110, <32 x float> undef, <32 x i32> zeroinitializer
  %112 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %87, <32 x float> %73)
  %113 = add nsw i64 %78, 320
  %114 = getelementptr inbounds float, float* %6, i64 %113
  %115 = load float, float* %114, align 4, !tbaa !856
  %116 = insertelement <32 x float> undef, float %115, i32 0
  %117 = shufflevector <32 x float> %116, <32 x float> undef, <32 x i32> zeroinitializer
  %118 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %87, <32 x float> %72)
  %119 = add nsw i64 %78, 384
  %120 = getelementptr inbounds float, float* %6, i64 %119
  %121 = load float, float* %120, align 4, !tbaa !856
  %122 = insertelement <32 x float> undef, float %121, i32 0
  %123 = shufflevector <32 x float> %122, <32 x float> undef, <32 x i32> zeroinitializer
  %124 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %87, <32 x float> %71)
  %125 = add nsw i64 %84, 2048
  %126 = getelementptr inbounds float, float* %9, i64 %125
  %127 = bitcast float* %126 to <32 x float>*
  %128 = load <32 x float>, <32 x float>* %127, align 64, !tbaa !862
  %129 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %93, <32 x float> %128, <32 x float> %88)
  %130 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %128, <32 x float> %94)
  %131 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %128, <32 x float> %100)
  %132 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %128, <32 x float> %106)
  %133 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %128, <32 x float> %112)
  %134 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %128, <32 x float> %118)
  %135 = add nsw i64 %78, 448
  %136 = getelementptr inbounds float, float* %6, i64 %135
  %137 = load float, float* %136, align 4, !tbaa !856
  %138 = insertelement <32 x float> undef, float %137, i32 0
  %139 = shufflevector <32 x float> %138, <32 x float> undef, <32 x i32> zeroinitializer
  %140 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %139, <32 x float> %128, <32 x float> %124)
  %141 = add nsw i64 %84, 4096
  %142 = getelementptr inbounds float, float* %9, i64 %141
  %143 = bitcast float* %142 to <32 x float>*
  %144 = load <32 x float>, <32 x float>* %143, align 64, !tbaa !862
  %145 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %99, <32 x float> %144, <32 x float> %129)
  %146 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %105, <32 x float> %144, <32 x float> %130)
  %147 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %111, <32 x float> %144, <32 x float> %131)
  %148 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %117, <32 x float> %144, <32 x float> %132)
  %149 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %123, <32 x float> %144, <32 x float> %133)
  %150 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %139, <32 x float> %144, <32 x float> %134)
  %151 = add nsw i64 %78, 512
  %152 = getelementptr inbounds float, float* %6, i64 %151
  %153 = load float, float* %152, align 4, !tbaa !856
  %154 = insertelement <32 x float> undef, float %153, i32 0
  %155 = shufflevector <32 x float> %154, <32 x float> undef, <32 x i32> zeroinitializer
  %156 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %155, <32 x float> %144, <32 x float> %140)
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 64
  br i1 %exitcond, label %for_end9, label %for_body8, !prof !29

for_end9:                                         ; preds = %for_body8
  %157 = add nsw i64 %63, %56
  br label %for_body8.1

for_body14:                                       ; preds = %for_body14, %for_end3
  %indvars.iv61 = phi i64 [ 0, %for_end3 ], [ %indvars.iv.next62, %for_body14 ]
  %158 = mul nuw nsw i64 %indvars.iv61, 224
  %159 = trunc i64 %158 to i32
  %160 = add i32 %65, %159
  %161 = getelementptr inbounds float, float* %50, i64 %158
  %162 = bitcast float* %161 to <32 x float>*
  %163 = load <32 x float>, <32 x float>* %162, align 64, !tbaa !865
  %164 = fadd <32 x float> %70, %163
  %165 = fcmp ogt <32 x float> %164, zeroinitializer
  %166 = select <32 x i1> %165, <32 x float> %164, <32 x float> zeroinitializer
  %167 = sext i32 %160 to i64
  %168 = getelementptr inbounds float, float* %12, i64 %167
  %169 = bitcast float* %168 to <32 x float>*
  store <32 x float> %166, <32 x float>* %169, align 64, !tbaa !868
  %170 = add nuw nsw i64 %158, 32
  %171 = trunc i64 %170 to i32
  %172 = add i32 %65, %171
  %173 = getelementptr inbounds float, float* %50, i64 %170
  %174 = bitcast float* %173 to <32 x float>*
  %175 = load <32 x float>, <32 x float>* %174, align 64, !tbaa !865
  %176 = fadd <32 x float> %70, %175
  %177 = fcmp ogt <32 x float> %176, zeroinitializer
  %178 = select <32 x i1> %177, <32 x float> %176, <32 x float> zeroinitializer
  %179 = sext i32 %172 to i64
  %180 = getelementptr inbounds float, float* %12, i64 %179
  %181 = bitcast float* %180 to <32 x float>*
  store <32 x float> %178, <32 x float>* %181, align 64, !tbaa !868
  %182 = add nuw nsw i64 %158, 64
  %183 = trunc i64 %182 to i32
  %184 = add i32 %65, %183
  %185 = getelementptr inbounds float, float* %50, i64 %182
  %186 = bitcast float* %185 to <32 x float>*
  %187 = load <32 x float>, <32 x float>* %186, align 64, !tbaa !865
  %188 = fadd <32 x float> %70, %187
  %189 = fcmp ogt <32 x float> %188, zeroinitializer
  %190 = select <32 x i1> %189, <32 x float> %188, <32 x float> zeroinitializer
  %191 = sext i32 %184 to i64
  %192 = getelementptr inbounds float, float* %12, i64 %191
  %193 = bitcast float* %192 to <32 x float>*
  store <32 x float> %190, <32 x float>* %193, align 64, !tbaa !868
  %194 = add nuw nsw i64 %158, 96
  %195 = trunc i64 %194 to i32
  %196 = add i32 %65, %195
  %197 = getelementptr inbounds float, float* %50, i64 %194
  %198 = bitcast float* %197 to <32 x float>*
  %199 = load <32 x float>, <32 x float>* %198, align 64, !tbaa !865
  %200 = fadd <32 x float> %70, %199
  %201 = fcmp ogt <32 x float> %200, zeroinitializer
  %202 = select <32 x i1> %201, <32 x float> %200, <32 x float> zeroinitializer
  %203 = sext i32 %196 to i64
  %204 = getelementptr inbounds float, float* %12, i64 %203
  %205 = bitcast float* %204 to <32 x float>*
  store <32 x float> %202, <32 x float>* %205, align 64, !tbaa !868
  %206 = add nuw nsw i64 %158, 128
  %207 = trunc i64 %206 to i32
  %208 = add i32 %65, %207
  %209 = getelementptr inbounds float, float* %50, i64 %206
  %210 = bitcast float* %209 to <32 x float>*
  %211 = load <32 x float>, <32 x float>* %210, align 64, !tbaa !865
  %212 = fadd <32 x float> %70, %211
  %213 = fcmp ogt <32 x float> %212, zeroinitializer
  %214 = select <32 x i1> %213, <32 x float> %212, <32 x float> zeroinitializer
  %215 = sext i32 %208 to i64
  %216 = getelementptr inbounds float, float* %12, i64 %215
  %217 = bitcast float* %216 to <32 x float>*
  store <32 x float> %214, <32 x float>* %217, align 64, !tbaa !868
  %218 = add nuw nsw i64 %158, 160
  %219 = trunc i64 %218 to i32
  %220 = add i32 %65, %219
  %221 = getelementptr inbounds float, float* %50, i64 %218
  %222 = bitcast float* %221 to <32 x float>*
  %223 = load <32 x float>, <32 x float>* %222, align 64, !tbaa !865
  %224 = fadd <32 x float> %70, %223
  %225 = fcmp ogt <32 x float> %224, zeroinitializer
  %226 = select <32 x i1> %225, <32 x float> %224, <32 x float> zeroinitializer
  %227 = sext i32 %220 to i64
  %228 = getelementptr inbounds float, float* %12, i64 %227
  %229 = bitcast float* %228 to <32 x float>*
  store <32 x float> %226, <32 x float>* %229, align 64, !tbaa !868
  %230 = add nuw nsw i64 %158, 192
  %231 = trunc i64 %230 to i32
  %232 = add i32 %65, %231
  %233 = getelementptr inbounds float, float* %50, i64 %230
  %234 = bitcast float* %233 to <32 x float>*
  %235 = load <32 x float>, <32 x float>* %234, align 64, !tbaa !865
  %236 = fadd <32 x float> %70, %235
  %237 = fcmp ogt <32 x float> %236, zeroinitializer
  %238 = select <32 x i1> %237, <32 x float> %236, <32 x float> zeroinitializer
  %239 = sext i32 %232 to i64
  %240 = getelementptr inbounds float, float* %12, i64 %239
  %241 = bitcast float* %240 to <32 x float>*
  store <32 x float> %238, <32 x float>* %241, align 64, !tbaa !868
  %indvars.iv.next62 = add nuw nsw i64 %indvars.iv61, 1
  %exitcond63 = icmp eq i64 %indvars.iv.next62, 8
  br i1 %exitcond63, label %for_end15, label %for_body14, !prof !29

for_end15:                                        ; preds = %for_body14
  %242 = load i32 (i32, i32, i8*)*, i32 (i32, i32, i8*)** @__TVMBackendFreeWorkspace, align 8, !tbaa !16
  %243 = tail call i32 %242(i32 1, i32 %18, i8* nonnull %46)
  %244 = add nsw i32 %44, 1
  %245 = icmp slt i32 %244, %26
  br i1 %245, label %for_body, label %for_end, !prof !19

for_body8.1:                                      ; preds = %for_body8.1, %for_end9
  %indvars.iv.1 = phi i64 [ 0, %for_end9 ], [ %indvars.iv.next.1, %for_body8.1 ]
  %246 = phi <32 x float> [ %156, %for_end9 ], [ %331, %for_body8.1 ]
  %247 = phi <32 x float> [ %150, %for_end9 ], [ %325, %for_body8.1 ]
  %248 = phi <32 x float> [ %149, %for_end9 ], [ %324, %for_body8.1 ]
  %249 = phi <32 x float> [ %148, %for_end9 ], [ %323, %for_body8.1 ]
  %250 = phi <32 x float> [ %147, %for_end9 ], [ %322, %for_body8.1 ]
  %251 = phi <32 x float> [ %146, %for_end9 ], [ %321, %for_body8.1 ]
  %252 = phi <32 x float> [ %145, %for_end9 ], [ %320, %for_body8.1 ]
  %253 = add nsw i64 %157, %indvars.iv.1
  %254 = getelementptr inbounds float, float* %6, i64 %253
  %255 = load float, float* %254, align 4, !tbaa !856
  %256 = insertelement <32 x float> undef, float %255, i32 0
  %257 = shufflevector <32 x float> %256, <32 x float> undef, <32 x i32> zeroinitializer
  %258 = shl nsw i64 %indvars.iv.1, 5
  %259 = add nsw i64 %57, %258
  %260 = getelementptr inbounds float, float* %9, i64 %259
  %261 = bitcast float* %260 to <32 x float>*
  %262 = load <32 x float>, <32 x float>* %261, align 64, !tbaa !862
  %263 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %257, <32 x float> %262, <32 x float> %252)
  %264 = add nsw i64 %253, 64
  %265 = getelementptr inbounds float, float* %6, i64 %264
  %266 = load float, float* %265, align 4, !tbaa !856
  %267 = insertelement <32 x float> undef, float %266, i32 0
  %268 = shufflevector <32 x float> %267, <32 x float> undef, <32 x i32> zeroinitializer
  %269 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %268, <32 x float> %262, <32 x float> %251)
  %270 = add nsw i64 %253, 128
  %271 = getelementptr inbounds float, float* %6, i64 %270
  %272 = load float, float* %271, align 4, !tbaa !856
  %273 = insertelement <32 x float> undef, float %272, i32 0
  %274 = shufflevector <32 x float> %273, <32 x float> undef, <32 x i32> zeroinitializer
  %275 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %274, <32 x float> %262, <32 x float> %250)
  %276 = add nsw i64 %253, 192
  %277 = getelementptr inbounds float, float* %6, i64 %276
  %278 = load float, float* %277, align 4, !tbaa !856
  %279 = insertelement <32 x float> undef, float %278, i32 0
  %280 = shufflevector <32 x float> %279, <32 x float> undef, <32 x i32> zeroinitializer
  %281 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %262, <32 x float> %249)
  %282 = add nsw i64 %253, 256
  %283 = getelementptr inbounds float, float* %6, i64 %282
  %284 = load float, float* %283, align 4, !tbaa !856
  %285 = insertelement <32 x float> undef, float %284, i32 0
  %286 = shufflevector <32 x float> %285, <32 x float> undef, <32 x i32> zeroinitializer
  %287 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %262, <32 x float> %248)
  %288 = add nsw i64 %253, 320
  %289 = getelementptr inbounds float, float* %6, i64 %288
  %290 = load float, float* %289, align 4, !tbaa !856
  %291 = insertelement <32 x float> undef, float %290, i32 0
  %292 = shufflevector <32 x float> %291, <32 x float> undef, <32 x i32> zeroinitializer
  %293 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %292, <32 x float> %262, <32 x float> %247)
  %294 = add nsw i64 %253, 384
  %295 = getelementptr inbounds float, float* %6, i64 %294
  %296 = load float, float* %295, align 4, !tbaa !856
  %297 = insertelement <32 x float> undef, float %296, i32 0
  %298 = shufflevector <32 x float> %297, <32 x float> undef, <32 x i32> zeroinitializer
  %299 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %298, <32 x float> %262, <32 x float> %246)
  %300 = add nsw i64 %259, 2048
  %301 = getelementptr inbounds float, float* %9, i64 %300
  %302 = bitcast float* %301 to <32 x float>*
  %303 = load <32 x float>, <32 x float>* %302, align 64, !tbaa !862
  %304 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %268, <32 x float> %303, <32 x float> %263)
  %305 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %274, <32 x float> %303, <32 x float> %269)
  %306 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %303, <32 x float> %275)
  %307 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %303, <32 x float> %281)
  %308 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %292, <32 x float> %303, <32 x float> %287)
  %309 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %298, <32 x float> %303, <32 x float> %293)
  %310 = add nsw i64 %253, 448
  %311 = getelementptr inbounds float, float* %6, i64 %310
  %312 = load float, float* %311, align 4, !tbaa !856
  %313 = insertelement <32 x float> undef, float %312, i32 0
  %314 = shufflevector <32 x float> %313, <32 x float> undef, <32 x i32> zeroinitializer
  %315 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %314, <32 x float> %303, <32 x float> %299)
  %316 = add nsw i64 %259, 4096
  %317 = getelementptr inbounds float, float* %9, i64 %316
  %318 = bitcast float* %317 to <32 x float>*
  %319 = load <32 x float>, <32 x float>* %318, align 64, !tbaa !862
  %320 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %274, <32 x float> %319, <32 x float> %304)
  %321 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %280, <32 x float> %319, <32 x float> %305)
  %322 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %286, <32 x float> %319, <32 x float> %306)
  %323 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %292, <32 x float> %319, <32 x float> %307)
  %324 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %298, <32 x float> %319, <32 x float> %308)
  %325 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %314, <32 x float> %319, <32 x float> %309)
  %326 = add nsw i64 %253, 512
  %327 = getelementptr inbounds float, float* %6, i64 %326
  %328 = load float, float* %327, align 4, !tbaa !856
  %329 = insertelement <32 x float> undef, float %328, i32 0
  %330 = shufflevector <32 x float> %329, <32 x float> undef, <32 x i32> zeroinitializer
  %331 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %330, <32 x float> %319, <32 x float> %315)
  %indvars.iv.next.1 = add nuw nsw i64 %indvars.iv.1, 1
  %exitcond.1 = icmp eq i64 %indvars.iv.next.1, 64
  br i1 %exitcond.1, label %for_end9.1, label %for_body8.1, !prof !29

for_end9.1:                                       ; preds = %for_body8.1
  %332 = add nsw i64 %63, %60
  br label %for_body8.2

for_body8.2:                                      ; preds = %for_body8.2, %for_end9.1
  %indvars.iv.2 = phi i64 [ 0, %for_end9.1 ], [ %indvars.iv.next.2, %for_body8.2 ]
  %333 = phi <32 x float> [ %331, %for_end9.1 ], [ %418, %for_body8.2 ]
  %334 = phi <32 x float> [ %325, %for_end9.1 ], [ %412, %for_body8.2 ]
  %335 = phi <32 x float> [ %324, %for_end9.1 ], [ %411, %for_body8.2 ]
  %336 = phi <32 x float> [ %323, %for_end9.1 ], [ %410, %for_body8.2 ]
  %337 = phi <32 x float> [ %322, %for_end9.1 ], [ %409, %for_body8.2 ]
  %338 = phi <32 x float> [ %321, %for_end9.1 ], [ %408, %for_body8.2 ]
  %339 = phi <32 x float> [ %320, %for_end9.1 ], [ %407, %for_body8.2 ]
  %340 = add nsw i64 %332, %indvars.iv.2
  %341 = getelementptr inbounds float, float* %6, i64 %340
  %342 = load float, float* %341, align 4, !tbaa !856
  %343 = insertelement <32 x float> undef, float %342, i32 0
  %344 = shufflevector <32 x float> %343, <32 x float> undef, <32 x i32> zeroinitializer
  %345 = shl nsw i64 %indvars.iv.2, 5
  %346 = add nsw i64 %61, %345
  %347 = getelementptr inbounds float, float* %9, i64 %346
  %348 = bitcast float* %347 to <32 x float>*
  %349 = load <32 x float>, <32 x float>* %348, align 64, !tbaa !862
  %350 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %344, <32 x float> %349, <32 x float> %339)
  %351 = add nsw i64 %340, 64
  %352 = getelementptr inbounds float, float* %6, i64 %351
  %353 = load float, float* %352, align 4, !tbaa !856
  %354 = insertelement <32 x float> undef, float %353, i32 0
  %355 = shufflevector <32 x float> %354, <32 x float> undef, <32 x i32> zeroinitializer
  %356 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %355, <32 x float> %349, <32 x float> %338)
  %357 = add nsw i64 %340, 128
  %358 = getelementptr inbounds float, float* %6, i64 %357
  %359 = load float, float* %358, align 4, !tbaa !856
  %360 = insertelement <32 x float> undef, float %359, i32 0
  %361 = shufflevector <32 x float> %360, <32 x float> undef, <32 x i32> zeroinitializer
  %362 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %349, <32 x float> %337)
  %363 = add nsw i64 %340, 192
  %364 = getelementptr inbounds float, float* %6, i64 %363
  %365 = load float, float* %364, align 4, !tbaa !856
  %366 = insertelement <32 x float> undef, float %365, i32 0
  %367 = shufflevector <32 x float> %366, <32 x float> undef, <32 x i32> zeroinitializer
  %368 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %349, <32 x float> %336)
  %369 = add nsw i64 %340, 256
  %370 = getelementptr inbounds float, float* %6, i64 %369
  %371 = load float, float* %370, align 4, !tbaa !856
  %372 = insertelement <32 x float> undef, float %371, i32 0
  %373 = shufflevector <32 x float> %372, <32 x float> undef, <32 x i32> zeroinitializer
  %374 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %373, <32 x float> %349, <32 x float> %335)
  %375 = add nsw i64 %340, 320
  %376 = getelementptr inbounds float, float* %6, i64 %375
  %377 = load float, float* %376, align 4, !tbaa !856
  %378 = insertelement <32 x float> undef, float %377, i32 0
  %379 = shufflevector <32 x float> %378, <32 x float> undef, <32 x i32> zeroinitializer
  %380 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %379, <32 x float> %349, <32 x float> %334)
  %381 = add nsw i64 %340, 384
  %382 = getelementptr inbounds float, float* %6, i64 %381
  %383 = load float, float* %382, align 4, !tbaa !856
  %384 = insertelement <32 x float> undef, float %383, i32 0
  %385 = shufflevector <32 x float> %384, <32 x float> undef, <32 x i32> zeroinitializer
  %386 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %349, <32 x float> %333)
  %387 = add nsw i64 %346, 2048
  %388 = getelementptr inbounds float, float* %9, i64 %387
  %389 = bitcast float* %388 to <32 x float>*
  %390 = load <32 x float>, <32 x float>* %389, align 64, !tbaa !862
  %391 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %355, <32 x float> %390, <32 x float> %350)
  %392 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %390, <32 x float> %356)
  %393 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %390, <32 x float> %362)
  %394 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %373, <32 x float> %390, <32 x float> %368)
  %395 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %379, <32 x float> %390, <32 x float> %374)
  %396 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %390, <32 x float> %380)
  %397 = add nsw i64 %340, 448
  %398 = getelementptr inbounds float, float* %6, i64 %397
  %399 = load float, float* %398, align 4, !tbaa !856
  %400 = insertelement <32 x float> undef, float %399, i32 0
  %401 = shufflevector <32 x float> %400, <32 x float> undef, <32 x i32> zeroinitializer
  %402 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %401, <32 x float> %390, <32 x float> %386)
  %403 = add nsw i64 %346, 4096
  %404 = getelementptr inbounds float, float* %9, i64 %403
  %405 = bitcast float* %404 to <32 x float>*
  %406 = load <32 x float>, <32 x float>* %405, align 64, !tbaa !862
  %407 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %361, <32 x float> %406, <32 x float> %391)
  %408 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %367, <32 x float> %406, <32 x float> %392)
  %409 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %373, <32 x float> %406, <32 x float> %393)
  %410 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %379, <32 x float> %406, <32 x float> %394)
  %411 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %385, <32 x float> %406, <32 x float> %395)
  %412 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %401, <32 x float> %406, <32 x float> %396)
  %413 = add nsw i64 %340, 512
  %414 = getelementptr inbounds float, float* %6, i64 %413
  %415 = load float, float* %414, align 4, !tbaa !856
  %416 = insertelement <32 x float> undef, float %415, i32 0
  %417 = shufflevector <32 x float> %416, <32 x float> undef, <32 x i32> zeroinitializer
  %418 = tail call <32 x float> @llvm.fmuladd.v32f32(<32 x float> %417, <32 x float> %406, <32 x float> %402)
  %indvars.iv.next.2 = add nuw nsw i64 %indvars.iv.2, 1
  %exitcond.2 = icmp eq i64 %indvars.iv.next.2, 64
  br i1 %exitcond.2, label %for_end9.2, label %for_body8.2, !prof !29

for_end9.2:                                       ; preds = %for_body8.2
  store <32 x float> %407, <32 x float>* %.sub, align 128, !tbaa !871
  store <32 x float> %408, <32 x float>* %32, align 128, !tbaa !871
  store <32 x float> %409, <32 x float>* %34, align 128, !tbaa !871
  store <32 x float> %410, <32 x float>* %36, align 128, !tbaa !871
  store <32 x float> %411, <32 x float>* %38, align 128, !tbaa !871
  store <32 x float> %412, <32 x float>* %40, align 128, !tbaa !871
  store <32 x float> %418, <32 x float>* %42, align 128, !tbaa !871
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %scevgep, i8* nonnull %4, i64 896, i32 64, i1 false)
  %indvar.next = add nuw nsw i64 %indvar, 1
  %exitcond57 = icmp eq i64 %indvar.next, 8
  br i1 %exitcond57, label %for_end3, label %for_body2, !prof !29
}

define dllexport i32 @fused_layout_transform_31(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !880 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !882, metadata !DIExpression()), !dbg !885
  call void @llvm.dbg.value(metadata i8* %1, metadata !883, metadata !DIExpression()), !dbg !885
  call void @llvm.dbg.value(metadata i32 %2, metadata !884, metadata !DIExpression()), !dbg !885
  %3 = bitcast i8* %0 to %1**, !dbg !885
  %4 = load %1*, %1** %3, align 8, !dbg !885
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !885
  %6 = bitcast i8* %5 to %1**, !dbg !885
  %7 = load %1*, %1** %6, align 8, !dbg !885
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !885
  %9 = load i8*, i8** %8, align 8, !dbg !885
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !885
  %11 = load i8*, i8** %10, align 8, !dbg !885
  %12 = tail call fastcc i32 @fused_layout_transform_31_compute_(i8* %11, i8* %9), !dbg !885
  ret i32 %12, !dbg !885
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_31_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %52, align 8
  %3 = getelementptr inbounds %52, %52* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %52, %52* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %52* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.48, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.48(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_body
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_body ]
  %24 = mul nsw i64 %indvars.iv7, 28
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 7
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 7
  %29 = mul nsw i32 %28, 224
  %30 = srem i32 %27, 32
  %31 = sdiv i32 %25, 56
  %32 = mul nsw i32 %31, 1568
  %33 = or i32 %27, 1
  %34 = srem i32 %33, 32
  %35 = sdiv i32 %33, 32
  %36 = mul nsw i32 %35, 1568
  %37 = or i32 %27, 2
  %38 = srem i32 %37, 32
  %39 = sdiv i32 %37, 32
  %40 = mul nsw i32 %39, 1568
  %41 = or i32 %27, 3
  %42 = srem i32 %41, 32
  %43 = sdiv i32 %41, 32
  %44 = mul nsw i32 %43, 1568
  %45 = add nsw i32 %29, %30
  %46 = add i32 %45, %32
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds float, float* %7, i64 %47
  %49 = bitcast float* %48 to i32*
  %50 = load i32, i32* %49, align 4, !tbaa !886
  %51 = getelementptr inbounds float, float* %4, i64 %24
  %52 = bitcast float* %51 to i32*
  store i32 %50, i32* %52, align 4, !tbaa !889
  %53 = or i64 %24, 1
  %54 = add nsw i32 %29, %34
  %55 = add i32 %54, %36
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds float, float* %7, i64 %56
  %58 = bitcast float* %57 to i32*
  %59 = load i32, i32* %58, align 4, !tbaa !886
  %60 = getelementptr inbounds float, float* %4, i64 %53
  %61 = bitcast float* %60 to i32*
  store i32 %59, i32* %61, align 4, !tbaa !889
  %62 = or i64 %24, 2
  %63 = add nsw i32 %29, %38
  %64 = add i32 %63, %40
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds float, float* %7, i64 %65
  %67 = bitcast float* %66 to i32*
  %68 = load i32, i32* %67, align 4, !tbaa !886
  %69 = getelementptr inbounds float, float* %4, i64 %62
  %70 = bitcast float* %69 to i32*
  store i32 %68, i32* %70, align 4, !tbaa !889
  %71 = or i64 %24, 3
  %72 = add nsw i32 %29, %42
  %73 = add i32 %72, %44
  %74 = sext i32 %73 to i64
  %75 = getelementptr inbounds float, float* %7, i64 %74
  %76 = bitcast float* %75 to i32*
  %77 = load i32, i32* %76, align 4, !tbaa !886
  %78 = getelementptr inbounds float, float* %4, i64 %71
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 4, !tbaa !889
  %80 = add nsw i64 %24, 4
  %81 = add nsw i32 %29, 32
  %82 = add nsw i32 %81, %30
  %83 = add i32 %82, %32
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds float, float* %7, i64 %84
  %86 = bitcast float* %85 to i32*
  %87 = load i32, i32* %86, align 4, !tbaa !886
  %88 = getelementptr inbounds float, float* %4, i64 %80
  %89 = bitcast float* %88 to i32*
  store i32 %87, i32* %89, align 4, !tbaa !889
  %90 = or i64 %80, 1
  %91 = add nsw i32 %29, 32
  %92 = add nsw i32 %91, %34
  %93 = add i32 %92, %36
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds float, float* %7, i64 %94
  %96 = bitcast float* %95 to i32*
  %97 = load i32, i32* %96, align 4, !tbaa !886
  %98 = getelementptr inbounds float, float* %4, i64 %90
  %99 = bitcast float* %98 to i32*
  store i32 %97, i32* %99, align 4, !tbaa !889
  %100 = or i64 %80, 2
  %101 = add nsw i32 %91, %38
  %102 = add i32 %101, %40
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds float, float* %7, i64 %103
  %105 = bitcast float* %104 to i32*
  %106 = load i32, i32* %105, align 4, !tbaa !886
  %107 = getelementptr inbounds float, float* %4, i64 %100
  %108 = bitcast float* %107 to i32*
  store i32 %106, i32* %108, align 4, !tbaa !889
  %109 = or i64 %80, 3
  %110 = add nsw i32 %91, %42
  %111 = add i32 %110, %44
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds float, float* %7, i64 %112
  %114 = bitcast float* %113 to i32*
  %115 = load i32, i32* %114, align 4, !tbaa !886
  %116 = getelementptr inbounds float, float* %4, i64 %109
  %117 = bitcast float* %116 to i32*
  store i32 %115, i32* %117, align 4, !tbaa !889
  %118 = add nsw i64 %24, 8
  %119 = add nsw i32 %29, 64
  %120 = add nsw i32 %119, %30
  %121 = add i32 %120, %32
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds float, float* %7, i64 %122
  %124 = bitcast float* %123 to i32*
  %125 = load i32, i32* %124, align 4, !tbaa !886
  %126 = getelementptr inbounds float, float* %4, i64 %118
  %127 = bitcast float* %126 to i32*
  store i32 %125, i32* %127, align 4, !tbaa !889
  %128 = or i64 %118, 1
  %129 = add nsw i32 %29, 64
  %130 = add nsw i32 %129, %34
  %131 = add i32 %130, %36
  %132 = sext i32 %131 to i64
  %133 = getelementptr inbounds float, float* %7, i64 %132
  %134 = bitcast float* %133 to i32*
  %135 = load i32, i32* %134, align 4, !tbaa !886
  %136 = getelementptr inbounds float, float* %4, i64 %128
  %137 = bitcast float* %136 to i32*
  store i32 %135, i32* %137, align 4, !tbaa !889
  %138 = or i64 %118, 2
  %139 = add nsw i32 %129, %38
  %140 = add i32 %139, %40
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds float, float* %7, i64 %141
  %143 = bitcast float* %142 to i32*
  %144 = load i32, i32* %143, align 4, !tbaa !886
  %145 = getelementptr inbounds float, float* %4, i64 %138
  %146 = bitcast float* %145 to i32*
  store i32 %144, i32* %146, align 4, !tbaa !889
  %147 = or i64 %118, 3
  %148 = add nsw i32 %129, %42
  %149 = add i32 %148, %44
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds float, float* %7, i64 %150
  %152 = bitcast float* %151 to i32*
  %153 = load i32, i32* %152, align 4, !tbaa !886
  %154 = getelementptr inbounds float, float* %4, i64 %147
  %155 = bitcast float* %154 to i32*
  store i32 %153, i32* %155, align 4, !tbaa !889
  %156 = add nsw i64 %24, 12
  %157 = add nsw i32 %29, 96
  %158 = add nsw i32 %157, %30
  %159 = add i32 %158, %32
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds float, float* %7, i64 %160
  %162 = bitcast float* %161 to i32*
  %163 = load i32, i32* %162, align 4, !tbaa !886
  %164 = getelementptr inbounds float, float* %4, i64 %156
  %165 = bitcast float* %164 to i32*
  store i32 %163, i32* %165, align 4, !tbaa !889
  %166 = or i64 %156, 1
  %167 = add nsw i32 %29, 96
  %168 = add nsw i32 %167, %34
  %169 = add i32 %168, %36
  %170 = sext i32 %169 to i64
  %171 = getelementptr inbounds float, float* %7, i64 %170
  %172 = bitcast float* %171 to i32*
  %173 = load i32, i32* %172, align 4, !tbaa !886
  %174 = getelementptr inbounds float, float* %4, i64 %166
  %175 = bitcast float* %174 to i32*
  store i32 %173, i32* %175, align 4, !tbaa !889
  %176 = or i64 %156, 2
  %177 = add nsw i32 %167, %38
  %178 = add i32 %177, %40
  %179 = sext i32 %178 to i64
  %180 = getelementptr inbounds float, float* %7, i64 %179
  %181 = bitcast float* %180 to i32*
  %182 = load i32, i32* %181, align 4, !tbaa !886
  %183 = getelementptr inbounds float, float* %4, i64 %176
  %184 = bitcast float* %183 to i32*
  store i32 %182, i32* %184, align 4, !tbaa !889
  %185 = or i64 %156, 3
  %186 = add nsw i32 %167, %42
  %187 = add i32 %186, %44
  %188 = sext i32 %187 to i64
  %189 = getelementptr inbounds float, float* %7, i64 %188
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4, !tbaa !886
  %192 = getelementptr inbounds float, float* %4, i64 %185
  %193 = bitcast float* %192 to i32*
  store i32 %191, i32* %193, align 4, !tbaa !889
  %194 = add nsw i64 %24, 16
  %195 = add nsw i32 %29, 128
  %196 = add nsw i32 %195, %30
  %197 = add i32 %196, %32
  %198 = sext i32 %197 to i64
  %199 = getelementptr inbounds float, float* %7, i64 %198
  %200 = bitcast float* %199 to i32*
  %201 = load i32, i32* %200, align 4, !tbaa !886
  %202 = getelementptr inbounds float, float* %4, i64 %194
  %203 = bitcast float* %202 to i32*
  store i32 %201, i32* %203, align 4, !tbaa !889
  %204 = or i64 %194, 1
  %205 = add nsw i32 %29, 128
  %206 = add nsw i32 %205, %34
  %207 = add i32 %206, %36
  %208 = sext i32 %207 to i64
  %209 = getelementptr inbounds float, float* %7, i64 %208
  %210 = bitcast float* %209 to i32*
  %211 = load i32, i32* %210, align 4, !tbaa !886
  %212 = getelementptr inbounds float, float* %4, i64 %204
  %213 = bitcast float* %212 to i32*
  store i32 %211, i32* %213, align 4, !tbaa !889
  %214 = or i64 %194, 2
  %215 = add nsw i32 %205, %38
  %216 = add i32 %215, %40
  %217 = sext i32 %216 to i64
  %218 = getelementptr inbounds float, float* %7, i64 %217
  %219 = bitcast float* %218 to i32*
  %220 = load i32, i32* %219, align 4, !tbaa !886
  %221 = getelementptr inbounds float, float* %4, i64 %214
  %222 = bitcast float* %221 to i32*
  store i32 %220, i32* %222, align 4, !tbaa !889
  %223 = or i64 %194, 3
  %224 = add nsw i32 %205, %42
  %225 = add i32 %224, %44
  %226 = sext i32 %225 to i64
  %227 = getelementptr inbounds float, float* %7, i64 %226
  %228 = bitcast float* %227 to i32*
  %229 = load i32, i32* %228, align 4, !tbaa !886
  %230 = getelementptr inbounds float, float* %4, i64 %223
  %231 = bitcast float* %230 to i32*
  store i32 %229, i32* %231, align 4, !tbaa !889
  %232 = add nsw i64 %24, 20
  %233 = add nsw i32 %29, 160
  %234 = add nsw i32 %233, %30
  %235 = add i32 %234, %32
  %236 = sext i32 %235 to i64
  %237 = getelementptr inbounds float, float* %7, i64 %236
  %238 = bitcast float* %237 to i32*
  %239 = load i32, i32* %238, align 4, !tbaa !886
  %240 = getelementptr inbounds float, float* %4, i64 %232
  %241 = bitcast float* %240 to i32*
  store i32 %239, i32* %241, align 4, !tbaa !889
  %242 = or i64 %232, 1
  %243 = add nsw i32 %29, 160
  %244 = add nsw i32 %243, %34
  %245 = add i32 %244, %36
  %246 = sext i32 %245 to i64
  %247 = getelementptr inbounds float, float* %7, i64 %246
  %248 = bitcast float* %247 to i32*
  %249 = load i32, i32* %248, align 4, !tbaa !886
  %250 = getelementptr inbounds float, float* %4, i64 %242
  %251 = bitcast float* %250 to i32*
  store i32 %249, i32* %251, align 4, !tbaa !889
  %252 = or i64 %232, 2
  %253 = add nsw i32 %243, %38
  %254 = add i32 %253, %40
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds float, float* %7, i64 %255
  %257 = bitcast float* %256 to i32*
  %258 = load i32, i32* %257, align 4, !tbaa !886
  %259 = getelementptr inbounds float, float* %4, i64 %252
  %260 = bitcast float* %259 to i32*
  store i32 %258, i32* %260, align 4, !tbaa !889
  %261 = or i64 %232, 3
  %262 = add nsw i32 %243, %42
  %263 = add i32 %262, %44
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds float, float* %7, i64 %264
  %266 = bitcast float* %265 to i32*
  %267 = load i32, i32* %266, align 4, !tbaa !886
  %268 = getelementptr inbounds float, float* %4, i64 %261
  %269 = bitcast float* %268 to i32*
  store i32 %267, i32* %269, align 4, !tbaa !889
  %270 = add nsw i64 %24, 24
  %271 = add nsw i32 %29, 192
  %272 = add nsw i32 %271, %30
  %273 = add i32 %272, %32
  %274 = sext i32 %273 to i64
  %275 = getelementptr inbounds float, float* %7, i64 %274
  %276 = bitcast float* %275 to i32*
  %277 = load i32, i32* %276, align 4, !tbaa !886
  %278 = getelementptr inbounds float, float* %4, i64 %270
  %279 = bitcast float* %278 to i32*
  store i32 %277, i32* %279, align 4, !tbaa !889
  %280 = or i64 %270, 1
  %281 = add nsw i32 %29, 192
  %282 = add nsw i32 %281, %34
  %283 = add i32 %282, %36
  %284 = sext i32 %283 to i64
  %285 = getelementptr inbounds float, float* %7, i64 %284
  %286 = bitcast float* %285 to i32*
  %287 = load i32, i32* %286, align 4, !tbaa !886
  %288 = getelementptr inbounds float, float* %4, i64 %280
  %289 = bitcast float* %288 to i32*
  store i32 %287, i32* %289, align 4, !tbaa !889
  %290 = or i64 %270, 2
  %291 = add nsw i32 %281, %38
  %292 = add i32 %291, %40
  %293 = sext i32 %292 to i64
  %294 = getelementptr inbounds float, float* %7, i64 %293
  %295 = bitcast float* %294 to i32*
  %296 = load i32, i32* %295, align 4, !tbaa !886
  %297 = getelementptr inbounds float, float* %4, i64 %290
  %298 = bitcast float* %297 to i32*
  store i32 %296, i32* %298, align 4, !tbaa !889
  %299 = or i64 %270, 3
  %300 = add nsw i32 %281, %42
  %301 = add i32 %300, %44
  %302 = sext i32 %301 to i64
  %303 = getelementptr inbounds float, float* %7, i64 %302
  %304 = bitcast float* %303 to i32*
  %305 = load i32, i32* %304, align 4, !tbaa !886
  %306 = getelementptr inbounds float, float* %4, i64 %299
  %307 = bitcast float* %306 to i32*
  store i32 %305, i32* %307, align 4, !tbaa !889
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %308 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %308, label %for_body, label %for_end, !prof !19

for_end:                                          ; preds = %for_body, %entry
  ret i32 0
}

define dllexport i32 @fused_layout_transform_43(i8* noalias nocapture readonly, i8* noalias nocapture readnone, i32) local_unnamed_addr !dbg !892 {
entry:
  call void @llvm.dbg.value(metadata i8* %0, metadata !894, metadata !DIExpression()), !dbg !897
  call void @llvm.dbg.value(metadata i8* %1, metadata !895, metadata !DIExpression()), !dbg !897
  call void @llvm.dbg.value(metadata i32 %2, metadata !896, metadata !DIExpression()), !dbg !897
  %3 = bitcast i8* %0 to %1**, !dbg !897
  %4 = load %1*, %1** %3, align 8, !dbg !897
  %5 = getelementptr inbounds i8, i8* %0, i64 8, !dbg !897
  %6 = bitcast i8* %5 to %1**, !dbg !897
  %7 = load %1*, %1** %6, align 8, !dbg !897
  %8 = getelementptr inbounds %1, %1* %4, i64 0, i32 0, !dbg !897
  %9 = load i8*, i8** %8, align 8, !dbg !897
  %10 = getelementptr inbounds %1, %1* %7, i64 0, i32 0, !dbg !897
  %11 = load i8*, i8** %10, align 8, !dbg !897
  %12 = tail call fastcc i32 @fused_layout_transform_43_compute_(i8* %11, i8* %9), !dbg !897
  ret i32 %12, !dbg !897
}

; Function Attrs: noinline
define private fastcc i32 @fused_layout_transform_43_compute_(i8* noalias, i8* noalias) unnamed_addr #0 {
entry:
  %2 = alloca %53, align 8
  %3 = getelementptr inbounds %53, %53* %2, i64 0, i32 0
  store i8* %0, i8** %3, align 8
  %4 = getelementptr inbounds %53, %53* %2, i64 0, i32 1
  store i8* %1, i8** %4, align 8
  %5 = bitcast %53* %2 to i8*
  %6 = load i32 (i32 (i32, %0*, i8*)*, i8*, i32)*, i32 (i32 (i32, %0*, i8*)*, i8*, i32)** @__TVMBackendParallelLaunch, align 8, !tbaa !16
  %7 = call i32 %6(i32 (i32, %0*, i8*)* nonnull @__tvm_parallel_lambda.49, i8* nonnull %5, i32 0)
  ret i32 %7
}

; Function Attrs: norecurse nounwind
define private i32 @__tvm_parallel_lambda.49(i32, %0* nocapture readonly, i8* nocapture readonly) #2 {
entry:
  %3 = bitcast i8* %2 to float**
  %4 = load float*, float** %3, align 8
  %5 = getelementptr inbounds i8, i8* %2, i64 8
  %6 = bitcast i8* %5 to float**
  %7 = load float*, float** %6, align 8
  %8 = getelementptr inbounds %0, %0* %1, i64 0, i32 1
  %9 = load i32, i32* %8, align 4
  %10 = add nsw i32 %9, 895
  %11 = sdiv i32 %10, %9
  %12 = add nsw i32 %0, 1
  %13 = mul nsw i32 %11, %12
  %14 = icmp slt i32 %13, 896
  %15 = select i1 %14, i32 %13, i32 896
  %16 = mul nsw i32 %11, %0
  %17 = icmp slt i32 %16, 896
  %18 = select i1 %17, i32 %16, i32 896
  %19 = icmp slt i32 %18, %15
  br i1 %19, label %for_body.lr.ph, label %for_end, !prof !19

for_body.lr.ph:                                   ; preds = %entry
  %20 = add i32 %18, 1
  %21 = sext i32 %20 to i64
  %22 = add nsw i64 %21, -1
  %23 = sext i32 %15 to i64
  br label %for_body

for_body:                                         ; preds = %for_body.lr.ph, %for_end3
  %indvars.iv7 = phi i64 [ %22, %for_body.lr.ph ], [ %indvars.iv.next8, %for_end3 ]
  %24 = mul nsw i64 %indvars.iv7, 224
  %25 = trunc i64 %indvars.iv7 to i32
  %26 = sdiv i32 %25, 56
  %27 = shl nsw i32 %26, 2
  %28 = srem i32 %25, 56
  %29 = mul nsw i32 %28, 1792
  %30 = srem i32 %27, 32
  %31 = sdiv i32 %25, 448
  %32 = mul nsw i32 %31, 100352
  %33 = or i32 %27, 1
  %34 = srem i32 %33, 32
  %35 = sdiv i32 %33, 32
  %36 = mul nsw i32 %35, 100352
  %37 = or i32 %27, 2
  %38 = srem i32 %37, 32
  %39 = sdiv i32 %37, 32
  %40 = mul nsw i32 %39, 100352
  %41 = or i32 %27, 3
  %42 = srem i32 %41, 32
  %43 = sdiv i32 %41, 32
  %44 = mul nsw i32 %43, 100352
  br label %for_body2

for_end:                                          ; preds = %for_end3, %entry
  ret i32 0

for_body2:                                        ; preds = %for_body2, %for_body
  %indvars.iv = phi i64 [ 0, %for_body ], [ %indvars.iv.next, %for_body2 ]
  %45 = phi i32 [ 0, %for_body ], [ %87, %for_body2 ]
  %46 = shl i64 %indvars.iv, 2
  %47 = add nsw i64 %46, %24
  %48 = shl i32 %45, 5
  %49 = add nsw i32 %48, %29
  %50 = add i32 %49, %30
  %51 = add i32 %50, %32
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds float, float* %7, i64 %52
  %54 = bitcast float* %53 to i32*
  %55 = load i32, i32* %54, align 4, !tbaa !898
  %56 = getelementptr inbounds float, float* %4, i64 %47
  %57 = bitcast float* %56 to i32*
  store i32 %55, i32* %57, align 4, !tbaa !901
  %58 = or i64 %47, 1
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %59 = shl i32 %indvars.iv.tr, 5
  %60 = add i32 %29, %59
  %61 = add i32 %60, %34
  %62 = add i32 %61, %36
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds float, float* %7, i64 %63
  %65 = bitcast float* %64 to i32*
  %66 = load i32, i32* %65, align 4, !tbaa !898
  %67 = getelementptr inbounds float, float* %4, i64 %58
  %68 = bitcast float* %67 to i32*
  store i32 %66, i32* %68, align 4, !tbaa !901
  %69 = or i64 %47, 2
  %70 = add i32 %60, %38
  %71 = add i32 %70, %40
  %72 = sext i32 %71 to i64
  %73 = getelementptr inbounds float, float* %7, i64 %72
  %74 = bitcast float* %73 to i32*
  %75 = load i32, i32* %74, align 4, !tbaa !898
  %76 = getelementptr inbounds float, float* %4, i64 %69
  %77 = bitcast float* %76 to i32*
  store i32 %75, i32* %77, align 4, !tbaa !901
  %78 = or i64 %47, 3
  %79 = add i32 %60, %42
  %80 = add i32 %79, %44
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds float, float* %7, i64 %81
  %83 = bitcast float* %82 to i32*
  %84 = load i32, i32* %83, align 4, !tbaa !898
  %85 = getelementptr inbounds float, float* %4, i64 %78
  %86 = bitcast float* %85 to i32*
  store i32 %84, i32* %86, align 4, !tbaa !901
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %87 = add nuw nsw i32 %45, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 56
  br i1 %exitcond, label %for_end3, label %for_body2, !prof !29

for_end3:                                         ; preds = %for_body2
  %indvars.iv.next8 = add nsw i64 %indvars.iv7, 1
  %88 = icmp slt i64 %indvars.iv.next8, %23
  br i1 %88, label %for_body, label %for_end, !prof !19
}

; Function Attrs: nounwind readnone speculatable
declare void @llvm.dbg.value(metadata, metadata, metadata) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i32, i1) #5

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i32, i1) #5

attributes #0 = { noinline }
attributes #1 = { nounwind readnone speculatable }
attributes #2 = { norecurse nounwind }
attributes #3 = { nounwind }
attributes #4 = { noinline norecurse nounwind }
attributes #5 = { argmemonly nounwind }

!llvm.dbg.cu = !{!0}
!llvm.module.flags = !{!3, !4}

!0 = distinct !DICompileUnit(language: DW_LANG_C, file: !1, producer: "TVM", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !2, dwoId: 1)
!1 = !DIFile(filename: "model.tvm", directory: "/tmp/")
!2 = !{}
!3 = !{i32 2, !"tvm_target", !"llvm"}
!4 = !{i32 4, !"Debug Info Version", i32 3}
!5 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_1", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !11)
!6 = !DISubroutineType(types: !7)
!7 = !{!8, !9, !9, !8}
!8 = !DIBasicType(name: "int32", size: 32, encoding: DW_ATE_signed)
!9 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !10)
!10 = !DIBasicType(name: "int8", size: 8, encoding: DW_ATE_signed)
!11 = !{!12, !13, !14}
!12 = !DILocalVariable(name: "arg1", arg: 1, scope: !5, file: !1, type: !9)
!13 = !DILocalVariable(name: "arg2", arg: 2, scope: !5, file: !1, type: !9)
!14 = !DILocalVariable(name: "arg3", arg: 3, scope: !5, file: !1, type: !8)
!15 = !DILocation(line: 0, scope: !5)
!16 = !{!17, !17, i64 0}
!17 = !{!"ctx_ptr", !18, i64 0}
!18 = !{!"tvm-tbaa"}
!19 = !{!"branch_weights", i32 1048576, i32 1}
!20 = !{!21, !21, i64 0}
!21 = !{!"float32", !22, i64 0}
!22 = !{!"0x55f211aa70d0", !18, i64 0}
!23 = !{!24, !24, i64 0}
!24 = !{!"float32", !25, i64 0}
!25 = !{!"0x55f211a9c000", !18, i64 0}
!26 = !{!27, !27, i64 0}
!27 = !{!"float32", !28, i64 0}
!28 = !{!"0x55f211a9c7b0", !18, i64 0}
!29 = !{!"branch_weights", i32 1, i32 1048576}
!30 = !{!31, !31, i64 0}
!31 = !{!"float32", !32, i64 0}
!32 = !{!"0x55f211a9c120", !18, i64 0}
!33 = !{!34, !34, i64 0}
!34 = !{!"float32", !35, i64 0}
!35 = !{!"0x55f211a9c0d0", !18, i64 0}
!36 = distinct !DISubprogram(name: "fused_layout_transform_48", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !37)
!37 = !{!38, !39, !40}
!38 = !DILocalVariable(name: "arg1", arg: 1, scope: !36, file: !1, type: !9)
!39 = !DILocalVariable(name: "arg2", arg: 2, scope: !36, file: !1, type: !9)
!40 = !DILocalVariable(name: "arg3", arg: 3, scope: !36, file: !1, type: !8)
!41 = !DILocation(line: 0, scope: !36)
!42 = !{!43, !43, i64 0}
!43 = !{!"float32", !44, i64 0}
!44 = !{!"0x55f211a92e30", !18, i64 0}
!45 = !{!46, !46, i64 0}
!46 = !{!"float32", !47, i64 0}
!47 = !{!"0x55f211a931e0", !18, i64 0}
!48 = distinct !DISubprogram(name: "fused_layout_transform_47", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !49)
!49 = !{!50, !51, !52}
!50 = !DILocalVariable(name: "arg1", arg: 1, scope: !48, file: !1, type: !9)
!51 = !DILocalVariable(name: "arg2", arg: 2, scope: !48, file: !1, type: !9)
!52 = !DILocalVariable(name: "arg3", arg: 3, scope: !48, file: !1, type: !8)
!53 = !DILocation(line: 0, scope: !48)
!54 = !{!55, !55, i64 0}
!55 = !{!"float32", !56, i64 0}
!56 = !{!"0x55f1f24a2e90", !18, i64 0}
!57 = !{!58, !58, i64 0}
!58 = !{!"float32", !59, i64 0}
!59 = !{!"0x55f1f24a2ee0", !18, i64 0}
!60 = distinct !{!60, !61}
!61 = !{!"llvm.loop.isvectorized", i32 1}
!62 = distinct !{!62, !61}
!63 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_4", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !64)
!64 = !{!65, !66, !67}
!65 = !DILocalVariable(name: "arg1", arg: 1, scope: !63, file: !1, type: !9)
!66 = !DILocalVariable(name: "arg2", arg: 2, scope: !63, file: !1, type: !9)
!67 = !DILocalVariable(name: "arg3", arg: 3, scope: !63, file: !1, type: !8)
!68 = !DILocation(line: 0, scope: !63)
!69 = !{!70, !70, i64 0}
!70 = !{!"float32", !71, i64 0}
!71 = !{!"0x55f213372f90", !18, i64 0}
!72 = !{!73, !73, i64 0}
!73 = !{!"float32", !74, i64 0}
!74 = !{!"0x55f1f7c34910", !18, i64 0}
!75 = !{!76, !76, i64 0}
!76 = !{!"float32", !77, i64 0}
!77 = !{!"0x55f2133729b0", !18, i64 0}
!78 = !{!79, !79, i64 0}
!79 = !{!"0x55f1f245dbe0.w32.b0", !80, i64 0}
!80 = !{!"0x55f1f245dbe0.w64.b0", !81, i64 0}
!81 = !{!"0x55f1f245dbe0.w128.b0", !82, i64 0}
!82 = !{!"0x55f1f245dbe0.w256.b0", !83, i64 0}
!83 = !{!"0x55f1f245dbe0.w512.b0", !84, i64 0}
!84 = !{!"0x55f1f245dbe0.w1024.b0", !85, i64 0}
!85 = !{!"float32", !86, i64 0}
!86 = !{!"0x55f1f245dbe0", !18, i64 0}
!87 = !{!88, !88, i64 0}
!88 = !{!"float32", !89, i64 0}
!89 = !{!"0x55f2133719e0", !18, i64 0}
!90 = !{!91, !91, i64 0}
!91 = !{!"float32", !92, i64 0}
!92 = !{!"0x55f21928bbb0", !18, i64 0}
!93 = !{!94, !94, i64 0}
!94 = !{!"float32", !95, i64 0}
!95 = !{!"0x55f213371d70", !18, i64 0}
!96 = distinct !DISubprogram(name: "fused_layout_transform_46", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !97)
!97 = !{!98, !99, !100}
!98 = !DILocalVariable(name: "arg1", arg: 1, scope: !96, file: !1, type: !9)
!99 = !DILocalVariable(name: "arg2", arg: 2, scope: !96, file: !1, type: !9)
!100 = !DILocalVariable(name: "arg3", arg: 3, scope: !96, file: !1, type: !8)
!101 = !DILocation(line: 0, scope: !96)
!102 = !{!103, !103, i64 0}
!103 = !{!"float32", !104, i64 0}
!104 = !{!"0x55f2192ada00", !18, i64 0}
!105 = !{!106, !106, i64 0}
!106 = !{!"float32", !107, i64 0}
!107 = !{!"0x55f2192adc70", !18, i64 0}
!108 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_3", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !109)
!109 = !{!110, !111, !112}
!110 = !DILocalVariable(name: "arg1", arg: 1, scope: !108, file: !1, type: !9)
!111 = !DILocalVariable(name: "arg2", arg: 2, scope: !108, file: !1, type: !9)
!112 = !DILocalVariable(name: "arg3", arg: 3, scope: !108, file: !1, type: !8)
!113 = !DILocation(line: 0, scope: !108)
!114 = !{!115, !115, i64 0}
!115 = !{!"float32", !116, i64 0}
!116 = !{!"0x55f1f5781c70", !18, i64 0}
!117 = !{!118, !118, i64 0}
!118 = !{!"float32", !119, i64 0}
!119 = !{!"0x55f1f5782680", !18, i64 0}
!120 = !{!121, !121, i64 0}
!121 = !{!"float32", !122, i64 0}
!122 = !{!"0x55f1f5781f30", !18, i64 0}
!123 = !{!124, !124, i64 0}
!124 = !{!"float32", !125, i64 0}
!125 = !{!"0x55f1f5781ee0", !18, i64 0}
!126 = distinct !DISubprogram(name: "fused_layout_transform_36", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !127)
!127 = !{!128, !129, !130}
!128 = !DILocalVariable(name: "arg1", arg: 1, scope: !126, file: !1, type: !9)
!129 = !DILocalVariable(name: "arg2", arg: 2, scope: !126, file: !1, type: !9)
!130 = !DILocalVariable(name: "arg3", arg: 3, scope: !126, file: !1, type: !8)
!131 = !DILocation(line: 0, scope: !126)
!132 = !{!133, !133, i64 0}
!133 = !{!"float32", !134, i64 0}
!134 = !{!"0x55f1fc5f4780", !18, i64 0}
!135 = !{!136, !136, i64 0}
!136 = !{!"float32", !137, i64 0}
!137 = !{!"0x55f1fc5d2630", !18, i64 0}
!138 = distinct !DISubprogram(name: "fused_layout_transform_35", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !139)
!139 = !{!140, !141, !142}
!140 = !DILocalVariable(name: "arg1", arg: 1, scope: !138, file: !1, type: !9)
!141 = !DILocalVariable(name: "arg2", arg: 2, scope: !138, file: !1, type: !9)
!142 = !DILocalVariable(name: "arg3", arg: 3, scope: !138, file: !1, type: !8)
!143 = !DILocation(line: 0, scope: !138)
!144 = !{!145, !145, i64 0}
!145 = !{!"float32", !146, i64 0}
!146 = !{!"0x55f1edba3250", !18, i64 0}
!147 = !{!148, !148, i64 0}
!148 = !{!"float32", !149, i64 0}
!149 = !{!"0x55f1fdc828d0", !18, i64 0}
!150 = distinct !DISubprogram(name: "fused_layout_transform_33", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !151)
!151 = !{!152, !153, !154}
!152 = !DILocalVariable(name: "arg1", arg: 1, scope: !150, file: !1, type: !9)
!153 = !DILocalVariable(name: "arg2", arg: 2, scope: !150, file: !1, type: !9)
!154 = !DILocalVariable(name: "arg3", arg: 3, scope: !150, file: !1, type: !8)
!155 = !DILocation(line: 0, scope: !150)
!156 = !{!157, !157, i64 0}
!157 = !{!"float32", !158, i64 0}
!158 = !{!"0x55f1fdc1e210", !18, i64 0}
!159 = !{!160, !160, i64 0}
!160 = !{!"float32", !161, i64 0}
!161 = !{!"0x55f1fdc92920", !18, i64 0}
!162 = distinct !DISubprogram(name: "fused_layout_transform_44", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !163)
!163 = !{!164, !165, !166}
!164 = !DILocalVariable(name: "arg1", arg: 1, scope: !162, file: !1, type: !9)
!165 = !DILocalVariable(name: "arg2", arg: 2, scope: !162, file: !1, type: !9)
!166 = !DILocalVariable(name: "arg3", arg: 3, scope: !162, file: !1, type: !8)
!167 = !DILocation(line: 0, scope: !162)
!168 = !{!169, !169, i64 0}
!169 = !{!"float32", !170, i64 0}
!170 = !{!"0x55f1f3c7fa70", !18, i64 0}
!171 = !{!172, !172, i64 0}
!172 = !{!"float32", !173, i64 0}
!173 = !{!"0x55f1f3c7fce0", !18, i64 0}
!174 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !175)
!175 = !{!176, !177, !178}
!176 = !DILocalVariable(name: "arg1", arg: 1, scope: !174, file: !1, type: !9)
!177 = !DILocalVariable(name: "arg2", arg: 2, scope: !174, file: !1, type: !9)
!178 = !DILocalVariable(name: "arg3", arg: 3, scope: !174, file: !1, type: !8)
!179 = !DILocation(line: 0, scope: !174)
!180 = !{!181, !181, i64 0}
!181 = !{!"float32", !182, i64 0}
!182 = !{!"0x55f1fdc6de90", !18, i64 0}
!183 = !{!184, !184, i64 0}
!184 = !{!"float32", !185, i64 0}
!185 = !{!"0x55f2192a41f0", !18, i64 0}
!186 = !{!187, !187, i64 0}
!187 = !{!"float32", !188, i64 0}
!188 = !{!"0x55f1ffc4f720", !18, i64 0}
!189 = !{!190, !190, i64 0}
!190 = !{!"float32", !191, i64 0}
!191 = !{!"0x55f1f0eb19f0", !18, i64 0}
!192 = !{!193, !193, i64 0}
!193 = !{!"float32", !194, i64 0}
!194 = !{!"0x55f212cc3590", !18, i64 0}
!195 = distinct !DISubprogram(name: "fused_layout_transform_32", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !196)
!196 = !{!197, !198, !199}
!197 = !DILocalVariable(name: "arg1", arg: 1, scope: !195, file: !1, type: !9)
!198 = !DILocalVariable(name: "arg2", arg: 2, scope: !195, file: !1, type: !9)
!199 = !DILocalVariable(name: "arg3", arg: 3, scope: !195, file: !1, type: !8)
!200 = !DILocation(line: 0, scope: !195)
!201 = !{!202, !202, i64 0}
!202 = !{!"float32", !203, i64 0}
!203 = !{!"0x55f1edeb1c10", !18, i64 0}
!204 = !{!205, !205, i64 0}
!205 = !{!"float32", !206, i64 0}
!206 = !{!"0x55f1edec2260", !18, i64 0}
!207 = distinct !DISubprogram(name: "fused_layout_transform_40", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !208)
!208 = !{!209, !210, !211}
!209 = !DILocalVariable(name: "arg1", arg: 1, scope: !207, file: !1, type: !9)
!210 = !DILocalVariable(name: "arg2", arg: 2, scope: !207, file: !1, type: !9)
!211 = !DILocalVariable(name: "arg3", arg: 3, scope: !207, file: !1, type: !8)
!212 = !DILocation(line: 0, scope: !207)
!213 = !{!214, !214, i64 0}
!214 = !{!"float32", !215, i64 0}
!215 = !{!"0x55f1f1d0c430", !18, i64 0}
!216 = !{!217, !217, i64 0}
!217 = !{!"float32", !218, i64 0}
!218 = !{!"0x55f21d106200", !18, i64 0}
!219 = distinct !DISubprogram(name: "fused_layout_transform_42", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !220)
!220 = !{!221, !222, !223}
!221 = !DILocalVariable(name: "arg1", arg: 1, scope: !219, file: !1, type: !9)
!222 = !DILocalVariable(name: "arg2", arg: 2, scope: !219, file: !1, type: !9)
!223 = !DILocalVariable(name: "arg3", arg: 3, scope: !219, file: !1, type: !8)
!224 = !DILocation(line: 0, scope: !219)
!225 = !{!226, !226, i64 0}
!226 = !{!"float32", !227, i64 0}
!227 = !{!"0x55f1f523edb0", !18, i64 0}
!228 = !{!229, !229, i64 0}
!229 = !{!"float32", !230, i64 0}
!230 = !{!"0x55f207a7d220", !18, i64 0}
!231 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !232)
!232 = !{!233, !234, !235}
!233 = !DILocalVariable(name: "arg1", arg: 1, scope: !231, file: !1, type: !9)
!234 = !DILocalVariable(name: "arg2", arg: 2, scope: !231, file: !1, type: !9)
!235 = !DILocalVariable(name: "arg3", arg: 3, scope: !231, file: !1, type: !8)
!236 = !DILocation(line: 0, scope: !231)
!237 = !{!238, !238, i64 0}
!238 = !{!"float32", !239, i64 0}
!239 = !{!"0x55f1f7c2cec0", !18, i64 0}
!240 = !{!241, !241, i64 0}
!241 = !{!"float32", !242, i64 0}
!242 = !{!"0x55f1fdc74940", !18, i64 0}
!243 = !{!244, !244, i64 0}
!244 = !{!"float32", !245, i64 0}
!245 = !{!"0x55f21928e090", !18, i64 0}
!246 = !{!247, !247, i64 0}
!247 = !{!"float32", !248, i64 0}
!248 = !{!"0x55f2192999b0", !18, i64 0}
!249 = !{!250, !250, i64 0}
!250 = !{!"float32", !251, i64 0}
!251 = !{!"0x55f1f7c49620", !18, i64 0}
!252 = distinct !DISubprogram(name: "fused_layout_transform_39", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !253)
!253 = !{!254, !255, !256}
!254 = !DILocalVariable(name: "arg1", arg: 1, scope: !252, file: !1, type: !9)
!255 = !DILocalVariable(name: "arg2", arg: 2, scope: !252, file: !1, type: !9)
!256 = !DILocalVariable(name: "arg3", arg: 3, scope: !252, file: !1, type: !8)
!257 = !DILocation(line: 0, scope: !252)
!258 = !{!259, !259, i64 0}
!259 = !{!"float32", !260, i64 0}
!260 = !{!"0x55f212cb2a30", !18, i64 0}
!261 = !{!262, !262, i64 0}
!262 = !{!"float32", !263, i64 0}
!263 = !{!"0x55f21c432650", !18, i64 0}
!264 = distinct !DISubprogram(name: "fused_layout_transform_nn_batch_flatten_nn_batch_flatten_multiply", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !265)
!265 = !{!266, !267, !268}
!266 = !DILocalVariable(name: "arg1", arg: 1, scope: !264, file: !1, type: !9)
!267 = !DILocalVariable(name: "arg2", arg: 2, scope: !264, file: !1, type: !9)
!268 = !DILocalVariable(name: "arg3", arg: 3, scope: !264, file: !1, type: !8)
!269 = !DILocation(line: 0, scope: !264)
!270 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_2", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !271)
!271 = !{!272, !273, !274}
!272 = !DILocalVariable(name: "arg1", arg: 1, scope: !270, file: !1, type: !9)
!273 = !DILocalVariable(name: "arg2", arg: 2, scope: !270, file: !1, type: !9)
!274 = !DILocalVariable(name: "arg3", arg: 3, scope: !270, file: !1, type: !8)
!275 = !DILocation(line: 0, scope: !270)
!276 = !{!277, !277, i64 0}
!277 = !{!"float32", !278, i64 0}
!278 = !{!"0x55f21bda37f0", !18, i64 0}
!279 = !{!280, !280, i64 0}
!280 = !{!"float32", !281, i64 0}
!281 = !{!"0x55f21bd97f20", !18, i64 0}
!282 = !{!283, !283, i64 0}
!283 = !{!"float32", !284, i64 0}
!284 = !{!"0x55f21bd98930", !18, i64 0}
!285 = !{!286, !286, i64 0}
!286 = !{!"float32", !287, i64 0}
!287 = !{!"0x55f21bd981e0", !18, i64 0}
!288 = !{!289, !289, i64 0}
!289 = !{!"float32", !290, i64 0}
!290 = !{!"0x55f21bd98190", !18, i64 0}
!291 = distinct !DISubprogram(name: "fused_nn_global_avg_pool2d", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !292)
!292 = !{!293, !294, !295}
!293 = !DILocalVariable(name: "arg1", arg: 1, scope: !291, file: !1, type: !9)
!294 = !DILocalVariable(name: "arg2", arg: 2, scope: !291, file: !1, type: !9)
!295 = !DILocalVariable(name: "arg3", arg: 3, scope: !291, file: !1, type: !8)
!296 = !DILocation(line: 0, scope: !291)
!297 = !{!298, !298, i64 0}
!298 = !{!"float32", !299, i64 0}
!299 = !{!"0x55f1f1f67060", !18, i64 0}
!300 = !{!301, !301, i64 0}
!301 = !{!"float32", !302, i64 0}
!302 = !{!"0x55f20a777470", !18, i64 0}
!303 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_2", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !304)
!304 = !{!305, !306, !307}
!305 = !DILocalVariable(name: "arg1", arg: 1, scope: !303, file: !1, type: !9)
!306 = !DILocalVariable(name: "arg2", arg: 2, scope: !303, file: !1, type: !9)
!307 = !DILocalVariable(name: "arg3", arg: 3, scope: !303, file: !1, type: !8)
!308 = !DILocation(line: 0, scope: !303)
!309 = !{!310, !310, i64 0}
!310 = !{!"float32", !311, i64 0}
!311 = !{!"0x55f1f9ccee10", !18, i64 0}
!312 = !{!313, !313, i64 0}
!313 = !{!"float32", !314, i64 0}
!314 = !{!"0x55f20a77cfd0", !18, i64 0}
!315 = !{!316, !316, i64 0}
!316 = !{!"float32", !317, i64 0}
!317 = !{!"0x55f212c854e0", !18, i64 0}
!318 = !{!319, !319, i64 0}
!319 = !{!"float32", !320, i64 0}
!320 = !{!"0x55f21caa04e0", !18, i64 0}
!321 = !{!322, !322, i64 0}
!322 = !{!"float32", !323, i64 0}
!323 = !{!"0x55f1f246c770", !18, i64 0}
!324 = !{!325, !325, i64 0}
!325 = !{!"float32", !326, i64 0}
!326 = !{!"0x55f2140fad30", !18, i64 0}
!327 = !{!328, !328, i64 0}
!328 = !{!"float32", !329, i64 0}
!329 = !{!"0x55f1f3c45910", !18, i64 0}
!330 = !{!331, !331, i64 0}
!331 = !{!"float32", !332, i64 0}
!332 = !{!"0x55f1f1cc3d80", !18, i64 0}
!333 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !334)
!334 = !{!335, !336, !337}
!335 = !DILocalVariable(name: "arg1", arg: 1, scope: !333, file: !1, type: !9)
!336 = !DILocalVariable(name: "arg2", arg: 2, scope: !333, file: !1, type: !9)
!337 = !DILocalVariable(name: "arg3", arg: 3, scope: !333, file: !1, type: !8)
!338 = !DILocation(line: 0, scope: !333)
!339 = !{!340, !340, i64 0}
!340 = !{!"float32", !341, i64 0}
!341 = !{!"0x55f1f9d07f00", !18, i64 0}
!342 = !{!343, !343, i64 0}
!343 = !{!"float32", !344, i64 0}
!344 = !{!"0x55f1fd1aeeb0", !18, i64 0}
!345 = !{!346, !346, i64 0}
!346 = !{!"float32", !347, i64 0}
!347 = !{!"0x55f21ab71370", !18, i64 0}
!348 = !{!349, !349, i64 0}
!349 = !{!"float32", !350, i64 0}
!350 = !{!"0x55f1f1cea830", !18, i64 0}
!351 = !{!352, !352, i64 0}
!352 = !{!"float32", !353, i64 0}
!353 = !{!"0x55f1f3c7f6b0", !18, i64 0}
!354 = !{!355, !355, i64 0}
!355 = !{!"float32", !356, i64 0}
!356 = !{!"0x55f21ab713c0", !18, i64 0}
!357 = distinct !DISubprogram(name: "fused_nn_dense_add", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !358)
!358 = !{!359, !360, !361}
!359 = !DILocalVariable(name: "arg1", arg: 1, scope: !357, file: !1, type: !9)
!360 = !DILocalVariable(name: "arg2", arg: 2, scope: !357, file: !1, type: !9)
!361 = !DILocalVariable(name: "arg3", arg: 3, scope: !357, file: !1, type: !8)
!362 = !DILocation(line: 0, scope: !357)
!363 = !{!364, !364, i64 0}
!364 = !{!"float32", !365, i64 0}
!365 = !{!"0x55f1fcdd73b0", !18, i64 0}
!366 = !{!367, !367, i64 0}
!367 = !{!"float32", !368, i64 0}
!368 = !{!"0x55f1f9698bb0", !18, i64 0}
!369 = !{!370, !370, i64 0}
!370 = !{!"float32", !371, i64 0}
!371 = !{!"0x55f1f63dc6e0", !18, i64 0}
!372 = distinct !{!372, !61}
!373 = !{!374, !374, i64 0}
!374 = !{!"float32", !375, i64 0}
!375 = !{!"0x55f1f105f4d0", !18, i64 0}
!376 = !{!377, !377, i64 0}
!377 = !{!"float32", !378, i64 0}
!378 = !{!"0x55f1edb4d250", !18, i64 0}
!379 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_1", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !380)
!380 = !{!381, !382, !383}
!381 = !DILocalVariable(name: "arg1", arg: 1, scope: !379, file: !1, type: !9)
!382 = !DILocalVariable(name: "arg2", arg: 2, scope: !379, file: !1, type: !9)
!383 = !DILocalVariable(name: "arg3", arg: 3, scope: !379, file: !1, type: !8)
!384 = !DILocation(line: 0, scope: !379)
!385 = !{!386, !386, i64 0}
!386 = !{!"float32", !387, i64 0}
!387 = !{!"0x55f212c84ef0", !18, i64 0}
!388 = !{!389, !389, i64 0}
!389 = !{!"float32", !390, i64 0}
!390 = !{!"0x55f1f565ae20", !18, i64 0}
!391 = !{!392, !392, i64 0}
!392 = !{!"float32", !393, i64 0}
!393 = !{!"0x55f1f56507d0", !18, i64 0}
!394 = !{!395, !395, i64 0}
!395 = !{!"float32", !396, i64 0}
!396 = !{!"0x55f20a780000", !18, i64 0}
!397 = !{!398, !398, i64 0}
!398 = !{!"float32", !399, i64 0}
!399 = !{!"0x55f1f247e060", !18, i64 0}
!400 = !{!401, !401, i64 0}
!401 = !{!"float32", !402, i64 0}
!402 = !{!"0x55f1f565c230", !18, i64 0}
!403 = !{!404, !404, i64 0}
!404 = !{!"float32", !405, i64 0}
!405 = !{!"0x55f1fc76d6e0", !18, i64 0}
!406 = !{!407, !407, i64 0}
!407 = !{!"float32", !408, i64 0}
!408 = !{!"0x55f218c0d180", !18, i64 0}
!409 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !410)
!410 = !{!411, !412, !413}
!411 = !DILocalVariable(name: "arg1", arg: 1, scope: !409, file: !1, type: !9)
!412 = !DILocalVariable(name: "arg2", arg: 2, scope: !409, file: !1, type: !9)
!413 = !DILocalVariable(name: "arg3", arg: 3, scope: !409, file: !1, type: !8)
!414 = !DILocation(line: 0, scope: !409)
!415 = !{!416, !416, i64 0}
!416 = !{!"float32", !417, i64 0}
!417 = !{!"0x55f21d116f10", !18, i64 0}
!418 = !{!419, !419, i64 0}
!419 = !{!"float32", !420, i64 0}
!420 = !{!"0x55f21d1163c0", !18, i64 0}
!421 = !{!422, !422, i64 0}
!422 = !{!"float32", !423, i64 0}
!423 = !{!"0x55f21d116a40", !18, i64 0}
!424 = !{!425, !425, i64 0}
!425 = !{!"float32", !426, i64 0}
!426 = !{!"0x55f1ed0b1f70", !18, i64 0}
!427 = !{!428, !428, i64 0}
!428 = !{!"float32", !429, i64 0}
!429 = !{!"0x55f21d7b1870", !18, i64 0}
!430 = !{!431, !431, i64 0}
!431 = !{!"float32", !432, i64 0}
!432 = !{!"0x55f1f1f120a0", !18, i64 0}
!433 = !{!434, !434, i64 0}
!434 = !{!"float32", !435, i64 0}
!435 = !{!"0x55f21d1189b0", !18, i64 0}
!436 = distinct !DISubprogram(name: "fused_nn_max_pool2d", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !437)
!437 = !{!438, !439, !440}
!438 = !DILocalVariable(name: "arg1", arg: 1, scope: !436, file: !1, type: !9)
!439 = !DILocalVariable(name: "arg2", arg: 2, scope: !436, file: !1, type: !9)
!440 = !DILocalVariable(name: "arg3", arg: 3, scope: !436, file: !1, type: !8)
!441 = !DILocation(line: 0, scope: !436)
!442 = !{!443, !443, i64 0}
!443 = !{!"float32", !444, i64 0}
!444 = !{!"0x55f1f242f1e0", !18, i64 0}
!445 = !{!446, !446, i64 0}
!446 = !{!"float32", !447, i64 0}
!447 = !{!"0x55f1f242f500", !18, i64 0}
!448 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !449)
!449 = !{!450, !451, !452}
!450 = !DILocalVariable(name: "arg1", arg: 1, scope: !448, file: !1, type: !9)
!451 = !DILocalVariable(name: "arg2", arg: 2, scope: !448, file: !1, type: !9)
!452 = !DILocalVariable(name: "arg3", arg: 3, scope: !448, file: !1, type: !8)
!453 = !DILocation(line: 0, scope: !448)
!454 = !{!455, !455, i64 0}
!455 = !{!"float32", !456, i64 0}
!456 = !{!"0x55f1f3f95a10", !18, i64 0}
!457 = distinct !{!457, !61}
!458 = distinct !{!458, !61}
!459 = distinct !{!459, !61}
!460 = distinct !{!460, !61}
!461 = distinct !{!461, !61}
!462 = distinct !{!462, !61}
!463 = distinct !{!463, !61}
!464 = distinct !{!464, !61}
!465 = distinct !{!465, !61}
!466 = distinct !{!466, !61}
!467 = !{!468, !468, i64 0}
!468 = !{!"float32", !469, i64 0}
!469 = !{!"0x55f1fa3c5b60", !18, i64 0}
!470 = distinct !{!470, !61}
!471 = distinct !{!471, !61}
!472 = distinct !{!472, !61}
!473 = distinct !{!473, !61}
!474 = distinct !{!474, !61}
!475 = distinct !{!475, !61}
!476 = distinct !{!476, !61}
!477 = distinct !{!477, !61}
!478 = !{!479, !479, i64 0}
!479 = !{!"float32", !480, i64 0}
!480 = !{!"0x55f1fc11f880", !18, i64 0}
!481 = !{!482, !482, i64 0}
!482 = !{!"float32", !483, i64 0}
!483 = !{!"0x55f200850e00", !18, i64 0}
!484 = !{!485, !485, i64 0}
!485 = !{!"float32", !486, i64 0}
!486 = !{!"0x55f1f3c83db0", !18, i64 0}
!487 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !488)
!488 = !{!489, !490, !491}
!489 = !DILocalVariable(name: "arg1", arg: 1, scope: !487, file: !1, type: !9)
!490 = !DILocalVariable(name: "arg2", arg: 2, scope: !487, file: !1, type: !9)
!491 = !DILocalVariable(name: "arg3", arg: 3, scope: !487, file: !1, type: !8)
!492 = !DILocation(line: 0, scope: !487)
!493 = !{!494, !494, i64 0}
!494 = !{!"float32", !495, i64 0}
!495 = !{!"0x55f1f2475850", !18, i64 0}
!496 = !{!497, !497, i64 0}
!497 = !{!"float32", !498, i64 0}
!498 = !{!"0x55f207a77db0", !18, i64 0}
!499 = !{!500, !500, i64 0}
!500 = !{!"float32", !501, i64 0}
!501 = !{!"0x55f1f106a2a0", !18, i64 0}
!502 = !{!503, !503, i64 0}
!503 = !{!"float32", !504, i64 0}
!504 = !{!"0x55f212c97690", !18, i64 0}
!505 = !{!506, !506, i64 0}
!506 = !{!"float32", !507, i64 0}
!507 = !{!"0x55f1fa2d54d0", !18, i64 0}
!508 = !{!509, !509, i64 0}
!509 = !{!"float32", !510, i64 0}
!510 = !{!"0x55f1f1d49ad0", !18, i64 0}
!511 = !{!512, !512, i64 0}
!512 = !{!"float32", !513, i64 0}
!513 = !{!"0x55f1f0b8c7e0", !18, i64 0}
!514 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_3", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !515)
!515 = !{!516, !517, !518}
!516 = !DILocalVariable(name: "arg1", arg: 1, scope: !514, file: !1, type: !9)
!517 = !DILocalVariable(name: "arg2", arg: 2, scope: !514, file: !1, type: !9)
!518 = !DILocalVariable(name: "arg3", arg: 3, scope: !514, file: !1, type: !8)
!519 = !DILocation(line: 0, scope: !514)
!520 = !{!521, !521, i64 0}
!521 = !{!"float32", !522, i64 0}
!522 = !{!"0x55f1f53303b0", !18, i64 0}
!523 = !{!524, !524, i64 0}
!524 = !{!"float32", !525, i64 0}
!525 = !{!"0x55f1f52184a0", !18, i64 0}
!526 = !{!527, !527, i64 0}
!527 = !{!"float32", !528, i64 0}
!528 = !{!"0x55f21c42d670", !18, i64 0}
!529 = !{!530, !530, i64 0}
!530 = !{!"float32", !531, i64 0}
!531 = !{!"0x55f1fc78afc0", !18, i64 0}
!532 = !{!533, !533, i64 0}
!533 = !{!"float32", !534, i64 0}
!534 = !{!"0x55f1f0bb15e0", !18, i64 0}
!535 = !{!536, !536, i64 0}
!536 = !{!"float32", !537, i64 0}
!537 = !{!"0x55f21c42d620", !18, i64 0}
!538 = distinct !DISubprogram(name: "fused_layout_transform_38", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !539)
!539 = !{!540, !541, !542}
!540 = !DILocalVariable(name: "arg1", arg: 1, scope: !538, file: !1, type: !9)
!541 = !DILocalVariable(name: "arg2", arg: 2, scope: !538, file: !1, type: !9)
!542 = !DILocalVariable(name: "arg3", arg: 3, scope: !538, file: !1, type: !8)
!543 = !DILocation(line: 0, scope: !538)
!544 = !{!545, !545, i64 0}
!545 = !{!"float32", !546, i64 0}
!546 = !{!"0x55f1f24723b0", !18, i64 0}
!547 = !{!548, !548, i64 0}
!548 = !{!"float32", !549, i64 0}
!549 = !{!"0x55f2169549f0", !18, i64 0}
!550 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_add_nn_relu_3", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !551)
!551 = !{!552, !553, !554}
!552 = !DILocalVariable(name: "arg1", arg: 1, scope: !550, file: !1, type: !9)
!553 = !DILocalVariable(name: "arg2", arg: 2, scope: !550, file: !1, type: !9)
!554 = !DILocalVariable(name: "arg3", arg: 3, scope: !550, file: !1, type: !8)
!555 = !DILocation(line: 0, scope: !550)
!556 = !{!557, !557, i64 0}
!557 = !{!"float32", !558, i64 0}
!558 = !{!"0x55f1f3c60f00", !18, i64 0}
!559 = !{!560, !560, i64 0}
!560 = !{!"float32", !561, i64 0}
!561 = !{!"0x55f20c2eabd0", !18, i64 0}
!562 = !{!563, !563, i64 0}
!563 = !{!"float32", !564, i64 0}
!564 = !{!"0x55f207fc00b0", !18, i64 0}
!565 = !{!566, !566, i64 0}
!566 = !{!"float32", !567, i64 0}
!567 = !{!"0x55f2185bca50", !18, i64 0}
!568 = !{!569, !569, i64 0}
!569 = !{!"float32", !570, i64 0}
!570 = !{!"0x55f207fc1e60", !18, i64 0}
!571 = !{!572, !572, i64 0}
!572 = !{!"float32", !573, i64 0}
!573 = !{!"0x55f207f97030", !18, i64 0}
!574 = !{!575, !575, i64 0}
!575 = !{!"float32", !576, i64 0}
!576 = !{!"0x55f21d11eae0", !18, i64 0}
!577 = !{!578, !578, i64 0}
!578 = !{!"float32", !579, i64 0}
!579 = !{!"0x55f2185b6c50", !18, i64 0}
!580 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_4", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !581)
!581 = !{!582, !583, !584}
!582 = !DILocalVariable(name: "arg1", arg: 1, scope: !580, file: !1, type: !9)
!583 = !DILocalVariable(name: "arg2", arg: 2, scope: !580, file: !1, type: !9)
!584 = !DILocalVariable(name: "arg3", arg: 3, scope: !580, file: !1, type: !8)
!585 = !DILocation(line: 0, scope: !580)
!586 = !{!587, !587, i64 0}
!587 = !{!"float32", !588, i64 0}
!588 = !{!"0x55f1f2478570", !18, i64 0}
!589 = !{!590, !590, i64 0}
!590 = !{!"float32", !591, i64 0}
!591 = !{!"0x55f20c2f71d0", !18, i64 0}
!592 = !{!593, !593, i64 0}
!593 = !{!"float32", !594, i64 0}
!594 = !{!"0x55f1f24925b0", !18, i64 0}
!595 = !{!596, !596, i64 0}
!596 = !{!"float32", !597, i64 0}
!597 = !{!"0x55f1f2494b50", !18, i64 0}
!598 = !{!599, !599, i64 0}
!599 = !{!"float32", !600, i64 0}
!600 = !{!"0x55f20d044480", !18, i64 0}
!601 = !{!602, !602, i64 0}
!602 = !{!"float32", !603, i64 0}
!603 = !{!"0x55f2169505c0", !18, i64 0}
!604 = !{!605, !605, i64 0}
!605 = !{!"float32", !606, i64 0}
!606 = !{!"0x55f20c2f7060", !18, i64 0}
!607 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !608)
!608 = !{!609, !610, !611}
!609 = !DILocalVariable(name: "arg1", arg: 1, scope: !607, file: !1, type: !9)
!610 = !DILocalVariable(name: "arg2", arg: 2, scope: !607, file: !1, type: !9)
!611 = !DILocalVariable(name: "arg3", arg: 3, scope: !607, file: !1, type: !8)
!612 = !DILocation(line: 0, scope: !607)
!613 = !{!614, !614, i64 0}
!614 = !{!"float32", !615, i64 0}
!615 = !{!"0x55f1f65fdae0", !18, i64 0}
!616 = !{!617, !617, i64 0}
!617 = !{!"float32", !618, i64 0}
!618 = !{!"0x55f2140fe4e0", !18, i64 0}
!619 = !{!620, !620, i64 0}
!620 = !{!"float32", !621, i64 0}
!621 = !{!"0x55f218c3ab30", !18, i64 0}
!622 = !{!623, !623, i64 0}
!623 = !{!"float32", !624, i64 0}
!624 = !{!"0x55f1fbcee0e0", !18, i64 0}
!625 = !{!626, !626, i64 0}
!626 = !{!"float32", !627, i64 0}
!627 = !{!"0x55f207a58250", !18, i64 0}
!628 = !{!629, !629, i64 0}
!629 = !{!"float32", !630, i64 0}
!630 = !{!"0x55f21cac0710", !18, i64 0}
!631 = !{!632, !632, i64 0}
!632 = !{!"0x55f2140fdff0.w32.b0", !633, i64 0}
!633 = !{!"0x55f2140fdff0.w64.b0", !634, i64 0}
!634 = !{!"0x55f2140fdff0.w128.b0", !635, i64 0}
!635 = !{!"0x55f2140fdff0.w256.b0", !636, i64 0}
!636 = !{!"0x55f2140fdff0.w512.b0", !637, i64 0}
!637 = !{!"0x55f2140fdff0.w1024.b0", !638, i64 0}
!638 = !{!"float32", !639, i64 0}
!639 = !{!"0x55f2140fdff0", !18, i64 0}
!640 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !641)
!641 = !{!642, !643, !644}
!642 = !DILocalVariable(name: "arg1", arg: 1, scope: !640, file: !1, type: !9)
!643 = !DILocalVariable(name: "arg2", arg: 2, scope: !640, file: !1, type: !9)
!644 = !DILocalVariable(name: "arg3", arg: 3, scope: !640, file: !1, type: !8)
!645 = !DILocation(line: 0, scope: !640)
!646 = !{!647, !647, i64 0}
!647 = !{!"float32", !648, i64 0}
!648 = !{!"0x55f2074c4eb0", !18, i64 0}
!649 = !{!650, !650, i64 0}
!650 = !{!"float32", !651, i64 0}
!651 = !{!"0x55f1f248bb40", !18, i64 0}
!652 = !{!653, !653, i64 0}
!653 = !{!"float32", !654, i64 0}
!654 = !{!"0x55f1f248baf0", !18, i64 0}
!655 = !{!656, !656, i64 0}
!656 = !{!"float32", !657, i64 0}
!657 = !{!"0x55f1f248b880", !18, i64 0}
!658 = !{!659, !659, i64 0}
!659 = !{!"float32", !660, i64 0}
!660 = !{!"0x55f1f248c4a0", !18, i64 0}
!661 = distinct !DISubprogram(name: "fused_layout_transform_34", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !662)
!662 = !{!663, !664, !665}
!663 = !DILocalVariable(name: "arg1", arg: 1, scope: !661, file: !1, type: !9)
!664 = !DILocalVariable(name: "arg2", arg: 2, scope: !661, file: !1, type: !9)
!665 = !DILocalVariable(name: "arg3", arg: 3, scope: !661, file: !1, type: !8)
!666 = !DILocation(line: 0, scope: !661)
!667 = !{!668, !668, i64 0}
!668 = !{!"float32", !669, i64 0}
!669 = !{!"0x55f2074a81e0", !18, i64 0}
!670 = !{!671, !671, i64 0}
!671 = !{!"float32", !672, i64 0}
!672 = !{!"0x55f2074a8690", !18, i64 0}
!673 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_4", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !674)
!674 = !{!675, !676, !677}
!675 = !DILocalVariable(name: "arg1", arg: 1, scope: !673, file: !1, type: !9)
!676 = !DILocalVariable(name: "arg2", arg: 2, scope: !673, file: !1, type: !9)
!677 = !DILocalVariable(name: "arg3", arg: 3, scope: !673, file: !1, type: !8)
!678 = !DILocation(line: 0, scope: !673)
!679 = !{!680, !680, i64 0}
!680 = !{!"float32", !681, i64 0}
!681 = !{!"0x55f1f1d35190", !18, i64 0}
!682 = !{!683, !683, i64 0}
!683 = !{!"float32", !684, i64 0}
!684 = !{!"0x55f218c0e020", !18, i64 0}
!685 = !{!686, !686, i64 0}
!686 = !{!"float32", !687, i64 0}
!687 = !{!"0x55f218c0dfd0", !18, i64 0}
!688 = !{!689, !689, i64 0}
!689 = !{!"float32", !690, i64 0}
!690 = !{!"0x55f2140fd300", !18, i64 0}
!691 = !{!692, !692, i64 0}
!692 = !{!"float32", !693, i64 0}
!693 = !{!"0x55f201643b30", !18, i64 0}
!694 = !{!695, !695, i64 0}
!695 = !{!"float32", !696, i64 0}
!696 = !{!"0x55f212c93f30", !18, i64 0}
!697 = distinct !DISubprogram(name: "fused_layout_transform_37", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !698)
!698 = !{!699, !700, !701}
!699 = !DILocalVariable(name: "arg1", arg: 1, scope: !697, file: !1, type: !9)
!700 = !DILocalVariable(name: "arg2", arg: 2, scope: !697, file: !1, type: !9)
!701 = !DILocalVariable(name: "arg3", arg: 3, scope: !697, file: !1, type: !8)
!702 = !DILocation(line: 0, scope: !697)
!703 = !{!704, !704, i64 0}
!704 = !{!"float32", !705, i64 0}
!705 = !{!"0x55f21ab46c20", !18, i64 0}
!706 = !{!707, !707, i64 0}
!707 = !{!"float32", !708, i64 0}
!708 = !{!"0x55f216dc2bd0", !18, i64 0}
!709 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_3", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !710)
!710 = !{!711, !712, !713}
!711 = !DILocalVariable(name: "arg1", arg: 1, scope: !709, file: !1, type: !9)
!712 = !DILocalVariable(name: "arg2", arg: 2, scope: !709, file: !1, type: !9)
!713 = !DILocalVariable(name: "arg3", arg: 3, scope: !709, file: !1, type: !8)
!714 = !DILocation(line: 0, scope: !709)
!715 = !{!716, !716, i64 0}
!716 = !{!"float32", !717, i64 0}
!717 = !{!"0x55f21d128e20", !18, i64 0}
!718 = !{!719, !719, i64 0}
!719 = !{!"float32", !720, i64 0}
!720 = !{!"0x55f1f2498fc0", !18, i64 0}
!721 = !{!722, !722, i64 0}
!722 = !{!"float32", !723, i64 0}
!723 = !{!"0x55f21d7a7430", !18, i64 0}
!724 = !{!725, !725, i64 0}
!725 = !{!"float32", !726, i64 0}
!726 = !{!"0x55f21a4e13b0", !18, i64 0}
!727 = !{!728, !728, i64 0}
!728 = !{!"float32", !729, i64 0}
!729 = !{!"0x55f21cabbbd0", !18, i64 0}
!730 = !{!731, !731, i64 0}
!731 = !{!"float32", !732, i64 0}
!732 = !{!"0x55f21cabbb80", !18, i64 0}
!733 = !{!734, !734, i64 0}
!734 = !{!"float32", !735, i64 0}
!735 = !{!"0x55f21c434e90", !18, i64 0}
!736 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_1", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !737)
!737 = !{!738, !739, !740}
!738 = !DILocalVariable(name: "arg1", arg: 1, scope: !736, file: !1, type: !9)
!739 = !DILocalVariable(name: "arg2", arg: 2, scope: !736, file: !1, type: !9)
!740 = !DILocalVariable(name: "arg3", arg: 3, scope: !736, file: !1, type: !8)
!741 = !DILocation(line: 0, scope: !736)
!742 = !{!743, !743, i64 0}
!743 = !{!"float32", !744, i64 0}
!744 = !{!"0x55f1f3c4c990", !18, i64 0}
!745 = !{!746, !746, i64 0}
!746 = !{!"float32", !747, i64 0}
!747 = !{!"0x55f212cafe40", !18, i64 0}
!748 = !{!749, !749, i64 0}
!749 = !{!"float32", !750, i64 0}
!750 = !{!"0x55f212cafe90", !18, i64 0}
!751 = !{!752, !752, i64 0}
!752 = !{!"float32", !753, i64 0}
!753 = !{!"0x55f1fa2f7570", !18, i64 0}
!754 = !{!755, !755, i64 0}
!755 = !{!"float32", !756, i64 0}
!756 = !{!"0x55f1f1f4a300", !18, i64 0}
!757 = !{!758, !758, i64 0}
!758 = !{!"float32", !759, i64 0}
!759 = !{!"0x55f1f185f950", !18, i64 0}
!760 = !{!761, !761, i64 0}
!761 = !{!"float32", !762, i64 0}
!762 = !{!"0x55f212c9d5f0", !18, i64 0}
!763 = distinct !DISubprogram(name: "fused_layout_transform_49", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !764)
!764 = !{!765, !766, !767}
!765 = !DILocalVariable(name: "arg1", arg: 1, scope: !763, file: !1, type: !9)
!766 = !DILocalVariable(name: "arg2", arg: 2, scope: !763, file: !1, type: !9)
!767 = !DILocalVariable(name: "arg3", arg: 3, scope: !763, file: !1, type: !8)
!768 = !DILocation(line: 0, scope: !763)
!769 = !{!770, !770, i64 0}
!770 = !{!"float32", !771, i64 0}
!771 = !{!"0x55f1f579b3b0", !18, i64 0}
!772 = !{!773, !773, i64 0}
!773 = !{!"float32", !774, i64 0}
!774 = !{!"0x55f1f579b4a0", !18, i64 0}
!775 = distinct !DISubprogram(name: "fused_layout_transform_45", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !776)
!776 = !{!777, !778, !779}
!777 = !DILocalVariable(name: "arg1", arg: 1, scope: !775, file: !1, type: !9)
!778 = !DILocalVariable(name: "arg2", arg: 2, scope: !775, file: !1, type: !9)
!779 = !DILocalVariable(name: "arg3", arg: 3, scope: !775, file: !1, type: !8)
!780 = !DILocation(line: 0, scope: !775)
!781 = !{!782, !782, i64 0}
!782 = !{!"float32", !783, i64 0}
!783 = !{!"0x55f21859ec00", !18, i64 0}
!784 = !{!785, !785, i64 0}
!785 = !{!"float32", !786, i64 0}
!786 = !{!"0x55f21859ee70", !18, i64 0}
!787 = distinct !DISubprogram(name: "fused_layout_transform_41", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !788)
!788 = !{!789, !790, !791}
!789 = !DILocalVariable(name: "arg1", arg: 1, scope: !787, file: !1, type: !9)
!790 = !DILocalVariable(name: "arg2", arg: 2, scope: !787, file: !1, type: !9)
!791 = !DILocalVariable(name: "arg3", arg: 3, scope: !787, file: !1, type: !8)
!792 = !DILocation(line: 0, scope: !787)
!793 = !{!794, !794, i64 0}
!794 = !{!"float32", !795, i64 0}
!795 = !{!"0x55f21cac2a20", !18, i64 0}
!796 = !{!797, !797, i64 0}
!797 = !{!"float32", !798, i64 0}
!798 = !{!"0x55f21cac2bd0", !18, i64 0}
!799 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_multiply_add_nn_relu_2", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !800)
!800 = !{!801, !802, !803}
!801 = !DILocalVariable(name: "arg1", arg: 1, scope: !799, file: !1, type: !9)
!802 = !DILocalVariable(name: "arg2", arg: 2, scope: !799, file: !1, type: !9)
!803 = !DILocalVariable(name: "arg3", arg: 3, scope: !799, file: !1, type: !8)
!804 = !DILocation(line: 0, scope: !799)
!805 = !{!806, !806, i64 0}
!806 = !{!"float32", !807, i64 0}
!807 = !{!"0x55f1f1ec26f0", !18, i64 0}
!808 = !{!809, !809, i64 0}
!809 = !{!"float32", !810, i64 0}
!810 = !{!"0x55f1f1ec2740", !18, i64 0}
!811 = !{!812, !812, i64 0}
!812 = !{!"float32", !813, i64 0}
!813 = !{!"0x55f2140ed440", !18, i64 0}
!814 = !{!815, !815, i64 0}
!815 = !{!"float32", !816, i64 0}
!816 = !{!"0x55f1f1cf3ff0", !18, i64 0}
!817 = !{!818, !818, i64 0}
!818 = !{!"float32", !819, i64 0}
!819 = !{!"0x55f21ca97050", !18, i64 0}
!820 = !{!821, !821, i64 0}
!821 = !{!"float32", !822, i64 0}
!822 = !{!"0x55f1f1edff20", !18, i64 0}
!823 = !{!824, !824, i64 0}
!824 = !{!"float32", !825, i64 0}
!825 = !{!"0x55f1f1cf3e40", !18, i64 0}
!826 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_1", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !827)
!827 = !{!828, !829, !830}
!828 = !DILocalVariable(name: "arg1", arg: 1, scope: !826, file: !1, type: !9)
!829 = !DILocalVariable(name: "arg2", arg: 2, scope: !826, file: !1, type: !9)
!830 = !DILocalVariable(name: "arg3", arg: 3, scope: !826, file: !1, type: !8)
!831 = !DILocation(line: 0, scope: !826)
!832 = !{!833, !833, i64 0}
!833 = !{!"float32", !834, i64 0}
!834 = !{!"0x55f1fbf6c890", !18, i64 0}
!835 = !{!836, !836, i64 0}
!836 = !{!"float32", !837, i64 0}
!837 = !{!"0x55f1efdb9c00", !18, i64 0}
!838 = !{!839, !839, i64 0}
!839 = !{!"float32", !840, i64 0}
!840 = !{!"0x55f1f9e41c50", !18, i64 0}
!841 = !{!842, !842, i64 0}
!842 = !{!"float32", !843, i64 0}
!843 = !{!"0x55f1f87325a0", !18, i64 0}
!844 = !{!845, !845, i64 0}
!845 = !{!"float32", !846, i64 0}
!846 = !{!"0x55f1f0eb2420", !18, i64 0}
!847 = distinct !DISubprogram(name: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_3", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !848)
!848 = !{!849, !850, !851}
!849 = !DILocalVariable(name: "arg1", arg: 1, scope: !847, file: !1, type: !9)
!850 = !DILocalVariable(name: "arg2", arg: 2, scope: !847, file: !1, type: !9)
!851 = !DILocalVariable(name: "arg3", arg: 3, scope: !847, file: !1, type: !8)
!852 = !DILocation(line: 0, scope: !847)
!853 = !{!854, !854, i64 0}
!854 = !{!"float32", !855, i64 0}
!855 = !{!"0x55f1f2490db0", !18, i64 0}
!856 = !{!857, !857, i64 0}
!857 = !{!"float32", !858, i64 0}
!858 = !{!"0x55f2016441c0", !18, i64 0}
!859 = !{!860, !860, i64 0}
!860 = !{!"float32", !861, i64 0}
!861 = !{!"0x55f21929f0c0", !18, i64 0}
!862 = !{!863, !863, i64 0}
!863 = !{!"float32", !864, i64 0}
!864 = !{!"0x55f1f247be70", !18, i64 0}
!865 = !{!866, !866, i64 0}
!866 = !{!"float32", !867, i64 0}
!867 = !{!"0x55f219299600", !18, i64 0}
!868 = !{!869, !869, i64 0}
!869 = !{!"float32", !870, i64 0}
!870 = !{!"0x55f21928f970", !18, i64 0}
!871 = !{!872, !872, i64 0}
!872 = !{!"0x55f2192b3f30.w32.b0", !873, i64 0}
!873 = !{!"0x55f2192b3f30.w64.b0", !874, i64 0}
!874 = !{!"0x55f2192b3f30.w128.b0", !875, i64 0}
!875 = !{!"0x55f2192b3f30.w256.b0", !876, i64 0}
!876 = !{!"0x55f2192b3f30.w512.b0", !877, i64 0}
!877 = !{!"0x55f2192b3f30.w1024.b0", !878, i64 0}
!878 = !{!"float32", !879, i64 0}
!879 = !{!"0x55f2192b3f30", !18, i64 0}
!880 = distinct !DISubprogram(name: "fused_layout_transform_31", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !881)
!881 = !{!882, !883, !884}
!882 = !DILocalVariable(name: "arg1", arg: 1, scope: !880, file: !1, type: !9)
!883 = !DILocalVariable(name: "arg2", arg: 2, scope: !880, file: !1, type: !9)
!884 = !DILocalVariable(name: "arg3", arg: 3, scope: !880, file: !1, type: !8)
!885 = !DILocation(line: 0, scope: !880)
!886 = !{!887, !887, i64 0}
!887 = !{!"float32", !888, i64 0}
!888 = !{!"0x55f21ca93420", !18, i64 0}
!889 = !{!890, !890, i64 0}
!890 = !{!"float32", !891, i64 0}
!891 = !{!"0x55f204472d90", !18, i64 0}
!892 = distinct !DISubprogram(name: "fused_layout_transform_43", scope: !1, file: !1, type: !6, isLocal: false, isDefinition: true, flags: DIFlagPrototyped, isOptimized: true, unit: !0, variables: !893)
!893 = !{!894, !895, !896}
!894 = !DILocalVariable(name: "arg1", arg: 1, scope: !892, file: !1, type: !9)
!895 = !DILocalVariable(name: "arg2", arg: 2, scope: !892, file: !1, type: !9)
!896 = !DILocalVariable(name: "arg3", arg: 3, scope: !892, file: !1, type: !8)
!897 = !DILocation(line: 0, scope: !892)
!898 = !{!899, !899, i64 0}
!899 = !{!"float32", !900, i64 0}
!900 = !{!"0x55f1f7c42470", !18, i64 0}
!901 = !{!902, !902, i64 0}
!902 = !{!"float32", !903, i64 0}
!903 = !{!"0x55f212cbe300", !18, i64 0}
